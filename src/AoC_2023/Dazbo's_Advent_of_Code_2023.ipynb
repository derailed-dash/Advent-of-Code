{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "This notebook contains my solutions for **<a href=\"https://adventofcode.com/2023\" target=\"_blank\">Advent of Code 2023</a>**.\n",
    "\n",
    "A few notes...\n",
    "- The source for this notebook source lives in my GitHub repo, <a href=\"https://github.com/derailed-dash/Advent-of-Code/blob/master/src/AoC_2023/Dazbo's_Advent_of_Code_2023.ipynb\" target=\"_blank\">here</a>.\n",
    "- You can run this Notebook wherever you like. For example, you could...\n",
    "  - Run it locally, in your own Jupyter environment.\n",
    "  - Run it in a cloud-based Jupyter environment, with no setup required on your part!  For example, <a href=\"https://colab.research.google.com/github/derailed-dash/Advent-of-Code/blob/master/src/AoC_2023/Dazbo's_Advent_of_Code_2023.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Google Colab\"/></a>\n",
    "- **To run the notebook, execute the cells in the [Setup](#Setup) section, as described below. Then you can run the code for any given day.**\n",
    "- Be mindful that the first time you run this notebook, you will need to **obtain your AoC session key** and store it, if you have not done so already. This allows the notebook to automatically retrieve your input data. (See the guidance in the **[Get Access to Your AoC Data](#Get-Access-to-Your-AoC-Data)** section for details.)\n",
    "- Use the navigation menu on the left to jump to any particular day.\n",
    "- All of my AoC solutions are documented in my <a href=\"https://aoc.just2good.co.uk/\" target=\"_blank\">AoC Python Walkthrough site</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3PMQJRrR38P",
    "tags": []
   },
   "source": [
    "# Setup\n",
    "\n",
    "You need to run all cells in this section, before running any particular day solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWxsAMaXTGEQ"
   },
   "source": [
    "## Packages and Imports\n",
    "\n",
    "Here we use `pip` to install the packages used by my solutions in this event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9Dgeww1rMrkQ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyterlab-lsp in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: colorama in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: python-dotenv in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: ipykernel in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (6.25.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyterlab-lsp) (2.2.0)\n",
      "Requirement already satisfied: jupyterlab<5.0.0a0,>=4.0.6 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyterlab-lsp) (4.0.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipykernel) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipykernel) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipykernel) (8.15.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipykernel) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipykernel) (5.3.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\djl\\appdata\\roaming\\python\\python311\\site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipykernel) (1.5.6)\n",
      "Requirement already satisfied: packaging in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipykernel) (23.1)\n",
      "Requirement already satisfied: psutil in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipykernel) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=20 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipykernel) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipykernel) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipykernel) (5.7.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\djl\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\djl\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\djl\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.15.1)\n",
      "Requirement already satisfied: stack-data in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: entrypoints in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (305.1)\n",
      "Requirement already satisfied: jupyter-server>=1.1.2 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-lsp>=2.0.0->jupyterlab-lsp) (2.10.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (2.0.4)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (3.1.2)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (2.22.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (0.2.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\djl\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jinja2>=3.0.3->jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (2.1.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (3.5.0)\n",
      "Requirement already satisfied: argon2-cffi in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (21.3.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.6.3)\n",
      "Requirement already satisfied: jupyter-server-terminals in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (6.5.4)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (5.9.2)\n",
      "Requirement already satisfied: overrides in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.14.1)\n",
      "Requirement already satisfied: pywinpty in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (2.0.10)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.17.1)\n",
      "Requirement already satisfied: websocket-client in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.58.0)\n",
      "Requirement already satisfied: babel>=2.10 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.17.3 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (4.17.3)\n",
      "Requirement already satisfied: requests>=2.28 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (2.31.0)\n",
      "Requirement already satisfied: wcwidth in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: asttokens in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\djl\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from anyio>=3.1.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from anyio>=3.1.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from babel>=2.10->jupyterlab-server<3,>=2.19.0->jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (2023.3.post1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jsonschema>=4.17.3->jupyterlab-server<3,>=2.19.0->jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (0.18.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (6.0)\n",
      "Requirement already satisfied: rfc3339-validator in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.1.1)\n",
      "Requirement already satisfied: lxml in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (4.9.3)\n",
      "Requirement already satisfied: beautifulsoup4 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (4.12.2)\n",
      "Requirement already satisfied: bleach in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.5.13)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from requests>=2.28->jupyterlab-server<3,>=2.19.0->jupyterlab<5.0.0a0,>=4.0.6->jupyterlab-lsp) (2023.7.22)\n",
      "Requirement already satisfied: argon2-cffi-bindings in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from argon2-cffi->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (21.2.0)\n",
      "Requirement already satisfied: fqdn in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.5.1)\n",
      "Requirement already satisfied: isoduration in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (2.1)\n",
      "Requirement already satisfied: uri-template in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (2.5)\n",
      "Requirement already satisfied: webencodings in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from bleach->nbconvert>=6.4.4->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (0.5.1)\n",
      "Requirement already satisfied: pycparser in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in f:\\users\\darren\\anaconda3\\envs\\ana-aoc\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=3.2.0->jupyter-events>=0.6.0->jupyter-server>=1.1.2->jupyter-lsp>=2.0.0->jupyterlab-lsp) (2.8.19.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jupyterlab-lsp colorama python-dotenv ipykernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "p5Ki_HvOJUWk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from enum import Enum, auto\n",
    "from functools import cache, reduce\n",
    "from itertools import permutations, combinations, count\n",
    "from collections import Counter, deque, defaultdict\n",
    "import heapq\n",
    "import copy\n",
    "import operator\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import unittest\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from colorama import Fore\n",
    "from IPython.display import display\n",
    "from IPython.core.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZNTgtGzUImv",
    "tags": []
   },
   "source": [
    "## Logging and Output\n",
    "\n",
    "Set up a new logger that uses `ColouredFormatter`, such that we have coloured logging.  The log colour depends on the logging level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SwzjfUFCKhXe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# SETUP LOGGING\n",
    "#\n",
    "# Create a new instance of \"logger\" in the client application\n",
    "# Set to your preferred logging level\n",
    "# And add the stream_handler from this module, if you want coloured output\n",
    "##########################################################################\n",
    "\n",
    "# logger for aoc_commons only\n",
    "logger = logging.getLogger(__name__) # aoc_common.aoc_commons\n",
    "logger.setLevel(logging.INFO)\n",
    "stream_handler = None\n",
    "\n",
    "class ColouredFormatter(logging.Formatter):\n",
    "    \"\"\" Custom Formater which adds colour to output, based on logging level \"\"\"\n",
    "\n",
    "    level_mapping = {\"DEBUG\": (Fore.BLUE, \"DBG\"),\n",
    "                     \"INFO\": (Fore.GREEN, \"INF\"),\n",
    "                     \"WARNING\": (Fore.YELLOW, \"WRN\"),\n",
    "                     \"ERROR\": (Fore.RED, \"ERR\"),\n",
    "                     \"CRITICAL\": (Fore.MAGENTA, \"CRT\")\n",
    "    }\n",
    "\n",
    "    def __init__(self, *args, apply_colour=True, shorten_lvl=True, **kwargs) -> None:\n",
    "        \"\"\" Args:\n",
    "            apply_colour (bool, optional): Apply colouring to messages. Defaults to True.\n",
    "            shorten_lvl (bool, optional): Shorten level names to 3 chars. Defaults to True.\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._apply_colour = apply_colour\n",
    "        self._shorten_lvl = shorten_lvl\n",
    "\n",
    "    def format(self, record):\n",
    "        if record.levelname in ColouredFormatter.level_mapping:\n",
    "            new_rec = copy.copy(record)\n",
    "            colour, new_level = ColouredFormatter.level_mapping[record.levelname]\n",
    "\n",
    "            if self._shorten_lvl:\n",
    "                new_rec.levelname = new_level\n",
    "\n",
    "            if self._apply_colour:\n",
    "                msg = colour + super().format(new_rec) + Fore.RESET\n",
    "            else:\n",
    "                msg = super().format(new_rec)\n",
    "\n",
    "            return msg\n",
    "\n",
    "        # If our logging message is not using one of these levels...\n",
    "        return super().format(record)\n",
    "\n",
    "if not stream_handler:\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_fmt = ColouredFormatter(fmt='%(asctime)s.%(msecs)03d:%(name)s - %(levelname)s: %(message)s',\n",
    "                                   datefmt='%H:%M:%S')\n",
    "    stream_handler.setFormatter(stream_fmt)\n",
    "    \n",
    "if not logger.handlers:\n",
    "    # Add our ColouredFormatter as the default console logging\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "def retrieve_console_logger(script_name):\n",
    "    \"\"\" Create and return a new logger, named after the script\n",
    "    So, in your calling code, add a line like this:\n",
    "    logger = ac.retrieve_console_logger(locations.script_name)\n",
    "    \"\"\"\n",
    "    a_logger = logging.getLogger(script_name)\n",
    "    a_logger.addHandler(stream_handler)\n",
    "    a_logger.propagate = False\n",
    "    return a_logger\n",
    "\n",
    "def setup_file_logging(a_logger: logging.Logger, folder: str|Path=\"\"):\n",
    "    \"\"\" Add a FileHandler to the specified logger. File name is based on the logger name.\n",
    "    In calling code, we can add a line like this:\n",
    "    td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "    Args:\n",
    "        a_logger (Logger): The existing logger\n",
    "        folder (str): Where the log file will be created. Will be created if it doesn't exist\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)     # Create directory if it does not exist\n",
    "    file_handler = logging.FileHandler(Path(folder, a_logger.name + \".log\"), mode='w')\n",
    "    file_fmt = logging.Formatter(fmt=\"%(asctime)s.%(msecs)03d:%(name)s:%(levelname)8s: %(message)s\",\n",
    "                                datefmt='%H:%M:%S')\n",
    "    file_handler.setFormatter(file_fmt)\n",
    "    a_logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_and_tail(data, block_size=5, include_line_numbers=True, zero_indexed=False):\n",
    "    \"\"\" Print a summary of a large amount of data \n",
    "\n",
    "    Args:\n",
    "        data (_type_): The data to present in summary form.\n",
    "        block_size (int, optional): How many rows to include in the top, and in the tail.\n",
    "        include_line_numbers (bool, optional): Prefix with line number. Defaults to True.\n",
    "        zero_indexed (bool, optional): Lines start at 0? Defaults to False.\n",
    "    \"\"\"\n",
    "    if isinstance(data, list):\n",
    "        # Get the number of digits of the last item for proper alignment\n",
    "        num_digits_last_item = len(str(len(data)))\n",
    "\n",
    "        # Format the string with line number\n",
    "        def format_with_line_number(idx, line):\n",
    "            start = 0 if zero_indexed else 1\n",
    "            if include_line_numbers:\n",
    "                return f\"{idx + start:>{num_digits_last_item}}: {line}\"\n",
    "            else:\n",
    "                return line\n",
    "\n",
    "        start = 0 if zero_indexed else 1\n",
    "        if len(data) < 11:\n",
    "            return \"\\n\".join(format_with_line_number(i, line) for i, line in enumerate(data))\n",
    "        else:\n",
    "            top = [format_with_line_number(i, line) for i, line in enumerate(data[:block_size])]\n",
    "            tail = [format_with_line_number(i, line) for i, line in enumerate(data[-block_size:], start=len(data)-block_size)]\n",
    "            return \"\\n\".join(top + [\"...\"] + tail)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y61RhVrHSjVA"
   },
   "source": [
    "## Get Access to Your AoC Data\n",
    "\n",
    "Now provide your unique AoC session key, in order to download your input data. You can get this by:\n",
    "1. Logging into [Advent of Code](https://adventofcode.com/).\n",
    "1. From your browser, open Developer Tools. (In Chrome, you can do this by pressing F12.)\n",
    "1. Open the `Application` tab.\n",
    "1. Storage -> Cookies -> https://adventofcode.com\n",
    "1. Copy the value associated with the cookie called `session`.\n",
    "1. Once you've determiend your session key, I recommend you store it in a file called `.env`, in your `Advent-of-Code` folder, like this: \\\n",
    "`AOC_SESSION_COOKIE=536...your-own-session-key...658` \\\n",
    "This notebook will try to retrieve the key from that location.  If it is unable to retrieve the key, it will prompt you to enter your key in the cell below.\n",
    "\n",
    "![Finding the session cookie](https://aoc.just2good.co.uk/assets/images/aoc-cookie.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m20:38:58.133:__main__ - INF: Using .env at F:\\Users\\Darren\\localdev\\Python\\Advent-of-Code\\.env\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_envs_from_file() -> bool:\n",
    "    \"\"\" Look for .env files, read variables from it, and store as environment variables \"\"\"\n",
    "    potential_path = \".env\"\n",
    "    for _ in range(3):\n",
    "        logger.debug(\"Trying .env at %s\", os.path.realpath(potential_path))\n",
    "        if os.path.exists(potential_path):\n",
    "            logger.info(\"Using .env at %s\", os.path.realpath(potential_path))\n",
    "            load_dotenv(potential_path, verbose=True)\n",
    "            return True\n",
    "        \n",
    "        potential_path = os.path.join('..', potential_path)\n",
    "   \n",
    "    logger.warning(\"No .env file found.\")\n",
    "    return False\n",
    "\n",
    "get_envs_from_file() # read env variables from a .env file, if we can find one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kSem0cT_LApT",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m20:38:58.148:__main__ - INF: Session cookie retrieved: 53616c...13d33c\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "if os.getenv('AOC_SESSION_COOKIE'):\n",
    "    logger.info('Session cookie retrieved: %s...%s', os.environ['AOC_SESSION_COOKIE'][0:6], os.environ['AOC_SESSION_COOKIE'][-6:])\n",
    "else: # it's not in our environment variables, so we'll need to input the value\n",
    "    os.environ['AOC_SESSION_COOKIE'] = getpass('Enter AoC session key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9A24B4MSyhT"
   },
   "source": [
    "## Load Helpers and Useful Classes\n",
    "\n",
    "Now we load a bunch of helper functions and classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPOsmENmYf8h",
    "tags": []
   },
   "source": [
    "### Locations\n",
    "\n",
    "Where any input and output files get stored.\n",
    "\n",
    "<img src=\"https://aoc.just2good.co.uk/assets/images/notebook-content-screenshot.png\" width=\"320\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VK27bcGiK0_M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Paths and Locations\n",
    "#################################################################\n",
    "\n",
    "@dataclass\n",
    "class Locations:\n",
    "    \"\"\" Dataclass for storing various location properties \"\"\"\n",
    "    script_name: str\n",
    "    script_dir: Path\n",
    "    input_dir: Path\n",
    "    output_dir: Path\n",
    "    input_file: Path\n",
    "\n",
    "def get_locations(script_name, folder=\"\") -> Locations:\n",
    "    \"\"\" Set various paths, based on the location of the calling script. \"\"\"\n",
    "    current_directory = os.getcwd()\n",
    "    script_dir = Path(Path().resolve(), folder, script_name)\n",
    "    input_dir = Path(script_dir, \"input\")\n",
    "    output_dir = Path(script_dir, \"output\")\n",
    "    input_file = Path(input_dir, \"input.txt\")\n",
    "\n",
    "    return Locations(script_name, script_dir,\n",
    "                     input_dir,\n",
    "                     output_dir,\n",
    "                     input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14ISscMTadAO"
   },
   "source": [
    "### Retrieve the Input Data\n",
    "\n",
    "This works by using your unique session cookie to retrieve your input data. E.g. from a URL like:\n",
    "\n",
    "`https://adventofcode.com/2015/day/1/input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lwP0r3BAaxjt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Retrieving input data\n",
    "##################################################################\n",
    "\n",
    "def write_puzzle_input_file(year: int, day, locations: Locations):\n",
    "    \"\"\" Use session key to obtain user's unique data for this year and day.\n",
    "    Only retrieve if the input file does not already exist.\n",
    "    Return True if successful.\n",
    "    Requires env: AOC_SESSION_COOKIE, which can be set from the .env.\n",
    "    \"\"\"\n",
    "    if os.path.exists(locations.input_file):\n",
    "        logger.debug(\"%s already exists\", os.path.basename(locations.input_file))\n",
    "        return os.path.basename(locations.input_file)\n",
    "\n",
    "    session_cookie = os.getenv('AOC_SESSION_COOKIE')\n",
    "    if not session_cookie:\n",
    "        raise ValueError(\"Could not retrieve session cookie.\")\n",
    "\n",
    "    logger.info('Session cookie retrieved: %s...%s', session_cookie[0:6], session_cookie[-6:])\n",
    "\n",
    "    # Create input folder, if it doesn't exist\n",
    "    if not locations.input_dir.exists():\n",
    "        locations.input_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    url = f\"https://adventofcode.com/{year}/day/{day}/input\"\n",
    "    \n",
    "    # Don't think we need to set a user-agent\n",
    "    # headers = {\n",
    "    #     \"User-Agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'\n",
    "    # }\n",
    "    cookies = { \n",
    "        \"session\": session_cookie\n",
    "    }\n",
    "    response = requests.get(url, cookies=cookies, timeout=5)\n",
    "\n",
    "    data = \"\"\n",
    "    if response.status_code == 200:\n",
    "        data = response.text\n",
    "\n",
    "        with open(locations.input_file, 'w') as file:\n",
    "            logger.debug(\"Writing input file %s\", os.path.basename(locations.input_file))\n",
    "            file.write(data)\n",
    "            return data\n",
    "    else:\n",
    "        raise ValueError(f\"Unable to retrieve input data.\\n\" +\n",
    "                         f\"HTTP response: {response.status_code}\\n\" +\n",
    "                         f\"{response.reason}: {response.content.decode('utf-8').strip()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yakibhW73Rqi"
   },
   "source": [
    "### Testing\n",
    "\n",
    "A really simple function for testing that our solution produces the expected test output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Y6nbd6WMryWi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(test, answer):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        test: the answer given by our solution\n",
    "        answer: the expected answer, e.g. from instructions\n",
    "    \"\"\"\n",
    "    if test != answer:\n",
    "        raise AssertionError(f\"{test} != {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bcBQkP0a2zA"
   },
   "source": [
    "### Useful Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "A8sU4Ez_bBKl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# POINTS, VECTORS AND GRIDS\n",
    "#################################################################\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Point:\n",
    "    \"\"\" Class for storing a point x,y coordinate \"\"\"\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "    def __add__(self, other: Point):\n",
    "        return Point(self.x + other.x, self.y + other.y)\n",
    "\n",
    "    def __mul__(self, other: Point):\n",
    "        \"\"\" (x, y) * (a, b) = (xa, yb) \"\"\"\n",
    "        return Point(self.x * other.x, self.y * other.y)\n",
    "\n",
    "    def __sub__(self, other: Point):\n",
    "        return self + Point(-other.x, -other.y)\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        # Arbitrary comparison logic\n",
    "        return (self.x, self.y) < (other.x, other.y)\n",
    "    \n",
    "    def yield_neighbours(self, include_diagonals=True, include_self=False):\n",
    "        \"\"\" Generator to yield neighbouring Points \"\"\"\n",
    "\n",
    "        deltas: list\n",
    "        if not include_diagonals:\n",
    "            deltas = [vector.value for vector in Vectors if abs(vector.value[0]) != abs(vector.value[1])]\n",
    "        else:\n",
    "            deltas = [vector.value for vector in Vectors]\n",
    "\n",
    "        if include_self:\n",
    "            deltas.append((0, 0))\n",
    "\n",
    "        for delta in deltas:\n",
    "            yield Point(self.x + delta[0], self.y + delta[1])\n",
    "\n",
    "    def neighbours(self, include_diagonals=True, include_self=False) -> list[Point]:\n",
    "        \"\"\" Return all the neighbours, with specified constraints.\n",
    "        It wraps the generator with a list. \"\"\"\n",
    "        return list(self.yield_neighbours(include_diagonals, include_self))\n",
    "\n",
    "    def get_specific_neighbours(self, directions: list[Vectors]) -> list[Point]:\n",
    "        \"\"\" Get neighbours, given a specific list of allowed locations \"\"\"\n",
    "        return [(self + Point(*vector.value)) for vector in list(directions)]\n",
    "\n",
    "    @staticmethod\n",
    "    def manhattan_distance(a_point: Point) -> int:\n",
    "        \"\"\" Return the Manhattan distance value of this vector \"\"\"\n",
    "        return sum(abs(coord) for coord in asdict(a_point).values())\n",
    "\n",
    "    def manhattan_distance_from(self, other: Point) -> int:\n",
    "        \"\"\" Manhattan distance between this Vector and another Vector \"\"\"\n",
    "        diff = self-other\n",
    "        return Point.manhattan_distance(diff)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"P({self.x},{self.y})\"\n",
    "\n",
    "class Vectors(Enum):\n",
    "    \"\"\" Enumeration of 8 directions.\n",
    "    Note: y axis increments in the North direction, i.e. N = (0, 1) \"\"\"\n",
    "    N = (0, 1)\n",
    "    NE = (1, 1)\n",
    "    E = (1, 0)\n",
    "    SE = (1, -1)\n",
    "    S = (0, -1)\n",
    "    SW = (-1, -1)\n",
    "    W = (-1, 0)\n",
    "    NW = (-1, 1)\n",
    "\n",
    "    @property\n",
    "    def y_inverted(self):\n",
    "        \"\"\" Return vector, but with y-axis inverted. I.e. N = (0, -1) \"\"\"\n",
    "        x, y = self.value\n",
    "        return (x, -y)\n",
    "\n",
    "class VectorDicts():\n",
    "    \"\"\" Contains constants for Vectors \"\"\"\n",
    "    ARROWS = {\n",
    "        '^': Vectors.N.value,\n",
    "        '>': Vectors.E.value,\n",
    "        'v': Vectors.S.value,\n",
    "        '<': Vectors.W.value\n",
    "    }\n",
    "\n",
    "    DIRS = {\n",
    "        'U': Vectors.N.value,\n",
    "        'R': Vectors.E.value,\n",
    "        'D': Vectors.S.value,\n",
    "        'L': Vectors.W.value\n",
    "    }\n",
    "\n",
    "    NINE_BOX: dict[str, tuple[int, int]] = {\n",
    "        # x, y vector for adjacent locations\n",
    "        'tr': (1, 1),\n",
    "        'mr': (1, 0),\n",
    "        'br': (1, -1),\n",
    "        'bm': (0, -1),\n",
    "        'bl': (-1, -1),\n",
    "        'ml': (-1, 0),\n",
    "        'tl': (-1, 1),\n",
    "        'tm': (0, 1)\n",
    "    }\n",
    "\n",
    "class Grid():\n",
    "    \"\"\" 2D grid of point values. \"\"\"\n",
    "    def __init__(self, grid_array: list) -> None:\n",
    "        self._array = grid_array\n",
    "        self._width = len(self._array[0])\n",
    "        self._height = len(self._array)\n",
    "\n",
    "    def value_at_point(self, point: Point):\n",
    "        \"\"\" The value at this point \"\"\"\n",
    "        return self._array[point.y][point.x]\n",
    "\n",
    "    def set_value_at_point(self, point: Point, value):\n",
    "        self._array[point.y][point.x] = value\n",
    "\n",
    "    def valid_location(self, point: Point) -> bool:\n",
    "        \"\"\" Check if a location is within the grid \"\"\"\n",
    "        if (0 <= point.x < self._width and  0 <= point.y < self._height):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def width(self):\n",
    "        \"\"\" Array width (cols) \"\"\"\n",
    "        return self._width\n",
    "\n",
    "    @property\n",
    "    def height(self):\n",
    "        \"\"\" Array height (rows) \"\"\"\n",
    "        return self._height\n",
    "\n",
    "    def all_points(self) -> list[Point]:\n",
    "        points = [Point(x, y) for x in range(self.width) for y in range(self.height)]\n",
    "        return points\n",
    "\n",
    "    def rows_as_str(self):\n",
    "        \"\"\" Return the grid \"\"\"\n",
    "        return [\"\".join(str(char) for char in row) for row in self._array]\n",
    "\n",
    "    def cols_as_str(self):\n",
    "        \"\"\" Render columns as str. Returns: list of str \"\"\"\n",
    "        cols_list = list(zip(*self._array))\n",
    "        return [\"\".join(str(char) for char in col) for col in cols_list]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Grid(size={self.width}*{self.height})\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"\\n\".join(\"\".join(map(str, row)) for row in self._array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xNijk6xbCVa"
   },
   "source": [
    "### Useful Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DT5FSYliC9wp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# CONSOLE STUFF\n",
    "#################################################################\n",
    "\n",
    "def cls():\n",
    "    \"\"\" Clear console \"\"\"\n",
    "    os.system('cls' if os.name=='nt' else 'clear')\n",
    "\n",
    "#################################################################\n",
    "# USEFUL FUNCTIONS\n",
    "#################################################################\n",
    "\n",
    "def binary_search(target, low:int, high:int, func, *func_args, reverse_search=False):\n",
    "    \"\"\" Generic binary search function that takes a target to find,\n",
    "    low and high values to start with, and a function to run, plus its args.\n",
    "    Implicitly returns None if the search is exceeded. \"\"\"\n",
    "\n",
    "    res = None  # just set it to something that isn't the target\n",
    "    candidate = 0  # initialise; we'll set it to the mid point in a second\n",
    "\n",
    "    while low < high:  # search exceeded\n",
    "        candidate = int((low+high) // 2)  # pick mid-point of our low and high\n",
    "        res = func(candidate, *func_args) # run our function, whatever it is\n",
    "        logger.debug(\"%d -> %d\", candidate, res)\n",
    "        if res == target:\n",
    "            return candidate  # solution found\n",
    "\n",
    "        comp = operator.lt if not reverse_search else operator.gt\n",
    "        if comp(res, target):\n",
    "            low = candidate\n",
    "        else:\n",
    "            high = candidate\n",
    "\n",
    "def merge_intervals(intervals: list[list]) -> list[list]:\n",
    "    \"\"\" Takes intervals in the form [[a, b][c, d][d, e]...]\n",
    "    Intervals can overlap.  Compresses to minimum number of non-overlapping intervals. \"\"\"\n",
    "    intervals.sort()\n",
    "    stack = []\n",
    "    stack.append(intervals[0])\n",
    "\n",
    "    for interval in intervals[1:]:\n",
    "        # Check for overlapping interval\n",
    "        if stack[-1][0] <= interval[0] <= stack[-1][-1]:\n",
    "            stack[-1][-1] = max(stack[-1][-1], interval[-1])\n",
    "        else:\n",
    "            stack.append(interval)\n",
    "\n",
    "    return stack\n",
    "\n",
    "@cache\n",
    "def get_factors(num: int) -> set[int]:\n",
    "    \"\"\" Gets the factors for a given number. Returns a set[int] of factors.\n",
    "        # E.g. when num=8, factors will be 1, 2, 4, 8 \"\"\"\n",
    "    factors = set()\n",
    "\n",
    "    # Iterate from 1 to sqrt of 8,\n",
    "    # since a larger factor of num must be a multiple of a smaller factor already checked\n",
    "    for i in range(1, int(num**0.5) + 1):  # e.g. with num=8, this is range(1, 3)\n",
    "        if num % i == 0: # if it is a factor, then dividing num by it will yield no remainder\n",
    "            factors.add(i)  # e.g. 1, 2\n",
    "            factors.add(num//i)  # i.e. 8//1 = 8, 8//2 = 4\n",
    "\n",
    "    return factors\n",
    "\n",
    "def to_base_n(number: int, base: int):\n",
    "    \"\"\" Convert any integer number into a base-n string representation of that number.\n",
    "    E.g. to_base_n(38, 5) = 123\n",
    "\n",
    "    Args:\n",
    "        number (int): The number to convert\n",
    "        base (int): The base to apply\n",
    "\n",
    "    Returns:\n",
    "        [str]: The string representation of the number\n",
    "    \"\"\"\n",
    "    ret_str = \"\"\n",
    "    curr_num = number\n",
    "    while curr_num:\n",
    "        ret_str = str(curr_num % base) + ret_str\n",
    "        curr_num //= base\n",
    "\n",
    "    return ret_str if number > 0 else \"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YtEtBnfNUKw"
   },
   "source": [
    "### Generic Initialisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "sbdA-geUNqAF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "FOLDER = \"aoc\"\n",
    "YEAR = 2023\n",
    "logger_identifier = \"aoc\" + str(YEAR)\n",
    "logger = retrieve_console_logger(logger_identifier)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y68fv1BebLsG"
   },
   "source": [
    "# Days\n",
    "\n",
    "Here you'll find a template to build a solution for a given day, and then the solutions for all days in this event.\n",
    "\n",
    "To copy the template day, select all the cells in the `Day n` template, add a new cell at the end, and then paste the cells there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FT4HLZLwevr"
   },
   "source": [
    "---\n",
    "## Day 1: Trebuchet?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VoMC3MaJ1I9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = 1\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNvM0hOF0tBR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.INFO)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAh6_AWRbYPo"
   },
   "source": [
    "### Day 1 Part 1\n",
    "\n",
    "And we're off!!  Welcome to the first day of Advent of Code 2023!!\n",
    "\n",
    "Today was a troublesome start for me.  My Internet was out.  (Thanks, Virgin Media.) So, after unsuccessful restarts of the router and home network, I switched over to mobile hotspot.\n",
    "\n",
    "Part 1 is pretty trivial, as we've come to expect. You need to identify the first and last digits of each line of a string. Concatenating these two values gives you a two digit number, which the puzzle calls a _calibration value_. Then we just add them all together.\n",
    "\n",
    "**My Solution**\n",
    "\n",
    "- For each line, I simply loop through each char in the line, and use the `isdigit()` method to determine if it is a digit.\n",
    "- Then repeat, but this time, looping from the end using the Python construct `[::-1]` which just means: start from the end, and then step with increments of `-1`. I.e. move backwards.\n",
    "- Finally, concatenate the two digits (still as strings), to update a two digit number. Then convert it to an int.\n",
    "- Store all these ints in a list.  And at the end, return the sum of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = {\"one\": 1,\n",
    "             \"two\": 2,\n",
    "             \"three\": 3,\n",
    "             \"four\": 4,\n",
    "             \"five\": 5,\n",
    "             \"six\": 6,\n",
    "             \"seven\": 7,\n",
    "             \"eight\": 8,\n",
    "             \"nine\": 9\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhWomZ6ewNi-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def solve(data, with_spelled_nums=False):\n",
    "    calibration_vals = []\n",
    "    for line in data:\n",
    "        logger.debug(line)\n",
    "        \n",
    "        first_posn = 1e6        \n",
    "        last_posn = -1\n",
    "        first = last = \"\"\n",
    "\n",
    "        for posn, char in enumerate(line): # read from start\n",
    "            if char.isdigit():\n",
    "                first_posn = posn\n",
    "                first = char\n",
    "                break\n",
    "            \n",
    "        for posn, char in enumerate(line[::-1]): # read from the end\n",
    "            if char.isdigit():\n",
    "                last_posn = len(line) - posn - 1 # remember, we're now counting from the end!!\n",
    "                last = char\n",
    "                break\n",
    "\n",
    "        if with_spelled_nums:\n",
    "            for num_word in num_words:\n",
    "                posn = line.find(num_word)\n",
    "                if 0 <= posn < first_posn:\n",
    "                    first_posn = posn\n",
    "                    first = str(num_words[num_word]) # map it back to int\n",
    "            \n",
    "                posn = line.rfind(num_word)\n",
    "                if posn > last_posn:\n",
    "                    last_posn = posn\n",
    "                    last = str(num_words[num_word]) # map to the int\n",
    "        \n",
    "        calibration_vals.append(int(first + last))\n",
    "    \n",
    "    return sum(calibration_vals)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uw4xFe7R7jf0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"1abc2\", \"pqr3stu8vwx\", \"a1b2c3d4e5f\", \"treb7uchetabcdef\"]]\n",
    "sample_answers = [142]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6ARzwH_AHU0"
   },
   "source": [
    "### Day 1 Part 2\n",
    "\n",
    "For Day 1, this wasn't quite as trivial as I was expecting! Now we have to also find the positions of any \"spelled\" versions of the digits 0-9.\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- Create a `dict` to store the spelled versions of 1-9, and map them to their respective int values.\n",
    "- Now, with each line, perform the same code as we did for Part 1 to find the first and last positions of the digit representation. \n",
    "  - But this time, store the positions found, as well as the values. I use the [`enumerate()`](https://aoc.just2good.co.uk/python/enumerate) to give me the current position of each char in my line.\n",
    "  - Be really careful when storing the position when counting from the end.  This tripped me up for a couple of minutes!!  When we're looping through chars from the end, backwards, we want to store the position in the string, not the current enumeration value. \n",
    "- Then, run another loop that looks for each spelled number in our dict of spelled numbers.\n",
    "  - To search for our current spelled number in our line from the start, using the `find()` method.\n",
    "  - To search for our current spelled number in our line from the end, using the `rfind()` method.\n",
    "  - Whenever we find a spelled number, check whether we found it at a position that is earlier / later (as required) than the digit we found before.\n",
    "  - Whenever I find such a spelled number, I convert the int value in the dict to a string, so that I can concatenate the string values, just as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcJdRHyK8TRY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"two1nine\", \n",
    "                  \"eightwothree\", \n",
    "                  \"abcone2threexyz\", \n",
    "                  \"xtwone3four\", \n",
    "                  \"4nineeightseven2\", \n",
    "                  \"zoneight234\", \n",
    "                  \"7pqrstsixteen\"]]\n",
    "sample_answers = [281]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input, with_spelled_nums=True), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve(input_data, with_spelled_nums=True)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 2: Cube Conundrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"2\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 2 Part 1\n",
    "\n",
    "In each game, we have a bag containing some number of red, green and blue cubes.  The bag is samples several times per game. Our input data shows these random samples for each game. E.g.\n",
    "\n",
    "```\n",
    "Game 1: 3 blue, 4 red; 1 red, 2 green, 6 blue; 2 green\n",
    "Game 2: 1 blue, 2 green; 3 green, 4 blue, 1 red; 1 green, 1 blue\n",
    "Game 3: 8 green, 6 blue, 20 red; 5 blue, 4 red, 13 green; 5 green, 1 red\n",
    "Game 4: 1 green, 3 red, 6 blue; 3 green, 6 red; 3 green, 15 blue, 14 red\n",
    "Game 5: 6 red, 1 blue, 3 green; 2 blue, 1 red, 2 green\n",
    "```\n",
    "\n",
    "**Determine which games would have been possible if the bag had been loaded with only 12 red cubes, 13 green cubes, and 14 blue cubes. What is the sum of the IDs of those games?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- I create a CubeSample [class](https://aoc.just2good.co.uk/python/classes) to store each sample, i.e. the number of r, g, b cubes.\n",
    "- I create a Game class to store the game ID and all the samples for that game.\n",
    "- I parse the input with [regex](https://aoc.just2good.co.uk/python/regex). My approach was:\n",
    "  - Split the game line into the game part, and the samples part. Retrieving the game ID is trivial.\n",
    "  - For the samples, use a regex that looks for \"n colour\", and use a regex `finditer()` to find all matches for this.\n",
    "  - Create a [defaultdict](https://aoc.just2good.co.uk/python/defaultdict) that sets the initial values for r, g, b to 0.\n",
    "  - Then iterate over the matches from `finditer()``, and update the r, g, b as required.\n",
    "- Now I simply loop through each game. \n",
    "  - For each game, I loop through the samples. If any sample has more r, g, b than we're allowed, then this game is impossible.\n",
    "  - Build up a list of the games that are possible. Then sum up the IDs with a [comprehension](https://aoc.just2good.co.uk/python/comprehensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CubeSample:\n",
    "    \"\"\" A sample contains a number of red, blue, and green cubes \"\"\"\n",
    "    red: int=0\n",
    "    blue: int=0\n",
    "    green: int=0\n",
    "\n",
    "@dataclass\n",
    "class Game:\n",
    "    \"\"\" A game has an ID, and a random number of samples \"\"\"\n",
    "    id: int\n",
    "    samples: list[CubeSample]\n",
    "\n",
    "def parse_input(data) -> list[Game]:\n",
    "    game_pattern = re.compile(r\"Game\\s+(\\d+)\")\n",
    "    cubes_pattern = re.compile(r\"(\\d+)\\s*(\\w+)\") # E.g. \"3 blue\" \n",
    "    \n",
    "    games = []\n",
    "    for line in data:\n",
    "        game_part, samples_part = line.split(\":\")\n",
    "        game_id = int(game_pattern.findall(game_part)[0])\n",
    "        samples = samples_part.split(\";\")\n",
    "        \n",
    "        cube_samples = []\n",
    "        for sample in samples:\n",
    "            matches = cubes_pattern.finditer(sample)\n",
    "            cube_counts = {\"red\": 0, \"green\": 0, \"blue\": 0} # reset cube counts for each sample\n",
    "            for match in matches:\n",
    "                cube_count, cube_colour = match.groups()\n",
    "                cube_counts[cube_colour] = int(cube_count)\n",
    "            \n",
    "            cube_samples.append(CubeSample(cube_counts[\"red\"], cube_counts[\"blue\"], cube_counts[\"green\"]))\n",
    "        \n",
    "        games.append(Game(game_id, cube_samples))\n",
    "        \n",
    "    return games\n",
    "      \n",
    "def solve_part1(games: list[Game]):\n",
    "    \"\"\" Return the sum of the IDs for games that are possible. \"\"\"\n",
    "    \n",
    "    allowed_red = 12\n",
    "    allowed_green = 13\n",
    "    allowed_blue = 14\n",
    "    \n",
    "    possible_games = []\n",
    "    for game in games:\n",
    "        possible = True\n",
    "        for game_sample in game.samples:\n",
    "            if (game_sample.red > allowed_red\n",
    "                    or game_sample.green > allowed_green\n",
    "                    or game_sample.blue > allowed_blue):\n",
    "                possible = False\n",
    "            \n",
    "        if possible:\n",
    "            possible_games.append(game)\n",
    "            \n",
    "    return sum(game.id for game in possible_games) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"Game 1: 3 blue, 4 red; 1 red, 2 green, 6 blue; 2 green\",\n",
    "                  \"Game 2: 1 blue, 2 green; 3 green, 4 blue, 1 red; 1 green, 1 blue\",\n",
    "                  \"Game 3: 8 green, 6 blue, 20 red; 5 blue, 4 red, 13 green; 5 green, 1 red\",\n",
    "                  \"Game 4: 1 green, 3 red, 6 blue; 3 green, 6 red; 3 green, 15 blue, 14 red\",\n",
    "                  \"Game 5: 6 red, 1 blue, 3 green; 2 blue, 1 red, 2 green\"]\n",
    "                ]\n",
    "sample_answers = [8]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    sample_games = parse_input(curr_input)\n",
    "    validate(solve_part1(sample_games), curr_ans) # test with sample data\n",
    "\n",
    "games = parse_input(input_data)\n",
    "soln = solve_part1(games)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 2 Part 2\n",
    "\n",
    "**For each game, find the minimum set of cubes that must have been present. What is the sum of the power of these sets?**\n",
    "\n",
    "Here, we need to look at all the samples for a given game, and determine the largest number of cubes shown of each colour, across the samples.\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "Fortunately, since we already have our list of Games, this is now trivial to do. Simply iterate through the games, and for each game, iterate over all the samples. For each sample, determine if the number of any of r, g, b is greater than the biggest number of which we've found so far.\n",
    "\n",
    "Then, multiply the r, g, b to get the `power` of the game. Then sum up all the powers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(games: list[Game]):\n",
    "    \"\"\" Return the sum of the powers of all the games \"\"\"\n",
    "    game_powers = []\n",
    "    for game in games:\n",
    "        max_blue = max_green = max_red = 0\n",
    "        for game_sample in game.samples:\n",
    "            max_blue = max(max_blue, game_sample.blue)\n",
    "            max_green = max(max_green, game_sample.green)\n",
    "            max_red = max(max_red, game_sample.red)\n",
    "     \n",
    "        # We're told that power = product of r, g, b   \n",
    "        game_powers.append(max_blue*max_green*max_red)\n",
    "    \n",
    "    return sum(game_powers)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"Game 1: 3 blue, 4 red; 1 red, 2 green, 6 blue; 2 green\",\n",
    "                  \"Game 2: 1 blue, 2 green; 3 green, 4 blue, 1 red; 1 green, 1 blue\",\n",
    "                  \"Game 3: 8 green, 6 blue, 20 red; 5 blue, 4 red, 13 green; 5 green, 1 red\",\n",
    "                  \"Game 4: 1 green, 3 red, 6 blue; 3 green, 6 red; 3 green, 15 blue, 14 red\",\n",
    "                  \"Game 5: 6 red, 1 blue, 3 green; 2 blue, 1 red, 2 green\"]\n",
    "                ]\n",
    "sample_answers = [2286]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    sample_games = parse_input(curr_input)\n",
    "    validate(solve_part2(sample_games), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve_part2(games)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 3: Gear Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"3\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3 Part 1\n",
    "\n",
    "I'm finding AoC fairly tough this year. I wasn't expecting the early challenges to be this tricky.\n",
    "\n",
    "Anyhoo...\n",
    "\n",
    "We're given a 2D grid, called the _engine schematic_. That grid contains numbers, periods (which should be ignored), and symbols (anything else). We need to determine the _part numbers_, which are told are any numbers adjacent to a symbol.\n",
    "\n",
    "**What is the sum of all of the part numbers in the engine schematic?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- I get to reuse one of my [helper classes](https://aoc.just2good.co.uk/python/reusable_code).  Yay!  \n",
    "  - I'm going to reuse my `Point` class, which stores x, y coordinates, but also has the ability to return all of its adjacent neighbours.\n",
    "  - I'm going to reuse my `Grid` class, which already knows how to create a 2D grid, iterate through the points in the grid, get the values at any location, and determine if a specied point is in the grid.\n",
    "- I create a new [class](https://aoc.just2good.co.uk/python/classes) called `EngineGrid` by extending `Grid`.\n",
    "  - This class knows how to return all the points that are symbols.\n",
    "- To solve:\n",
    "  - First, get all the symbol locations. This is trivial.\n",
    "  - Get the value of this symbol, and store it alongside the location in a dictionary.\n",
    "  - Then, get all the neighbour locations for each symbol location.\n",
    "  - Check if this neighbour is part of a part number range we've already found.  If it is, then we don't need to check this neighbour; we already know it's part of a part number.\n",
    "  - If the neighbour is a valid location, check if it is a digit. If it is, then this location is _in_ a part number. If so, use the method `get_part_number_continugous_range()` to determine the full set of points that make up this part number. It works by taking this location on this line of the grid, and walking backwards and fowards, until the value found is no longer a digit. We return the full set of contiguous digits as a part number range.\n",
    "  - Add this to the [set](https://aoc.just2good.co.uk/python/sets) of ranges for this symbol, i.e. in the `ranges_for_symbol` dict. Note, here I'm using a [defaultdict](https://aoc.just2good.co.uk/python/defaultdict), such that I can initialise each entry with an empty `set`, and then add to the set whenever we find a range.\n",
    "  - Also, add all the points from this range to a `set` called `all_range_locations_for_symbol`. We use this when checking each neighbour, to see if this neighbour is already part of a range associated with this symbol.\n",
    "  - Also, determine the part number for this range, using our `get_part_number_for_range()` method. Store the result in a `dict` called `part_range_to_num`, where the key is the range `tuple` itself.\n",
    "  - Finally, we can sum up all the part number values, by summing the values from the `dict` of `part_range_to_num`.\n",
    "\n",
    "### Day 3 Part 2\n",
    "\n",
    "Now we're told we need to find symbols that are _gears_, i.e. the symbols that are simply `*`. And we need to find all the gears that have exactly two adjacent part numbers. Where this is true, the product of the two part numbers is the _gear ratio_. Then we need to add up all the gear ratios.\n",
    "\n",
    "**What is the sum of all of the gear ratios in your engine schematic?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "This is a fairly trivial addition. We already have the `ranges_for_symbol` dictionary. So, in our loop that processes each symbol, we now:\n",
    "\n",
    "- Check if the symbol is a gear, i.e. `*`\n",
    "- If so, check how many ranges are associated with this symbol.\n",
    "- If there are exactly two ranges, then we need to determine the part number values of this ranges, and multiply them together to obtain our `gear_ratio` for this gear.\n",
    "- Finally, add up all the gear ratios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EngineGrid(Grid):\n",
    "    def get_symbol_locations(self) -> list[Point]:\n",
    "        \"\"\" Return all locations that contain a symbol \"\"\"\n",
    "        symbol_locations = [point for point in self.all_points() if self._is_symbol(point)]\n",
    "        return symbol_locations\n",
    "    \n",
    "    def _is_symbol(self, point: Point) -> bool:\n",
    "        \"\"\" A symbol is anything that is not numeric, or not a period. \"\"\"\n",
    "        val = str(self.value_at_point(point))\n",
    "        if val.isdigit():\n",
    "            return False\n",
    "        \n",
    "        if val == \".\":\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def get_part_number_contiguous_range(self, point: Point) -> tuple[Point, ...]:\n",
    "        \"\"\" Given a point within a part number, we want to return the entire range or points that make up that part number. \"\"\"\n",
    "        line = self._array[point.y] # get the row this point is on\n",
    "    \n",
    "        # Find the start of the contiguous digits\n",
    "        start = point.x\n",
    "        while start > 0 and line[start - 1].isdigit():\n",
    "            start -= 1\n",
    "\n",
    "        # Find the end of the contiguous digits\n",
    "        end = point.x\n",
    "        while end < len(line) - 1 and line[end + 1].isdigit():\n",
    "            end += 1\n",
    "\n",
    "        # Return the contiguous locations that make up a part number\n",
    "        contiguous_locations = [Point(x, point.y) for x in range(start, end+1)]\n",
    "        return tuple(contiguous_locations)\n",
    "\n",
    "    def get_part_number_for_range(self, part_range: tuple[Point, ...]) -> int:\n",
    "        \"\"\" Given a set of points that make up a part number, return the part number they contain. \"\"\"\n",
    "        part_num = \"\"\n",
    "        for point in part_range:\n",
    "            part_num += self.value_at_point(point)\n",
    "            \n",
    "        return int(part_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(input_data) -> tuple[int, int]:\n",
    "    \"\"\" Part 1: determine the sum of all part numbers, where a part number is \n",
    "                a full set of continguous digits adjacent to a symbol. \n",
    "        Part 2: determine the gear ratios, where a gear ratio is the product of the part numbers\n",
    "                adjacent to a gear, for any gear that has exactly two adjacent part numbers. \"\"\"\n",
    "    points_and_symbols = [] # (point, value-for-point)\n",
    "    part_number_ranges = set() # = all the points in a range. Use set so we don't double count ranges.\n",
    "    ranges_for_symbol = defaultdict(set) # { (point, value), {ranges} }\n",
    "    part_range_to_num = {} # so we can cache the part number corresponding to a range\n",
    "    gear_ratios = [] # a gear ratio is given by the product of its two adjacent part numbers\n",
    "    \n",
    "    engine = EngineGrid(input_data)\n",
    "    \n",
    "    # get the locations of symbols, e.g. * ?, but not .\n",
    "    symbol_locations = engine.get_symbol_locations()\n",
    "    for point in symbol_locations:\n",
    "        all_range_locations_for_symbol = set()\n",
    "        symbol_val = engine.value_at_point(point)\n",
    "        points_and_symbols.append((point, symbol_val))\n",
    "        \n",
    "        # get adjacent locations to this symbol\n",
    "        for neighbour in point.neighbours():\n",
    "            if neighbour in all_range_locations_for_symbol:\n",
    "                continue    # we don't care about neighbours in ranges we've already found\n",
    "            \n",
    "            if engine.valid_location(neighbour): # check it is in the grid\n",
    "                val = str(engine.value_at_point(neighbour))\n",
    "                if val.isdigit(): # this neighbour is a point in a part number\n",
    "                    range_for_locn = engine.get_part_number_contiguous_range(neighbour) # gets range as tuple\n",
    "                    part_range_to_num[range_for_locn] = engine.get_part_number_for_range(range_for_locn)\n",
    "                    ranges_for_symbol[(point, symbol_val)].add(range_for_locn) # add this range for this symbol\n",
    "                    all_range_locations_for_symbol.update(set(range_for_locn)) # add all locations from this range\n",
    "                \n",
    "        if symbol_val == \"*\": # if this is a gear\n",
    "            gear_ranges = ranges_for_symbol[(point, symbol_val)]\n",
    "            if gear_ranges and len(gear_ranges) == 2: # if this gear has exactly two ranges\n",
    "                gear_part_nums = [part_range_to_num[gear_range] for gear_range in gear_ranges]\n",
    "                gear_ratios.append(reduce(operator.mul, gear_part_nums))\n",
    "                \n",
    "        part_number_ranges.update(ranges_for_symbol[(point, symbol_val)])\n",
    "        \n",
    "    return sum(part_range_to_num.values()), sum(gear_ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"467..114..\",\n",
    "                  \"...*......\",\n",
    "                  \"..35..633.\",\n",
    "                  \"......#...\",\n",
    "                  \"617*......\",\n",
    "                  \".....+.58.\",\n",
    "                  \"..592.....\",\n",
    "                  \"......755.\",\n",
    "                  \"...$.*....\",\n",
    "                  \".664.598..\"]]\n",
    "sample_answers = [(4361, 467835)]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "part_num_sum, gear_ratios_sum = solve(input_data)\n",
    "logger.info(f\"Part 1 soln: {part_num_sum=}\")\n",
    "logger.info(f\"Part 2 soln: {gear_ratios_sum=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 4: Scratchcards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### See [Day 4](https://adventofcode.com/2023/day/4)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DAY = \"4\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:53:13.177:aoc2023 - INF: Input data:\n",
      "  1: Card   1: 20 72 30 38 18 65  6 55 70 27 | 12 28 47 50 60 17 14 25 41 95 66 88 61 52 76  5 23 77 31 32 99 89 53 54 96\n",
      "  2: Card   2: 15 98 12  3 20 60 58 54 34 18 | 98 23 12 19 61 38 11 43 58 97 63 10 49 67 44 52 88  4 22  1 42 65 20 13 25\n",
      "  3: Card   3: 47 97  2 80 89 56 66 85 62 46 | 78 97 47 14 15 85 42 66 24 28 54 46 89 62 80 56 22  5 57 52 69  2  3 95 19\n",
      "  4: Card   4: 60 59 88 14 53 46 96 29 99 37 | 52 46 92 26 72 74 99 38  7 65 43 63 39 36 44  9 56 42 79 50 89 48 85 28 27\n",
      "  5: Card   5: 44 46 42  9 65 98 97 67 72 22 | 80 14 29 39 98 64  9 46 52 24 69 22 51 65 66 20 72 21 55 12 97 42 44 41 67\n",
      "...\n",
      "183: Card 183: 58 73 31 77 33 10 49 92 28 25 | 39  3 96 41 45 32 82 79  8 21 36  9  6 17 84 14 27 20 88 60 98 43 61 24  5\n",
      "184: Card 184: 10 41 56 32 84 29 85 26 34 27 |  6  4  9 38 25 26  8 86 68 87 11 30  5 79 78 52 49 81 65 64 40  2 37 39 17\n",
      "185: Card 185: 95 13 15 61 49 19 60 21 33 87 | 30 36 52 88 23 65 95 25 53 51 77 32 66 31 68 84 39 29  8 47 62 26 22 11 89\n",
      "186: Card 186: 41 48 94 68 60 15 22 55 84  2 | 57 53  9 50  4 16 11 62 61  6 46 52  8 35 23 39 51 72 43 22 81 56 77 45 19\n",
      "187: Card 187: 57 81 33  3 42 78 83 30  2  9 | 14 85 99  1 55 54 66 56 26 21 12 86 20 39 37 41 94 15 24 76 91 73 44 36  8\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.INFO)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 4 Part 1\n",
    "\n",
    "We have a set of scratch cards.  Each card has an `id`, then a set of `winning` numbers, then a set of `actual` numbers that were scratched. The score of each scratch card depends on the number of winning numbers we have matched. The first match gives us 1 point, and each additional match doubles the score.\n",
    "\n",
    "**How points are the pile of scratch cards worth, in total?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "This is pretty simple.\n",
    "\n",
    "- I create a `ScratchCard` [dataclass](https://aoc.just2good.co.uk/python/classes#dataclass) which:\n",
    "  - Stores the card ID.\n",
    "  - Stores the winning numbers, and the scratched numbers, both as sets.  I want to use sets because I will want to determine the intersection of these two sets, i.e. how many winning numbers were matched. [Set algebra](https://aoc.just2good.co.uk/python/sets) makes this super easy.\n",
    "  - Has a `score()` method which determines the score, according to the rules.\n",
    "- Then I parse the input data using [regex](https://aoc.just2good.co.uk/python/regex). Let me explain how \\\n",
    "  `Card(?:\\s+)(\\d+):\\s*((?:\\d+\\s*)+)(?: \\|\\s+)((?:\\d+\\s*)+)` works:\n",
    "  - `(\\d+)`: This is a capturing group that matches one or more digits. The `\\d` is a shorthand character class that matches any digit (0-9), and the `+` means one or more of the preceding element. This is how I capture the `id`.\n",
    "  - `\\s*`: This matches zero or more whitespace characters. The `*` means zero or more of the preceding element.\n",
    "  - `((?:\\d+\\s*)+)`: This is a capturing group containing a non-capturing group. The non-capturing group `(?:\\d+\\s*)` matches one or more digits followed by zero or more whitespace characters. The outer capturing group with the `+` at the end repeats this pattern one or more times. This is how I capture ALL of the `winning` numbers.\n",
    "  - `(?: \\|\\s+)`: This is another non-capturing group. It matches a literal space, followed by a vertical bar `|`, followed by one or more whitespace characters.\n",
    "  - `((?:\\d+\\s*)+)`: The same as before. This is how I capture ALL of the `actual` numbers.\n",
    "- I use this regex to parse each line:\n",
    "  - This gives me the `id`, a string containing all the `winning` numbers, and a string containing all the `actual` numbers.\n",
    "  - I split the `winning` and `actual` numbers at the space, using `split()`. This gives me a list of string values. Then I convert the string values to `int` using `map()`, and finally convert each `list` to a `set`.\n",
    "  - Now I can create an instance of `ScoreCard` from the `id` and the two sets.\n",
    "\n",
    "- Finally, just add up all the scores from each card using `sum` and a [list comprehension](https://aoc.just2good.co.uk/python/comprehensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ScratchCard:\n",
    "    \"\"\" A scratchcard has an ID, winning numbers, and (actual) numbers scratched. \"\"\"\n",
    "    id: int\n",
    "    winning: set[int]\n",
    "    actual: set[int]\n",
    "    \n",
    "    def matches(self) -> int:\n",
    "        \"\"\" Return the number of winning numbers we have matched. \"\"\"\n",
    "        return len(self.winning & self.actual)\n",
    "    \n",
    "    def score(self) -> int:\n",
    "        \"\"\" For every winning number, double the score. Examples scores...\n",
    "        0 matches -> 0\n",
    "        1 match   -> 1\n",
    "        2 matches -> 2\n",
    "        3 matches -> 4, etc \"\"\"\n",
    "        num_matches = self.matches()\n",
    "        return 2**(num_matches-1) if num_matches > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cards(data) -> list[ScratchCard]:\n",
    "    scratch_card_pattern = r\"Card(?:\\s+)(\\d+):\\s*((?:\\d+\\s*)+)(?: \\|\\s+)((?:\\d+\\s*)+)\"\n",
    "    scratch_card_matcher = re.compile(scratch_card_pattern)\n",
    "    scratch_cards = []\n",
    "    for line in data:\n",
    "        id, winning, actual = scratch_card_matcher.findall(line)[0]\n",
    "        \n",
    "        id = int(id)\n",
    "        winning = set(map(int, winning.split()))\n",
    "        actual = set(map(int, actual.split()))\n",
    "        scratch_cards.append(ScratchCard(id, winning, actual))\n",
    "        \n",
    "    return scratch_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(cards: list[ScratchCard]):  \n",
    "    return sum(card.score() for card in cards)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:53:25.271:aoc2023 - INF: Part 1 soln=22674\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"Card 1: 41 48 83 86 17 | 83 86  6 31 17  9 48 53\",\n",
    "                  \"Card 2: 13 32 20 16 61 | 61 30 68 82 17 32 24 19\",\n",
    "                  \"Card 3:  1 21 53 59 44 | 69 82 63 72 16 21 14  1\",\n",
    "                  \"Card 4: 41 92 73 84 69 | 59 84 76 51 58  5 54 83\",\n",
    "                  \"Card 5: 87 83 26 28 32 | 88 30 70 12 93 22 82 36\",\n",
    "                  \"Card 6: 31 18 13 56 72 | 74 77 10 23 35 67 36 11\"]\n",
    "]\n",
    "sample_answers = [13]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    sample_cards = parse_cards(curr_input)  \n",
    "    validate(solve_part1(sample_cards), curr_ans) # test with sample data\n",
    "\n",
    "cards = parse_cards(input_data)\n",
    "soln = solve_part1(cards)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 4 Part 2\n",
    "\n",
    "Now we're told that there's no such thing as a _score_. Instead scratchcards only cause you to win more scratchcards equal to the number of winning numbers you have. You win copies of the scratchcards below the winning card equal to the number of matches.\n",
    "\n",
    "**how many total scratchcards do you end up with?**\n",
    "\n",
    "**My solution**\n",
    "\n",
    "I spent several minutes thinking about how to solve this problem, before writing any code.  At first, I was thinking about some sort of `while loop` that iterates through cards, and only exits when there are no more cards. I was thinking I could insert duplicate cards into the list as I iterate.\n",
    "\n",
    "But then I realised that I didn't need to do that.  I simply needed to keep a count of how many there are of each card ID. I can do that with a `dict`. So my strategy:\n",
    "\n",
    "- Create a `dict` that stores the number of cards for each card ID.\n",
    "- Loop through all the cards we have to initialise the dict. There will be one of each.\n",
    "- Then, loop through the cards again, in order.  For each card:\n",
    "  - Get the number of matches.\n",
    "  - Use this number of matches to determine the successive cards that need to be duplicated.\n",
    "  - Increment the count of each of those successive cards, by the count of the card we're currently on. (Because it might not be 1.)\n",
    "\n",
    "Even though it took my tiny brain a little while to realise this approach, the actual code is pretty trivial.\n",
    "\n",
    "The solution is fast, and only takes a couple of milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(cards: list[ScratchCard]):\n",
    "    card_counts = {}\n",
    "    for card in cards: # initialise our card counts \n",
    "        card_counts[card.id] = 1\n",
    "    \n",
    "    for card in cards:\n",
    "        count_this_card = card_counts[card.id]\n",
    "        for i in range(card.id+1, card.id+1+card.matches()):\n",
    "            card_counts[i] += count_this_card\n",
    "    \n",
    "    logger.debug(card_counts)\n",
    "    total_card_count = sum(card_counts.values())\n",
    "    return total_card_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:53:31.776:aoc2023 - INF: Part 2 soln=5747443\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"Card 1: 41 48 83 86 17 | 83 86  6 31 17  9 48 53\",\n",
    "                  \"Card 2: 13 32 20 16 61 | 61 30 68 82 17 32 24 19\",\n",
    "                  \"Card 3:  1 21 53 59 44 | 69 82 63 72 16 21 14  1\",\n",
    "                  \"Card 4: 41 92 73 84 69 | 59 84 76 51 58  5 54 83\",\n",
    "                  \"Card 5: 87 83 26 28 32 | 88 30 70 12 93 22 82 36\",\n",
    "                  \"Card 6: 31 18 13 56 72 | 74 77 10 23 35 67 36 11\"]\n",
    "]\n",
    "sample_answers = [30]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    sample_cards = parse_cards(curr_input)  \n",
    "    validate(solve_part2(sample_cards), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve_part2(cards)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 5: If You Give A Seed A Fertilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### See [Day 5](https://adventofcode.com/2023/day/5)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DAY = \"5\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m22:52:29.042:aoc2023 - INF: Input data:\n",
      "  1: seeds: 1778931867 1436999653 3684516104 2759374 1192793053 358764985 1698790056 76369598 3733854793 214008036 4054174000 171202266 3630057255 25954395 798587440 316327323 290129780 7039123 3334326492 246125391\n",
      "  2: \n",
      "  3: seed-to-soil map:\n",
      "  4: 1965922922 2387203602 59808406\n",
      "  5: 2540447436 434094583 220346698\n",
      "...\n",
      "231: 3584396646 1757986922 143559505\n",
      "232: 267143672 161914533 100367854\n",
      "233: 3527298136 3080301496 57098510\n",
      "234: 1082510516 3749523110 18833794\n",
      "235: 3727956151 3150282471 536984712\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.INFO)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 5 Part 1\n",
    "\n",
    "Our input includes:\n",
    "\n",
    "- Seeds to be planted, as ints.\n",
    "- Maps, in the the format: \n",
    "  - destination-range-start, source-range-start, range-length. \\\n",
    "    The source and destination ranges will be the same length.\n",
    "- We have the following maps:\n",
    "  - seed-to-soil\n",
    "  - soil-to-fertilizer\n",
    "  - fertilizer-to-water\n",
    "  - water-to-light\n",
    "  - light-to-temperature\n",
    "  - temperature-to-humidity\n",
    "  - humidity-to-location\n",
    "\n",
    "E.g. \n",
    "\n",
    "```\n",
    "soil-to-fertilizer map:\n",
    "0 15 37\n",
    "37 52 2\n",
    "39 0 15\n",
    "```\n",
    "\n",
    "Unmapped source numbers map to the same destination number.\n",
    "\n",
    "**What is the lowest location number that corresponds to any of the initial seed numbers?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- We need a rules engine that takes a value and determines the target value for that map.\n",
    "- I've done this by creating a class called `GardinerMap`.\n",
    "- Each instance of `GardinerMap` contains the source and target ranges for that map type.\n",
    "- The `GardinerMap`:\n",
    "  - Stores all source ranges in that map as a list of tuples, with each tuple being `(source start, range length)`.\n",
    "  - Stores all destination ranges in that map as a list of tuples, with each tuple being `(destination start, range length)`.\n",
    "  - All the actual mapping is done in the method `get_target()`. It iterates through each range, and determines if our input value is part of that range. If it is, we apply the required _shift_, which is the difference between the destination range start and the source range start. Now we've finished mapping, so we return the mapped value.\n",
    "\n",
    "We need to start by passing the seed value to `get_target()` of our first `GardinerMap`. This returns a new value.  We then take this value and pass it into `get_target()` of the second `GardinerMap`.  And so on, until we've done this for every `GardinerMap`.\n",
    "\n",
    "\n",
    "\n",
    "  - Finally, back in our `solve_part1()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GardinerMap():\n",
    "    source_type: str\n",
    "    dest_type: str\n",
    "    \n",
    "    src_ranges: list[tuple[int,int]] = field(default_factory=list) # [(src_start, length), (src_start, length), ... ]\n",
    "    dest_ranges: list[tuple[int,int]] = field(default_factory=list) # [(dest_start, length), (dest_start, length), ... ]\n",
    "    \n",
    "    def add_range(self, src_start: int, dest_start: int, range_length: int):\n",
    "        \"\"\" Add a range which contains src start, dest start, and the length of the range \"\"\"\n",
    "        self.src_ranges.append((src_start, range_length)) \n",
    "        self.dest_ranges.append((dest_start, range_length))\n",
    "        \n",
    "    def _sort_ranges(self):\n",
    "        \"\"\" Sort the range into ascending numeric, based on source range start values \"\"\"\n",
    "        \n",
    "        # Sort src_ranges and get the order of indices\n",
    "        index_order = sorted(range(len(self.src_ranges)), key=lambda i: self.src_ranges[i][0])\n",
    "\n",
    "        # Now sort both ranges\n",
    "        self.src_ranges = [self.src_ranges[i] for i in index_order]\n",
    "        self.dest_ranges = [self.dest_ranges[i] for i in index_order]\n",
    "\n",
    "    def finalise(self):\n",
    "        \"\"\" Sort the range into ascending numeric, based on source range start values \"\"\"\n",
    "        self._sort_ranges()\n",
    "        \n",
    "    def get_target(self, src_val: int):\n",
    "        \"\"\" Map a source value to a target value \"\"\"\n",
    "        target = src_val # if our source isn't in a range, then return the same value\n",
    "        \n",
    "        for i, curr_range in enumerate(self.src_ranges):\n",
    "            src_start = curr_range[0]\n",
    "            src_end = curr_range[0] + curr_range[1] # exclusive end\n",
    "            if src_start <= src_val < src_end: # if our source is in a range, then apply the shift\n",
    "                target = src_val - src_start + self.dest_ranges[i][0]\n",
    "                break # we've mapped the value, so no more ranges need to be checked\n",
    "        \n",
    "        return target\n",
    "\n",
    "    # For Part 2\n",
    "    def map_intervals(self, src_intervals: list[tuple[int, int]]) -> list[tuple[int, int]]:\n",
    "        \"\"\" \n",
    "        Take input ranges and return output ranges.\n",
    "        - src_ranges: [(rng1_start, rng1_end), (rng2_start, rng2_end), ... ] \n",
    "        \"\"\"\n",
    "        new_intervals = []\n",
    "        \n",
    "        # Iterate through the ranges, just as we did when mapping a single seed\n",
    "        for i, curr_range in enumerate(self.src_ranges): \n",
    "            src_start = curr_range[0]\n",
    "            src_end = curr_range[0] + curr_range[1] # exclusive end\n",
    "            dest = self.dest_ranges[i][0]\n",
    "\n",
    "            temp_intervals = []\n",
    "\n",
    "            while src_intervals: # process the current interval       \n",
    "                (int_start, int_end) = src_intervals.pop()\n",
    "                \n",
    "                # Split the interval using the ranges in our map\n",
    "                #### Scenario 1: ####\n",
    "                # [int_start                                  int_end]\n",
    "                #            [src_start      src_end]\n",
    "                # [left     ][mid                   ][right          ]\n",
    "                #\n",
    "                #### Scenario 2: ####\n",
    "                #                [int_start         int_end]\n",
    "                #   [src_start     src_end]\n",
    "                #   [n/a        ][mid     ][right          ]\n",
    "                left = (int_start, min(int_end, src_start))\n",
    "                mid = (max(int_start, src_start), min(src_end, int_end))\n",
    "                right = (max(src_end, int_start), int_end)\n",
    "                \n",
    "                if left[1] > left[0]: # if left has +ve length, then scenario 1, else scenario 2\n",
    "                    temp_intervals.append(left) # pass on the interval unchanged\n",
    "                if mid[1] > mid[0]: # if mid has +ve length, then we need to apply the shift to this interval\n",
    "                    # furthermore, once mapped, we know this interval wont appear in another range\n",
    "                    new_intervals.append((mid[0]-src_start+dest, mid[1]-src_start+dest))\n",
    "                if right[1] > right[0]:  # if right has +ve length\n",
    "                    temp_intervals.append(right) # pass on the interval unchanged\n",
    "            \n",
    "            src_intervals = temp_intervals\n",
    "                    \n",
    "        return new_intervals + src_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data: list[str]) -> tuple[list[int], list[GardinerMap]]:\n",
    "    \"\"\" Parse input data, and convert to:\n",
    "    - seeds: list of int\n",
    "    - GardinerMap instances: list of GardinerMap \"\"\"\n",
    "    \n",
    "    seeds = []\n",
    "    source_maps = [] # Store our GardinerMap instances\n",
    "    \n",
    "    # Process the input file line by line, and switch modes based on the line last read\n",
    "    current_map = None \n",
    "    for line in data:\n",
    "        if line.startswith(\"seeds\"): # The first line contains the seeds values\n",
    "            _, seeds_part = line.split(\":\")\n",
    "            seeds = [int(x) for x in seeds_part.split()]\n",
    "        elif \"map:\" in line: # start of a map block; enter map processing mode\n",
    "            map_src, _, map_dest = line.split()[0].split(\"-\")\n",
    "            current_map = GardinerMap(map_src, map_dest) # initialise our GardinerMap\n",
    "        elif not line: # empty line, so finish with the current_map and add it to our list of GardinerMaps\n",
    "            if current_map:\n",
    "                current_map.finalise()\n",
    "                source_maps.append(current_map)  # add it to the list\n",
    "                current_map = None # and ensure we're no longer in map processing mode\n",
    "        else: # we're in map processing mode\n",
    "            assert line[0].isdigit(), \"Line must start with numbers\"\n",
    "            assert current_map, \"We must be adding to a Map now\"\n",
    "            dest_start, src_start, interval_len = [int(x) for x in line.split()]\n",
    "            current_map.add_range(src_start=src_start, dest_start=dest_start, range_length=interval_len)\n",
    "    \n",
    "    # We don't read a final empty line at the end of the input, but I still want to finalise the block\n",
    "    if current_map: # process the final map\n",
    "        current_map.finalise()\n",
    "        source_maps.append(current_map)   # add it to the dict\n",
    "            \n",
    "    return seeds, source_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    seeds, source_maps = parse_data(data)\n",
    "    location_map = {}\n",
    "    \n",
    "    logger.debug(f\"{seeds=}\")\n",
    "    for current_map in source_maps:\n",
    "        logger.debug(f\"{current_map=}\")\n",
    "        \n",
    "    for seed in seeds:\n",
    "        current_val = seed\n",
    "        for current_map in source_maps:\n",
    "            current_val = current_map.get_target(current_val)\n",
    "        \n",
    "        location_map[seed] = current_val\n",
    "    \n",
    "    logger.debug(f\"Seeds->locations: {location_map}\")\n",
    "    return min(location_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m23:06:00.877:aoc2023 - INF: Part 1 soln=107430936\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 7.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample_inputs = [\"\"\"seeds: 79 14 55 13\n",
    "\n",
    "seed-to-soil map:\n",
    "50 98 2\n",
    "52 50 48\n",
    "\n",
    "soil-to-fertilizer map:\n",
    "0 15 37\n",
    "37 52 2\n",
    "39 0 15\n",
    "\n",
    "fertilizer-to-water map:\n",
    "49 53 8\n",
    "0 11 42\n",
    "42 0 7\n",
    "57 7 4\n",
    "\n",
    "water-to-light map:\n",
    "88 18 7\n",
    "18 25 70\n",
    "\n",
    "light-to-temperature map:\n",
    "45 77 23\n",
    "81 45 19\n",
    "68 64 13\n",
    "\n",
    "temperature-to-humidity map:\n",
    "0 69 1\n",
    "1 0 69\n",
    "\n",
    "humidity-to-location map:\n",
    "60 56 37\n",
    "56 93 4\"\"\"]\n",
    "sample_answers = [35]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Day 5 Part 2\n",
    "\n",
    "_\"The values on the initial `seeds:` line come in pairs. Within each pair, the first value is the start of the range and the second value is the length of the range.\"_\n",
    "\n",
    "Uh oh, the values on the seeds line now describes ranges of seed numbers. In the real input, these numbers are huge. We're going to have way too many seeds to iterate over each seed.\n",
    "\n",
    "Instead of mapping a source seed to a target value, we need to map the entire interval. By the way... **I hate intervals.**\n",
    "\n",
    "I was struggling to get my head around this problem, so I created a sketch:\n",
    "\n",
    "![Fertiliser range mappings](https://aoc.just2good.co.uk/assets/images/fertiliser.png)\n",
    "\n",
    "Things to note:\n",
    "\n",
    "- We start with intervals that represent our seeds.\n",
    "- In each map, any given target range will always be the same length as the source range.\n",
    "- As we propagate our seed intervals through each map, the following rules will apply:\n",
    "  - If the interval sits outside a mapped range, the target interval will be the same.\n",
    "  - If the interval sits inside a mapped range, the target interval will be shifted by the appropriate delta.\n",
    "  - If the interval is both within and outside a mapped range, then we will need to split the interval. The part that is in the range will be moved by the appropriate delta.  That part that is out of the range will stay the same.\n",
    "  - An interval might span multiple ranges. In this scenario, the interval must be split accordingly which will create more intervals.\n",
    "  - Although it is possible to get intervals that are adjacent, a given source interval will never create overlapping intervals. Phew!\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- We can't map individual seed values, as there's just too many. Instead, we can map the intervals of seed values, and we only care about any boundaries. I.e. at the beginning of end of any mapping range, at the beginning and end of any seeds interval, and at any intersections.\n",
    "- I added a `map_intervals()` method to my `GardinerMap` class. The job of this method is to map the supplied intervals into a new set of intervals. It works like this:\n",
    "  - Take all the intervals supplied (which will initally be the seed intervals) as an input list.\n",
    "  - Then iterate through our mapping ranges, as we did before.\n",
    "  - For each range, determine the source start, source end, and destination start values, as we did before.\n",
    "  - Initialise `temp_intervals`. We use this to store intervals that we still need to map.\n",
    "  - Now, loop over each interval supplied as input. With each loop iteration, `pop`` the current interval off the list.\n",
    "  - For each interval, determine the boundary conditions that make up the left, middle, and right parts of the interval, after intersecting with the current range. There may be no intersection, in which case only the `left` or `right` portion will be available.\n",
    "  - If we have a `left` or `right` portion, then these are not intersecting with the current range.  So add these to our `temp_intervals`, and we can test them with the next range.\n",
    "  - If we have a `mid` portion, then this portion is intersecting with the current range. If so, we need to _shift_ the range to obtain the new range, using exactly the same logic as we used for shifting individual values in Part 1. Note: once we've a interval portion like this, that portion will not be mapped again by this GardinerMap.\n",
    "  - Now, at the end of the loop for this interval, continue to the next loop iteration, which will process the next interval with this range.\n",
    "  - Once we've processed all intervals for this range, re-populate `src_intervals` using the current intervals stored in `temp_intervals`. This allows us to test these intervals with the next range.\n",
    "  - Any intervals that are never mapped with a range will instead be passed on, as is.\n",
    "\n",
    "Back in our `solve_part2()` method, we iterate over all the `GardinerMap` instances, just as we did with Part 1. But this time, we're passing in the seed intervals into the `map_intervals` method of the first `GardinerMap`. This returns a new list of intervals, which we pass into the next `GardinerMap`. And so on.\n",
    "\n",
    "Eventually, we've left with the intervals generated by the _humidity-to-location_ map. This is a list of tuples, with each tuple containin the start and end values for that interval. So it's a trival matter to get the `min` of all the `start` values.\n",
    "\n",
    "And that's it!\n",
    "\n",
    "**That was a brutal day 5!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    location_map = {}\n",
    "    seeds, source_maps = parse_data(data)\n",
    "    \n",
    "    # convert seeds to intervals, of format [(start, end), ...] where end is exclusive\n",
    "    # let's call them intervals, to avoid confusion with the ranges we stored in our GardinerMap\n",
    "    seed_intervals = [(seeds[i], seeds[i]+seeds[i+1]) for i in range(0, len(seeds), 2)]\n",
    "    logger.debug(f\"{seed_intervals=}\")\n",
    "    \n",
    "    current_intervals = seed_intervals\n",
    "    for current_map in source_maps:\n",
    "        current_intervals = current_map.map_intervals(current_intervals)\n",
    "        logger.debug(f\"Mapping to {current_map.dest_type}: {current_intervals}\")\n",
    "        \n",
    "    return min(start for start, _ in current_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m22:52:44.188:aoc2023 - INF: Part 2 soln=23738616\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 20 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample_answers = [46]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day n: title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"n\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day n Part 1\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [\"abcdef\"]\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day n Part 2\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [\"abcdef\"]\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ana-aoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
