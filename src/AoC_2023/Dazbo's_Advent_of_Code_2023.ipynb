{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "This notebook contains my solutions for **<a href=\"https://adventofcode.com/2023\" target=\"_blank\">Advent of Code 2023</a>**.\n",
    "\n",
    "A few notes...\n",
    "- The source for this notebook source lives in my GitHub repo, <a href=\"https://github.com/derailed-dash/Advent-of-Code/blob/master/src/AoC_2023/Dazbo's_Advent_of_Code_2023.ipynb\" target=\"_blank\">here</a>.\n",
    "- You can run this Notebook wherever you like. For example, you could...\n",
    "  - Run it locally, in your own Jupyter environment.\n",
    "  - Run it in a cloud-based Jupyter environment, with no setup required on your part!  For example, <a href=\"https://colab.research.google.com/github/derailed-dash/Advent-of-Code/blob/master/src/AoC_2023/Dazbo's_Advent_of_Code_2023.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Google Colab\"/></a>\n",
    "- **To run the notebook, execute the cells in the [Setup](#Setup) section, as described below. Then you can run the code for any given day.**\n",
    "- Be mindful that the first time you run this notebook, you will need to **obtain your AoC session key** and store it, if you have not done so already. This allows the notebook to automatically retrieve your input data. (See the guidance in the **[Get Access to Your AoC Data](#Get-Access-to-Your-AoC-Data)** section for details.)\n",
    "- Use the navigation menu on the left to jump to any particular day.\n",
    "- All of my AoC solutions are documented in my <a href=\"https://aoc.just2good.co.uk/\" target=\"_blank\">AoC Python Walkthrough site</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3PMQJRrR38P",
    "tags": []
   },
   "source": [
    "# Setup\n",
    "\n",
    "You need to run all cells in this section, before running any particular day solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWxsAMaXTGEQ"
   },
   "source": [
    "## Packages and Imports\n",
    "\n",
    "Here we use `pip` to install the packages used by my solutions in this event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Dgeww1rMrkQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install jupyterlab-lsp colorama python-dotenv ipykernel ffmpeg mediapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5Ki_HvOJUWk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from typing import Optional, Callable, cast\n",
    "from enum import Enum, auto\n",
    "from functools import cache, reduce\n",
    "from itertools import permutations, combinations, count, cycle\n",
    "from collections import Counter, deque, defaultdict\n",
    "from io import BytesIO\n",
    "import abc\n",
    "import heapq\n",
    "import copy\n",
    "import operator\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import platform\n",
    "import re\n",
    "import ast\n",
    "import unittest\n",
    "import requests\n",
    "import imageio.v3 as iio\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.markers import MarkerStyle\n",
    "from matplotlib import path as pltpath\n",
    "import mediapy as media\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from colorama import Fore, Back, Style\n",
    "from IPython.display import display\n",
    "from IPython.core.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZNTgtGzUImv",
    "tags": []
   },
   "source": [
    "## Logging and Output\n",
    "\n",
    "Set up a new logger that uses `ColouredFormatter`, such that we have coloured logging.  The log colour depends on the logging level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwzjfUFCKhXe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# SETUP LOGGING\n",
    "#\n",
    "# Create a new instance of \"logger\" in the client application\n",
    "# Set to your preferred logging level\n",
    "# And add the stream_handler from this module, if you want coloured output\n",
    "##########################################################################\n",
    "\n",
    "# logger for aoc_commons only\n",
    "logger = logging.getLogger(__name__) # aoc_common.aoc_commons\n",
    "logger.setLevel(logging.INFO)\n",
    "stream_handler = None\n",
    "\n",
    "class ColouredFormatter(logging.Formatter):\n",
    "    \"\"\" Custom Formater which adds colour to output, based on logging level \"\"\"\n",
    "\n",
    "    level_mapping = {\"DEBUG\": (Fore.BLUE, \"DBG\"),\n",
    "                     \"INFO\": (Fore.GREEN, \"INF\"),\n",
    "                     \"WARNING\": (Fore.YELLOW, \"WRN\"),\n",
    "                     \"ERROR\": (Fore.RED, \"ERR\"),\n",
    "                     \"CRITICAL\": (Fore.MAGENTA, \"CRT\")\n",
    "    }\n",
    "\n",
    "    def __init__(self, *args, apply_colour=True, shorten_lvl=True, **kwargs) -> None:\n",
    "        \"\"\" Args:\n",
    "            apply_colour (bool, optional): Apply colouring to messages. Defaults to True.\n",
    "            shorten_lvl (bool, optional): Shorten level names to 3 chars. Defaults to True.\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._apply_colour = apply_colour\n",
    "        self._shorten_lvl = shorten_lvl\n",
    "\n",
    "    def format(self, record):\n",
    "        if record.levelname in ColouredFormatter.level_mapping:\n",
    "            new_rec = copy.copy(record)\n",
    "            colour, new_level = ColouredFormatter.level_mapping[record.levelname]\n",
    "\n",
    "            if self._shorten_lvl:\n",
    "                new_rec.levelname = new_level\n",
    "\n",
    "            if self._apply_colour:\n",
    "                msg = colour + super().format(new_rec) + Fore.RESET\n",
    "            else:\n",
    "                msg = super().format(new_rec)\n",
    "\n",
    "            return msg\n",
    "\n",
    "        # If our logging message is not using one of these levels...\n",
    "        return super().format(record)\n",
    "\n",
    "if not stream_handler:\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_fmt = ColouredFormatter(fmt='%(asctime)s.%(msecs)03d:%(name)s - %(levelname)s: %(message)s',\n",
    "                                   datefmt='%H:%M:%S')\n",
    "    stream_handler.setFormatter(stream_fmt)\n",
    "    \n",
    "if not logger.handlers:\n",
    "    # Add our ColouredFormatter as the default console logging\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "def retrieve_console_logger(script_name):\n",
    "    \"\"\" Create and return a new logger, named after the script\n",
    "    So, in your calling code, add a line like this:\n",
    "    logger = ac.retrieve_console_logger(locations.script_name)\n",
    "    \"\"\"\n",
    "    a_logger = logging.getLogger(script_name)\n",
    "    a_logger.addHandler(stream_handler)\n",
    "    a_logger.propagate = False\n",
    "    return a_logger\n",
    "\n",
    "def setup_file_logging(a_logger: logging.Logger, folder: str|Path=\"\"):\n",
    "    \"\"\" Add a FileHandler to the specified logger. File name is based on the logger name.\n",
    "    In calling code, we can add a line like this:\n",
    "    td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "    Args:\n",
    "        a_logger (Logger): The existing logger\n",
    "        folder (str): Where the log file will be created. Will be created if it doesn't exist\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)     # Create directory if it does not exist\n",
    "    file_handler = logging.FileHandler(Path(folder, a_logger.name + \".log\"), mode='w')\n",
    "    file_fmt = logging.Formatter(fmt=\"%(asctime)s.%(msecs)03d:%(name)s:%(levelname)8s: %(message)s\",\n",
    "                                datefmt='%H:%M:%S')\n",
    "    file_handler.setFormatter(file_fmt)\n",
    "    a_logger.addHandler(file_handler)\n",
    "    \n",
    "def top_and_tail(data, block_size=5, include_line_numbers=True, zero_indexed=False):\n",
    "    \"\"\" Print a summary of a large amount of data \n",
    "\n",
    "    Args:\n",
    "        data (_type_): The data to present in summary form.\n",
    "        block_size (int, optional): How many rows to include in the top, and in the tail.\n",
    "        include_line_numbers (bool, optional): Prefix with line number. Defaults to True.\n",
    "        zero_indexed (bool, optional): Lines start at 0? Defaults to False.\n",
    "    \"\"\"\n",
    "    if isinstance(data, list):\n",
    "        # Get the number of digits of the last item for proper alignment\n",
    "        num_digits_last_item = len(str(len(data)))\n",
    "\n",
    "        # Format the string with line number\n",
    "        def format_with_line_number(idx, line):\n",
    "            start = 0 if zero_indexed else 1\n",
    "            if include_line_numbers:\n",
    "                return f\"{idx + start:>{num_digits_last_item}}: {line}\"\n",
    "            else:\n",
    "                return line\n",
    "\n",
    "        start = 0 if zero_indexed else 1\n",
    "        if len(data) < 11:\n",
    "            return \"\\n\".join(format_with_line_number(i, line) for i, line in enumerate(data))\n",
    "        else:\n",
    "            top = [format_with_line_number(i, line) for i, line in enumerate(data[:block_size])]\n",
    "            tail = [format_with_line_number(i, line) for i, line in enumerate(data[-block_size:], start=len(data)-block_size)]\n",
    "            return \"\\n\".join(top + [\"...\"] + tail)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install ffmpeg\n",
    "\n",
    "This is installed in order to render video output, i.e. for visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_ffmpeg():\n",
    "    os_name = platform.system()\n",
    "    \n",
    "    if os_name == \"Windows\":\n",
    "        logger.info(\"Installing FFmpeg on Windows...\")\n",
    "        os.system(\"winget install ffmpeg\")\n",
    "    elif os_name == \"Linux\":\n",
    "        logger.info(\"Installing FFmpeg on Linux...\")\n",
    "        os.system(\"apt-get -qq update && apt-get -qq -y install ffmpeg\")\n",
    "    elif os_name == \"Darwin\":\n",
    "        logger.info(\"Installing FFmpeg on macOS...\")\n",
    "        os.system(\"brew install ffmpeg\")\n",
    "    else:\n",
    "        logger.error(f\"Unsupported operating system: {os_name}\")\n",
    "\n",
    "install_ffmpeg()\n",
    "\n",
    "logger.info(\"Note that the ffmpeg command may not be immediately available after first installing ffmpeg.\\n\" \\\n",
    "            \"It may be necessary to relaunch the notebook environment.\")\n",
    "!ffmpeg -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y61RhVrHSjVA"
   },
   "source": [
    "## Get Access to Your AoC Data\n",
    "\n",
    "Now provide your unique AoC session key, in order to download your input data. You can get this by:\n",
    "1. Logging into [Advent of Code](https://adventofcode.com/).\n",
    "1. From your browser, open Developer Tools. (In Chrome, you can do this by pressing F12.)\n",
    "1. Open the `Application` tab.\n",
    "1. Storage -> Cookies -> https://adventofcode.com\n",
    "1. Copy the value associated with the cookie called `session`.\n",
    "1. Once you've determiend your session key, I recommend you store it in a file called `.env`, in your `Advent-of-Code` folder, like this: \\\n",
    "`AOC_SESSION_COOKIE=536...your-own-session-key...658` \\\n",
    "This notebook will try to retrieve the key from that location.  If it is unable to retrieve the key, it will prompt you to enter your key in the cell below.\n",
    "\n",
    "![Finding the session cookie](https://aoc.just2good.co.uk/assets/images/aoc-cookie.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_envs_from_file() -> bool:\n",
    "    \"\"\" Look for .env files, read variables from it, and store as environment variables \"\"\"\n",
    "    potential_path = \".env\"\n",
    "    for _ in range(3):\n",
    "        logger.debug(\"Trying .env at %s\", os.path.realpath(potential_path))\n",
    "        if os.path.exists(potential_path):\n",
    "            logger.info(\"Using .env at %s\", os.path.realpath(potential_path))\n",
    "            load_dotenv(potential_path, override=True, verbose=True)\n",
    "            return True\n",
    "        \n",
    "        potential_path = os.path.join('..', potential_path)\n",
    "   \n",
    "    logger.warning(\"No .env file found.\")\n",
    "    return False\n",
    "\n",
    "get_envs_from_file() # read env variables from a .env file, if we can find one\n",
    "\n",
    "if os.getenv('AOC_SESSION_COOKIE'):\n",
    "    logger.info('Session cookie retrieved: %s...%s', os.environ['AOC_SESSION_COOKIE'][0:6], os.environ['AOC_SESSION_COOKIE'][-6:])\n",
    "else: # it's not in our environment variables, so we'll need to input the value\n",
    "    os.environ['AOC_SESSION_COOKIE'] = getpass('Enter AoC session key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9A24B4MSyhT"
   },
   "source": [
    "## Load Helpers and Useful Classes\n",
    "\n",
    "Now we load a bunch of helper functions and classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPOsmENmYf8h",
    "tags": []
   },
   "source": [
    "### Locations\n",
    "\n",
    "Where any input and output files get stored.\n",
    "\n",
    "<img src=\"https://aoc.just2good.co.uk/assets/images/notebook-content-screenshot.png\" width=\"320\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VK27bcGiK0_M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Paths and Locations\n",
    "#################################################################\n",
    "\n",
    "@dataclass\n",
    "class Locations:\n",
    "    \"\"\" Dataclass for storing various location properties \"\"\"\n",
    "    script_name: str\n",
    "    script_dir: Path\n",
    "    input_dir: Path\n",
    "    output_dir: Path\n",
    "    input_file: Path\n",
    "\n",
    "def get_locations(script_name, folder=\"\") -> Locations:\n",
    "    \"\"\" Set various paths, based on the location of the calling script. \"\"\"\n",
    "    current_directory = os.getcwd()\n",
    "    script_dir = Path(Path().resolve(), folder, script_name)\n",
    "    input_dir = Path(script_dir, \"input\")\n",
    "    output_dir = Path(script_dir, \"output\")\n",
    "    input_file = Path(input_dir, \"input.txt\")\n",
    "\n",
    "    return Locations(script_name, script_dir,\n",
    "                     input_dir,\n",
    "                     output_dir,\n",
    "                     input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14ISscMTadAO"
   },
   "source": [
    "### Retrieve the Input Data\n",
    "\n",
    "This works by using your unique session cookie to retrieve your input data. E.g. from a URL like:\n",
    "\n",
    "`https://adventofcode.com/2015/day/1/input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwP0r3BAaxjt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Retrieving input data\n",
    "##################################################################\n",
    "\n",
    "def write_puzzle_input_file(year: int, day, locations: Locations):\n",
    "    \"\"\" Use session key to obtain user's unique data for this year and day.\n",
    "    Only retrieve if the input file does not already exist.\n",
    "    Return True if successful.\n",
    "    Requires env: AOC_SESSION_COOKIE, which can be set from the .env.\n",
    "    \"\"\"\n",
    "    if os.path.exists(locations.input_file):\n",
    "        logger.debug(\"%s already exists\", os.path.basename(locations.input_file))\n",
    "        return os.path.basename(locations.input_file)\n",
    "\n",
    "    session_cookie = os.getenv('AOC_SESSION_COOKIE')\n",
    "    if not session_cookie:\n",
    "        raise ValueError(\"Could not retrieve session cookie.\")\n",
    "\n",
    "    logger.info('Session cookie retrieved: %s...%s', session_cookie[0:6], session_cookie[-6:])\n",
    "\n",
    "    # Create input folder, if it doesn't exist\n",
    "    if not locations.input_dir.exists():\n",
    "        locations.input_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    url = f\"https://adventofcode.com/{year}/day/{day}/input\"\n",
    "    \n",
    "    # Don't think we need to set a user-agent\n",
    "    # headers = {\n",
    "    #     \"User-Agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'\n",
    "    # }\n",
    "    cookies = { \n",
    "        \"session\": session_cookie\n",
    "    }\n",
    "    response = requests.get(url, cookies=cookies, timeout=5)\n",
    "\n",
    "    data = \"\"\n",
    "    if response.status_code == 200:\n",
    "        data = response.text\n",
    "\n",
    "        with open(locations.input_file, 'w') as file:\n",
    "            logger.debug(\"Writing input file %s\", os.path.basename(locations.input_file))\n",
    "            file.write(data)\n",
    "            return data\n",
    "    else:\n",
    "        raise ValueError(f\"Unable to retrieve input data.\\n\" +\n",
    "                         f\"HTTP response: {response.status_code}\\n\" +\n",
    "                         f\"{response.reason}: {response.content.decode('utf-8').strip()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yakibhW73Rqi"
   },
   "source": [
    "### Testing\n",
    "\n",
    "A really simple function for testing that our solution produces the expected test output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6nbd6WMryWi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(test, answer):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        test: the answer given by our solution\n",
    "        answer: the expected answer, e.g. from instructions\n",
    "    \"\"\"\n",
    "    if test != answer:\n",
    "        raise AssertionError(f\"{test} != {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bcBQkP0a2zA"
   },
   "source": [
    "### Useful Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8sU4Ez_bBKl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# POINTS, VECTORS AND GRIDS\n",
    "#################################################################\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Point:\n",
    "    \"\"\" Class for storing a point x,y coordinate \"\"\"\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "    def __add__(self, other: Point):\n",
    "        return Point(self.x + other.x, self.y + other.y)\n",
    "\n",
    "    def __mul__(self, other: Point):\n",
    "        \"\"\" (x, y) * (a, b) = (xa, yb) \"\"\"\n",
    "        return Point(self.x * other.x, self.y * other.y)\n",
    "\n",
    "    def __sub__(self, other: Point):\n",
    "        return self + Point(-other.x, -other.y)\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        # Arbitrary comparison logic\n",
    "        return (self.x, self.y) < (other.x, other.y)\n",
    "    \n",
    "    def yield_neighbours(self, include_diagonals=True, include_self=False):\n",
    "        \"\"\" Generator to yield neighbouring Points \"\"\"\n",
    "\n",
    "        deltas: list\n",
    "        if not include_diagonals:\n",
    "            deltas = [vector.value for vector in Vectors if abs(vector.value[0]) != abs(vector.value[1])]\n",
    "        else:\n",
    "            deltas = [vector.value for vector in Vectors]\n",
    "\n",
    "        if include_self:\n",
    "            deltas.append((0, 0))\n",
    "\n",
    "        for delta in deltas:\n",
    "            yield Point(self.x + delta[0], self.y + delta[1])\n",
    "\n",
    "    def neighbours(self, include_diagonals=True, include_self=False) -> list[Point]:\n",
    "        \"\"\" Return all the neighbours, with specified constraints.\n",
    "        They are returned clockwise, starting with N.\n",
    "        It wraps the generator with a list. \"\"\"\n",
    "        return list(self.yield_neighbours(include_diagonals, include_self))\n",
    "\n",
    "    def get_specific_neighbours(self, directions: list[Vectors]) -> list[Point]:\n",
    "        \"\"\" Get neighbours, given a specific list of allowed locations. \"\"\"\n",
    "        return [(self + Point(*vector.value)) for vector in list(directions)]\n",
    "\n",
    "    @staticmethod\n",
    "    def manhattan_distance(a_point: Point) -> int:\n",
    "        \"\"\" Return the Manhattan distance value of this vector \"\"\"\n",
    "        return sum(abs(coord) for coord in asdict(a_point).values())\n",
    "\n",
    "    def manhattan_distance_from(self, other: Point) -> int:\n",
    "        \"\"\" Manhattan distance between this Vector and another Vector \"\"\"\n",
    "        diff = self-other\n",
    "        return Point.manhattan_distance(diff)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"P({self.x},{self.y})\"\n",
    "\n",
    "class Vectors(Enum):\n",
    "    \"\"\" Enumeration of 8 directions.\n",
    "    Note: y axis increments in the North direction, i.e. N = (0, 1) \"\"\"\n",
    "    N = (0, -1)\n",
    "    NE = (1, -1)\n",
    "    E = (1, 0)\n",
    "    SE = (1, 1)\n",
    "    S = (0, 1)\n",
    "    SW = (-1, 1)\n",
    "    W = (-1, 0)\n",
    "    NW = (-1, -1)\n",
    "\n",
    "class VectorDicts():\n",
    "    \"\"\" Contains constants for Vectors \"\"\"\n",
    "    ARROWS = {\n",
    "        '^': Vectors.N.value,\n",
    "        '>': Vectors.E.value,\n",
    "        'v': Vectors.S.value,\n",
    "        '<': Vectors.W.value\n",
    "    }\n",
    "\n",
    "    DIRS = {\n",
    "        'U': Vectors.N.value,\n",
    "        'R': Vectors.E.value,\n",
    "        'D': Vectors.S.value,\n",
    "        'L': Vectors.W.value\n",
    "    }\n",
    "\n",
    "    NINE_BOX: dict[str, tuple[int, int]] = {\n",
    "        # x, y vector for adjacent locations\n",
    "        'tr': (1, 1),\n",
    "        'mr': (1, 0),\n",
    "        'br': (1, -1),\n",
    "        'bm': (0, -1),\n",
    "        'bl': (-1, -1),\n",
    "        'ml': (-1, 0),\n",
    "        'tl': (-1, 1),\n",
    "        'tm': (0, 1)\n",
    "    }\n",
    "\n",
    "class Grid():\n",
    "    \"\"\" 2D grid of point values. \"\"\"\n",
    "    def __init__(self, grid_array: list, animating: bool=False) -> None:\n",
    "        self.array = grid_array\n",
    "        self._width = len(self.array[0])\n",
    "        self._height = len(self.array)\n",
    "        \n",
    "        self.animating = animating\n",
    "        if self.animating:\n",
    "            self._plot_info = self._setup_fig()\n",
    "            self._frame_index = 0\n",
    "    \n",
    "    def _setup_fig(self):\n",
    "        my_dpi = 120\n",
    "        fig, axes = plt.subplots(figsize=(1024/my_dpi, 768/my_dpi), dpi=my_dpi, facecolor=\"black\") # set size in pixels\n",
    "\n",
    "        axes.get_xaxis().set_visible(False)\n",
    "        axes.get_yaxis().set_visible(False)\n",
    "        axes.set_aspect('equal') # set x and y to equal aspect\n",
    "        axes.set_facecolor('xkcd:orange')\n",
    "        \n",
    "        min_x, max_x = -0.5, self.width - 0.5\n",
    "        min_y, max_y = -0.5, self.height - 0.5\n",
    "        axes.set_xlim(min_x, max_x)\n",
    "        axes.set_ylim(max_y, min_y)\n",
    "\n",
    "        # dynamically compute the marker size\n",
    "        fig.canvas.draw()\n",
    "        mkr_size = ((axes.get_window_extent().width / (max_x-min_x) * (45/fig.dpi)) ** 2)\n",
    "        \n",
    "        return fig, axes, mkr_size\n",
    "\n",
    "    def animate_step(self, i):\n",
    "        \"\"\" Update the plot for the ith step in the animation.\n",
    "        Abstract implementation: add your logic when extending this class. \"\"\"\n",
    "        \n",
    "        # if self._frame_index < len(self.some_updating_attribute):\n",
    "        #     self._render_plot()\n",
    "        #     self._frame_index += 1\n",
    "        return []\n",
    "    \n",
    "    def create_animation(self, output_path='animation.mp4', fps=10):\n",
    "        \"\"\" Abstract implementation: add your logic when extending this class.\n",
    "        Creates the animation, by calling the animate_step() method to generate frames. \"\"\"\n",
    "        \n",
    "        self._plot_info = self._setup_fig()  # Set up the figure for plotting\n",
    "        fig, axes, mkr_size = self._plot_info\n",
    "        \n",
    "        # # Creating the animation\n",
    "        # anim = FuncAnimation(fig, self.animate_step, frames=len(self.some_updating_attribute), \n",
    "        #                      interval=1000/fps, blit=True)\n",
    "\n",
    "        # # Save the animation\n",
    "        # anim.save(output_path, writer='ffmpeg')\n",
    "    \n",
    "    def _render_plot(self):\n",
    "        \"\"\" Abstract implementation: add your rendering logic when extending this class. \"\"\"\n",
    "        fig, axes, mkr_size = self._plot_info\n",
    "        axes.clear() # clear for each frame\n",
    "        \n",
    "        # plot stuff - IT SHOULD DRAW WHATEVER IS RELEVANT FOR A GIVEN FRAME\n",
    "        # E.g.\n",
    "        # Only plot the path up to the current frame index\n",
    "        # for point, dirn in self.path_taken[:self._frame_index + 1]:\n",
    "    \n",
    "    def value_at_point(self, point: Point):\n",
    "        \"\"\" The value at this point \"\"\"\n",
    "        return self.array[point.y][point.x]\n",
    "\n",
    "    def set_value_at_point(self, point: Point, value):\n",
    "        if isinstance(self.array[0], str):\n",
    "            row = self.array[point.y]\n",
    "            self.array[point.y] = row[:point.x] + value + row[point.x + 1:]\n",
    "        else: # assume we have a replaceable type, like list[int]\n",
    "            self.array[point.y][point.x] = value\n",
    "\n",
    "    def valid_location(self, point: Point) -> bool:\n",
    "        \"\"\" Check if a location is within the grid \"\"\"\n",
    "        if (0 <= point.x < self._width and  0 <= point.y < self._height):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def width(self):\n",
    "        \"\"\" Array width (cols) \"\"\"\n",
    "        return self._width\n",
    "\n",
    "    @property\n",
    "    def height(self):\n",
    "        \"\"\" Array height (rows) \"\"\"\n",
    "        return self._height\n",
    "\n",
    "    def all_points(self) -> list[Point]:\n",
    "        points = [Point(x, y) for x in range(self.width) for y in range(self.height)]\n",
    "        return points\n",
    "\n",
    "    def rows_as_str(self):\n",
    "        \"\"\" Return the grid \"\"\"\n",
    "        return [\"\".join(str(char) for char in row) for row in self.array]\n",
    "\n",
    "    def cols_as_str(self):\n",
    "        \"\"\" Render columns as str. Returns: list of str \"\"\"\n",
    "        cols_list = list(zip(*self.array))\n",
    "        return [\"\".join(str(char) for char in col) for col in cols_list]\n",
    "\n",
    "    def transpose(self) -> Grid:\n",
    "        return Grid(list(zip(*self.array)))\n",
    "    \n",
    "    def flip_vertical(self) -> Grid:\n",
    "        \"\"\" Flip the array about the vertical axis of symmetry \"\"\"\n",
    "        return Grid([row[::-1] for row in self.array])\n",
    "    \n",
    "    def flip_horizontal(self) -> Grid:\n",
    "        \"\"\" Flip the array about the horizontal axis of symmetry \"\"\"\n",
    "        return Grid(self.array[::-1])\n",
    "    \n",
    "    def rotate_90(self, ccw=False) -> Grid:\n",
    "        \"\"\" Rotates 90 degrees CW. It works by transposing, then flipping. \"\"\"\n",
    "        if ccw:\n",
    "            flipped = self.flip_vertical()\n",
    "        else:\n",
    "            flipped = self.flip_horizontal()\n",
    "    \n",
    "        return flipped.transpose()\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Grid(size={self.width}*{self.height})\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"\\n\".join(\"\".join(map(str, row)) for row in self.array)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xNijk6xbCVa"
   },
   "source": [
    "### Useful Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DT5FSYliC9wp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# CONSOLE STUFF\n",
    "#################################################################\n",
    "\n",
    "def cls():\n",
    "    \"\"\" Clear console \"\"\"\n",
    "    os.system('cls' if os.name=='nt' else 'clear')\n",
    "\n",
    "#################################################################\n",
    "# USEFUL FUNCTIONS\n",
    "#################################################################\n",
    "\n",
    "def binary_search(target, low:int, high:int, func, *func_args, reverse_search=False):\n",
    "    \"\"\" Generic binary search function that takes a target to find,\n",
    "    low and high values to start with, and a function to run, plus its args.\n",
    "    Implicitly returns None if the search is exceeded. \"\"\"\n",
    "\n",
    "    res = None  # just set it to something that isn't the target\n",
    "    candidate = 0  # initialise; we'll set it to the mid point in a second\n",
    "\n",
    "    while low < high:  # search exceeded\n",
    "        candidate = int((low+high) // 2)  # pick mid-point of our low and high\n",
    "        res = func(candidate, *func_args) # run our function, whatever it is\n",
    "        logger.debug(\"%d -> %d\", candidate, res)\n",
    "        if res == target:\n",
    "            return candidate  # solution found\n",
    "\n",
    "        comp = operator.lt if not reverse_search else operator.gt\n",
    "        if comp(res, target):\n",
    "            low = candidate\n",
    "        else:\n",
    "            high = candidate\n",
    "\n",
    "def merge_intervals(intervals: list[list]) -> list[list]:\n",
    "    \"\"\" Takes intervals in the form [[a, b][c, d][d, e]...]\n",
    "    Intervals can overlap.  Compresses to minimum number of non-overlapping intervals. \"\"\"\n",
    "    intervals.sort()\n",
    "    stack = []\n",
    "    stack.append(intervals[0])\n",
    "\n",
    "    for interval in intervals[1:]:\n",
    "        # Check for overlapping interval\n",
    "        if stack[-1][0] <= interval[0] <= stack[-1][-1]:\n",
    "            stack[-1][-1] = max(stack[-1][-1], interval[-1])\n",
    "        else:\n",
    "            stack.append(interval)\n",
    "\n",
    "    return stack\n",
    "\n",
    "@cache\n",
    "def get_factors(num: int) -> set[int]:\n",
    "    \"\"\" Gets the factors for a given number. Returns a set[int] of factors.\n",
    "        # E.g. when num=8, factors will be 1, 2, 4, 8 \"\"\"\n",
    "    factors = set()\n",
    "\n",
    "    # Iterate from 1 to sqrt of 8,\n",
    "    # since a larger factor of num must be a multiple of a smaller factor already checked\n",
    "    for i in range(1, int(num**0.5) + 1):  # e.g. with num=8, this is range(1, 3)\n",
    "        if num % i == 0: # if it is a factor, then dividing num by it will yield no remainder\n",
    "            factors.add(i)  # e.g. 1, 2\n",
    "            factors.add(num//i)  # i.e. 8//1 = 8, 8//2 = 4\n",
    "\n",
    "    return factors\n",
    "\n",
    "def to_base_n(number: int, base: int):\n",
    "    \"\"\" Convert any integer number into a base-n string representation of that number.\n",
    "    E.g. to_base_n(38, 5) = 123\n",
    "\n",
    "    Args:\n",
    "        number (int): The number to convert\n",
    "        base (int): The base to apply\n",
    "\n",
    "    Returns:\n",
    "        [str]: The string representation of the number\n",
    "    \"\"\"\n",
    "    ret_str = \"\"\n",
    "    curr_num = number\n",
    "    while curr_num:\n",
    "        ret_str = str(curr_num % base) + ret_str\n",
    "        curr_num //= base\n",
    "\n",
    "    return ret_str if number > 0 else \"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YtEtBnfNUKw"
   },
   "source": [
    "### Generic Initialisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbdA-geUNqAF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "FOLDER = \"aoc\"\n",
    "YEAR = 2023\n",
    "logger_identifier = \"aoc\" + str(YEAR)\n",
    "logger = retrieve_console_logger(logger_identifier)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y68fv1BebLsG"
   },
   "source": [
    "# Days\n",
    "\n",
    "Here you'll find a template to build a solution for a given day, and then the solutions for all days in this event.\n",
    "\n",
    "To copy the template day, select all the cells in the `Day n` template, add a new cell at the end, and then paste the cells there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FT4HLZLwevr"
   },
   "source": [
    "---\n",
    "## Day 1: Trebuchet?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VoMC3MaJ1I9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = 1\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNvM0hOF0tBR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.INFO)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAh6_AWRbYPo"
   },
   "source": [
    "### Day 1 Part 1\n",
    "\n",
    "And we're off!!  Welcome to the first day of Advent of Code 2023!!\n",
    "\n",
    "Today was a troublesome start for me.  My Internet was out.  (Thanks, Virgin Media.) So, after unsuccessful restarts of the router and home network, I switched over to mobile hotspot.\n",
    "\n",
    "Part 1 is pretty trivial, as we've come to expect. You need to identify the first and last digits of each line of a string. Concatenating these two values gives you a two digit number, which the puzzle calls a _calibration value_. Then we just add them all together.\n",
    "\n",
    "**My Solution**\n",
    "\n",
    "- For each line, I simply loop through each char in the line, and use the `isdigit()` method to determine if it is a digit.\n",
    "- Then repeat, but this time, looping from the end using the Python construct `[::-1]` which just means: start from the end, and then step with increments of `-1`. I.e. move backwards.\n",
    "- Finally, concatenate the two digits (still as strings), to update a two digit number. Then convert it to an int.\n",
    "- Store all these ints in a list.  And at the end, return the sum of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = {\"one\": 1,\n",
    "             \"two\": 2,\n",
    "             \"three\": 3,\n",
    "             \"four\": 4,\n",
    "             \"five\": 5,\n",
    "             \"six\": 6,\n",
    "             \"seven\": 7,\n",
    "             \"eight\": 8,\n",
    "             \"nine\": 9\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhWomZ6ewNi-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def solve(data: list[str], with_spelled_nums=False):\n",
    "    calibration_vals = []\n",
    "    for line in data:\n",
    "        logger.debug(line)\n",
    "        \n",
    "        first_posn = 1e6        \n",
    "        last_posn = -1\n",
    "        first = last = \"\"\n",
    "\n",
    "        for posn, char in enumerate(line): # read from start\n",
    "            if char.isdigit():\n",
    "                first_posn = posn\n",
    "                first = char\n",
    "                break\n",
    "            \n",
    "        for posn, char in enumerate(line[::-1]): # read from the end\n",
    "            if char.isdigit():\n",
    "                last_posn = len(line) - posn - 1 # remember, we're now counting from the end!!\n",
    "                last = char\n",
    "                break\n",
    "\n",
    "        if with_spelled_nums:\n",
    "            for num_word in num_words:\n",
    "                posn = line.find(num_word)\n",
    "                if 0 <= posn < first_posn:\n",
    "                    first_posn = posn\n",
    "                    first = str(num_words[num_word]) # map it back to int\n",
    "            \n",
    "                posn = line.rfind(num_word)\n",
    "                if posn > last_posn:\n",
    "                    last_posn = posn\n",
    "                    last = str(num_words[num_word]) # map to the int\n",
    "        \n",
    "        calibration_vals.append(int(first + last))\n",
    "    \n",
    "    return sum(calibration_vals)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uw4xFe7R7jf0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"1abc2\", \"pqr3stu8vwx\", \"a1b2c3d4e5f\", \"treb7uchetabcdef\"]]\n",
    "sample_answers = [142]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6ARzwH_AHU0"
   },
   "source": [
    "### Day 1 Part 2\n",
    "\n",
    "For Day 1, this wasn't quite as trivial as I was expecting! Now we have to also find the positions of any \"spelled\" versions of the digits 0-9.\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- Create a `dict` to store the spelled versions of 1-9, and map them to their respective int values.\n",
    "- Now, with each line, perform the same code as we did for Part 1 to find the first and last positions of the digit representation. \n",
    "  - But this time, store the positions found, as well as the values. I use the [`enumerate()`](https://aoc.just2good.co.uk/python/enumerate) to give me the current position of each char in my line.\n",
    "  - Be really careful when storing the position when counting from the end.  This tripped me up for a couple of minutes!!  When we're looping through chars from the end, backwards, we want to store the position in the string, not the current enumeration value. \n",
    "- Then, run another loop that looks for each spelled number in our dict of spelled numbers.\n",
    "  - To search for our current spelled number in our line from the start, using the `find()` method.\n",
    "  - To search for our current spelled number in our line from the end, using the `rfind()` method.\n",
    "  - Whenever we find a spelled number, check whether we found it at a position that is earlier / later (as required) than the digit we found before.\n",
    "  - Whenever I find such a spelled number, I convert the int value in the dict to a string, so that I can concatenate the string values, just as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcJdRHyK8TRY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"two1nine\", \n",
    "                  \"eightwothree\", \n",
    "                  \"abcone2threexyz\", \n",
    "                  \"xtwone3four\", \n",
    "                  \"4nineeightseven2\", \n",
    "                  \"zoneight234\", \n",
    "                  \"7pqrstsixteen\"]]\n",
    "sample_answers = [281]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input, with_spelled_nums=True), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve(input_data, with_spelled_nums=True)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 2: Cube Conundrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"2\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 2 Part 1\n",
    "\n",
    "In each game, we have a bag containing some number of red, green and blue cubes.  The bag is sampled several times per game. Our input data shows these random samples for each game. E.g.\n",
    "\n",
    "```\n",
    "Game 1: 3 blue, 4 red; 1 red, 2 green, 6 blue; 2 green\n",
    "Game 2: 1 blue, 2 green; 3 green, 4 blue, 1 red; 1 green, 1 blue\n",
    "Game 3: 8 green, 6 blue, 20 red; 5 blue, 4 red, 13 green; 5 green, 1 red\n",
    "Game 4: 1 green, 3 red, 6 blue; 3 green, 6 red; 3 green, 15 blue, 14 red\n",
    "Game 5: 6 red, 1 blue, 3 green; 2 blue, 1 red, 2 green\n",
    "```\n",
    "\n",
    "**Determine which games would have been possible if the bag had been loaded with only 12 red cubes, 13 green cubes, and 14 blue cubes. What is the sum of the IDs of those games?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- I create a CubeSample [class](https://aoc.just2good.co.uk/python/classes) to store each sample, i.e. the number of r, g, b cubes.\n",
    "- I create a Game class to store the game ID and all the samples for that game.\n",
    "- I parse the input with [regex](https://aoc.just2good.co.uk/python/regex). My approach was:\n",
    "  - Split the game line into the game part, and the samples part. Retrieving the game ID is trivial.\n",
    "  - For the samples, use a regex that looks for \"n colour\", and use a regex `finditer()` to find all matches for this.\n",
    "  - Create a [defaultdict](https://aoc.just2good.co.uk/python/defaultdict) that sets the initial values for r, g, b to 0.\n",
    "  - Then iterate over the matches from `finditer()``, and update the r, g, b as required.\n",
    "- Now I simply loop through each game. \n",
    "  - For each game, I loop through the samples. If any sample has more r, g, b than we're allowed, then this game is impossible.\n",
    "  - Build up a list of the games that are possible. Then sum up the IDs with a [comprehension](https://aoc.just2good.co.uk/python/comprehensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CubeSample:\n",
    "    \"\"\" A sample contains a number of red, blue, and green cubes \"\"\"\n",
    "    red: int=0\n",
    "    blue: int=0\n",
    "    green: int=0\n",
    "\n",
    "@dataclass\n",
    "class Game:\n",
    "    \"\"\" A game has an ID, and a random number of samples \"\"\"\n",
    "    id: int\n",
    "    samples: list[CubeSample]\n",
    "\n",
    "def parse_input(data) -> list[Game]:\n",
    "    game_pattern = re.compile(r\"Game\\s+(\\d+)\")\n",
    "    cubes_pattern = re.compile(r\"(\\d+)\\s*(\\w+)\") # E.g. \"3 blue\" \n",
    "    \n",
    "    games = []\n",
    "    for line in data:\n",
    "        game_part, samples_part = line.split(\":\")\n",
    "        game_id = int(game_pattern.findall(game_part)[0])\n",
    "        samples = samples_part.split(\";\")\n",
    "        \n",
    "        cube_samples = []\n",
    "        for sample in samples:\n",
    "            matches = cubes_pattern.finditer(sample)\n",
    "            cube_counts = {\"red\": 0, \"green\": 0, \"blue\": 0} # reset cube counts for each sample\n",
    "            for match in matches:\n",
    "                cube_count, cube_colour = match.groups()\n",
    "                cube_counts[cube_colour] = int(cube_count)\n",
    "            \n",
    "            cube_samples.append(CubeSample(cube_counts[\"red\"], cube_counts[\"blue\"], cube_counts[\"green\"]))\n",
    "        \n",
    "        games.append(Game(game_id, cube_samples))\n",
    "        \n",
    "    return games\n",
    "      \n",
    "def solve(games: list[Game]):\n",
    "    \"\"\" Return the sum of the IDs for games that are possible. \"\"\"\n",
    "    \n",
    "    allowed_red = 12\n",
    "    allowed_green = 13\n",
    "    allowed_blue = 14\n",
    "    \n",
    "    possible_games = []\n",
    "    for game in games:\n",
    "        possible = True\n",
    "        for game_sample in game.samples:\n",
    "            if (game_sample.red > allowed_red\n",
    "                    or game_sample.green > allowed_green\n",
    "                    or game_sample.blue > allowed_blue):\n",
    "                possible = False\n",
    "            \n",
    "        if possible:\n",
    "            possible_games.append(game)\n",
    "            \n",
    "    return sum(game.id for game in possible_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"Game 1: 3 blue, 4 red; 1 red, 2 green, 6 blue; 2 green\",\n",
    "                  \"Game 2: 1 blue, 2 green; 3 green, 4 blue, 1 red; 1 green, 1 blue\",\n",
    "                  \"Game 3: 8 green, 6 blue, 20 red; 5 blue, 4 red, 13 green; 5 green, 1 red\",\n",
    "                  \"Game 4: 1 green, 3 red, 6 blue; 3 green, 6 red; 3 green, 15 blue, 14 red\",\n",
    "                  \"Game 5: 6 red, 1 blue, 3 green; 2 blue, 1 red, 2 green\"]\n",
    "                ]\n",
    "sample_answers = [8]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    sample_games = parse_input(curr_input)\n",
    "    validate(solve(sample_games), curr_ans) # test with sample data\n",
    "\n",
    "games = parse_input(input_data)\n",
    "soln = solve(games)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 2 Part 2\n",
    "\n",
    "**For each game, find the minimum set of cubes that must have been present. What is the sum of the power of these sets?**\n",
    "\n",
    "Here, we need to look at all the samples for a given game, and determine the largest number of cubes shown of each colour, across the samples.\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "Fortunately, since we already have our list of Games, this is now trivial to do. Simply iterate through the games, and for each game, iterate over all the samples. For each sample, determine if the number of any of r, g, b is greater than the biggest number of which we've found so far.\n",
    "\n",
    "Then, multiply the r, g, b to get the `power` of the game. Then sum up all the powers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(games: list[Game]):\n",
    "    \"\"\" Return the sum of the powers of all the games \"\"\"\n",
    "    game_powers = []\n",
    "    for game in games:\n",
    "        max_blue = max_green = max_red = 0\n",
    "        for game_sample in game.samples:\n",
    "            max_blue = max(max_blue, game_sample.blue)\n",
    "            max_green = max(max_green, game_sample.green)\n",
    "            max_red = max(max_red, game_sample.red)\n",
    "     \n",
    "        # We're told that power = product of r, g, b   \n",
    "        game_powers.append(max_blue*max_green*max_red)\n",
    "    \n",
    "    return sum(game_powers)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"Game 1: 3 blue, 4 red; 1 red, 2 green, 6 blue; 2 green\",\n",
    "                  \"Game 2: 1 blue, 2 green; 3 green, 4 blue, 1 red; 1 green, 1 blue\",\n",
    "                  \"Game 3: 8 green, 6 blue, 20 red; 5 blue, 4 red, 13 green; 5 green, 1 red\",\n",
    "                  \"Game 4: 1 green, 3 red, 6 blue; 3 green, 6 red; 3 green, 15 blue, 14 red\",\n",
    "                  \"Game 5: 6 red, 1 blue, 3 green; 2 blue, 1 red, 2 green\"]\n",
    "                ]\n",
    "sample_answers = [2286]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    sample_games = parse_input(curr_input)\n",
    "    validate(solve_part2(sample_games), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve_part2(games)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 3: Gear Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"3\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3 Part 1\n",
    "\n",
    "I'm finding AoC fairly tough this year. I wasn't expecting the early challenges to be this tricky.\n",
    "\n",
    "Anyhoo...\n",
    "\n",
    "We're given a 2D grid, called the _engine schematic_. That grid contains numbers, periods (which should be ignored), and symbols (anything else). We need to determine the _part numbers_, which we are told are any numbers adjacent to a symbol.\n",
    "\n",
    "It looks like this:\n",
    "\n",
    "```text\n",
    "467..114..\n",
    "...*......\n",
    "..35..633.\n",
    "......#...\n",
    "617*......\n",
    ".....+.58.\n",
    "..592.....\n",
    "......755.\n",
    "...$.*....\n",
    ".664.598..\n",
    "```\n",
    "\n",
    "**What is the sum of all of the part numbers in the engine schematic?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- I get to reuse one of my [helper classes](https://aoc.just2good.co.uk/python/reusable_code).  Yay!  \n",
    "  - I'm going to reuse my `Point` class, which stores x, y coordinates, but also has the ability to return all of its adjacent neighbours.\n",
    "  - I'm going to reuse my `Grid` class, which already knows how to create a 2D grid, iterate through the points in the grid, get the values at any location, and determine if a specied point is in the grid.\n",
    "- I create a new [class](https://aoc.just2good.co.uk/python/classes) called `EngineGrid` by extending `Grid`.\n",
    "  - This class knows how to return all the points that are symbols.\n",
    "- To solve:\n",
    "  - First, get all the symbol locations. This is trivial.\n",
    "  - Get the value of this symbol, and store it alongside the location in a dictionary.\n",
    "  - Then, get all the neighbour locations for each symbol location.\n",
    "  - Check if this neighbour is part of a part number range we've already found.  If it is, then we don't need to check this neighbour; we already know it's part of a part number.\n",
    "  - If the neighbour is a valid location, check if it is a digit. If it is, then this location is _in_ a part number. If so, use the method `get_part_number_continugous_range()` to determine the full set of points that make up this part number. It works by taking this location on this line of the grid, and walking backwards and fowards, until the value found is no longer a digit. We return the full set of contiguous digits as a part number range.\n",
    "  - Add this to the [set](https://aoc.just2good.co.uk/python/sets) of ranges for this symbol, i.e. in the `ranges_for_symbol` dict. Note, here I'm using a [defaultdict](https://aoc.just2good.co.uk/python/defaultdict), such that I can initialise each entry with an empty `set`, and then add to the set whenever we find a range.\n",
    "  - Also, add all the points from this range to a `set` called `all_range_locations_for_symbol`. We use this when checking each neighbour, to see if this neighbour is already part of a range associated with this symbol.\n",
    "  - Also, determine the part number for this range, using our `get_part_number_for_range()` method. Store the result in a `dict` called `part_range_to_num`, where the key is the range `tuple` itself.\n",
    "  - Finally, we can sum up all the part number values, by summing the values from the `dict` of `part_range_to_num`.\n",
    "\n",
    "### Day 3 Part 2\n",
    "\n",
    "Now we're told we need to find symbols that are _gears_, i.e. the symbols that are simply `*`. And we need to find all the gears that have exactly two adjacent part numbers. Where this is true, the product of the two part numbers is the _gear ratio_. Then we need to add up all the gear ratios.\n",
    "\n",
    "**What is the sum of all of the gear ratios in your engine schematic?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "This is a fairly trivial addition. We already have the `ranges_for_symbol` dictionary. So, in our loop that processes each symbol, we now:\n",
    "\n",
    "- Check if the symbol is a gear, i.e. `*`\n",
    "- If so, check how many ranges are associated with this symbol.\n",
    "- If there are exactly two ranges, then we need to determine the part number values of this ranges, and multiply them together to obtain our `gear_ratio` for this gear.\n",
    "- Finally, add up all the gear ratios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EngineGrid(Grid):\n",
    "    def get_symbol_locations(self) -> list[Point]:\n",
    "        \"\"\" Return all locations that contain a symbol \"\"\"\n",
    "        symbol_locations = [point for point in self.all_points() if self._is_symbol(point)]\n",
    "        return symbol_locations\n",
    "    \n",
    "    def _is_symbol(self, point: Point) -> bool:\n",
    "        \"\"\" A symbol is anything that is not numeric, or not a period. \"\"\"\n",
    "        val = str(self.value_at_point(point))\n",
    "        if val.isdigit():\n",
    "            return False\n",
    "        \n",
    "        if val == \".\":\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def get_part_number_contiguous_range(self, point: Point) -> tuple[Point, ...]:\n",
    "        \"\"\" Given a point within a part number, we want to return the entire range or points that make up that part number. \"\"\"\n",
    "        line = self.array[point.y] # get the row this point is on\n",
    "    \n",
    "        # Find the start of the contiguous digits\n",
    "        start = point.x\n",
    "        while start > 0 and line[start - 1].isdigit():\n",
    "            start -= 1\n",
    "\n",
    "        # Find the end of the contiguous digits\n",
    "        end = point.x\n",
    "        while end < len(line) - 1 and line[end + 1].isdigit():\n",
    "            end += 1\n",
    "\n",
    "        # Return the contiguous locations that make up a part number\n",
    "        contiguous_locations = [Point(x, point.y) for x in range(start, end+1)]\n",
    "        return tuple(contiguous_locations)\n",
    "\n",
    "    def get_part_number_for_range(self, part_range: tuple[Point, ...]) -> int:\n",
    "        \"\"\" Given a set of points that make up a part number, return the part number they contain. \"\"\"\n",
    "        part_num = \"\"\n",
    "        for point in part_range:\n",
    "            part_num += self.value_at_point(point)\n",
    "            \n",
    "        return int(part_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(input_data) -> tuple[int, int]:\n",
    "    \"\"\" Part 1: determine the sum of all part numbers, where a part number is \n",
    "                a full set of continguous digits adjacent to a symbol. \n",
    "        Part 2: determine the gear ratios, where a gear ratio is the product of the part numbers\n",
    "                adjacent to a gear, for any gear that has exactly two adjacent part numbers. \"\"\"\n",
    "    points_and_symbols = [] # (point, value-for-point)\n",
    "    part_number_ranges = set() # = all the points in a range. Use set so we don't double count ranges.\n",
    "    ranges_for_symbol = defaultdict(set) # { (point, value), {ranges} }\n",
    "    part_range_to_num = {} # so we can cache the part number corresponding to a range\n",
    "    gear_ratios = [] # a gear ratio is given by the product of its two adjacent part numbers\n",
    "    \n",
    "    engine = EngineGrid(input_data)\n",
    "    \n",
    "    # get the locations of symbols, e.g. * ?, but not .\n",
    "    symbol_locations = engine.get_symbol_locations()\n",
    "    for point in symbol_locations:\n",
    "        all_range_locations_for_symbol = set()\n",
    "        symbol_val = engine.value_at_point(point)\n",
    "        points_and_symbols.append((point, symbol_val))\n",
    "        \n",
    "        # get adjacent locations to this symbol\n",
    "        for neighbour in point.neighbours():\n",
    "            if neighbour in all_range_locations_for_symbol:\n",
    "                continue    # we don't care about neighbours in ranges we've already found\n",
    "            \n",
    "            if engine.valid_location(neighbour): # check it is in the grid\n",
    "                val = str(engine.value_at_point(neighbour))\n",
    "                if val.isdigit(): # this neighbour is a point in a part number\n",
    "                    range_for_locn = engine.get_part_number_contiguous_range(neighbour) # gets range as tuple\n",
    "                    part_range_to_num[range_for_locn] = engine.get_part_number_for_range(range_for_locn)\n",
    "                    ranges_for_symbol[(point, symbol_val)].add(range_for_locn) # add this range for this symbol\n",
    "                    all_range_locations_for_symbol.update(set(range_for_locn)) # add all locations from this range\n",
    "                \n",
    "        if symbol_val == \"*\": # if this is a gear\n",
    "            gear_ranges = ranges_for_symbol[(point, symbol_val)]\n",
    "            if gear_ranges and len(gear_ranges) == 2: # if this gear has exactly two ranges\n",
    "                gear_part_nums = [part_range_to_num[gear_range] for gear_range in gear_ranges]\n",
    "                gear_ratios.append(reduce(operator.mul, gear_part_nums))\n",
    "                \n",
    "        part_number_ranges.update(ranges_for_symbol[(point, symbol_val)])\n",
    "        \n",
    "    return sum(part_range_to_num.values()), sum(gear_ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"467..114..\",\n",
    "                  \"...*......\",\n",
    "                  \"..35..633.\",\n",
    "                  \"......#...\",\n",
    "                  \"617*......\",\n",
    "                  \".....+.58.\",\n",
    "                  \"..592.....\",\n",
    "                  \"......755.\",\n",
    "                  \"...$.*....\",\n",
    "                  \".664.598..\"]]\n",
    "sample_answers = [(4361, 467835)]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "part_num_sum, gear_ratios_sum = solve(input_data)\n",
    "logger.info(f\"Part 1 soln: {part_num_sum=}\")\n",
    "logger.info(f\"Part 2 soln: {gear_ratios_sum=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 4: Scratchcards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"4\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.INFO)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 4 Part 1\n",
    "\n",
    "We have a set of scratch cards.  Each card has an `id`, then a set of `winning` numbers, then a set of `actual` numbers that were scratched. The score of each scratch card depends on the number of winning numbers we have matched. The first match gives us 1 point, and each additional match doubles the score.\n",
    "\n",
    "**How points are the pile of scratch cards worth, in total?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "This is pretty simple.\n",
    "\n",
    "- I create a `ScratchCard` [dataclass](https://aoc.just2good.co.uk/python/classes#dataclass) which:\n",
    "  - Stores the card ID.\n",
    "  - Stores the winning numbers, and the scratched numbers, both as sets.  I want to use sets because I will want to determine the intersection of these two sets, i.e. how many winning numbers were matched. [Set algebra](https://aoc.just2good.co.uk/python/sets) makes this super easy.\n",
    "  - Has a `score()` method which determines the score, according to the rules.\n",
    "- Then I parse the input data using [regex](https://aoc.just2good.co.uk/python/regex). Let me explain how \\\n",
    "  `Card(?:\\s+)(\\d+):\\s*((?:\\d+\\s*)+)(?: \\|\\s+)((?:\\d+\\s*)+)` works:\n",
    "  - `(\\d+)`: This is a capturing group that matches one or more digits. The `\\d` is a shorthand character class that matches any digit (0-9), and the `+` means one or more of the preceding element. This is how I capture the `id`.\n",
    "  - `\\s*`: This matches zero or more whitespace characters. The `*` means zero or more of the preceding element.\n",
    "  - `((?:\\d+\\s*)+)`: This is a capturing group containing a non-capturing group. The non-capturing group `(?:\\d+\\s*)` matches one or more digits followed by zero or more whitespace characters. The outer capturing group with the `+` at the end repeats this pattern one or more times. This is how I capture ALL of the `winning` numbers.\n",
    "  - `(?: \\|\\s+)`: This is another non-capturing group. It matches a literal space, followed by a vertical bar `|`, followed by one or more whitespace characters.\n",
    "  - `((?:\\d+\\s*)+)`: The same as before. This is how I capture ALL of the `actual` numbers.\n",
    "- I use this regex to parse each line:\n",
    "  - This gives me the `id`, a string containing all the `winning` numbers, and a string containing all the `actual` numbers.\n",
    "  - I split the `winning` and `actual` numbers at the space, using `split()`. This gives me a list of string values. Then I convert the string values to `int` using `map()`, and finally convert each `list` to a `set`.\n",
    "  - Now I can create an instance of `ScoreCard` from the `id` and the two sets.\n",
    "\n",
    "- Finally, just add up all the scores from each card using `sum` and a [list comprehension](https://aoc.just2good.co.uk/python/comprehensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ScratchCard:\n",
    "    \"\"\" A scratchcard has an ID, winning numbers, and (actual) numbers scratched. \"\"\"\n",
    "    id: int\n",
    "    winning: set[int]\n",
    "    actual: set[int]\n",
    "    \n",
    "    def matches(self) -> int:\n",
    "        \"\"\" Return the number of winning numbers we have matched. \"\"\"\n",
    "        return len(self.winning & self.actual)\n",
    "    \n",
    "    def score(self) -> int:\n",
    "        \"\"\" For every winning number, double the score. Examples scores...\n",
    "        0 matches -> 0\n",
    "        1 match   -> 1\n",
    "        2 matches -> 2\n",
    "        3 matches -> 4, etc \"\"\"\n",
    "        num_matches = self.matches()\n",
    "        return 2**(num_matches-1) if num_matches > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cards(data) -> list[ScratchCard]:\n",
    "    scratch_card_pattern = r\"Card(?:\\s+)(\\d+):\\s*((?:\\d+\\s*)+)(?: \\|\\s+)((?:\\d+\\s*)+)\"\n",
    "    scratch_card_matcher = re.compile(scratch_card_pattern)\n",
    "    scratch_cards = []\n",
    "    for line in data:\n",
    "        id, winning, actual = scratch_card_matcher.findall(line)[0]\n",
    "        \n",
    "        id = int(id)\n",
    "        winning = set(map(int, winning.split()))\n",
    "        actual = set(map(int, actual.split()))\n",
    "        scratch_cards.append(ScratchCard(id, winning, actual))\n",
    "        \n",
    "    return scratch_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(cards: list[ScratchCard]):  \n",
    "    return sum(card.score() for card in cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"Card 1: 41 48 83 86 17 | 83 86  6 31 17  9 48 53\",\n",
    "                  \"Card 2: 13 32 20 16 61 | 61 30 68 82 17 32 24 19\",\n",
    "                  \"Card 3:  1 21 53 59 44 | 69 82 63 72 16 21 14  1\",\n",
    "                  \"Card 4: 41 92 73 84 69 | 59 84 76 51 58  5 54 83\",\n",
    "                  \"Card 5: 87 83 26 28 32 | 88 30 70 12 93 22 82 36\",\n",
    "                  \"Card 6: 31 18 13 56 72 | 74 77 10 23 35 67 36 11\"]\n",
    "]\n",
    "sample_answers = [13]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    sample_cards = parse_cards(curr_input)  \n",
    "    validate(solve_part1(sample_cards), curr_ans) # test with sample data\n",
    "\n",
    "cards = parse_cards(input_data)\n",
    "soln = solve_part1(cards)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 4 Part 2\n",
    "\n",
    "Now we're told that there's no such thing as a _score_. Instead scratchcards only cause you to win more scratchcards equal to the number of winning numbers you have. You win copies of the scratchcards below the winning card equal to the number of matches.\n",
    "\n",
    "**how many total scratchcards do you end up with?**\n",
    "\n",
    "**My solution**\n",
    "\n",
    "I spent several minutes thinking about how to solve this problem, before writing any code.  At first, I was thinking about some sort of `while loop` that iterates through cards, and only exits when there are no more cards. I was thinking I could insert duplicate cards into the list as I iterate.\n",
    "\n",
    "But then I realised that I didn't need to do that.  I simply needed to keep a count of how many there are of each card ID. I can do that with a `dict`. So my strategy:\n",
    "\n",
    "- Create a `dict` that stores the number of cards for each card ID.\n",
    "- Loop through all the cards we have to initialise the dict. There will be one of each.\n",
    "- Then, loop through the cards again, in order.  For each card:\n",
    "  - Get the number of matches.\n",
    "  - Use this number of matches to determine the successive cards that need to be duplicated.\n",
    "  - Increment the count of each of those successive cards, by the count of the card we're currently on. (Because it might not be 1.)\n",
    "\n",
    "Even though it took my tiny brain a little while to realise this approach, the actual code is pretty trivial.\n",
    "\n",
    "The solution is fast, and only takes a couple of milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(cards: list[ScratchCard]):\n",
    "    card_counts = {}\n",
    "    for card in cards: # initialise our card counts \n",
    "        card_counts[card.id] = 1\n",
    "    \n",
    "    for card in cards:\n",
    "        count_this_card = card_counts[card.id]\n",
    "        for i in range(card.id+1, card.id+1+card.matches()):\n",
    "            card_counts[i] += count_this_card\n",
    "    \n",
    "    logger.debug(card_counts)\n",
    "    total_card_count = sum(card_counts.values())\n",
    "    return total_card_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"Card 1: 41 48 83 86 17 | 83 86  6 31 17  9 48 53\",\n",
    "                  \"Card 2: 13 32 20 16 61 | 61 30 68 82 17 32 24 19\",\n",
    "                  \"Card 3:  1 21 53 59 44 | 69 82 63 72 16 21 14  1\",\n",
    "                  \"Card 4: 41 92 73 84 69 | 59 84 76 51 58  5 54 83\",\n",
    "                  \"Card 5: 87 83 26 28 32 | 88 30 70 12 93 22 82 36\",\n",
    "                  \"Card 6: 31 18 13 56 72 | 74 77 10 23 35 67 36 11\"]\n",
    "]\n",
    "sample_answers = [30]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    sample_cards = parse_cards(curr_input)  \n",
    "    validate(solve_part2(sample_cards), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve_part2(cards)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 5: If You Give A Seed A Fertilizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"5\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.INFO)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 5 Part 1\n",
    "\n",
    "Our input includes:\n",
    "\n",
    "- Seeds to be planted, as ints.\n",
    "- Maps, in the the format: \n",
    "  - destination-range-start, source-range-start, range-length. \\\n",
    "    The source and destination ranges will be the same length.\n",
    "- We have the following maps:\n",
    "  - seed-to-soil\n",
    "  - soil-to-fertilizer\n",
    "  - fertilizer-to-water\n",
    "  - water-to-light\n",
    "  - light-to-temperature\n",
    "  - temperature-to-humidity\n",
    "  - humidity-to-location\n",
    "\n",
    "E.g. \n",
    "\n",
    "```\n",
    "soil-to-fertilizer map:\n",
    "0 15 37\n",
    "37 52 2\n",
    "39 0 15\n",
    "```\n",
    "\n",
    "Unmapped source numbers map to the same destination number.\n",
    "\n",
    "**What is the lowest location number that corresponds to any of the initial seed numbers?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- We need a rules engine that takes a value and determines the target value for that map.\n",
    "- I've done this by creating a class called `GardinerMap`.\n",
    "- Each instance of `GardinerMap` contains the source and target ranges for that map type.\n",
    "- The `GardinerMap`:\n",
    "  - Stores all source ranges in that map as a list of tuples, with each tuple being `(source start, range length)`.\n",
    "  - Stores all destination ranges in that map as a list of tuples, with each tuple being `(destination start, range length)`.\n",
    "  - All the actual mapping is done in the method `get_target()`. It iterates through each range, and determines if our input value is part of that range. If it is, we apply the required _shift_, which is the difference between the destination range start and the source range start. Now we've finished mapping, so we return the mapped value.\n",
    "\n",
    "We need to start by passing the seed value to `get_target()` of our first `GardinerMap`. This returns a new value.  We then take this value and pass it into `get_target()` of the second `GardinerMap`.  And so on, until we've done this for every `GardinerMap`.\n",
    "\n",
    "\n",
    "\n",
    "  - Finally, back in our `solve_part1()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GardinerMap():\n",
    "    source_type: str\n",
    "    dest_type: str\n",
    "    \n",
    "    src_ranges: list[tuple[int,int]] = field(default_factory=list) # [(src_start, length), (src_start, length), ... ]\n",
    "    dest_ranges: list[tuple[int,int]] = field(default_factory=list) # [(dest_start, length), (dest_start, length), ... ]\n",
    "    \n",
    "    def add_range(self, src_start: int, dest_start: int, range_length: int):\n",
    "        \"\"\" Add a range which contains src start, dest start, and the length of the range \"\"\"\n",
    "        self.src_ranges.append((src_start, range_length)) \n",
    "        self.dest_ranges.append((dest_start, range_length))\n",
    "        \n",
    "    def _sort_ranges(self):\n",
    "        \"\"\" Sort the range into ascending numeric, based on source range start values \"\"\"\n",
    "        \n",
    "        # Sort src_ranges and get the order of indices\n",
    "        index_order = sorted(range(len(self.src_ranges)), key=lambda i: self.src_ranges[i][0])\n",
    "\n",
    "        # Now sort both ranges\n",
    "        self.src_ranges = [self.src_ranges[i] for i in index_order]\n",
    "        self.dest_ranges = [self.dest_ranges[i] for i in index_order]\n",
    "\n",
    "    def finalise(self):\n",
    "        \"\"\" Sort the range into ascending numeric, based on source range start values \"\"\"\n",
    "        self._sort_ranges()\n",
    "        \n",
    "    def get_target(self, src_val: int):\n",
    "        \"\"\" Map a source value to a target value \"\"\"\n",
    "        target = src_val # if our source isn't in a range, then return the same value\n",
    "        \n",
    "        for i, curr_range in enumerate(self.src_ranges):\n",
    "            src_start = curr_range[0]\n",
    "            src_end = curr_range[0] + curr_range[1] # exclusive end\n",
    "            if src_start <= src_val < src_end: # if our source is in a range, then apply the shift\n",
    "                target = src_val - src_start + self.dest_ranges[i][0]\n",
    "                break # we've mapped the value, so no more ranges need to be checked\n",
    "        \n",
    "        return target\n",
    "\n",
    "    # For Part 2\n",
    "    def map_intervals(self, src_intervals: list[tuple[int, int]]) -> list[tuple[int, int]]:\n",
    "        \"\"\" \n",
    "        Take input ranges and return output ranges.\n",
    "        - src_ranges: [(rng1_start, rng1_end), (rng2_start, rng2_end), ... ] \n",
    "        \"\"\"\n",
    "        new_intervals = []\n",
    "        \n",
    "        # Iterate through the ranges, just as we did when mapping a single seed\n",
    "        for i, curr_range in enumerate(self.src_ranges): \n",
    "            src_start = curr_range[0]\n",
    "            src_end = curr_range[0] + curr_range[1] # exclusive end\n",
    "            dest = self.dest_ranges[i][0]\n",
    "\n",
    "            temp_intervals = []\n",
    "\n",
    "            while src_intervals: # process the current interval       \n",
    "                (int_start, int_end) = src_intervals.pop()\n",
    "                \n",
    "                # Split the interval using the ranges in our map\n",
    "                #### Scenario 1: ####\n",
    "                # [int_start                                  int_end]\n",
    "                #            [src_start      src_end]\n",
    "                # [left     ][mid                   ][right          ]\n",
    "                #\n",
    "                #### Scenario 2: ####\n",
    "                #                [int_start         int_end]\n",
    "                #   [src_start     src_end]\n",
    "                #   [n/a        ][mid     ][right          ]\n",
    "                left = (int_start, min(int_end, src_start))\n",
    "                mid = (max(int_start, src_start), min(src_end, int_end))\n",
    "                right = (max(src_end, int_start), int_end)\n",
    "                \n",
    "                if left[1] > left[0]: # if left has +ve length, then scenario 1, else scenario 2\n",
    "                    temp_intervals.append(left) # pass on the interval unchanged\n",
    "                if mid[1] > mid[0]: # if mid has +ve length, then we need to apply the shift to this interval\n",
    "                    # furthermore, once mapped, we know this interval wont appear in another range\n",
    "                    new_intervals.append((mid[0]-src_start+dest, mid[1]-src_start+dest))\n",
    "                if right[1] > right[0]:  # if right has +ve length\n",
    "                    temp_intervals.append(right) # pass on the interval unchanged\n",
    "            \n",
    "            src_intervals = temp_intervals\n",
    "                    \n",
    "        return new_intervals + src_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data: list[str]) -> tuple[list[int], list[GardinerMap]]:\n",
    "    \"\"\" Parse input data, and convert to:\n",
    "    - seeds: list of int\n",
    "    - GardinerMap instances: list of GardinerMap \"\"\"\n",
    "    \n",
    "    seeds = []\n",
    "    source_maps = [] # Store our GardinerMap instances\n",
    "    \n",
    "    # Process the input file line by line, and switch modes based on the line last read\n",
    "    current_map = None \n",
    "    for line in data:\n",
    "        if line.startswith(\"seeds\"): # The first line contains the seeds values\n",
    "            _, seeds_part = line.split(\":\")\n",
    "            seeds = [int(x) for x in seeds_part.split()]\n",
    "        elif \"map:\" in line: # start of a map block; enter map processing mode\n",
    "            map_src, _, map_dest = line.split()[0].split(\"-\")\n",
    "            current_map = GardinerMap(map_src, map_dest) # initialise our GardinerMap\n",
    "        elif not line: # empty line, so finish with the current_map and add it to our list of GardinerMaps\n",
    "            if current_map:\n",
    "                current_map.finalise()\n",
    "                source_maps.append(current_map)  # add it to the list\n",
    "                current_map = None # and ensure we're no longer in map processing mode\n",
    "        else: # we're in map processing mode\n",
    "            assert line[0].isdigit(), \"Line must start with numbers\"\n",
    "            assert current_map, \"We must be adding to a Map now\"\n",
    "            dest_start, src_start, interval_len = [int(x) for x in line.split()]\n",
    "            current_map.add_range(src_start=src_start, dest_start=dest_start, range_length=interval_len)\n",
    "    \n",
    "    # We don't read a final empty line at the end of the input, but I still want to finalise the block\n",
    "    if current_map: # process the final map\n",
    "        current_map.finalise()\n",
    "        source_maps.append(current_map)   # add it to the dict\n",
    "            \n",
    "    return seeds, source_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    seeds, source_maps = parse_data(data)\n",
    "    location_map = {}\n",
    "    \n",
    "    logger.debug(f\"{seeds=}\")\n",
    "    for current_map in source_maps:\n",
    "        logger.debug(f\"{current_map=}\")\n",
    "        \n",
    "    for seed in seeds:\n",
    "        current_val = seed\n",
    "        for current_map in source_maps:\n",
    "            current_val = current_map.get_target(current_val)\n",
    "        \n",
    "        location_map[seed] = current_val\n",
    "    \n",
    "    logger.debug(f\"Seeds->locations: {location_map}\")\n",
    "    return min(location_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [\"\"\"seeds: 79 14 55 13\n",
    "\n",
    "seed-to-soil map:\n",
    "50 98 2\n",
    "52 50 48\n",
    "\n",
    "soil-to-fertilizer map:\n",
    "0 15 37\n",
    "37 52 2\n",
    "39 0 15\n",
    "\n",
    "fertilizer-to-water map:\n",
    "49 53 8\n",
    "0 11 42\n",
    "42 0 7\n",
    "57 7 4\n",
    "\n",
    "water-to-light map:\n",
    "88 18 7\n",
    "18 25 70\n",
    "\n",
    "light-to-temperature map:\n",
    "45 77 23\n",
    "81 45 19\n",
    "68 64 13\n",
    "\n",
    "temperature-to-humidity map:\n",
    "0 69 1\n",
    "1 0 69\n",
    "\n",
    "humidity-to-location map:\n",
    "60 56 37\n",
    "56 93 4\"\"\"]\n",
    "sample_answers = [35]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Day 5 Part 2\n",
    "\n",
    "_\"The values on the initial `seeds:` line come in pairs. Within each pair, the first value is the start of the range and the second value is the length of the range.\"_\n",
    "\n",
    "Uh oh, the values on the seeds line now describes ranges of seed numbers. In the real input, these numbers are huge. We're going to have way too many seeds to iterate over each seed.\n",
    "\n",
    "Instead of mapping a source seed to a target value, we need to map the entire interval. By the way... **I hate intervals.**\n",
    "\n",
    "I was struggling to get my head around this problem, so I created a sketch:\n",
    "\n",
    "![Fertiliser range mappings](https://aoc.just2good.co.uk/assets/images/fertiliser.png)\n",
    "\n",
    "Things to note:\n",
    "\n",
    "- We start with intervals that represent our seeds.\n",
    "- In each map, any given target range will always be the same length as the source range.\n",
    "- As we propagate our seed intervals through each map, the following rules will apply:\n",
    "  - If the interval sits outside a mapped range, the target interval will be the same.\n",
    "  - If the interval sits inside a mapped range, the target interval will be shifted by the appropriate delta.\n",
    "  - If the interval is both within and outside a mapped range, then we will need to split the interval. The part that is in the range will be moved by the appropriate delta.  That part that is out of the range will stay the same.\n",
    "  - An interval might span multiple ranges. In this scenario, the interval must be split accordingly which will create more intervals.\n",
    "  - Although it is possible to get intervals that are adjacent, a given source interval will never create overlapping intervals. Phew!\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- We can't map individual seed values, as there's just too many. Instead, we can map the intervals of seed values, and we only care about any boundaries. I.e. at the beginning and end of any mapping range, at the beginning and end of any seeds interval, and at any intersections.\n",
    "- I added a `map_intervals()` method to my `GardinerMap` class. The job of this method is to map the supplied intervals into a new set of intervals. It works like this:\n",
    "  - Take all the intervals supplied (which will initally be the seed intervals) as an input list.\n",
    "  - Then iterate through our mapping ranges, as we did before.\n",
    "  - For each range, determine the source start, source end, and destination start values, as we did before.\n",
    "  - Initialise `temp_intervals`. We use this to store intervals that we still need to map.\n",
    "  - Now, loop over each interval supplied as input. With each loop iteration, `pop` the current interval off the list.\n",
    "  - For each interval, determine the boundary conditions that make up the left, middle, and right parts of the interval, after intersecting with the current range. There may be no intersection, in which case only the `left` or `right` portion will be available.\n",
    "  - If we have a `left` or `right` portion, then these are not intersecting with the current range.  So add these to our `temp_intervals`, and we can test them with the next range.\n",
    "  - If we have a `mid` portion, then this portion is intersecting with the current range. If so, we need to _shift_ the range to obtain the new range, using exactly the same logic as we used for shifting individual values in Part 1. Note: once we've mapped an interval portion like this, that portion will not be mapped again by this GardinerMap.\n",
    "  - Now, at the end of the loop for this interval, continue to the next loop iteration, which will process the next interval with this range.\n",
    "  - Once we've processed all intervals for this range, re-populate `src_intervals` using the current intervals stored in `temp_intervals`. This allows us to test these intervals with the next range.\n",
    "  - Any intervals that are never mapped with a range will instead be passed on, as is.\n",
    "\n",
    "Back in our `solve_part2()` method, we iterate over all the `GardinerMap` instances, just as we did with Part 1. But this time, we're passing in the seed intervals into the `map_intervals` method of the first `GardinerMap`. This returns a new list of intervals, which we pass into the next `GardinerMap`. And so on.\n",
    "\n",
    "Eventually, we've left with the intervals generated by the _humidity-to-location_ map. This is a list of tuples, with each tuple containin the start and end values for that interval. So it's a trival matter to get the `min` of all the `start` values.\n",
    "\n",
    "And that's it!\n",
    "\n",
    "**That was a brutal day 5!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    location_map = {}\n",
    "    seeds, source_maps = parse_data(data)\n",
    "    \n",
    "    # convert seeds to intervals, of format [(start, end), ...] where end is exclusive\n",
    "    # let's call them intervals, to avoid confusion with the ranges we stored in our GardinerMap\n",
    "    seed_intervals = [(seeds[i], seeds[i]+seeds[i+1]) for i in range(0, len(seeds), 2)]\n",
    "    logger.debug(f\"{seed_intervals=}\")\n",
    "    \n",
    "    current_intervals = seed_intervals\n",
    "    for current_map in source_maps:\n",
    "        current_intervals = current_map.map_intervals(current_intervals)\n",
    "        logger.debug(f\"Mapping to {current_map.dest_type}: {current_intervals}\")\n",
    "        \n",
    "    return min(start for start, _ in current_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_answers = [46]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 6: Wait For It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"6\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 6 Part 1\n",
    "\n",
    "We're racing toy boats. There is a button that charges the boat; releasing the button sends off the boat. Charging causes the boat to go faster, but charging time counts towards overall race time.\n",
    "\n",
    "Our input shows multiple races as columns. Races have allotted durations, in ms. The record (best) distance for each race is recorded in mm. Our example has three races:\n",
    "\n",
    "```\n",
    "Time:      7  15   30\n",
    "Distance:  9  40  200\n",
    "```\n",
    "\n",
    "Our boat starts at 0mm/ms. Charing of 1ms increases speed by 1mm/ms.\n",
    "\n",
    "**Determine the number of ways you could beat the record in each race. What do you get if you multiply these numbers together?**\n",
    "\n",
    "This one is pretty trivial. (Thank god. I needed a better day after yesterday!!)\n",
    "\n",
    "- Read in the race durations and distances from our input.\n",
    "- For each race, try hold times from 1 through to duration-1. (We won't go anywhere if we hold the button for 0ms, or for the total duration of the race.)\n",
    "- The distance we travel is given by: `d = (race_duration - hold_time) * hold_time`, since `hold_time` gives us our speed.\n",
    "- Every time our distance `d` is greater than the record distances from our input, store it as a win.\n",
    "- I decided to store each win as a dict of `{ hold_time, distance }` because I thought I might need it later. (I didn't!)\n",
    "- The length of this dict gives us the number of ways we won that particular race. So, multiply these dict lengths together to get the answer required for Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    _, durations_part = data[0].split(\":\")\n",
    "    _, distances_part = data[1].split(\":\")\n",
    "    durations = [int(x) for x in durations_part.split()]\n",
    "    distances = [int(x) for x in distances_part.split()]\n",
    "        \n",
    "    logger.debug(f\"{durations=}\")\n",
    "    logger.debug(f\"{distances=}\")\n",
    "    \n",
    "    wins = defaultdict(dict) # { race_num: { hold_time: distance, hold_time: distance, ...} }\n",
    "    for i, duration in enumerate(durations): # e.g. 0, 7\n",
    "        for hold_time in range(1, duration): # e.g. 0-7\n",
    "            d = (duration - hold_time) * hold_time\n",
    "            if d > distances[i]: # did we win?\n",
    "                wins[i][hold_time] = d\n",
    "    \n",
    "    ways_to_win_product = 1\n",
    "    for race_num, my_results in wins.items():\n",
    "        logger.debug(f\"{race_num=}, ways to win={len(my_results)}\")\n",
    "        ways_to_win_product *= len(my_results)\n",
    "        \n",
    "    return ways_to_win_product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"Time:      7  15   30\", \n",
    "                  \"Distance:  9  40  200\"]\n",
    "]\n",
    "sample_answers = [288]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 6 Part 2\n",
    "\n",
    "Uh oh, there's only one race and the spaces should be ignored. E.g.\n",
    "\n",
    "```\n",
    "Time:      71530\n",
    "Distance:  940200\n",
    "```\n",
    "\n",
    "The input data is much larger. My race durations is millions of ms. So, my thought process was... _\"I don't think my Part 1 solution is going to scale. I'm going to need to do something smarter. But let's just try it and see.\"_\n",
    "\n",
    "**Part 1 Solution is Good Enough!!**\n",
    "\n",
    "I adapted Part 1 to parse the input as specified, and then removed the outer loop, since there's only one race. I also added a bit of optimisation to stop trying hold times if we previously won, but now we're not winning. This is because once the hold time stops producing wins, adding more time to the hold time will NEVER win again.\n",
    "\n",
    "And then I ran it... And it ran in under 10s!! That was a big surprise to me. Phew, nothing clever required!!\n",
    "\n",
    "**The Smart Way?**\n",
    "\n",
    "If we expand the formula for distance that we used in Part 1, we can see it is a quadratic problem:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "d &= (t - h) \\times h \\\\\n",
    "d &= th - h^2 \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We can rearrange to find the roots for $h$:\n",
    "\n",
    "$$\n",
    "h^2 - th + d = 0\n",
    "$$\n",
    "\n",
    "Remember the quadratic formula?\n",
    "\n",
    "$$\n",
    "x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n",
    "$$\n",
    "\n",
    "So we can use this to obtain the two roots, i.e. the hold times where where our distance is equal to the record distance. Using the sample data we were given:\n",
    "\n",
    "$$\n",
    "h^2 - 71530h + 940200 = 0 \\\\\n",
    "$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "b &= -71530 \\\\\n",
    "c &= 940200\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Substituting into the quadratic equation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "h &= \\frac{71530 \\pm \\sqrt{-71530^2 - 4 \\times 940200}}{2} \\\\\n",
    "  &= \\frac{71530 \\pm 71503.71}{2} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So our two answers are approximately 13.15 and 71516.85. We need to find all the integer values between this range. So our answer is:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "ans &= 71516 - 13 \\\\\n",
    "    &= 71503\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Which is the right answer!  So now, I'll can code this as a solution!\n",
    "\n",
    "If we plot this quadratic, we can see the range of hold times for which we can beat the record:\n",
    "\n",
    "![Boat race quadratic plot](https://aoc.just2good.co.uk/assets/images/boat_race_quadratic.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve Part 2 the naive way..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    _, durations_part = data[0].split(\":\")\n",
    "    _, distances_part = data[1].split(\":\")\n",
    "    race_duration = int(\"\".join(x for x in durations_part.split()))\n",
    "    distance = int(\"\".join(x for x in distances_part.split()))\n",
    "    \n",
    "    logger.debug(f\"{race_duration=}, {distance=}\")\n",
    "    \n",
    "    wins = []\n",
    "    for hold_time in range(1, race_duration):\n",
    "        d = (race_duration - hold_time) * hold_time\n",
    "        if d > distance: # have we won against the record?\n",
    "            wins.append(d)\n",
    "        else: # we lost\n",
    "            if wins: # but we won before\n",
    "                break # so holding the button for longer will always lose.\n",
    "    \n",
    "    return len(wins)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_answers = [71503]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve Part 2 with the quadratic..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2_quadratic(data):\n",
    "    \"\"\" d = (t - h) * h\n",
    "          = th - h^2\n",
    "          \n",
    "        Where d is the distance to beat, t is the race duration, and h is the hold time.\n",
    "          \n",
    "        Therefore:\n",
    "        h^2 - th + d = 0\n",
    "    \"\"\"\n",
    "    _, durations_part = data[0].split(\":\")\n",
    "    _, distances_part = data[1].split(\":\")\n",
    "    race_duration = int(\"\".join(x for x in durations_part.split()))\n",
    "    distance = int(\"\".join(x for x in distances_part.split()))\n",
    "\n",
    "    logger.debug(f\"{race_duration=}, {distance=}\")\n",
    "    \n",
    "    # solve using quadratic        \n",
    "    discriminant = (-race_duration)**2 - (4 * distance)\n",
    "    h1 = int((-race_duration + math.sqrt(discriminant)) / 2)\n",
    "    h2 = int((-race_duration - math.sqrt(discriminant)) / 2)\n",
    "    \n",
    "    return abs(h1-h2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_answers = [71503]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2_quadratic(curr_input), curr_ans) # test with sample data\n",
    "    \n",
    "soln = solve_part2_quadratic(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 7: Camel Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"7\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 7 Part 1\n",
    "\n",
    "_\"Camel Cards is sort of similar to poker except it's designed to be easier to play while riding a camel.\"_\n",
    "\n",
    "Brilliant. I love these stories!!\n",
    "\n",
    "Anyway, we're paying a poker variant. Our input contains five-card hands, along with bid amounts, e.g.\n",
    "\n",
    "```\n",
    "32T3K 765\n",
    "T55J5 684\n",
    "KK677 28\n",
    "KTJJT 220\n",
    "QQQJA 483\n",
    "```\n",
    "\n",
    "**Find the rank of every hand in your set. What are the total winnings?**\n",
    "\n",
    "Basically, we're being asked to sort the hands from weakest to strongest.  Weakest is ranking 1, second weakest is rank 2, etc. Then, we determine winnings by multiplying rank by bid amount for each hand, and then adding them together to get total winnings.\n",
    "\n",
    "Rules for determining hand strengh:\n",
    "\n",
    "- Usual poker hand strengths, i.e.\n",
    "  ```\n",
    "  5-of-a-kind > 4-of-a-kind\n",
    "              > full-house\n",
    "              > 3-of-a-kind\n",
    "              > two pair\n",
    "              > one pair\n",
    "              > high card\n",
    "  ```\n",
    "- But unlike normal poker, hand strength tie-breakers are achieved by comparing the successive card strengths of cards in the hand, starting from first to last.\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- Create a `Hand` class:\n",
    "  - In this class, create a dict class attribute to store `card_scores`. I've assigned integer values so we can compare card strength.\n",
    "  - Create a dict class attribute to store `HAND_TYPE`. Again, I've assigned integer values so that we can compare hands.\n",
    "  - Initialise with a string that represents our five cards.\n",
    "  - I'm using the Python `collections.Counter` class to help me determine the `HAND_TYPE`. The `Counter` class counts members of any collection passed to it, including strings. It stores the counts as a dict, in the form `{character: count}`. Then we can use `most_common()` to convert this dict into an ordered list of tuples, ordered by count.\n",
    "  - From here, it's trivial to determine the hand type.  For example, if `most_common()` count is 5, then we have five-of-a-kind.  If it's 4, then we have four-of-a-kind, and so on. Once we've determined the hand type, store it in the `self._hand_type` instance variable.\n",
    "  - Lastly, I need to be able compare one `Hand` to another, according to the rules above. In Python, we can do this by implementing the `__lt__()` (_less than_) method. Here, my `__lt__()` works by first comparing the values of the hand types. If the two hands have the same type, it then compares the cards in each hand, from left to right. Note that I'm using the cool [zip](https://aoc.just2good.co.uk/python/zip) function to combine the two hands into a single iterable of tuples. This is a cool way to compare _items from thing1_ to _items from thing2_, where the two _things_ are the same size.\n",
    "\n",
    "- Now I read the input. For each line, I create a new `Hand` instance, and bid integer. I store these two values as a tuple, and add it to a list of `hands_and_bids`.\n",
    "- Then I sort the hands.  This is easy to do with `sorted()`, because of the work we already did in the `Hand` class. But because I want to sort the tuples of `(hand, bid)`, not just the hands, I need to tell the `sorted()` function that it should sort based on the first item in each tuple. \n",
    "  - This is easily done with a [lambda function](https://aoc.just2good.co.uk/python/functions#lambda-functions): \\\n",
    "  `hands_and_bids = sorted(hands_and_bids, key=lambda x: x[0])`\n",
    "  - The `key` needs to be a function. Here, that function is simply returning the first item in the tuple.\n",
    "\n",
    "- Once sorted, it's easy to loop through my hands from weakest to strongest, and multiply the rank by the bid amount.\n",
    "\n",
    "Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 7 Part 2\n",
    "\n",
    "Now `J` is a Joker. \n",
    "\n",
    "- It has the lowest score of any card, but it acts a wildcard.\n",
    "- When determine hand type, `J` becomes whatever results in the strongest hand type.\n",
    "- But when breaking ties, `J` is always considered as `J`, with low value.\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- I tweaked my `Hand` class so that we can pass in an optional `joker` boolean attribute upon initialisation.\n",
    "- When `joker=True`:\n",
    "  - Update the value of `J` in our `card_scores`. Thus, our `__lt__()` will now work without modification.\n",
    "  - In `_determine_hand_type()` I've added an extra block that only runs if we're in _joker mode_. This block replaces any `J` in the hand with the card type that is most common. (If the card type that is most common is the `J` itself, then we instead identify the next most common card type.) We then recount the cards, and then perform the same logic as before to determine the hand type.\n",
    "\n",
    "So that's it!  Very little change required for Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hand:\n",
    "    card_scores = { # card labels\n",
    "        \"A\": 14, \n",
    "        \"K\": 13,\n",
    "        \"Q\": 12,\n",
    "        \"J\": 11,\n",
    "        \"T\": 10,\n",
    "        \"9\": 9,\n",
    "        \"8\": 8,\n",
    "        \"7\": 7,\n",
    "        \"6\": 6,\n",
    "        \"5\": 5,\n",
    "        \"4\": 4,\n",
    "        \"3\": 3,\n",
    "        \"2\": 2\n",
    "    }\n",
    "    \n",
    "    HAND_TYPE = {\n",
    "        \"FIVE\": 7,\n",
    "        \"FOUR\": 6,\n",
    "        \"FH\": 5,\n",
    "        \"THREE\": 4,\n",
    "        \"TP\": 3,\n",
    "        \"OP\": 2,\n",
    "        \"HC\": 1\n",
    "    }\n",
    "    \n",
    "    def __init__(self, cards: str, joker=False) -> None:\n",
    "        self.cards = cards\n",
    "        self._joker = joker\n",
    "        if self._joker:\n",
    "            Hand.card_scores[\"J\"] = 1\n",
    "            \n",
    "        self._hand_type = self._determine_hand_type()\n",
    "        \n",
    "    def _determine_hand_type(self):\n",
    "        cards = self.cards # we will replace value of joker\n",
    "        ordered_counts = Counter(cards).most_common() # e.g. [('3', 2), ('2', 1), ('T', 1), ('K', 1)]\n",
    "    \n",
    "        # get the most common card\n",
    "        best, best_count = ordered_counts[0] # e.g. ('3', 2)\n",
    "        if best_count == 5:\n",
    "            return \"FIVE\"\n",
    "        \n",
    "        second_best, second_best_count = ordered_counts[1] # e.g. ('2', 1)\n",
    "        \n",
    "        if self._joker: # Part 2\n",
    "            if best == 'J': # get the next best card\n",
    "                best, best_count = second_best, second_best_count\n",
    "            \n",
    "            # convert all J into the best card\n",
    "            cards = cards.replace(\"J\", best)\n",
    "\n",
    "            ordered_counts = Counter(cards).most_common() # recount the hand\n",
    "            best, best_count = ordered_counts[0]\n",
    "            if best_count == 5:\n",
    "                return \"FIVE\"\n",
    "        \n",
    "            second_best, second_best_count = ordered_counts[1] # e.g. ('2', 1)    \n",
    "        \n",
    "        if best_count == 4:\n",
    "            return \"FOUR\"\n",
    "        \n",
    "        if best_count == 3:\n",
    "            if second_best_count == 2:\n",
    "                return \"FH\"\n",
    "            else:\n",
    "                return \"THREE\"\n",
    "        \n",
    "        if best_count == 2:\n",
    "            if second_best_count == 2:\n",
    "                return \"TP\"\n",
    "            else:\n",
    "                return \"OP\"\n",
    "\n",
    "        return \"HC\"\n",
    "    \n",
    "    def value(self):\n",
    "        \"\"\" Return a score, based on hand type \"\"\"\n",
    "        return Hand.HAND_TYPE[self._hand_type]\n",
    "    \n",
    "    def __lt__(self, other: Hand):\n",
    "        \"\"\" Compare this hand with another hand.\n",
    "        Winning hand has stronger hand type; for hand type ties, \n",
    "        winning hand is determined by highest card, starting with the first card in the hand. \n",
    "        \"\"\"\n",
    "        if self.value() != other.value():\n",
    "            return self.value() < other.value()\n",
    "        \n",
    "        assert self.value() == other.value(), \"Hand types are the same\"\n",
    "        for this_card, other_card in zip(self.cards, other.cards):\n",
    "            if this_card == other_card:\n",
    "                continue\n",
    "            \n",
    "            return Hand.card_scores[this_card] < Hand.card_scores[other_card]\n",
    "        \n",
    "        assert False, \"We should not get here\"\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"cards={self.cards}; hand_type={self._hand_type}\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}(x={self.cards})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(data, joker=False):\n",
    "    hands_and_bids = []\n",
    "    for line in data:\n",
    "        cards, bid = line.split()\n",
    "        hand = Hand(cards, joker)\n",
    "        hands_and_bids.append((hand, int(bid)))\n",
    "    \n",
    "    hands_and_bids = sorted(hands_and_bids, key=lambda x: x[0])\n",
    "    \n",
    "    total_winnings = 0\n",
    "    for i, (hand, bid) in enumerate(hands_and_bids):\n",
    "        # logger.debug(f\"Hand: {hand}, bid={bid}\")\n",
    "        total_winnings += (i+1)*bid\n",
    "        \n",
    "    return total_winnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"32T3K 765\",\n",
    "                  \"T55J5 684\",\n",
    "                  \"KK677 28\",\n",
    "                  \"KTJJT 220\",\n",
    "                  \"QQQJA 483\"]\n",
    "                 ]\n",
    "sample_answers = [6440]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_answers = [5905]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input, joker=True), curr_ans) # test with sample data\n",
    "\n",
    "soln = solve(input_data, joker=True)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 8: Haunted Wasteland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"8\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 8 Part 1\n",
    "\n",
    "We're navigating a maze. The input looks like this:\n",
    "\n",
    "```\n",
    "RL\n",
    "\n",
    "AAA = (BBB, CCC)\n",
    "BBB = (DDD, EEE)\n",
    "CCC = (ZZZ, GGG)\n",
    "DDD = (DDD, DDD)\n",
    "EEE = (EEE, EEE)\n",
    "GGG = (GGG, GGG)\n",
    "ZZZ = (ZZZ, ZZZ)\n",
    "```\n",
    "\n",
    "- The top line is a list of left/right instructions. The instructions wrap indefinitely.\n",
    "- You start at `AAA`. If you follow a left instruction, you pick the next left node. If you follow a right instruction, you pick the next right node.\n",
    "\n",
    "**Starting at AAA, follow the left/right instructions. How many steps are required to reach ZZZ?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- First, parse the data. This is easy enough. \n",
    "  - I create a single string to represent the L/R instructions.\n",
    "  - I create a dict to map each source node to a pair of target nodes. The target nodes will be stored as a tuple, e.g. `(\"BBB\", \"CCC\")`\n",
    "\n",
    "- Set our starting node to \"AAA\".\n",
    "- Enter a while loop that ends when our current node is \"ZZZ\".\n",
    "- In the loop:\n",
    "  - Get the left and right target nodes for the current node.\n",
    "  - Retrieve the next instruction, and set the next node accordingly.\n",
    "\n",
    "Nice and easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_instructions(data):\n",
    "    instructions = data[0] # first line is our L/R instructions\n",
    "    nodes = {}\n",
    "    for line in data[2:]:\n",
    "        src_node, target_nodes = (x.strip() for x in line.split(\"=\"))\n",
    "        left_node, right_node = (x.strip() for x in target_nodes.split(\",\"))\n",
    "        left_node = left_node.replace(\"(\", \"\")\n",
    "        right_node = right_node.replace(\")\", \"\")\n",
    "        nodes[src_node] = (left_node, right_node)\n",
    "        \n",
    "    return instructions,nodes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(instructions: str, nodes: dict):\n",
    "    logger.debug(nodes)\n",
    "    instructions_cycler = cycle(instructions) # an infinite repeat of the instructions\n",
    "    \n",
    "    current_node = \"AAA\" # where we start\n",
    "    loop = 0\n",
    "    while current_node != \"ZZZ\": # our goal\n",
    "        instruction = next(instructions_cycler)\n",
    "        left, right = nodes[current_node]\n",
    "        current_node = left if instruction == \"L\" else right\n",
    "        loop += 1\n",
    "        if loop == 1000000: \n",
    "            assert False, \"I can't get out!\"\n",
    "    \n",
    "    return loop \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"RL\",\n",
    "                  \"\", \n",
    "                  \"AAA = (BBB, CCC)\",\n",
    "                  \"BBB = (DDD, EEE)\",\n",
    "                  \"CCC = (ZZZ, GGG)\",\n",
    "                  \"DDD = (DDD, DDD)\",\n",
    "                  \"EEE = (EEE, EEE)\",\n",
    "                  \"GGG = (GGG, GGG)\",\n",
    "                  \"ZZZ = (ZZZ, ZZZ)\"], \n",
    "                 [\"LLR\",\n",
    "                  \"\",\n",
    "                  \"AAA = (BBB, BBB)\",\n",
    "                  \"BBB = (AAA, ZZZ)\",\n",
    "                  \"ZZZ = (ZZZ, ZZZ)\"]\n",
    "]\n",
    "sample_answers = [2, 6]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_instructions = parse_instructions(curr_input)\n",
    "    validate(solve_part1(*curr_instructions), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "instructions = parse_instructions(input_data)\n",
    "soln = solve_part1(*instructions)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 8 Part 2\n",
    "\n",
    "Oh, _of course!_  The map is meant for ghosts!!\n",
    "\n",
    "We're told that we need to start by navigate away from ALL nodes that end with \"A\" in parallel. We only end when our navigation leads us to a set of nodes that all end with \"Z\" at the same time.\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "First, I tried to solve this in a similar way to Part 1. I.e.\n",
    "\n",
    "- Find all the nodes that end in `A`.\n",
    "- Then, loop through the instructions in a cyclic way, as before. For each loop:\n",
    "  - Follow the instruction for our nodes, which gives us the next set of nodes to follow.\n",
    "  - Quit the loop, when all of our current nodes end with `Z`. Here I used the Python `all()` function, which returns `True` only if ALL of the members of the collection passed to it are themselves `True`.\n",
    "\n",
    "And this solution worked straight away for the test input. Yay!\n",
    "\n",
    "But when I ran it with the real input... Well, it was still running 30 minutes later. So this solution does not scale.  **I need a better approach!!** (Read on after the code below to see the better approach.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(instructions: str, nodes: dict[str, tuple]):\n",
    "    instructions_cycler = cycle(instructions)\n",
    "    \n",
    "    starting_nodes = [node for node in nodes if node.endswith(\"A\")]\n",
    "    current_nodes = starting_nodes\n",
    "    for i, instruction in enumerate(instructions_cycler):\n",
    "        next_nodes = []\n",
    "        for node in current_nodes:\n",
    "            left, right = nodes[node]\n",
    "            next_nodes.append(left if instruction == \"L\" else right)\n",
    "        \n",
    "        if all([node.endswith(\"Z\") for node in next_nodes]):\n",
    "            return i\n",
    "        \n",
    "        current_nodes = next_nodes\n",
    "        if i == 1000000000: \n",
    "            break\n",
    "    \n",
    "    assert False, \"I can't get out!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The better approach:**\n",
    "\n",
    "- We have multiple paths to follow in parallel. Work out how long it takes to get from `??A` to `??Z` for each path, i.e. for each starting node.\n",
    "- The time taken to reach `??Z` is different for different paths.\n",
    "- We need to determine the time at which all the `??Z` converge.\n",
    "- And here's a crucial observation! Whenever you get to `??Z` and then continue, the _next_ node is always the node that the original `??A` took you to. (I checked this in my actual input data.) This means that the time required to get from `??A` to `??Z` is the same as the time required to get from this `??Z` back to itself. I.e. **the cycle time is constant, for any given path.**\n",
    "- And because we now have repeating constant cycle times, it means we just need to find a way to line up all the cycle times, such that we can converge on `??Z`. We can do this using the **lowest common multiple (LCM) of these times.** The LCM of a set of integers is the smallest number that is exactly divisible by all those integers.\n",
    "\n",
    "So, to solve:\n",
    "\n",
    "- Obtain the number of loops required to get from `??A` to `??Z`, exactly as we did for Part 1. (But now our goal is `??Z` rather than `ZZZ`.)\n",
    "- Do this for each starting position. Store all the resulting loop counts in `loops`.\n",
    "- Then use `math.lcm(*loops)`. \n",
    "  - Note that Python has implemented the `math.lcm()` function since Python 3.9. Before then, you had to write your own!\n",
    "  - The `lcm()` function expects two or more integers as arguments.  So here I'm using the _splat_ operator (`*`) to unpack my list of loop values.\n",
    "\n",
    "And that's it!  The solution returns instantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2_lcm(instructions: str, nodes: dict[str, tuple]):\n",
    "    starting_nodes = [node for node in nodes if node.endswith(\"A\")]\n",
    "    loops = []\n",
    "    for node in starting_nodes:\n",
    "        \n",
    "        # determine how long this nodes gets to \"??Z\"\n",
    "        instructions_cycler = cycle(instructions)\n",
    "        loop = 0\n",
    "        while not node.endswith(\"Z\"): # our goal\n",
    "            instruction = next(instructions_cycler)\n",
    "            left, right = nodes[node]\n",
    "            node = left if instruction == \"L\" else right\n",
    "            loop += 1\n",
    "            if loop == 1000000: \n",
    "                assert False, \"I can't get out!\"\n",
    "        \n",
    "        loops.append(loop)\n",
    "    \n",
    "    return math.lcm(*loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"LR\",\n",
    "                  \"\", \n",
    "                  \"11A = (11B, XXX)\", \n",
    "                  \"11B = (XXX, 11Z)\", \n",
    "                  \"11Z = (11B, XXX)\", \n",
    "                  \"22A = (22B, XXX)\", \n",
    "                  \"22B = (22C, 22C)\", \n",
    "                  \"22C = (22Z, 22Z)\", \n",
    "                  \"22Z = (22B, 22B)\", \n",
    "                  \"XXX = (XXX, XXX)\"]\n",
    "] \n",
    "sample_answers = [6]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_instructions = parse_instructions(curr_input)\n",
    "    validate(solve_part2_lcm(*curr_instructions), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2_lcm(*instructions)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 9: Mirage Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"9\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 9 Part 1\n",
    "\n",
    "We're using an _Oasis And Sand Instability Sensor (OASIS)_ to take readings of our environment.  The data looks like this:\n",
    "\n",
    "```\n",
    "0 3 6 9 12 15\n",
    "1 3 6 10 15 21\n",
    "10 13 16 21 30 45\n",
    "```\n",
    "\n",
    "Each line is the history of a sequence representing a single attribute.\n",
    "\n",
    "Some of these sequences will be first-order arithmetic progressions, i.e. where the increment remains constant. E.g. 0, 3, 6, 9... \n",
    "\n",
    "```\n",
    "0   3   6   9  12  15  18\n",
    "  3   3   3   3   3   3\n",
    "    0   0   0   0   0\n",
    "```\n",
    "\n",
    "The first order difference is always 3.\n",
    "\n",
    "Some will be second-order arithmetic progressions, i.e. where the increment changes by a constant amount. E.g. 1, 3, 6, 10... \n",
    "\n",
    "```\n",
    "1   3   6  10  15  21\n",
    "  2   3   4   5   6\n",
    "    1   1   1   1\n",
    "      0   0   0\n",
    "```\n",
    "\n",
    "The differences are 2, 3, 4, etc. The second-order difference is constant.\n",
    "\n",
    "Some will be nth-order progressions. E.g. 10, 13, 16, 21, 30... \n",
    "\n",
    "```\n",
    "10  13  16  21  30  45  68\n",
    "   3   3   5   9  15  23\n",
    "     0   2   4   6   8\n",
    "       2   2   2   2\n",
    "         0   0   0\n",
    "```\n",
    "\n",
    "Here, the third order diferences are constant.  \n",
    "\n",
    "We need to find the next value in each sequence.\n",
    "\n",
    "**Analyze your OASIS report and extrapolate the next value for each history. What is the sum of these extrapolated values?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "I used to _really_ hate [recursion](https://aoc.just2good.co.uk/python/recursion). But, having been forced to use it a bit in previous AoCs, I now simply _dislike_ recursion. I don't dislike the _idea_ of it. I dislike the fact that my tiny brain seems to struggle with exactly what needs to be returned for each case.\n",
    "\n",
    "Anyhoo... This problem is just begging for recursion!  If we were only ever seeing first-order and second-order progressions, then we could use simple math to work out the _n_ th term. But it was my guess that the real input could go pretty deep. So we need to be able to keep recursing to the next set of differences, until the differences remain constant.\n",
    "\n",
    "**[NumPy](https://aoc.just2good.co.uk/python/numpy)** for the win!! NumPy has built in capabilities to determine the differences between values in an array, and return these differences as a new array!  This saves me a few lines of code.\n",
    "\n",
    "So, here's my approach:\n",
    "\n",
    "- First, I parse the input data. I convert each line into a `list` of `int`. I.e. each list represents our _sequence_.\n",
    "- Then, for each _sequence_, I convert it to a one dimension NumPy ndarray and pass to my `recurse_diffs()` function. Note that I'm using a [list comprehension](https://aoc.just2good.co.uk/python/comprehensions) to do all of this, for each _sequence_. As a result, my `solve()` function is short, neat, and _Pythonic_.\n",
    "- Now, my recursive function, `recurse_diffs()`:\n",
    "  - Here, I first use the NumPy method `diff()` to return all the differences between terms, as a new `ndarray`.\n",
    "  - Then I use `np.all(diffs == diffs[0])` to check if _all_ the values in this _diffs_ array are equal to the value of the first term in the array.  If so, then we've reached the point where the _diffs_ are constant.\n",
    "  - If not, then we recursively call this same function, but passing in the current set of _diffs_ as the new sequence.\n",
    "  - When we've reached the level of nesting where the diffs are constant, we add this diff to the current sequence of diffs, and use this to determine the next value in the diffs sequence.\n",
    "  - Then we bubble this same approach all the way back to the top. I.e. for each level of diffs, we obtain the next diff. And finally, at the very top, this gives us the next value in our sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sequences(data: list[str]):\n",
    "    return [[int(x) for x in line.split()] for line in data]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurse_diffs(sequence: np.ndarray, forwards=True) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the next value in a numeric sequence based on the pattern of differences.\n",
    "\n",
    "    Recursively analyses the differences between consecutive elements of the sequence. \n",
    "    Recurses until the differences remain constant. \n",
    "    It then calculates the next value in the sequence based on this constant difference.\n",
    "\n",
    "    Parameters:\n",
    "        sequence (np.ndarray): A NumPy array representing the sequence.\n",
    "        forwards (bool, optional): A flag to determine the direction of progression.\n",
    "                                   If True (default), the function calculates the next value. \n",
    "                                   If False, it calculates the previous value in the sequence.\n",
    "\n",
    "    Returns:\n",
    "        int: The next (or previous) value in the sequence\n",
    "    \"\"\"\n",
    "    diffs = np.diff(sequence)\n",
    "    \n",
    "    op = operator.add if forwards else operator.sub\n",
    "    term = sequence[-1] if forwards else sequence[0]\n",
    "    \n",
    "    # Check if all the diffs are constant\n",
    "    # If they are, we've reached the deepest point in our recursion, and we know the constant diff\n",
    "    if np.all(diffs == diffs[0]):\n",
    "        next_val = op(term, diffs[0])\n",
    "    else: # if the diffs are not constant, then we need to recurse\n",
    "        diff = recurse_diffs(diffs, forwards)\n",
    "        next_val = op(term, diff)\n",
    "        \n",
    "    return int(next_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(sequences: list[list[int]], forwards=True):\n",
    "    next_vals = [recurse_diffs(np.array(sequence), forwards) for sequence in sequences]\n",
    "    return sum(next_vals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"0 3 6 9 12 15\", \n",
    "                  \"1 3 6 10 15 21\",\n",
    "                  \"10 13 16 21 30 45\"]\n",
    "                ]\n",
    "sample_answers = [114]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_sequences = parse_sequences(curr_input)\n",
    "    validate(solve(curr_sequences), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "sequences = parse_sequences(input_data)\n",
    "soln = solve(sequences)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 9 Part 2\n",
    "\n",
    "Now we need to find the previous result in each series!!\n",
    "\n",
    "It turns out that I can do this with a pretty trivial change to my `recurse_diffs()` function. I add a new parameter (`forwards`) that determines if we want to move forwards to the _next_ term in the sequence, or backwards to the previous term in the sequence.  Forwards is the default. If we set `forwards` to `False`, all we need to do is always return the _first term minus_ the diff, rather than the _last term plus_ the diff.\n",
    "\n",
    "Note this cool construct:\n",
    "\n",
    "```python\n",
    "    op = operator.add if forwards else operator.sub\n",
    "    term = sequence[-1] if forwards else sequence[0]\n",
    "```\n",
    "\n",
    "This is a neat way to set the `op` variable to be either the _add_ function, or the _substract_ (_sub_) function, depending on the value of `forwards`. And I use the same approach for setting the term we want to add the _diff_ to.  I.e. either the last term in the sequence, or the first.\n",
    "\n",
    "And that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_answers = [2]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_sequences = parse_sequences(curr_input)\n",
    "    validate(solve(curr_sequences, False), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve(sequences, False)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 10: Pipe Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"10\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 10 Part 1\n",
    "\n",
    "Well, I didn't enjoy today at all.  Part 1 was okay, but Part 2 took me WAY TOO MUCH time.\n",
    "\n",
    "So... We're standing in a field packed with pipes.  The pipes are arranged into a 2D grid of tiles. The pipe forms one long continuous loop. E.g.\n",
    "\n",
    "```text\n",
    ".....\n",
    ".F-7.\n",
    ".|.|.\n",
    ".L-J.\n",
    ".....\n",
    "```\n",
    "\n",
    "Here, `-` represents a horizontal pipe, `|` is a vertical pipe, `F` is a top-left join, `7` is a top-right join, `L` is a bottom left-join, and `J` is a bottom-right join.\n",
    "\n",
    "We start at `S`. In our main loop, every pipe will be connected to one or two neighbours. But there may also be pipes not connected to the loop:\n",
    "\n",
    "```text\n",
    "-L|F7\n",
    "7S-7|\n",
    "L|7||\n",
    "-L-J|\n",
    "L|-JF\n",
    "```\n",
    "\n",
    "**Find the single giant loop starting at S. How many steps along the loop does it take to get from the starting position to the point farthest from the starting position?**\n",
    "\n",
    "This seems like a perfect case for a [BFS](https://aoc.just2good.co.uk/python/shortest_paths)!\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "I'll make a `PipeGrid` class by extending my previous `Grid` class.  In this class:\n",
    "\n",
    "- `pipes_for_direction` show the valid pipes and connectors if we move from a given pipe in that direction.\n",
    "- `directions_for_pipe` gives the valid directions we can move from, starting from a given pipe/connector.\n",
    "- `valid_neighbours_for_loop_pipe()` does the following:\n",
    "  - Determines what sort pipe or connector is at our current point.\n",
    "  - Determines which directions we can move towards, from this pipe, using `directions_for_pipe`.\n",
    "  - Determines which pipes/connects are valid in those directions, using `pipes_for_direction`.\n",
    "  - Uses these to determine which adjacent tiles are valid next moves, to continue our pipe.\n",
    "\n",
    "- Next, determine the location of our start point.\n",
    "- Then, use the `pipe_bfs()` function to determine all the locations that make up our closed loop. \n",
    "  - This uses the standard BFS approach, performing a flood fill outwards from the start location.\n",
    "  - It builds a breadcrumb trail called `came_from`. This is a dict which stores: \\\n",
    "    `{ point: (predecessor, step_count), ... }`\n",
    "  - As we find successive pipes/connectors (which grow symmetrically, since we have a loop), we store the current furthest distance from the start position.\n",
    "\n",
    "- Finally, we can return the furthest distance achieved.\n",
    "\n",
    "Not too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "For a bit of fun, I decided to plot a heatmap that shows the journey from start to furthest, using [matplotlib](https://aoc.just2good.co.uk/python/matplotlib). I do this in my `plot_grid()` function.  It works by:\n",
    "\n",
    "- Creating a [NumPy](https://aoc.just2good.co.uk/python/numpy) grid to represent all step counts.\n",
    "- We initialise all grid points to -1.\n",
    "- We extract step counts from our `dict_from`. Thus, `S` has value 0, and each subsequent step will increment the count by 1.\n",
    "- I've made the starting location black, and the final (furthest) location white.\n",
    "\n",
    "For our small square test grid, the result looks like this:\n",
    "\n",
    "![Pipe loop small square](https://aoc.just2good.co.uk/assets/images/pipeloop_1.png)\n",
    "\n",
    "And with my real data:\n",
    "\n",
    "![Pipe loop real](https://aoc.just2good.co.uk/assets/images/pipeloop_real.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipeGrid(Grid):\n",
    "    \"\"\" A 2D grid that contains tiles. Tiles may be empty, or have pipe parts. \"\"\"\n",
    "    \n",
    "    pipes_for_direction = { # if in the pipe loop, these are valid pipe parts in each direction\n",
    "        \"N\": {\"|\", \"F\", \"7\"},\n",
    "        \"E\": {\"-\", \"J\", \"7\"},\n",
    "        \"S\": {\"|\", \"L\", \"J\"},\n",
    "        \"W\": {\"-\", \"F\", \"L\"}\n",
    "    }\n",
    "    \n",
    "    directions_for_pipe = { # for a given pipe part, these are valid next directions\n",
    "        \"|\": [\"N\", \"S\"], # vertical pipe\n",
    "        \"-\": [\"E\", \"W\"], # horizontal pipe\n",
    "        \"L\": [\"N\", \"E\"], # bottom-left join\n",
    "        \"J\": [\"N\", \"W\"], # bottom-right join\n",
    "        \"7\": [\"S\", \"W\"], # top-right join\n",
    "        \"F\": [\"S\", \"E\"], # top-left join\n",
    "        \"S\": [\"N\", \"E\", \"S\", \"W\"] # start location\n",
    "    }\n",
    "    \n",
    "    def valid_neighbours_for_loop_pipe(self, point: Point) -> list[Point]:\n",
    "        \"\"\" Get valid neighbours, given a current location that is the main pipe loop. \"\"\"\n",
    "        valid = []\n",
    "        this_pipe = self.value_at_point(point)\n",
    "        assert this_pipe in PipeGrid.directions_for_pipe, \"Point must be a pipe or S\"   \n",
    "        \n",
    "        allowed_directions = PipeGrid.directions_for_pipe[this_pipe]\n",
    "        allowed_vectors = [Vectors[direction] for direction in allowed_directions]\n",
    "\n",
    "        assert allowed_vectors, \"We must be allowed to move in at least one direction\"\n",
    "        \n",
    "        for direction, neighbour_pt in zip(allowed_directions, point.get_specific_neighbours(allowed_vectors)):\n",
    "            neighbour_val = self.value_at_point(neighbour_pt)\n",
    "            if neighbour_val in PipeGrid.pipes_for_direction[direction]:\n",
    "                valid.append(neighbour_pt)\n",
    "                \n",
    "        return valid\n",
    "                    \n",
    "    def valid_neighbours_for_non_loop(self, point: Point, loop: list[Point]) -> list[Point]:\n",
    "        valid = []\n",
    "        for neighbour in point.neighbours(include_diagonals=False):\n",
    "            if self.valid_location(neighbour) and neighbour not in loop:\n",
    "                valid.append(neighbour)\n",
    "\n",
    "        return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_grid(data) -> PipeGrid:\n",
    "    return PipeGrid(data)\n",
    "    \n",
    "def pipe_bfs(grid: PipeGrid, start: Point) -> tuple[int, Point, dict[Point, tuple]]:\n",
    "    \"\"\" Use BFS to establish the points that make up the closed loop, \n",
    "    and determine the furthest location in the loop.\n",
    "\n",
    "    Args:\n",
    "        grid (PipeGrid): 2D grid containing a closed loop\n",
    "        start (Point): Starting point\n",
    "\n",
    "    Returns:\n",
    "        tuple[int, Point, dict[Point, tuple]]: max distance, furthest point, came_from\n",
    "    \"\"\"\n",
    "    assert grid.value_at_point(start) == \"S\", \"We have found the start\"    \n",
    "    frontier = deque()\n",
    "    frontier.append((start, 0)) # store (posn, step_count)\n",
    "    came_from = {}\n",
    "    came_from[start] = (None, 0) # store (posn, step_count)\n",
    "    \n",
    "    max_steps, furthest = 0, start\n",
    "    \n",
    "    # keep going until the frontier is empty; i.e. when we've explored all the valid nodes\n",
    "    # the frontier will expand in two directions as we build the loop\n",
    "    while frontier:\n",
    "        current, step_count = frontier.popleft()  # pop the first item off the FIFO queue\n",
    "        \n",
    "        if step_count > max_steps:\n",
    "            max_steps = step_count\n",
    "            furthest = current\n",
    "       \n",
    "        for neighbour in grid.valid_neighbours_for_loop_pipe(current):\n",
    "            steps_to_neighbour = step_count + 1\n",
    "            if neighbour not in came_from:\n",
    "                frontier.append((neighbour, steps_to_neighbour))\n",
    "                came_from[neighbour] = (current, steps_to_neighbour)\n",
    "    \n",
    "    return max_steps, furthest, came_from\n",
    "\n",
    "def plot_grid(grid: PipeGrid, max_steps: int, came_from: dict[Point, tuple]):\n",
    "    steps_array = np.full((grid.height, grid.width), fill_value=-1, dtype=int)\n",
    "    \n",
    "    # Fill the steps_array with steps taken for each point\n",
    "    for point, (predecessor, steps) in came_from.items():\n",
    "        steps_array[point.y, point.x] = steps\n",
    "   \n",
    "    plt.imshow(steps_array, cmap=\"viridis\", origin=\"lower\", interpolation=\"none\", \n",
    "               extent=[0, grid.width, 0, grid.height])\n",
    "\n",
    "    # Highlight squares where steps is max (white color)\n",
    "    for point, (predecessor, steps) in came_from.items():\n",
    "        if steps == 0:\n",
    "            rect = Rectangle((point.x, point.y), 1, 1, fill=True, color='black')\n",
    "            plt.gca().add_patch(rect)\n",
    "        \n",
    "        if steps == max_steps:\n",
    "            rect = Rectangle((point.x, point.y), 1, 1, fill=True, color='white')\n",
    "            plt.gca().add_patch(rect)\n",
    "            \n",
    "    plt.colorbar(label=\"Steps Taken\")\n",
    "    plt.grid(True, which=\"both\", color=\"black\", linewidth=0)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.title('Number of Steps Taken for Each Point')\n",
    "    plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "    plt.show()    \n",
    "    \n",
    "def solve_part1(grid: PipeGrid) -> tuple[int, Point, dict[Point, tuple]]:\n",
    "    \"\"\" Returns:\n",
    "        tuple[int, Point, dict[Point, tuple]]: max distance, furthest point, came from\n",
    "    \"\"\"\n",
    "    start = next(point for point in grid.all_points()\n",
    "                if grid.value_at_point(point) == \"S\")\n",
    "    max_steps, furthest, came_from = pipe_bfs(grid, start)\n",
    "    plot_grid(grid, max_steps, came_from)\n",
    "        \n",
    "    return max_steps, furthest, came_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [[\"..F7.\",\n",
    "                  \".FJ|.\",\n",
    "                  \"SJ.L7\",\n",
    "                  \"|F--J\",\n",
    "                  \"LJ...\"]\n",
    "]\n",
    "sample_answers = [8]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_grid = parse_grid(curr_input)\n",
    "    curr_soln, curr_furthest, curr_from = solve_part1(curr_grid)\n",
    "    validate(curr_soln, curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "grid = parse_grid(input_data)\n",
    "soln, furthest, came_from = solve_part1(grid)\n",
    "logger.info(f\"Part 1: steps to farthest point={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 10 Part 2\n",
    "\n",
    "**How many tiles are enclosed by the loop?**\n",
    "\n",
    "OMG. This was pretty tough for me.\n",
    "\n",
    "We're given a sample loop which contains pockets of _inside_ tiles:\n",
    "\n",
    "```text\n",
    "...........\n",
    ".S-------7.\n",
    ".|F-----7|.\n",
    ".||OOOOO||.\n",
    ".||OOOOO||.\n",
    ".|L-7OF-J|.\n",
    ".|II|O|II|.\n",
    ".L--JOL--J.\n",
    ".....O.....\n",
    "```\n",
    "\n",
    "Let's look at this same map, using the visualisation from Part 1. This makes it easy to see which tiles are _inside_ and which tiles are _outside_:\n",
    "\n",
    "![Finding loops, sample data](https://aoc.just2good.co.uk/assets/images/finding_loops_sample.png)\n",
    "\n",
    "The big challenge is that our pipe loop can have pipes adjacent to each other, forming pockets. Furthermore, our adjacent pipes might form a pocket with a channel to the outside.  So, in the next example, the channel to the outside is now made up of adjacent pipes.  But it _still counts_ as a channel to the outside:\n",
    "\n",
    "```text\n",
    "..........\n",
    ".S------7.\n",
    ".|F----7|.\n",
    ".||OOOO||.\n",
    ".||OOOO||.\n",
    ".|L-7F-J|.\n",
    ".|II||II|.\n",
    ".L--JL--J.\n",
    "..........\n",
    "```\n",
    "\n",
    "In the example above, the central pocket has tiles labelled as _outside_ (O), because they have a channel to the outside.\n",
    "\n",
    "![Adjacent channels](https://aoc.just2good.co.uk/assets/images/finding_loops_sample_2.png)\n",
    "\n",
    "Determining which pockets are inside or outside is tricky!\n",
    "\n",
    "**My solution**:\n",
    "\n",
    "- Start by taking the `came_from` breadcrumbs dict from Part 1, and converting it into a complete path of Points that make up our loop.\n",
    "  - Using the dict from farthest point out to starting point, I build a path of one half of the loop. Remember, the dict maps each point to its predecessor; it only goes one way so we have to go from furthest, and move all the way back to the start.\n",
    "  - But I still need to determine the path through the other half of the loop. I do this by determining: the _neighbour_ of the point that is furthest out, that is also part of our overall loop, that is not in the `first_half` path that we've already created, and which is also a valid move from the point that is furthest out. This gives me the _other_ point that is connected to the furthest out point in our loop.  And from here, I can now build a path from this point back to the start.\n",
    "  - Then I join these two paths together, thus creating the closed loop.\n",
    "\n",
    "Next, I determine all the _regions_ (pockets) i.e. contiguous points of tiles. \n",
    "- These are pockets of tiles that are either _inside_ or _outside_.\n",
    "- Again, I do this with a BFS _floodfill_, for all points that are not part of the main loop. \n",
    "- We expand a given point until we've fully flood-filled its associated region. Of course, each time we flood fill from a point, we eliminate a bunch of points that we need to flood fill form.\n",
    "- Interesting observation: I pass my main loop to my `get_tile_regions()` function in the form of a `list[Point]`. During our flood fill, we have to check if we've reached a point in the loop. However, it took minutes when I used a list. If I converted by loop points to a `set`, it **runs in seconds**!  Which just goes to show how much more efficient Python is at checking whether something is a member of `set`, vs checking membership of a `list`.`  \n",
    "\n",
    "Finally, I return these regions.\n",
    "\n",
    "For each region, I can now arbitrarily pick any point in that region and see if that point is enclosed by the main loop. In the end, I cheated a little, and made use of `matplotlib` `contains_points()` to determine which regions are contained by the loop. Where any region has any point that is contained by the loop, we can conclude that all the points that region are contained by the loop. So we can add all these points to the list of included points.\n",
    "\n",
    "And that's it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "I decied to plot the loops and _internal_ tiles. It's an interesting example of superimposing a scatter graph on a line graph.\n",
    "\n",
    "```python\n",
    "    plt.plot(loop_x_values, loop_y_values, \n",
    "             marker='o', linestyle='-', color=\"blue\", label=\"Loop\")\n",
    "        \n",
    "    plt.scatter(inside_x_values, inside_y_values, \n",
    "                marker='x', color=\"red\", label=\"Inside\")\n",
    "```\n",
    "\n",
    "Here's one of the sample grids:\n",
    "\n",
    "![Finding loops, sample data](https://aoc.just2good.co.uk/assets/images/contained_points.png)\n",
    "\n",
    "And with real data:\n",
    "\n",
    "![Finding loops, real data](https://aoc.just2good.co.uk/assets/images/contained_points_real.png)\n",
    "\n",
    "### Final Remarks and Useful Resources\n",
    "\n",
    "There are a couple of other ways to solve this problem. \n",
    "\n",
    "- One approach is to use the **[non-zero winding rule](https://en.wikipedia.org/wiki/Nonzero-rule)** to determine whether a point falls within an enclosed curve.\n",
    "- This [Reddit post](https://www.reddit.com/r/adventofcode/comments/18fgddy/2023_day_10_part_2_using_a_rendering_algorithm_to/) from `tomi901` provides a **nice visual** to explain how to determine whether a point is in or out.\n",
    "- One more option: you can **scale-up the entire grid by 3**. Every square is replaced by a 3x3 group of squares. The result is that loops that were adjacent now have a channel between them. This allows you to always flood fill to the outside, which makes elimination of _external_ tiles much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path(path: list[Point], inside: set[Point]):\n",
    "    # Extract x and y values from the path\n",
    "    loop_x_values = [point.x for point in path]\n",
    "    loop_y_values = [point.y for point in path]\n",
    "    \n",
    "    # Extract x and y values from the inside set\n",
    "    inside_x_values = [point.x for point in inside]\n",
    "    inside_y_values = [point.y for point in inside]\n",
    "\n",
    "    # Plot the line and scatter graphs\n",
    "    plt.plot(loop_x_values, loop_y_values, \n",
    "             marker=MarkerStyle('o'), linestyle='-', color=\"blue\", label=\"Loop\")\n",
    "        \n",
    "    plt.scatter(inside_x_values, inside_y_values, \n",
    "                marker=MarkerStyle('x'), color=\"red\", label=\"Inside\")\n",
    "    \n",
    "    plt.title('Path Plot')\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_regions(grid: PipeGrid, loop_path: list[Point]) -> list[set]:\n",
    "    \"\"\" Determine the regions (pockets) that enclose non-main-loop tiles.\n",
    "\n",
    "    Returns a list of multiple sets, where each set is a region.\n",
    "    The regions may be internal or external to the main loop.\n",
    "    \"\"\"\n",
    "    regions = [] # list of sets, where each set is a tile region\n",
    "    explored = set()\n",
    "    \n",
    "    logger.debug(\"Getting non_loop_tiles..\")\n",
    "    non_loop_tiles = set()\n",
    "    loop_path_set = set(loop_path) # converting to set makes a huge difference to performance\n",
    "    for point in tqdm(grid.all_points()): # if it's slow, we can watch the progress bar\n",
    "        if point not in loop_path_set:\n",
    "            non_loop_tiles.add(point)\n",
    "    \n",
    "    logger.debug(f\"Retrieved {len(non_loop_tiles)} non_loop_tiles\")\n",
    "    \n",
    "    # now let's BFS each region of non_loop_tiles\n",
    "    for tile in non_loop_tiles:\n",
    "        if tile in explored: # we've seen this before\n",
    "            continue\n",
    "        \n",
    "        frontier = deque()\n",
    "        frontier.append(tile)\n",
    "        this_region_explored = set()\n",
    "        this_region_explored.add(tile)\n",
    "        \n",
    "        # keep going until the frontier is empty; i.e. when we've explored all the valid nodes\n",
    "        while frontier:   \n",
    "            current = frontier.popleft()  # pop the first item off the FIFO queue\n",
    "            \n",
    "            if current in this_region_explored: # this massively improves performance\n",
    "                continue\n",
    "            \n",
    "            for neighbour in grid.valid_neighbours_for_non_loop(current, loop_path):\n",
    "                frontier.append(neighbour)\n",
    "                this_region_explored.add(neighbour)\n",
    "                    \n",
    "        explored.update(this_region_explored)\n",
    "        regions.append(this_region_explored)\n",
    "\n",
    "    return regions\n",
    "\n",
    "def get_loop_path(grid: PipeGrid, furthest: Point, came_from: dict[Point, tuple]) -> list[Point]:\n",
    "    \"\"\" Build the closed path of the main pipe loop. Returns as a list of points. \n",
    "    \n",
    "    This function constructs the loop path starting from the 'furthest' point, which is\n",
    "    the most distant point from the start in the grid, back to the starting point. The path\n",
    "    is constructed in two halves and then combined.\n",
    "    \"\"\"\n",
    "    start = next(point for point in grid.all_points()\n",
    "            if grid.value_at_point(point) == \"S\")\n",
    "\n",
    "    # Build the first half of the path from the furthest point back to the start\n",
    "    path_first_half = []\n",
    "    current = furthest\n",
    "    while current != start:\n",
    "        path_first_half.append(current)\n",
    "        current = came_from[current][0] # Get the predecessor of the current point\n",
    "    \n",
    "    path_first_half.append(start)\n",
    "    \n",
    "    # Now we need the second half of the loop\n",
    "    # Find the point with a valid pipe, that is:\n",
    "    # adjacent to 'furthest', in 'came_from', but not in the first half of the path\n",
    "    join_candidates = [neighbour for neighbour in furthest.neighbours(include_diagonals=False)\n",
    "                       if neighbour in came_from \n",
    "                       and neighbour not in path_first_half\n",
    "                       and neighbour in grid.valid_neighbours_for_loop_pipe(furthest)]\n",
    "    current = join_candidates[0]\n",
    "    path_second_half = []\n",
    "    while current != start:\n",
    "        path_second_half.append(current)\n",
    "        current = came_from[current][0]\n",
    "    path_second_half.reverse() # the second half needs to continue from the first half\n",
    "    path_second_half.append(furthest) \n",
    "    \n",
    "    path = path_first_half + path_second_half\n",
    "    # logger.debug(f\"{path=}\")\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(grid: PipeGrid, furthest: Point, came_from: dict[Point, tuple]):\n",
    "    \"\"\" Determine number of tiles (which can be empty or non-loop pipe components) that are internal\n",
    "    to the main loop. \"\"\"\n",
    "    \n",
    "    loop_path = get_loop_path(grid, furthest, came_from) # get complete enclosed main loop\n",
    "    logger.debug(f\"Loop path has length {len(loop_path)}.\")\n",
    "    pltp = pltpath.Path([(point.x, point.y) for point in loop_path]) # convert to matplotlib.Path\n",
    "\n",
    "    regions = get_tile_regions(grid, loop_path) # determine all internal / external regions of tiles\n",
    "    logger.debug(\"Regions retrieved.\")\n",
    "\n",
    "    inside = set()\n",
    "    # Now let's work out if each region is inside or outside.\n",
    "    # We only need to look at one point from each region.\n",
    "    for region in regions:\n",
    "        a_point = list(region)[0] # pick an arbitrary point in the region\n",
    "        x, y = float(a_point.x), float(a_point.y)\n",
    "        if pltp.contains_points([(x, y)]): \n",
    "            inside.update(region)\n",
    "    \n",
    "    logger.debug(f\"Inside={inside}\")\n",
    "    plot_path(loop_path, inside) # let's visualise it\n",
    "    \n",
    "    return len(inside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sample_inputs = []\n",
    "\n",
    "sample_inputs.append(\"\"\"...........\n",
    ".S-------7.\n",
    ".|F-----7|.\n",
    ".||.....||.\n",
    ".||.....||.\n",
    ".|L-7.F-J|.\n",
    ".|..|.|..|.\n",
    ".L--J.L--J.\n",
    "...........\"\"\")\n",
    "\n",
    "sample_inputs.append(\"\"\"..........\n",
    ".S------7.\n",
    ".|F----7|.\n",
    ".||....||.\n",
    ".||....||.\n",
    ".|L-7F-J|.\n",
    ".|..||..|.\n",
    ".L--JL--J.\n",
    "..........\n",
    "\"\"\")\n",
    "\n",
    "sample_inputs.append(\"\"\".F----7F7F7F7F-7....\n",
    ".|F--7||||||||FJ....\n",
    ".||.FJ||||||||L7....\n",
    "FJL7L7LJLJ||LJ.L-7..\n",
    "L--J.L7...LJS7F-7L7.\n",
    "....F-J..F7FJ|L7L7L7\n",
    "....L7.F7||L7|.L7L7|\n",
    ".....|FJLJ|FJ|F7|.LJ\n",
    "....FJL-7.||.||||...\n",
    "....L---J.LJ.LJLJ...\n",
    "\"\"\")\n",
    "\n",
    "sample_inputs.append(\"\"\"FF7FSF7F7F7F7F7F---7\n",
    "L|LJ||||||||||||F--J\n",
    "FL-7LJLJ||||||LJL-77\n",
    "F--JF--7||LJLJ7F7FJ-\n",
    "L---JF-JLJ.||-FJLJJ7\n",
    "|F|F-JF---7F7-L7L|7|\n",
    "|FFJF7L7F-JF7|JL---7\n",
    "7-L-JL7||F7|L7F-7F7|\n",
    "L.L7LFJ|||||FJL7||LJ\n",
    "L7JLJL-JLJLJL--JLJ.L\n",
    "\"\"\")\n",
    "\n",
    "sample_answers = [4, 4, 8, 10]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_grid = parse_grid(curr_input.splitlines())\n",
    "    curr_pt1_soln, curr_furthest, curr_from = solve_part1(curr_grid)\n",
    "    curr_pt2_soln = solve_part2(curr_grid, curr_furthest, curr_from)\n",
    "    validate(curr_pt2_soln, curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(grid, furthest, came_from)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 11: Cosmic Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"11\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 11 Part 1\n",
    "\n",
    "We have a 2D grid that represents galaxies `#` and empty space.  We need to get the shortest path between every pair of galaxies. But any rows or columns with no galaxies need to be duplicated!\n",
    "\n",
    "So this:\n",
    "\n",
    "```text\n",
    "...#......\n",
    ".......#..\n",
    "#.........\n",
    "..........\n",
    "......#...\n",
    ".#........\n",
    ".........#\n",
    "..........\n",
    ".......#..\n",
    "#...#.....\n",
    "```\n",
    "\n",
    "Becomes this:\n",
    "\n",
    "```text\n",
    "....#........\n",
    ".........#...\n",
    "#............\n",
    ".............\n",
    ".............\n",
    "........#....\n",
    ".#...........\n",
    "............#\n",
    ".............\n",
    ".............\n",
    ".........#...\n",
    "#....#.......\n",
    "```\n",
    "\n",
    "**My solution**:\n",
    "\n",
    "Grow the input according to the duplication rule:\n",
    "- Turn the 2D grid into a NumPy array, as this is faster for manipulating grids of data. I've converted all `#` to a `1` and all `.` to a `0`. This makes subsequent operations a bit easier. \n",
    "- For rows: iterate through each row check if a row contains `1`. If not, insert an extra row. I've parameterised this so that we can add an arbitrary number of rows. But for Part 1, we only ever need to add one additional row wherever a row contains no galaxies.\n",
    "- For cols: do the same, but transpose the array first, using the `ndarray transpose()` method. After transposing, each column now exists as a row.  So I can use the same function as I used for rows. After inserting the rows, we must transpose back.\n",
    "\n",
    "Determine all the locations of points. This code is pretty useful:\n",
    "\n",
    "```python\n",
    "    # Determine all locations with a galaxy and convert to Points\n",
    "    y, x = np.where(array == 1) # remember that 1 = #\n",
    "    hash_points = [Point(x, y) for (y, x) in zip(y, x)]\n",
    "```\n",
    "\n",
    "- Determine all the locations in the array where the value is 1.\n",
    "- For each of these locations return the list of `y` values and the list of `x` values.\n",
    "- Then I use [zip](https://aoc.just2good.co.uk/python/zip) to combine the two lists, to get a single list of `(y,x)` tuples. Then I use a [list comprehension](https://aoc.just2good.co.uk/python/comprehensions) to create a `Point` from each of these tuples.\n",
    "\n",
    "Next, get all the pairs of points using [`itertools.combinations()`](https://aoc.just2good.co.uk/python/perms_combos).\n",
    "- The `combinations()` function returns all unique combinations of points, but doesn't care about sequence. \n",
    "- I.e. if we have A -> B, it will not also return B -> A. \n",
    "- The instructions are pretty clear here: _\"Only count each pair once; order within the pair doesn't matter.\"_\n",
    "\n",
    "Now I find the  _Manhattan distance_ for each pair. \n",
    "- The Manhattan distance is the sum of horizontal and vertical distance, which is exactly what we want. \n",
    "- My `Point` class already knows how to do this.\n",
    "- Sum up the distances.\n",
    "\n",
    "Easy enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_rows(array: np.ndarray, insert_number) -> np.ndarray:\n",
    "    new_rows = []\n",
    "    for row in array:\n",
    "        new_rows.append(row)\n",
    "        if 1 not in row:\n",
    "            new_rows.extend(row for _ in range(insert_number))\n",
    "\n",
    "    return np.array(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(data, part=1, expansion_value:int=2):\n",
    "    # parse data into a NumPy array, swapping # for 1 and . for 0.\n",
    "    array_data = [[1 if char == '#' else 0 for char in line] for line in data]\n",
    "    array = np.array(array_data)\n",
    "    \n",
    "    insertions = expansion_value - 1 # we need to insert n-1 rows, given an expansion value\n",
    "    if part==1:\n",
    "        array = insert_rows(array, insertions) # triple rows\n",
    "        array = insert_rows(array.transpose(), insertions).transpose() # triple columns\n",
    "    \n",
    "    if part==2:\n",
    "        # work out which rows and cols have no #\n",
    "        empty_rows = np.where(np.all(array == 0, axis=1))[0]\n",
    "        empty_cols = np.where(np.all(array == 0, axis=0))[0]\n",
    "        \n",
    "    # Determine all locations with a galaxy and convert to Points\n",
    "    y, x = np.where(array == 1) # remember that 1 = #\n",
    "    hash_points = [Point(x, y) for (y, x) in zip(y, x)]\n",
    "\n",
    "    # get all unique pairs of points\n",
    "    point_dists = {} # store distances as { (point_a, point_b): distance, ... }\n",
    "    for (point_a, point_b) in combinations(hash_points, 2): # all combinations of 2 points   \n",
    "        point_dists[(point_a, point_b)] = point_a.manhattan_distance_from(point_b)\n",
    "        \n",
    "        if part == 2:\n",
    "            # Add insertion value for every row and every column that was empty, \n",
    "            # for each row and column that is between our two points\n",
    "            # Either point could be on the one to the left/right, above/below. So deterine min/max values.\n",
    "            for col in empty_cols:\n",
    "                if min(point_a.x, point_b.x) < col < max(point_a.x, point_b.x): # if this column between points\n",
    "                    point_dists[(point_a, point_b)] += insertions\n",
    "                    \n",
    "            for row in empty_rows:\n",
    "                if min(point_a.y, point_b.y) < row < max(point_a.y, point_b.y): # if this row between points\n",
    "                    point_dists[(point_a, point_b)] += insertions            \n",
    "            \n",
    "    sum_dists = sum(point_dists.values())\n",
    "    logger.debug(f\"{sum_dists=}\")\n",
    "    return sum_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_1 = \"\"\"...#......\n",
    ".......#..\n",
    "#.........\n",
    "..........\n",
    "......#...\n",
    ".#........\n",
    ".........#\n",
    "..........\n",
    ".......#..\n",
    "#...#.....\n",
    "\"\"\"\n",
    "sample_inputs = [sample_1.splitlines()]\n",
    "sample_answers = [374]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 11 Part 2\n",
    "\n",
    "Ah, if we're inserting millions of rows and columns, this isn't going to scale!! If we try creating a NumPy array where there are hundreds of millions of rows and hundreds of millions of columns, we'll run out of memory fast! We need to do something smarter.\n",
    "\n",
    "**My solution**:\n",
    "\n",
    "Rather than adding all the required extra rows and columns and then calculating distance, I will:\n",
    "\n",
    "- Determine the y values of all rows that are empty.\n",
    "- Determine the x values of all columns that are empty.\n",
    "- Calculate the distances between points in the original map.\n",
    "  - Using Manhattan distance, as before.\n",
    "  - Then determine if any of our empty rows and empty cols are between our two points. Note that we need to determine the min-x/min-y and max-x/max-y for each point, since we don't know which point will be on the left or above.\n",
    "  - For each empty row / empty column between our points, simply add the required expansion increment.\n",
    "  - Note that the instructions say _`each empty row should be replaced with 1000000 empty rows, and each empty column should be replaced with 1000000 empty columns.`_ **Replacing** is the key word.  So, for each empty row/column, we actually need to add n-1 to the Manhattan distance.\n",
    "\n",
    "When calculating if our rows or columns are empty, this code is interesting:\n",
    "\n",
    "```python\n",
    "        empty_rows = np.where(np.all(array == 0, axis=1))[0]\n",
    "        empty_cols = np.where(np.all(array == 0, axis=0))[0]\n",
    "```\n",
    "\n",
    "This works by saying:\n",
    "\n",
    " _\"Along the specified axis (either rows or columns), check if ALL the values in the array or 0. If they are, return the index values of those rows / columns.\"_\n",
    "\n",
    " So, not too bad in the end. A lot less painful than yesterday!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_answers = [8410]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input, part=1, expansion_value=100), curr_ans) # test with sample data, part 1 approach\n",
    "    validate(solve(curr_input, part=2, expansion_value=100), curr_ans) # test with sample data, part 2 approach\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve(input_data, part=2, expansion_value=1000000)\n",
    "logger.info(f\"Soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 12: Hot Springs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"12\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.INFO)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 12 Part 1\n",
    "\n",
    "The springs have fallen into disrepair. Our input is the condition record of which springs are damaged. But the input data is also damaged! We need to repair the damaged records.\n",
    "\n",
    "```text\n",
    "???.### 1,1,3\n",
    ".??..??...?##. 1,1,3\n",
    "?#?#?#?#?#?#?#? 1,3,1,6\n",
    "????.#...#... 4,1,1\n",
    "????.######..#####. 1,6,5\n",
    "?###???????? 3,2,1\n",
    "```\n",
    "\n",
    "Springs are arranged in rows. For each row, the condition record shows:\n",
    "\n",
    "- operational (`.`), damaged (`#`), or unknown (`?`) springs\n",
    "- followed by counts of contiguous groups of damaged sprints, which accounts for every damaged spring\n",
    "- groups are always separated by at least one operational spring\n",
    "\n",
    "**For each row, count all of the different arrangements of operational and broken springs that meet the given criteria. What is the sum of those counts?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "We need to find all substitutions for `?` that result in valid records.\n",
    "\n",
    "After parsing each row, I store the record in my `SpringRecord` [dataclass](https://aoc.just2good.co.uk/python/classes#dataclass). The count of possible valid arrangements is calculated by the [recursive](https://aoc.just2good.co.uk/python/recursion) `get_arrangements_count()` method.\n",
    "\n",
    "The method systematicalThe damaged_groups tuple defines the required lengths of contiguous blocks of #.\n",
    "The current group index indicates which group (block of #) you are currently trying to complete.\n",
    "This index helps in determining whether the current arrangement is in line with the damaged_groups requirements. For example, if you are working on the second group, the function knows to compare the current length of contiguous # characters with the second element in damaged_groups.ly explores every possible combination of `.`. and `#` for each `?` in the record. It keeps track of the current state (current character index, current group index, and length of the current group) to ensure the arrangement adheres to the constraints of `damaged_groups`.\n",
    "\n",
    "It works like this:\n",
    "- `char_idx` stores the current position in the record string. At each step, we decide what the character at this position could be (`#` or `.`).\n",
    "- The `damaged_groups` tuple defines the required lengths of contiguous blocks of `#`. The current group index (`curr_group_idx`) indicates which group (block of `#`) we are currently trying to complete.\n",
    "- `curr_group_len` keeps track of how many `#` characters have been consecutively placed in the current group.\n",
    "\n",
    "Together, these three pieces of information provide a complete snapshot of our progress through the string at any given recursion level. We know exactly where we are in the string, which group we are trying to fill, and how much of that group we have filled so far.\n",
    "\n",
    "- **Base case**\n",
    "  - When `char_idx` equals the length of the record, it means we've reached the end of the record.\n",
    "  - If `curr_group_idx` equals the length of `damaged_groups` and `curr_group_len` is `0`, all groups have been completed correctly, and this arrangement is valid.\n",
    "  - If `curr_group_idx` is the last group and `curr_group_len` equals the length of this last group, this is also a valid arrangement.\n",
    "  - In all other cases, the arrangement is invalid.\n",
    "\n",
    "- **Recursion**\n",
    "  - The function iterates over each character (using `char_idx`) in the record. For each character position, it considers both possible states (`.` and `#`).\n",
    "  - We check if the character at `char_idx` in the record is either the same as the state being considered, or a `?`. I.e. because if the current character in the record is a `.`, then `.` is the only valid `char` to try. If the current character in the record is a `#`, then `#` is the only valid `char` to try. If the current character in the record is a `?`, then we can try substituting either `.` or `#`. Thus, whenever we encoutner `?`, our recursion branches into two paths.\n",
    "  - If the considered state is `.`, then there are two cases: 1) `curr_group_len` is `0`, which means we are  not currently counting a group of `#`, so we can safely proceed to the next character. And 2) `curr_group_len` equals the length of the current group in `damaged_groups`, meaning we've completed a group and can proceed to the next group.\n",
    "  - If the considered state is `#`, then we're extending (or beginning) the current group. We increment `curr_group_len` and proceed to the next character.\n",
    "\n",
    "  **Why store only these three state values, rather than the entire arrangement string?**\n",
    "  \n",
    "  Storing the entire arrangement string at each step of the recursion would significantly increase the solution space requirement. For a string of length `n`, there would potentially be 2**n different arrangements (each `?` can be either `#` or `.`), and each arrangement would need to be stored in memory. For larger strings, this just gets too big. (And would not work for Part 2, when we get to it!)\n",
    "\n",
    "  Instead, this approach stores just three integer values, which is sufficient to continue the recursion without storing the entire arrangement. It's important to understand that the state values (current character index, current group index, and length of the current group) do not represent a complete arrangement in themselves. Instead, they represent a _state_ within the process of building an arrangement. \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class SpringsRecord():\n",
    "    record: str\n",
    "    damaged_groups: tuple\n",
    "    \n",
    "    @cache # to cache, our SpringRecord must be immutable - hence frozen\n",
    "    def get_arrangements_count(self, char_idx: int, curr_group_idx: int, curr_group_len: int):\n",
    "        \"\"\" Determine how many arrangements are possible by recursing.\n",
    "        Move through the record one char at a time. Whenever we reach the end of the record,\n",
    "        check if it has completed all the groups.\n",
    "        Our inputs represent a minimal state that defines where we are in the record, \n",
    "        which group we're processing, and the length the current group.\n",
    "\n",
    "        Args:\n",
    "            char_idx (int): current position in the record\n",
    "            curr_group_idx (int): current group in damaged_groups\n",
    "            curr_group_len (int): current length of damaged group\n",
    "\n",
    "        Returns:\n",
    "            int: count of arrangements\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        \n",
    "        # base case - check if we have a complete and valid arrangement\n",
    "        if char_idx == len(self.record): # if we're at the end; all chars have been processed\n",
    "            if curr_group_idx == len(self.damaged_groups) and curr_group_len == 0:\n",
    "                # we're past the last group\n",
    "                return 1 # valid arrangement\n",
    "            elif curr_group_idx == len(self.damaged_groups) - 1 and self.damaged_groups[curr_group_idx] == curr_group_len:\n",
    "                # we're on the last char of the last group, and the group is complete\n",
    "                return 1 # valid arrangement\n",
    "            else: # we have not completed all groups, or current group length is too long\n",
    "                return 0 # invalid\n",
    "        \n",
    "        # Process the current char in the record by recursion\n",
    "        # Determine valid states for recursion\n",
    "        for char in [\".\", \"#\"]:\n",
    "            # We can subst char for itself (no change), or for ?\n",
    "            if self.record[char_idx] in (char, \"?\"): \n",
    "                if char == \".\": \n",
    "                    # we're extending the operational section or ending the damaged group\n",
    "                    if curr_group_len == 0: # we're not in a group, so we must be extending\n",
    "                        count += self.get_arrangements_count(char_idx+1, curr_group_idx, 0)\n",
    "                    elif (curr_group_idx < len(self.damaged_groups) \n",
    "                          and curr_group_len == self.damaged_groups[curr_group_idx]):\n",
    "                        # we're adding a . after a #, so the group is now complete; move on to next group\n",
    "                        count += self.get_arrangements_count(char_idx+1, curr_group_idx+1, 0)\n",
    "                else: # we're adding a #; extend the current group (which might be empty at this point)\n",
    "                    count += self.get_arrangements_count(char_idx+1, curr_group_idx, curr_group_len+1)\n",
    "        \n",
    "        return count          \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_records(data) -> list[SpringsRecord]:\n",
    "    spring_records = []\n",
    "    for line in data:\n",
    "        record_part, groups_part = line.split()\n",
    "        spring_records.append(SpringsRecord(record_part, tuple([int(x) for x in groups_part.split(\",\")])))\n",
    "        \n",
    "    return spring_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Part 2\n",
    "def unfold(record: SpringsRecord, replica_count:int=5) -> SpringsRecord:\n",
    "    \"\"\" \n",
    "    Replace record with n copies of the record, separated by ? \n",
    "    Replace the damaged groups with a version that is n*current \n",
    "    \"\"\"\n",
    "    new_rec = \"?\".join(replica_count*[record.record])\n",
    "    new_groups = replica_count*record.damaged_groups\n",
    "    return SpringsRecord(new_rec, new_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(records: list[SpringsRecord], part:int=1):\n",
    "    counts = 0\n",
    "    for record in records:\n",
    "        if part==2:\n",
    "            record = unfold(record)\n",
    "        count = record.get_arrangements_count(0, 0, 0)\n",
    "        if logger.getEffectiveLevel() == logging.DEBUG: # avoid wasted compute effort\n",
    "            logger.debug(f\"{record=}, {count=}\")\n",
    "        counts += count\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"???.### 1,1,3\n",
    ".??..??...?##. 1,1,3\n",
    "?#?#?#?#?#?#?#? 1,3,1,6\n",
    "????.#...#... 4,1,1\n",
    "????.######..#####. 1,6,5\n",
    "?###???????? 3,2,1\n",
    "\"\"\")\n",
    "sample_answers = [21]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_records = parse_records(curr_input.splitlines())\n",
    "    validate(solve(curr_records), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "records = parse_records(input_data)\n",
    "soln = solve(records)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 12 Part 2\n",
    "\n",
    "Now we have to replace each record string with a record string that is five copies of the original, separated by `?`. And similarly, we have to replace the damaged springs groups with a new list of groups, that is five copies of the original.\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- Go through each `SpringRecord` we created before, and replicate the two fields as required.\n",
    "\n",
    "  - For the `damaged_groups`, we can simply multiply them by 5 to create the new tuple. Python is clever like that!\n",
    "  - For the `record` strings, we have to first convert each string to a `list` containing our string. Then we can multiply the list five times to result in a list with five members. Then we can use Python's `join()` method, to join the five string members together, putting `?` in between.\n",
    "\n",
    "- Then, we can run the same code as for Part 1, but with a couple of tweaks.\n",
    "\n",
    "  - I've added @cache to the `get_arrangements_count()` method.  This caches any results for any states that we have seen before. And this means that for every recursion, we will have cached all the states that led to this recursion. Because our state is minimal (there are far fewer combinations of [char position, group number, group length] than there are of [record combinations]), this means we can effectively cache each state with each recursed arrangement count.\n",
    "  - To make this work, I have to ensure that my _state_ is _hashable_. I.e. this means that all the parameters I pass to the `get_arrangements_count()` method must themselves be hashable. In my original Part 1, my `SpringRecord` class was not hashable, because my class was mutable. I fixed this by 1) changing my `damaged_groups` from a `list` to a `tuple`, and 2) by adding `(frozen=True)` to my `@dataclass` decorator. This is sufficient to make my `SpringRecord` hashable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_answers = [525152]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_records = parse_records(curr_input.splitlines())\n",
    "    validate(solve(curr_records, part=2), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve(records, part=2)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 13: Point of Incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"13\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 13 Part 1\n",
    "\n",
    "We're given several 2D patterns of ash (`.`) and rocks (`#`) as input.  Each pattern will have a line of symmetry, meaning that a pair of columns or a pair of rows will be identical.  The line of symmetry will not necessarily be in the middle of the pattern, so we can ignore rows / columns that are not reflected.\n",
    "\n",
    "_\"To find the reflection in each pattern, you need to find a perfect reflection across **either a horizontal line between two rows or across a vertical line between two columns.**\"_\n",
    "\n",
    "We're asked to:\n",
    "\n",
    "- Add up the number of columns to the left of each vertical line of reflection\n",
    "- Add 100 multiplied by the number of rows above each horizontal line of reflection\n",
    "\n",
    "**What is the total number?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "First, parse the input data.\n",
    "\n",
    "- Split into blocks at each empty line, which we can do with `data.split(\"\\n\\n\")`.\n",
    "- Then, for each block, split into a list of lines, and for each line, convert to a list that contains `1` in place of `#` and `0` in place of `.`.  (I could have built my array using `#` and `.` instead of `1` and `0`. But I converted just in case it made life easier later.)\n",
    "- Turn each block into a 2D [NumPy](https://aoc.just2good.co.uk/python/numpy) array, because it's easier to work with rows and columns in NumPy.\n",
    "\n",
    "Now we can iterate through each array, and find either the vertical or horizontal symmetry line. I do this with a function called `find_symmetry()`, which takes the `pattern ndarray` and the `axis` as a parameter.  In a 2D NumPy array, `axis==0` for rows, and `==1` for columns.\n",
    "\n",
    "- If we want columns, we transpose the array. This turns columns into rows, so that we can then use the same symmetry checking logic in both cases.\n",
    "- Then, in my original part 1, I compared the rows (or transposed columns) like this: \n",
    "\n",
    "```python\n",
    "np.array_equal(array[row_num], array[row_num + 1])\n",
    "```\n",
    "\n",
    "- This returns `True` if row `n` is identical to row `n+1`.\n",
    "- If the rows are identical, I then determine how many rows remain, after the symmetry line.\n",
    "- I then iterate through all remaining rows outwards from the symmetry line. For example, if the symmetry line were between rows 5 and 6, then the next pair of rows would be 4 and 7, then 3 and 8, and so on.\n",
    "- If we get to either end of the array and all the pairs contain identical rows, then we simply return the index of the current row.\n",
    "- We then add 1 to this value, to determine the number of _rows above_ or _columns before_ the symmetry line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_patterns(data) -> list[np.ndarray]:\n",
    "    pattern_blocks = data.split(\"\\n\\n\")\n",
    "    return [np.array([[1 if char == '#' else 0 for char in line] \n",
    "                        for line in block.splitlines()]) for block in pattern_blocks]\n",
    "\n",
    "def find_symmetry(array: np.ndarray, axis: int, diffs_required: int=0) -> int:\n",
    "    \"\"\" Find the line of symmetry, and return the count of rows or columns \n",
    "    before the line of symmetry.\n",
    "       \n",
    "    Args:\n",
    "        array (np.ndarray): The 2D array\n",
    "        axis (int): 0 for rows, 1 for cols\n",
    "        \n",
    "    Returns index of row/column that is above/left of symmetry line, or -1 if no symmetry\n",
    "    \"\"\"\n",
    "    if axis == 1: # we want columns, so transpose the array\n",
    "        array = array.T\n",
    "    \n",
    "    for row_num in range(len(array) - 1):\n",
    "        # Compare current row with the next row\n",
    "        diffs = np.sum(array[row_num] != array[row_num+1])\n",
    "        if diffs <= diffs_required:\n",
    "            rows_after = len(array) - (row_num + 2)\n",
    "            for i in range(rows_after): # check symmetry of each remaining row\n",
    "                # we've run out of rows in the first half, or symmetry at first row\n",
    "                if row_num-i == 0: \n",
    "                    break\n",
    "                # if not np.array_equal(array[row_num-1-i], array[row_num+2+i]):\n",
    "                diffs += np.sum(array[row_num-1-i] != array[row_num+2+i])\n",
    "                if diffs > diffs_required:\n",
    "                    break\n",
    "                \n",
    "            if diffs == diffs_required:\n",
    "                return row_num # the row where our symmetry is\n",
    "            else:\n",
    "                continue # move on to next row\n",
    "        \n",
    "    return -1 # no symmetry found\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(patterns: list, part:int=1):\n",
    "    diffs_required = 0 if part==1 else 1\n",
    "    \n",
    "    rows_above_symmetry = 0\n",
    "    cols_left_of_symmetry = 0\n",
    "    for pattern in patterns:\n",
    "        rows_above_symmetry += find_symmetry(pattern, axis=0, diffs_required=diffs_required) + 1\n",
    "        cols_left_of_symmetry += find_symmetry(pattern, axis=1, diffs_required=diffs_required) + 1\n",
    "    \n",
    "    answer = cols_left_of_symmetry + (100*rows_above_symmetry)\n",
    "    logger.debug(f\"{rows_above_symmetry=}, {cols_left_of_symmetry=}, {answer=}\")\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "\n",
    "# Samples from problem\n",
    "sample_inputs.append(\"\"\"#.##..##.\n",
    "..#.##.#.\n",
    "##......#\n",
    "##......#\n",
    "..#.##.#.\n",
    "..##..##.\n",
    "#.#.##.#.\n",
    "\n",
    "#...##..#\n",
    "#....#..#\n",
    "..##..###\n",
    "#####.##.\n",
    "#####.##.\n",
    "..##..###\n",
    "#....#..#\"\"\")\n",
    "\n",
    "# moving symmetry to top half and left half\n",
    "sample_inputs.append(\"\"\".##..##.#\n",
    ".#.##.#..\n",
    "#......##\n",
    "#......##\n",
    ".#.##.#..\n",
    ".##..##..\n",
    ".#.##.#.#\n",
    "\n",
    "#....#..#\n",
    "..##..###\n",
    "#####.##.\n",
    "#####.##.\n",
    "..##..###\n",
    "#....#..#\n",
    "#...##..#\"\"\")\n",
    "\n",
    "# testing symmetry at the edges\n",
    "sample_inputs.append(\"\"\"..##.#\n",
    "##.#..\n",
    "....##\n",
    "....##\n",
    "##.#..\n",
    "..##..\n",
    "##.#.#\n",
    "\n",
    "#####.##.\n",
    "#####.##.\n",
    "..##..###\n",
    "#....#..#\n",
    "#...##..#\"\"\")\n",
    "                     \n",
    "sample_answers = [405, 304, 101]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_patterns = parse_patterns(curr_input)\n",
    "    validate(solve(curr_patterns), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "patterns = parse_patterns(input_data)\n",
    "soln = solve(patterns)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 13 Part 2\n",
    "\n",
    "Every mirror has _exactly one_ smudge, which reverses a single `.` or `#` in our array.\n",
    "\n",
    "We're asked to change one smudge (`#`) in order to create a new line of reflection. I.e. for every 2D array, there will be a single `#` that we can change to a `.` that introduces a line of symmetry.  Note: this may or may not break the original line of symmetry.\n",
    "\n",
    "**In each pattern, fix the smudge and find the different line of reflection. What number do you get after summarizing the new reflection line in each pattern in your notes?**\n",
    "\n",
    "The crucial observation here is that we must calculate our answer based _only_ on the _new_ line of symmetry.  The existing line should be ignored.\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "We could substitute each `#` for `.`, and repeat our symmetry check for each substitution.  But that would be pretty slow.\n",
    "\n",
    "Better solution: look for a line of symmetry where there is exactly one mismatch. I.e. because if exactly one mirror needs to change, then we know that this mirror will be the only mismatch for the second line of symmetry.\n",
    "\n",
    "This requires very little change to the code:\n",
    "\n",
    "- I've added a `part` parameter to the `solve` function.\n",
    "- When `part` is set to `2`, we set a variable called `diffs_required` to `1`; otherwise, we set it to `0`.\n",
    "- We call `find_symmetry()` like we did for Part 1, but this time we supply the `diffs_required` parameter.\n",
    "\n",
    "The `find_symmetry()` function has been updated. Instead of this:\n",
    "\n",
    "```python\n",
    "    if np.array_equal(array[row_num], array[row_num + 1]):\n",
    "\n",
    "```\n",
    "\n",
    "We now do this:\n",
    "\n",
    "```python\n",
    "    diffs = np.sum(array[row_num] != array[row_num+1])\n",
    "    if diffs <= diffs_required:\n",
    "```\n",
    "\n",
    "Here `np.sum()` calculates the sum of all the elements the differ between the two supplied rows.\n",
    "\n",
    "When `diffs_required` is `0`, the result is the same as Part 1.  But when `diffs_required` is `1`, this now checks for symmetry, starting with 0 or 1 differences. Then, as we check each pair of rows, we keep track of the number of differences so far.\n",
    "\n",
    "- If `diffs` exceeds `1`, then we're bust.\n",
    "- If `diffs` is exactly `1` after completing our symmetry check, then the requirement for Part 2 has been satisfied, and we return the row / column index, as before.\n",
    "\n",
    "And that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "\n",
    "# Samples from problem\n",
    "sample_inputs.append(\"\"\"#.##..##.\n",
    "..#.##.#.\n",
    "##......#\n",
    "##......#\n",
    "..#.##.#.\n",
    "..##..##.\n",
    "#.#.##.#.\n",
    "\n",
    "#...##..#\n",
    "#....#..#\n",
    "..##..###\n",
    "#####.##.\n",
    "#####.##.\n",
    "..##..###\n",
    "#....#..#\"\"\")\n",
    "\n",
    "sample_answers = [400]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_patterns = parse_patterns(curr_input)    \n",
    "    validate(solve(curr_patterns, part=2), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve(patterns, part=2)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 14: Parabolic Reflector Dish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"14\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 14 Part 1\n",
    "\n",
    "We have rocks attached to pulleys which are used to focus the mirrors in our reflector dish. The rocks are located in a metal grid:\n",
    "\n",
    "- Rounded rocks (`O`) which can roll when the platform is tilted.\n",
    "- Cube rocks (`#`) whcih stay in place.\n",
    "- Empty spaces (`.`).\n",
    "\n",
    "E.g.\n",
    "\n",
    "```text\n",
    "O....#....\n",
    "O.OO#....#\n",
    ".....##...\n",
    "OO.#O....O\n",
    ".O.....O#.\n",
    "O.#..O.#.#\n",
    "..O..#O..O\n",
    ".......O..\n",
    "#....###..\n",
    "#OO..#....\n",
    "```\n",
    "\n",
    "When tilted north such that all round rolls roll to the top, total load is calculated as: the number of rows from a `O` to the south edge of the platform, inclusive of its own row. `#` don't contribute to load.\n",
    "\n",
    "**Tilt the platform so that the rounded rocks all roll north. Afterward, what is the total load on the north support beams?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- Read in the data and convert to a NumPy grid. This will make life much easier if we have to do any sort of flipping or rotating of our grid later!\n",
    "- Keep track of `highest_occupied` position in a dictionary of `{ col: row }`. Initially, we will set the highest occopied position of each column to be `-1`, to represent the row index above the start of our grid.  (Since our first grid row will be row number `0`.)\n",
    "- Now, iterate through each row, starting at the top.\n",
    "- For each row, iterate through each element.\n",
    "  - If the current element is `O` (i.e. a round rock), then we need to try to roll it to the top.\n",
    "  - The highest row we can roll it to will be `highest_occupied[col_num]`, plus `1`. Store this is our `target_row`.\n",
    "  - If our `target_row` is different to our current row, then we can move this stone. Set the current stone position to empty, and then place the stone in this column in the `target_row`. Then, update our `highest_occupied` value for this column.\n",
    "  - Finally, check if the element we're on is not empty. It may not be empty if it contains a `#`, or if we were unable to roll a stone stored here. If it's not empty, update `highest_occupied` for this columnn to be this row.\n",
    "- Once this outer loop finishes, we've finished our tilt. Now we just need to calculate the `total_load`:\n",
    "  - First, I use `np.sum()` to retrieve the counts of `O` in each row. We return these as a single dimension array of counts.\n",
    "  - Then, for each value in this list of counts, I simply multiply the value by the difference between the height of our grid, and the current count index position (which represents the row number).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(data) -> np.ndarray:\n",
    "    return np.array([list(row) for row in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tilt_north(grid: np.ndarray) -> np.ndarray:\n",
    "    # { col_num: row_num } Initialise to -1, i.e. the row above the grid\n",
    "    highest_occupied = { col_num: -1 for col_num, _ in enumerate(grid[0]) }\n",
    "    \n",
    "    for row_num, row in enumerate(grid):\n",
    "        for col_num, val in enumerate(row):\n",
    "            if val == \"O\": # roll this rock up to highest occupied + 1\n",
    "                target_row = highest_occupied[col_num] + 1\n",
    "                if target_row != row_num: # we need to move this rock; otherwise it is blocked\n",
    "                    grid[target_row,col_num] = \"O\"\n",
    "                    grid[row_num,col_num] = \".\"\n",
    "                    highest_occupied[col_num] = target_row\n",
    "\n",
    "            if grid[row_num,col_num] != \".\": # val may have changed\n",
    "                highest_occupied[col_num] = row_num\n",
    "\n",
    "    return grid    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(grid: np.ndarray):\n",
    "    logger.debug(f\"\\n{grid}\")\n",
    "\n",
    "    grid = tilt_north(grid)\n",
    "    row_counts = np.sum(grid==\"O\", axis=1)\n",
    "    total_load = sum((grid.shape[0]-row)*val for (row, val) in enumerate(row_counts))\n",
    "\n",
    "    logger.debug(f\"{total_load=}\")\n",
    "    return total_load\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"O....#....\n",
    "O.OO#....#\n",
    ".....##...\n",
    "OO.#O....O\n",
    ".O.....O#.\n",
    "O.#..O.#.#\n",
    "..O..#O..O\n",
    ".......O..\n",
    "#....###..\n",
    "#OO..#....\"\"\")\n",
    "sample_answers = [136]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_grid = parse_input(curr_input.splitlines())\n",
    "    validate(solve_part1(curr_grid), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "grid = parse_input(input_data)\n",
    "soln = solve_part1(grid)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 14 Part 2\n",
    "\n",
    "Now we need to move the rocks to the edges. \n",
    "\n",
    "The platform performs tilt cycles.  Each cycle tilts the platform: N, W, S, E.\n",
    "We're asked to perform 1000000000 cycles!!\n",
    "\n",
    "Well, I can't just scale up the above. That's too many cycles. I need to be a bit more clever!\n",
    "\n",
    "My guess is that after a number of cycles, we'll end up with a loop of repeating cycles. I need to find out when I've seen this cycle before.\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- Each cycle requires us to tilt N, W, S, E.\n",
    "  - We already know how to tilt north. So one way we can tilt west is to rotate our grid by 90 degrees clockwise - which results in the original west now pointing north - and then tilting north again. And from there, if we rotate 90 degrees clockwise again and tilt north, this is equivalent to performing a tilt south. Repeat again from E. Then rotate one more time to bring us back to facing north.\n",
    "  - [NumPy](https://aoc.just2good.co.uk/python/numpy) already provides a convenient method to rotate our grid: `np.rot90(grid, -1)`. Note: `-1` means clockwise. If we omit this, then the grid would rotate counterclockwise.\n",
    "- As I mentioned before, it's my expectation that after a number of initial cycles, the cycles will settle into a repeating pattern, where we will see the same configuration over and over again, every n cycles. So I need to keep track of all the post-cycle grid configurations I've' seen so far, until the point we see a grid configuration we've seen before.\n",
    "  - I can do this by storing each grid configuration in a dictionary _cache_ (along with the current cycle number as the value).\n",
    "  - However, the grid itself is not hashable, so I can convert it into a `tuple` (which is immutable) before storing it in the dictionary.\n",
    "  - Then, every time I perform a cycle, I check whether the resulting grid configuration is in the _cache_. If I haven't seen it before, I add this configuration to the _cache_. If I have seen it before, then I've found my first repeat.\n",
    "  - Having found the repeat, I can determine how many cycles are required between each repeat of configuration. I store this as `repeat_len`.\n",
    "\n",
    "Check this example:\n",
    "\n",
    "![Repeating configurations](https://aoc.just2good.co.uk/assets/images/repeating_configs.png)\n",
    "\n",
    "Here, the blue circles represent the grid configuration at the end of each cycle, where we haven't yet seen a repeat.  But eventually, we find that the green-yellow-red circles repeat.  So here we have a repeat length of 3.\n",
    "\n",
    "So, to find the nth configuration (which could be 999, 1000000, 1000000000, or whatever), then we:\n",
    "\n",
    "- Determine how many cycles are required to get to n from our current cycle position. I store this as `remaining_cycles`. In our example, our current cycle position is just after the second green, since the second green represents the first detection of a repeated config.\n",
    "- Divide `remaining_cycles` by the repeat length and obtain the remainder. This remainder gives us the number of cycles we need to execute from here, in order to create the configuration that will be the same as the configuration at n. I call this `additional_cycles`.\n",
    "- For example, `additional_cycles` were equal to 0, then it means that the nth grid would be a green. If it were equal to 1, then the nth grid would be a yellow. If it were 2, then it would be a red.\n",
    "\n",
    "For my real data, my logging output shows:\n",
    "\n",
    "```text\n",
    "Current iteration 131; last seen at 80; repeat_len=51\n",
    "additional_cycles=28\n",
    "```\n",
    "\n",
    "So, in total, I've only had to perform the cycle `131+28` times!  Which is a lot fewer than `1000000000`!!\n",
    "\n",
    "**Footnote:**\n",
    "\n",
    "When I was looking at this problem, it was immediately apparent to me that repeating cycles were likely. But you may be thinking... _\"Why would you think that?  Why did this solution occur to you?\"_\n",
    "\n",
    "Well, I guess it's partly intuition around what is likely to happen.  But perhaps more significantly... I've done a few AoCs now. And this isn't the first time we've seen a repeating cycle problem. So I think it's fair to say that a bit of AoC experience will help you quickly make an educated guess about what you need to do.  And if you haven't done AoC before (or similar), then this conclusion is less likely to be obvious.\n",
    "\n",
    "But don't sweat it.  This is where practice makes you better next time.\n",
    "\n",
    "(And I know that at my very best, I'm only mediocre!!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tilt_cycle(grid):\n",
    "    \"\"\" \n",
    "    Tilt N, S, E and W. \n",
    "    Do this by tiling north, and then rotate 90 degrees CW.\n",
    "    Repeat tile+rotate three times.  This brings us back to original orientation (north).\n",
    "    \"\"\"\n",
    "    for _ in range(4): # N, W, S, E\n",
    "        grid = tilt_north(grid)\n",
    "        grid = np.rot90(grid, -1) # clockwise\n",
    "        \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(grid: np.ndarray):\n",
    "    logger.debug(f\"\\n{grid}\")\n",
    "    required_cycles = 1000000000\n",
    "    repeat_len = 1\n",
    "\n",
    "    grid_cache = {}\n",
    "    for i in range(required_cycles):\n",
    "        grid = tilt_cycle(grid)\n",
    "\n",
    "        grid_top = tuple(map(tuple, grid)) # cache the grid as a tuple\n",
    "        if grid_top in grid_cache:\n",
    "            prev_iteration = grid_cache[grid_top]\n",
    "            repeat_len = i - prev_iteration\n",
    "            logger.debug(f\"Current iteration {i}; last seen at {prev_iteration}; {repeat_len=}\")\n",
    "            break\n",
    "\n",
    "        grid_cache[grid_top] = i\n",
    "\n",
    "    remaining_cycles = required_cycles - (i+1)\n",
    "    additional_cycles = remaining_cycles % repeat_len\n",
    "    logger.debug(f\"{additional_cycles=}\")\n",
    "\n",
    "    for i in range(additional_cycles):\n",
    "        grid = tilt_cycle(grid)\n",
    "\n",
    "    logger.debug(f\"\\n{grid}\")\n",
    "    row_counts = np.sum(grid==\"O\", axis=1)\n",
    "    total_load = sum((grid.shape[0]-row)*val for (row, val) in enumerate(row_counts))\n",
    "\n",
    "    logger.debug(f\"{total_load=}\")\n",
    "    return total_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_answers = [64]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_grid = parse_input(curr_input.splitlines())\n",
    "    validate(solve_part2(curr_grid), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "grid = parse_input(input_data)\n",
    "soln = solve_part2(grid)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 15: Lens Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"15\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 15 Part 1\n",
    "\n",
    "We need to turn a bunch of strings to into hashes using a special _HASH algorithm_. Each hash will be a single number in the range 0 to 255. It works like this:\n",
    "\n",
    "- Start with a current value of 0.\n",
    "- Determine the ASCII code for the current character of the string.\n",
    "- Increase the current value by the ASCII code you just determined.\n",
    "- Set the current value to itself multiplied by 17.\n",
    "- Set the current value to the remainder of dividing itself by 256.\n",
    "- Repeat for each character in the string.\n",
    "\n",
    "We need to do this for a collection of strings, and compute the sum.\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "Part 1 is a very trivial problem. I've just written a simple function that executes the steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hash(step_str: str) -> int:\n",
    "    curr_val = 0\n",
    "    for char in step_str:\n",
    "        curr_val += ord(char)\n",
    "        curr_val *= 17\n",
    "        curr_val %= 256\n",
    "        \n",
    "    return curr_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    strings = data[0].split(\",\")\n",
    "    logger.debug(f\"{strings}\")\n",
    "    \n",
    "    hashes = [compute_hash(step) for step in strings]\n",
    "    return sum(hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"rn=1,cm-,qp=3,cm=2,qp-,pc=4,ot=9,ab=5,pc-,pc=6,ot=7\")\n",
    "sample_answers = [1320]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 15 Part 2\n",
    "\n",
    "Well, it took me a while to read and understand the instructions!  But once I understood them and started writing code, this part wasn't too bad either.\n",
    "\n",
    "We have a series of 256 boxes in a line.\n",
    "- The boxes have holes to allow light through, and contain _multiple lenses_ for focussing. \n",
    "- The lenses can be removed, moved and replaced.\n",
    "- We have a library of lenses to choose from. Lenses are organised by focal length, ranging from 1 through 9.\n",
    "\n",
    "We're given the _Holiday ASCII String Helper Manual Arrangement Procedure (HASHMAP)_, and we're told to apply the procedure to our initialisation sequence. (I.e. the same input data). This is how the boxes are loaded with the right lenses in the right order.\n",
    "\n",
    "The initialisation sequence is a series of comma-separated values.  Each value represents a step or operation. For each operation:\n",
    "\n",
    "- `abc` (the chars before the `-` or `=`) -> the lens label for this operation.\n",
    "- `compute_hash(label)` -> the intended box number.\n",
    "- If followed by `-`: \n",
    "  - Go to the relevant box and remove the lens with that label, if present. \n",
    "  - Then move any remaining lenses as far forward as possible without changing their order, filling any space made by the removed lens.\n",
    "- Or, if followed by `=n`:\n",
    "  - Insert the lens with focal length `n`.\n",
    "  - If there is already a lens in the box with this label, replace it _in situ_.\n",
    "  - If there is not already a lens in the box with this label, add this lens behind any other lenses in the box, as far forward as possible.\n",
    "\n",
    "At the end, we're asked to determine the focussing power of each box, where focussing power is the product of:\n",
    "\n",
    "- One plus the box number of the lens in question.\n",
    "- The slot number of the lens within the box: 1 for the first lens, 2 for the second lens, and so on.\n",
    "- The focal length of the lens.\n",
    "\n",
    "The solution answer is the sum of these powers.\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- I start by defining a `Box` [dataclass](https://aoc.just2good.co.uk/python/classes#dataclass). The `Box` has attributes for:\n",
    "  - `num`\n",
    "  - `lenses` - a Python `list` containing our lenses, in the required order. Each lens is stored as a `(label, focus length)` tuple.\n",
    "  - `lenses_set` - this is possibly not necessary. But I wanted to make it efficient to determine if a given lens is in the `Box` without iterating through the `lenses` list of tuples. So I've added this set to do this check efficiently, before actually retrieving any lenses from the list. This set contains only the lens labels.\n",
    "\n",
    "- `focussing_power` - this is a pretty simple function that just follows the rules we've been given.\n",
    "- `get_lens_location(label)` - iterates through the `lenses` list, and checks if the supplied label matches the first term of the current tuple. If it does, we've found this lense.\n",
    "- `pop_lens(label)` - checks if this label is in our set. If it is, then use `get_lens_location(label)` to retrieve the index where this lens is stored, then pop that tuple from the list.  Note, when you `pop()` from a list `list` in Python, the remaining items automatically move up.  E.g. if we started with `[1, 2, 3, 4]` and we popped `3` (the item at index `2`), then the result would be `[1, 2, 4]`. Note: I also delete the label from our set.\n",
    "- `add_lens(label, f_length, location)` - this adds the lens to our `lenses` list, either at the end (if `location` is `None`) or at the specified location in the list. (And, of course, I need to add the lens label to our `lenses_set`.)\n",
    "\n",
    "I originally created a small bug here, because I was checking location like this:\n",
    "\n",
    "```python\n",
    "    if location:\n",
    "        self.lenses.insert(location, lens)\n",
    "    else:\n",
    "        self.lenses.append(lens)\n",
    "```\n",
    "\n",
    "My intent is to only insert at the specified location, if `location` is not `None`. But here, Python will return `False` if `location` is `None` or `0`. But `0` is a valid location, of course! So, to fix it:\n",
    "\n",
    "```python\n",
    "    if location is None:\n",
    "        self.lenses.insert(location, lens)\n",
    "    else:\n",
    "        self.lenses.append(lens)\n",
    "```\n",
    "\n",
    "So, to complete the solution:\n",
    "\n",
    "- Create our 256 boxes, initialised with empty lists of lenses.\n",
    "- Parse each step.\n",
    "- Get the lens label from the step.\n",
    "- Get the box number by hashing the step before the operation symbol.\n",
    "- If the operation is `-`, then simply call `pop_lens()` on the box.\n",
    "- If the operation is `=`, then check if this label already exists in the box. If it does, retrieve the current location and pop the lens at that location. Then, call `add_lens()` with the location we obtained, or `None` for the location.\n",
    "\n",
    "Finally, we can sum up all the box focussing powers by placing a [list comprehension](https://aoc.just2good.co.uk/python/comprehensions#aggregating-comprehensions) inside the `sum` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Box():\n",
    "    num: int\n",
    "    lenses:list[tuple[str,int]] = field(default_factory=list) # [ lens[label, focal_lengh], ... ]\n",
    "    lenses_set:set[str] = field(default_factory=set)\n",
    "    \n",
    "    def focusing_power(self) -> int:\n",
    "        \"\"\" Determine the focussing power of this box, calculated as:\n",
    "        \n",
    "        - sum over all lenses of:\n",
    "          box_num (1-indexed) * slot-num (1-indexed) * lens focal length\n",
    "\n",
    "        \"\"\"\n",
    "        pwr = 0\n",
    "        for slot, lens in enumerate(self.lenses):\n",
    "            pwr += (self.num+1) * (slot+1) * lens[1]\n",
    "            \n",
    "        return pwr\n",
    "    \n",
    "    def pop_lens(self, label: str) -> tuple[str, int] | None:\n",
    "        \"\"\" Pop the lens with the specified label. If the lens exists, return (location, lens) \"\"\"\n",
    "        if label in self.lenses_set:\n",
    "            self.lenses_set.remove(label)\n",
    "            return self.lenses.pop(self.get_lens_location(label))\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def get_lens_location(self, label:str) -> int:\n",
    "        for idx, (curr_label, curr_pwr) in enumerate(self.lenses):\n",
    "            if label == curr_label:\n",
    "                return idx\n",
    "            \n",
    "        raise KeyError(\"Lens not found\")\n",
    "    \n",
    "    def add_lens(self, label: str, f_length: int, location=None):\n",
    "        \"\"\" Add a lens at the specified location, or at the end. \"\"\"\n",
    "        lens = (label, f_length)\n",
    "        assert label not in self.lenses_set, \"There should be no lens with this label\"\n",
    "        self.lenses_set.add(label)        \n",
    "        if location is not None:\n",
    "            self.lenses.insert(location, lens)\n",
    "        else:\n",
    "            self.lenses.append(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    strings = data[0].split(\",\")\n",
    "    boxes = { box_num: Box(box_num) for box_num in range(256) }\n",
    "    logger.debug(boxes)\n",
    "    \n",
    "    for step in strings:\n",
    "        operation = \"=\" if \"=\" in step else \"-\"\n",
    "        lens_label = step.split(operation)[0]\n",
    "        curr_box = boxes[compute_hash(lens_label)] # 0- 255\n",
    "        if operation == \"-\": # remove lens\n",
    "            curr_box.pop_lens(lens_label)\n",
    "        else: # add lens of specified focal length\n",
    "            f_length = int(step[-1])\n",
    "            location = None\n",
    "            if lens_label in curr_box.lenses_set:\n",
    "                location = curr_box.get_lens_location(lens_label)\n",
    "                curr_box.pop_lens(lens_label)\n",
    "            \n",
    "            curr_box.add_lens(lens_label, f_length, location)\n",
    "    \n",
    "    return sum(box.focusing_power() for box in boxes.values())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_answers = [145]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 16: The Floor Will Be Lava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"16\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 16 Part 1\n",
    "\n",
    "We're in a giant cave! Here, our light beam is being focussed into a flat 2D grid containing:\n",
    "\n",
    "- Empty space (`.`) - light passes through these\n",
    "- Mirrors (`/` and `\\`) - these redirect the light through 90 degrees\n",
    "- Splitters (`|` and `-`) - light either passes through, or is split into two beams each at 90 degrees to the incident\n",
    "\n",
    "E.g.\n",
    "\n",
    "```text\n",
    ".|...\\....\n",
    "|.-.\\.....\n",
    ".....|-...\n",
    "........|.\n",
    "..........\n",
    ".........\\\n",
    "..../.\\\\..\n",
    ".-.-/..|..\n",
    ".|....-|.\\\n",
    "..//.|....\n",
    "```\n",
    "\n",
    "A tile is energised if at least one beam passes through it, reflects in it, or is split in it.\n",
    "\n",
    "**With the beam starting in the top-left heading right, how many tiles end up being energized?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "Okay, this problem wasn't too difficult, but I woke up with a terrible headache and made a complete mess of it.  Then I took some pills, had some coffee, cleared my head, and started again!\n",
    "\n",
    "I think the most sensible approach is to use a BFS to perform a _flood fill_, originating at our starting location, and only allowing adjacent locations that follow the rules we've been given.\n",
    "\n",
    "All the hard work is done in my `LightGrid` [class](https://aoc.just2good.co.uk/python/classes):\n",
    "\n",
    "- I build a dictionary, which maps combinations of (start location, start direction) to new directions, when we arrive at a mirror.\n",
    "- I build another dictionary which maps my N, E, S, W vectors to arrow characters, which is useful for printing the grid and debugging.\n",
    "- The `next_move(position, direction)` method:\n",
    "  - Expects a current location, and a current direction.\n",
    "  - Determines the one or two valid next moves, where a move is a combination of a new location, together with the direction we were facing when we arrived at that location.\n",
    "  - It first checks whether our current location is a `.`, or if we're arriving at the _pointy end_ of a splitter. In either case, the light can pass straight through to the next square in the same direction.\n",
    "  - It then checks if our current location is a mirror.  If it is, it uses the `MIRROR_DIRECTION_MAP` to determine the new direction. Then we add a unit in that direction to get the next location.\n",
    "  - It then checks if we've arrived at splitters. If we have, then we must be arriving perpendicular to the splitters. (Because we already checked for _pointy ends_ before.) If we arrive at a splitter, then we need to yield _two_ new next moves.\n",
    "\n",
    "- Next, the `bfs()` method!  If you need a recap of when to use a BFS and why it works, then check out my page [here](https://aoc.just2good.co.uk/python/shortest_paths). This is a pretty simple BFS implementation:\n",
    "  - I'm using a [deque](https://aoc.just2good.co.uk/python/lifo_fifo) for my first-in, first-out queue. Deques are very efficient for this.\n",
    "  - Then, for each current `(point, direction)` in the frontier, I expand out to valid neighbours. The neighbours are the next moves returned by `next_move()`, but additionally filtered on whether this move is in the grid or falls outside.\n",
    "  - Every time I retrieve a new next move in the BFS, I add it to `path_taken`, and also add next move to my `energised` dictionary. I can use this later to quickly count how many locations are energised. (Because the keys are unique locations.)\n",
    "\n",
    "Also of interest: in my `__str__()` method, I'm using [colorama](https://aoc.just2good.co.uk/python/colours) to draw a yellow path through the grid.\n",
    "\n",
    "Lastly, to determine how many tiles are energised, I just need to count the keys in my `energised` dictionary.\n",
    "\n",
    "That's all there is to it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "I figured now would be a good time for an animation!  I've created an animated gif by creating frames of [Matplotlib plots](https://aoc.just2good.co.uk/python/matplotlib).\n",
    "\n",
    "![Sample data animation](https://aoc.just2good.co.uk/assets/images/sample_lava_floor.gif)\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/VLvI0XIJiRM?si=HOROw6BUhyY-lqHp\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGrid(Grid):\n",
    "    \"\"\" Represents a 2D grid containing empty space (.), mirrors, and splitters (- and |).\n",
    "    Light passes through empty space. Light is refracted by 90 degrees at a mirror. \n",
    "    Light is split in the two orthogonal directions at a splitter, or allowed to pass through unchanged, \n",
    "    depending on orientation. \"\"\"\n",
    "    \n",
    "    MIRROR_DIRECTION_MAP = { # { (current char, current direction): new direction }\n",
    "        (\"/\", Vectors.E.value): Vectors.N.value,\n",
    "        (\"/\", Vectors.S.value): Vectors.W.value,\n",
    "        (\"/\", Vectors.W.value): Vectors.S.value,\n",
    "        (\"/\", Vectors.N.value): Vectors.E.value,\n",
    "        (\"\\\\\", Vectors.E.value): Vectors.S.value,\n",
    "        (\"\\\\\", Vectors.S.value): Vectors.E.value,\n",
    "        (\"\\\\\", Vectors.W.value): Vectors.N.value,\n",
    "        (\"\\\\\", Vectors.N.value): Vectors.W.value,\n",
    "    }\n",
    "    \n",
    "    VECTORS_TO_ARROWS = { # used for rendering a console representation\n",
    "        Vectors.N.value: \"^\",\n",
    "        Vectors.E.value: \">\",\n",
    "        Vectors.S.value: \"v\",\n",
    "        Vectors.W.value: \"<\",\n",
    "    }\n",
    "    \n",
    "    def __init__(self, grid_array: list, animating: bool = False, **kwargs) -> None:\n",
    "        \"\"\" Creates a grid that light beams pass through. \"\"\"\n",
    "       \n",
    "        # [ (posn, dirn), ... ]\n",
    "        # dirn is the direction we were facing when we arrived at this position\n",
    "        self.path_taken: list[tuple[Point, tuple[int,int]]] = []\n",
    "        self.energised = defaultdict(set) # { point: {dirn}, }\n",
    "        super().__init__(grid_array=grid_array, animating=animating, **kwargs)\n",
    "    \n",
    "    def animate_step(self, i):\n",
    "        \"\"\" Update the plot for the ith step in the animation. \"\"\"\n",
    "        if self._frame_index < len(self.path_taken):\n",
    "            if self._frame_index % 100 == 0:\n",
    "                logger.debug(f\"Rendering frame {self._frame_index}\")\n",
    "                \n",
    "            self._render_plot()\n",
    "            self._frame_index += 1\n",
    "        return []\n",
    "    \n",
    "    def create_animation(self, output_path='animation.mp4', fps=10):\n",
    "        \"\"\" Create the animation, by calling the animate_step() method to generate frames. \"\"\"\n",
    "        self._plot_info = self._setup_fig()  # Set up the figure for plotting\n",
    "        fig, axes, mkr_size = self._plot_info\n",
    "        \n",
    "        logger.debug(f\"Creating the animation. We have {len(self.path_taken)} frames to render.\")\n",
    "        # Creating the animation\n",
    "        anim = FuncAnimation(fig, self.animate_step, frames=len(self.path_taken), \n",
    "                             interval=1000/fps, blit=True)\n",
    "\n",
    "        # Save the animation\n",
    "        anim.save(output_path, writer='ffmpeg')\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\" Clear the path_taken and energised properties \"\"\"\n",
    "        self.path_taken = []\n",
    "        self.energised = defaultdict(set)\n",
    "    \n",
    "    def bfs(self, start:tuple[Point,tuple[int,int]]=(Point(0,0), Vectors.E.value)):\n",
    "        \"\"\" Perform a BFS to build the path that light takes through the grid.\n",
    "\n",
    "        Args:\n",
    "            start (tuple, optional): (point, vector value). Defaults to (Point(0,0), Vectors.E\n",
    "        \"\"\"\n",
    "        frontier = deque() # ideal for FIFO\n",
    "        frontier.append(start)\n",
    "        explored = set()\n",
    "        explored.add(start)\n",
    "\n",
    "        while frontier:\n",
    "            posn, dirn = frontier.popleft() # point, vector value\n",
    "            self.path_taken.append((posn, dirn))\n",
    "            self.energised[posn].add(dirn)       \n",
    "            \n",
    "            for neighbour in self.next_move(posn, dirn):\n",
    "                if self.valid_location(neighbour[0]): # is this next move in the grid?\n",
    "                    if neighbour not in explored:\n",
    "                        frontier.append(neighbour)\n",
    "                        explored.add(neighbour)\n",
    "    \n",
    "    def next_move(self, posn:Point, dirn:tuple):\n",
    "        \"\"\" Determine the next moves that are valid from here. Returns each move sequentially, as a generator.\n",
    "        For any given current (point, direction), we can move to 1 or 2 adjacent points. \n",
    "        If the current point is a mirror, the new direction will be different.\n",
    "        If the current point is a splitter, the new direction will be different if we've hit the splitter\n",
    "        from a perpendicular direction.\n",
    "\n",
    "        Args:\n",
    "            posn (Point): Our current location\n",
    "            dirn (Vector tuple): The direction we were facing when we landed at this point\n",
    "\n",
    "        Yields:\n",
    "            tuple: (next point, next direction)\n",
    "        \"\"\"\n",
    "\n",
    "        curr_val = self.value_at_point(posn) # where are we now\n",
    "\n",
    "        # First, check our \"pass through\" conditions...\n",
    "        if (curr_val == \".\" or (curr_val == \"|\" and dirn in (Vectors.N.value, Vectors.S.value))\n",
    "                            or (curr_val == \"-\" and dirn in (Vectors.E.value, Vectors.W.value))):\n",
    "            next_dirn = dirn \n",
    "            next_posn = posn + Point(*next_dirn)\n",
    "            yield (next_posn, dirn)            \n",
    "        elif curr_val in (\"/\", \"\\\\\"): # Now map directions if we're at a mirror\n",
    "            next_dirn = LightGrid.MIRROR_DIRECTION_MAP[(curr_val, dirn)]\n",
    "            next_posn = posn + Point(*next_dirn)\n",
    "            yield (next_posn, next_dirn)                      \n",
    "        elif curr_val ==  \"|\": # split at |, yielding two directions\n",
    "            assert dirn in (Vectors.E.value, Vectors.W.value), \"We must be going E or W\"\n",
    "            for next_dirn in (Vectors.N.value, Vectors.S.value):\n",
    "                next_posn = posn + Point(*next_dirn)\n",
    "                yield (next_posn, next_dirn)\n",
    "        else: # split at -, yielding two directions\n",
    "            assert curr_val == \"-\", \"We should be at -\"\n",
    "            assert dirn in (Vectors.N.value, Vectors.S.value), \"We must be going N or S\"\n",
    "            for next_dirn in (Vectors.E.value, Vectors.W.value):\n",
    "                next_posn = posn + Point(*next_dirn)\n",
    "                yield (next_posn, next_dirn)                    \n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        \"\"\" Generate a str representation of the grid, including the path_taken. \"\"\"\n",
    "        rows = []\n",
    "        for row_num, row in enumerate(self.array):\n",
    "            repr = []\n",
    "            for char_num, char in enumerate(row):\n",
    "                point = Point(char_num, row_num)\n",
    "                if point in self.energised:\n",
    "                    repr.append(Fore.YELLOW)\n",
    "                    if char not in (\"|\", \"-\", \"\\\\\", \"/\"):\n",
    "                        dirs_for_locn = len(self.energised[point])\n",
    "                        if dirs_for_locn == 1:\n",
    "                            dirn = list(self.energised[point])[0]\n",
    "                            repr.append(LightGrid.VECTORS_TO_ARROWS[dirn])                   \n",
    "                        else:\n",
    "                            repr.append(str(dirs_for_locn))\n",
    "                    else:\n",
    "                        repr.append(char)\n",
    "                    repr.append(Fore.RESET)\n",
    "                else:\n",
    "                    repr.append(char)\n",
    "            \n",
    "            rows.append(\"\".join(repr))\n",
    "        \n",
    "        return \"\\n\".join(rows)\n",
    "\n",
    "    def _setup_fig(self):\n",
    "        \"\"\" Initialise the plot \"\"\"      \n",
    "        my_dpi = 120\n",
    "        fig, axes = plt.subplots(figsize=(1024/my_dpi, 768/my_dpi), dpi=my_dpi, facecolor=\"white\") # set size in pixels\n",
    "\n",
    "        axes.get_xaxis().set_visible(True)\n",
    "        axes.get_yaxis().set_visible(True)\n",
    "        axes.invert_yaxis()\n",
    "        axes.set_aspect('equal') # set x and y to equal aspect\n",
    "        axes.set_facecolor('xkcd:black')\n",
    "        \n",
    "        min_x, max_x = -0.5, self.width - 0.5\n",
    "        min_y, max_y = -0.5, self.height - 0.5\n",
    "        axes.set_xlim(min_x, max_x)\n",
    "        axes.set_ylim(max_y, min_y)\n",
    "\n",
    "        # dynamically compute the marker size\n",
    "        fig.canvas.draw()\n",
    "        mkr_size = ((axes.get_window_extent().width / (max_x-min_x) * (45/fig.dpi)) ** 2)\n",
    "        return fig, axes, mkr_size\n",
    "    \n",
    "    def plot(self):\n",
    "        \"\"\" Show the current plot \"\"\"\n",
    "        self._render_plot(frame_idx=-1)\n",
    "        plt.show()\n",
    "        \n",
    "    def _render_plot(self, frame_idx=None):\n",
    "        \"\"\" Add each new frame. Note that this method should draw should only draw up to a particular state. \n",
    "        If frame_idx is set, it will render the plot at that particular frame. Use -1 for final state. \"\"\"\n",
    "        fig, axes, mkr_size = self._plot_info\n",
    "        axes.clear() # Clear the axes to start fresh for each frame\n",
    "        axes.invert_yaxis()\n",
    "       \n",
    "        dir_sets = [set() for _ in range(4)]\n",
    "            \n",
    "        # Plot the path\n",
    "        # Only plot the path up to the current frame index\n",
    "        last_frame = frame_idx if frame_idx else (self._frame_index + 1)\n",
    "        for point, dirn in self.path_taken[:last_frame]:\n",
    "            for dir_set, arrow in zip(dir_sets, (\"^\", \">\", \"v\", \"<\")):\n",
    "                if LightGrid.VECTORS_TO_ARROWS[dirn] == arrow:\n",
    "                    dir_set.add(point)\n",
    "                    continue\n",
    "\n",
    "        for dir_set, arrow in zip(dir_sets, (\"^\", \">\", \"v\", \"<\")):\n",
    "            if dir_set:\n",
    "                dir_set_x, dir_set_y = zip(*((point.x, point.y) for point in dir_set))\n",
    "                axes.scatter(dir_set_x, dir_set_y, marker=arrow, s=mkr_size*0.5, color=\"white\")            \n",
    "\n",
    "        # Plot the infra\n",
    "        vert_splitters, horz_splitters, forw_mirrors, back_mirrors = set(), set(), set(), set()\n",
    "        infra_mappings = {\n",
    "            '|': vert_splitters, \n",
    "            '-': horz_splitters, \n",
    "            '/': forw_mirrors, \n",
    "            '\\\\': back_mirrors\n",
    "        }\n",
    "        \n",
    "        for row_num, row in enumerate(self.array):\n",
    "            for char_num, char in enumerate(row):\n",
    "                point = Point(char_num, row_num)\n",
    "                if char in infra_mappings:\n",
    "                    infra_mappings[char].add(point)        \n",
    "                    \n",
    "        for infra_type, marker in [(vert_splitters, r'$\\vert$'), \n",
    "                                   (horz_splitters, r'$-$'), \n",
    "                                   (forw_mirrors, r'$\\slash$'), \n",
    "                                   (back_mirrors, r'$\\backslash$')]:\n",
    "            \n",
    "            if infra_type: # check not empty\n",
    "                x, y = zip(*((point.x, point.y) for point in infra_type))\n",
    "                axes.scatter(x, y, marker=marker, s=mkr_size, color=\"xkcd:azure\")                      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data, animate=False, out_name=\"animation.mp4\", fps=10):\n",
    "    grid = LightGrid(data, animating=True)\n",
    "    grid.bfs()\n",
    "    grid.plot()\n",
    "    if animate:\n",
    "        output_file = Path(locations.output_dir, out_name)\n",
    "        grid.create_animation(str(output_file), fps=fps)\n",
    "        \n",
    "    return len(grid.energised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(r\"\"\".|...\\....\n",
    "|.-.\\.....\n",
    ".....|-...\n",
    "........|.\n",
    "..........\n",
    ".........\\\n",
    "..../.\\\\..\n",
    ".-.-/..|..\n",
    ".|....-|.\\\n",
    "..//.|....\"\"\")\n",
    "sample_answers = [46]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines(), animate=True, out_name=\"sample_lava_floor.mp4\"), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data, animate=False, out_name=\"real_lava_floor.mp4\", fps=30)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 16 Part 2\n",
    "\n",
    "**Find the initial beam configuration that energizes the largest number of tiles; how many tiles are energized in that configuration?**\n",
    "\n",
    "We're told that valid starting configurations are:\n",
    "\n",
    "- All top row tiles, pointing south.\n",
    "- All bottom row tiles, pointing north.\n",
    "- All left edge tiles, pointing east.\n",
    "- All right edge tiles, pointing west.\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "There's probably a much faster solution, but my approach was simply to:\n",
    "\n",
    "- Build a list of all the starting locations, and their associated directions.\n",
    "- Perform the same BFS as before, but using these starting locations, rather than the top left square.\n",
    "\n",
    "So this requires very little code, and it still runs in under 10 seconds.\n",
    "\n",
    "- I had already coded by BFS to accept a start location, and starting location, but defaulting to top-left, and east, respectively. So no changes required there.\n",
    "- The other thing I added to my `LightGrid` class is a `reset()` method, to clear the `path_taken` and `energised` variables with each configuration. That way, I don't have to create a new `LightGrid` with each configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    grid = LightGrid(data)\n",
    "    \n",
    "    starts = [] # to store all possible starting locations and directions\n",
    "    for col in range(0, grid.width): \n",
    "        # points on top edge pointing down\n",
    "        starts.append((Point(col, 0), Vectors.S.value))\n",
    "        # points on bottom edge, pointing up\n",
    "        starts.append((Point(0, grid.height-1), Vectors.N.value))\n",
    "    \n",
    "    for row in range(0, grid.height):\n",
    "        # points on left edge, pointing right\n",
    "        starts.append((Point(0, row), Vectors.E.value))\n",
    "        # points on right edge, pointing left\n",
    "        starts.append((Point(grid.width-1, row), Vectors.W.value))\n",
    "    \n",
    "    energised = {} # { (start, direction), count_energised, ... }\n",
    "    for start in tqdm(starts): # let's view a progress bar\n",
    "        grid.bfs(start)\n",
    "        energised[start] = len(grid.energised)\n",
    "        grid.reset()\n",
    "    \n",
    "    return max(energised.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_answers = [51]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines())[1], curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)[1]\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 17: Clumsy Crucible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"17\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 17 Part 1\n",
    "\n",
    "_\"To get Desert Island the machine parts it needs as soon as possible, you'll need to find the best way to get the crucible from the lava pool to the machine parts factory. To do this, you need to minimize heat loss while choosing a route that doesn't require the crucible to go in a straight line for too long.\"_\n",
    "\n",
    "We have a map to that can be used to calculate heat loss at any particular city block.  E.g.\n",
    "\n",
    "```text\n",
    "2413432311323\n",
    "3215453535623\n",
    "3255245654254\n",
    "3446585845452\n",
    "4546657867536\n",
    "1438598798454\n",
    "4457876987766\n",
    "3637877979653\n",
    "4654967986887\n",
    "4564679986453\n",
    "1224686865563\n",
    "2546548887735\n",
    "4322674655533\n",
    "```\n",
    "\n",
    "Each digit represents the amoun tof heat loss if the crucible enters that block.\n",
    "\n",
    "We need to go from top-left to bottom-right. But here's the catch: we can only move a maximum of three blocks in a straight line, before we have to turn left or right. And we can't reverse.\n",
    "\n",
    "**Directing the crucible from the lava pool to the machine parts factory, but not moving more than three consecutive blocks in the same direction, what is the least heat loss it can incur?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "I found this one pretty tough.\n",
    "\n",
    "It was pretty obvious from the start that I needed either [Dijkstra’s or A* algorithm][https://aoc.just2good.co.uk/python/shortest_paths] to find the path with the lowest cumulative cost. But the actual implementation took me ages to get right.\n",
    "\n",
    "So... We need to find a path from a start to a goal, where the cost varies depending on the path taken. As usual for a Dijkstra, we need to use a [priority queue](https://aoc.just2good.co.uk/python/priority_queues). First, we need to define some way to represent the state of our journey through the map. I'll represent state in a tuple that stores `(cost, current position, direction, straight steps taken)`. It's important that `cost` comes first, because our priority queue pops the next state based on the lowest value of the first item in the tuple.\n",
    "\n",
    "We keep popping next states until we reach the goal. To determine valid next states:\n",
    "\n",
    "- We create `set` to store states that we've already explored.\n",
    "- If we're in our initial position, we don't have a direction yet.  So we can try all adjacent squares, and with each, we set `straight steps` to 1.\n",
    "- If we're not on the first step, then our valid next moves are left, right, or straight on. We can't go backwards.\n",
    "  - We can move left relative to our current direction by adding the vector `Point(-dirn.y, dirn.x)`.\n",
    "  - We can move right relative to our current direction by adding the vector `Point(dirn.y, -dirn.x)`.\n",
    "  - We can only go straight if `straight steps` is less than `3`.\n",
    "- Now we've got our new position and new direction, we can determine the cost of the next move, and add that cost to our current cumulative cost.\n",
    "\n",
    "Finally, we return the total cumulative cost, when we reach the goal.\n",
    "\n",
    "And that's basically all there is to it for the Dijkstra solution!\n",
    "\n",
    "I was interested to see what would happen if I changed to an A* implementation. I did this by creating a `heuristic` variable that stores the combination of `path cost` with the _Manhattan distance_ between start and goal. The idea here is that by using the heuristic, we will favour paths that take us towards the goal. But when I added this, the solution took about twice as long to compute. Oh well... It was worth a try! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(grid: list[list[int]], start: Point, goal: Point, max_straight: int, pre_turn: int):\n",
    "    \"\"\" Determine the path with lowest cost from start to goal\n",
    "\n",
    "    Args:\n",
    "        grid (list[list[int]]): A 2D grid containing int values\n",
    "        start (Point): Starting point\n",
    "        goal (Point): Final point\n",
    "        max_straight (int): Max moves we can make in a straight line before turning\n",
    "        pre_turn (int): Max moves we must make before turning or stopping\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no solution\n",
    "\n",
    "    Returns:\n",
    "        int: best cost for path\n",
    "    \"\"\"\n",
    "    queue = [] # priority queue to store current state\n",
    "    \n",
    "    cost:int = 0 # cumulative cost of all moves, based on value of each entered location\n",
    "    # heuristic:int = 0 + start.manhattan_distance_from(goal)\n",
    "    current_posn:Point = start\n",
    "    dirn:Optional[Point] = None # Current direction. (None when we start.)\n",
    "    straight_steps:int = 0 # number of steps taken in one direction without turning\n",
    "    heapq.heappush(queue, (cost, current_posn, dirn, straight_steps)) # cost must come first for our priority queue\n",
    "    \n",
    "    seen = set()\n",
    "    \n",
    "    while queue:\n",
    "        cost, current_posn, dirn, straight_steps = heapq.heappop(queue)\n",
    "        # logger.debug(f\"{cost=}, {current_posn=}, {dirn=}, {steps=}\")\n",
    "\n",
    "        if current_posn == goal and straight_steps >= pre_turn:\n",
    "            return cost\n",
    "        \n",
    "        # check if we've been in this configuration before\n",
    "        if (current_posn, dirn, straight_steps) in seen: \n",
    "            continue\n",
    "        \n",
    "        seen.add((current_posn, dirn, straight_steps)) # explored\n",
    "        \n",
    "        next_states = [] # point, dirn, steps\n",
    "        if dirn is None: # we're at the start, so we can go in any direction\n",
    "            for dir_x, dir_y in ((0, 1), (1, 0), (0, 1), (-1, 0)):\n",
    "                dirn = Point(dir_x, dir_y)\n",
    "                neighbour = current_posn + dirn\n",
    "                next_states.append((neighbour, dirn, 1))\n",
    "        else:\n",
    "            if straight_steps >= pre_turn:  # we can turn left or right, relative to current direction\n",
    "                next_states.append(((current_posn + Point(-dirn.y, dirn.x)), Point(-dirn.y, dirn.x), 1)) # turn 90 degrees CCW (left)\n",
    "                next_states.append(((current_posn + Point(dirn.y, -dirn.x)), Point(dirn.y, -dirn.x), 1)) # turn 90 degrees CW (right)\n",
    "            \n",
    "            if straight_steps < max_straight: # we can move straight ahead. \n",
    "                next_states.append(((current_posn + dirn), dirn, straight_steps+1))\n",
    "            \n",
    "        for neighbour, dirn, new_steps in next_states:\n",
    "            if (0 <= neighbour.x < len(grid[0]) and 0 <= neighbour.y < len(grid)):\n",
    "                new_cost = cost + grid[neighbour.y][neighbour.x]\n",
    "                # heuristic = new_cost + neighbour.manhattan_distance_from(goal)\n",
    "                heapq.heappush(queue, (new_cost, \n",
    "                                       neighbour, \n",
    "                                       dirn, \n",
    "                                       new_steps))\n",
    "    \n",
    "    raise ValueError(\"No solution found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data, max_straight=3, pre_turn=0):\n",
    "    grid = [list(map(int, line)) for line in data]\n",
    "\n",
    "    start = Point(0,0)\n",
    "    goal = Point(len(grid[0])-1, len(grid)-1)\n",
    "    cost = get_path(grid, start, goal, max_straight=max_straight, pre_turn=pre_turn)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"2413432311323\n",
    "3215453535623\n",
    "3255245654254\n",
    "3446585845452\n",
    "4546657867536\n",
    "1438598798454\n",
    "4457876987766\n",
    "3637877979653\n",
    "4654967986887\n",
    "4564679986453\n",
    "1224686865563\n",
    "2546548887735\n",
    "4322674655533\"\"\")\n",
    "sample_answers = [102]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 17 Part 2\n",
    "\n",
    "We're upgrading to _ultra crucibles_.  These:\n",
    "\n",
    "- Require a minimum of 4 blocks before it can turn or stop\n",
    "- But can move 10 blocks before turning\n",
    "\n",
    "**Directing the ultra crucible from the lava pool to the machine parts factory, what is the least heat loss it can incur?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- Change the `max_straight` value from 3 to 10. So I've parameterised this.\n",
    "- Add a new parameter called `pre_turn`, which determines how many `max_straight` is required before we're allowed to turn. So now I perform this test before turning left or right:\n",
    "\n",
    "```python\n",
    "if straight_steps >= pre_turn\n",
    "```\n",
    "\n",
    "- Finally, we also need to ensure that we've taken at least four straight steps when we arrive at the goal. So we simply amend our exit condition check like this:\n",
    "\n",
    "```python\n",
    "    if current_posn == goal and straight_steps >= pre_turn:\n",
    "        return cost\n",
    "```\n",
    "\n",
    "And that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data, max_straight=10, pre_turn=4):\n",
    "    grid = [list(map(int, line)) for line in data]\n",
    "\n",
    "    start = Point(0,0)\n",
    "    goal = Point(len(grid[0])-1, len(grid)-1)\n",
    "    cost = get_path(grid, start, goal, max_straight=max_straight, pre_turn=pre_turn)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs.append(\"\"\"111111111111\n",
    "999999999991\n",
    "999999999991\n",
    "999999999991\n",
    "999999999991\"\"\")\n",
    "\n",
    "sample_answers = [94, 71]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 18: Lavaduct Lagoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"18\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 18 Part 1\n",
    "\n",
    "We're going to dig a lagoon. We've been given a dig plan that looks like this:\n",
    "\n",
    "```text\n",
    "R 6 (#70c710)\n",
    "D 5 (#0dc571)\n",
    "L 2 (#5713f0)\n",
    "D 2 (#d2c081)\n",
    "R 2 (#59c680)\n",
    "D 2 (#411b91)\n",
    "L 5 (#8ceee2)\n",
    "U 2 (#caa173)\n",
    "L 1 (#1b58a2)\n",
    "U 2 (#caa171)\n",
    "R 2 (#7807d2)\n",
    "U 3 (#a77fa3)\n",
    "L 2 (#015232)\n",
    "U 2 (#7a21e3)\n",
    "```\n",
    "\n",
    "The digger starts in a 1 meter cube hole in the ground and can move the specified number of metres up, down, left or right. These directions are all in the same plane (as seen from above), so we're in a 2D grid. Having followed the instructions to dig a tunnel that represents the edge of the lagoon, we then dig out the interior.\n",
    "\n",
    "Each trench is also listed with the color that the edge of the trench should be painted as an RGB hexadecimal color code.\n",
    "\n",
    "**If they follow their dig plan, how many cubic meters of lava could it hold?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- First, parse the input data.  For each instruction in this part, we only care about the direction and distance in that direction.\n",
    "Then, let's plot the perimeter path with `process_plan()`:\n",
    "  - Create a list to represent the squares of the perimeter - i.e. what we'll dig with the instructions.\n",
    "  - Start at `(0,0)` and add it to the list.\n",
    "  - For each instruction, iterate over the required number of squares. For each iteration, add the current direction to the current square. This gives us the new current square. Add it to the `perimeter_path` list.\n",
    "  - Whenever we reach a turn, identify the inside square that is bordered by the three squares of the turn, and flag it as an _interior candidate_. The way I identify the candidate square is to create a `2x2` square from the three squares of the turn, and then simply identify the square that is missing.\n",
    "  - This method returns `perimeter_path` and `interior_candidates` as a tuple.\n",
    "- Next, I create `perimeter_set` from my `perimeter_path`, because this is much more efficient when checking membership. (I'll be using this later for my BFS.)\n",
    "- Then I call `create_bounds()` to determine the top-left and bottom-right coordinates of all points in the perimeter.\n",
    "- Now I'm ready to `flood_fill()`, to determine the interior volume of our perimeter.\n",
    "  - This is another [BFS flood fill](https://aoc.just2good.co.uk/python/shortest_paths).\n",
    "  - We create `interior` and `exterior` sets, to store points as we examine them.\n",
    "  - We iterating over candidate points from `interior_candidates`. If the candidate has already been placed in `interior` or `exterior`, then we can skip it.\n",
    "  - Otherwise, we set up a BFS to expand from this particular candidate. \n",
    "  - The BFS expands in each direction, until it reaches a perimeter point, or the boundary of the grid.\n",
    "  - With each point we find, we add it to a set called `region`.\n",
    "  - If our BFS touches the boundary of the grid, then we mark `region` as NOT `is_internal`. We then add the entire region to `exterior`, and continue to the next candidate.\n",
    "  - If our BFS never touches the boundary, then the `region` remains `is_internal`, and we add all the points from this region to `interior`.\n",
    "  - I return `interior`.\n",
    "  \n",
    "  Finally, I add up the counts of points from the `perimeter_set` to the `interior` set, and return this as the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "I'm plotting the `perimeter` and the `interior` points using [matplotlib](https://aoc.just2good.co.uk/python/matplotlib).\n",
    "\n",
    "Our sample data, after filling, is represented like this:\n",
    "\n",
    "```text\n",
    "#######\n",
    "#######\n",
    "#######\n",
    "..#####\n",
    "..#####\n",
    "#######\n",
    "#####..\n",
    "#######\n",
    ".######\n",
    ".######\n",
    "```\n",
    "\n",
    "After plotting, we end up with this:\n",
    "\n",
    "![Sample data lava lagoon](https://aoc.just2good.co.uk/assets/images/lava_lagoon_sample.png)\n",
    "\n",
    "And for my real data:\n",
    "\n",
    "![Real data lava lagoon](https://aoc.just2good.co.uk/assets/images/lava_lagoon_real.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_plan(data) -> list[tuple]:\n",
    "    \"\"\" Read the plan and convert to a light of instructions and edge lengths. E.g.\n",
    "    [('R', 6), ('D', 5), ('L', 2), ... \n",
    "    \"\"\"\n",
    "    plan = []\n",
    "    for line in data:\n",
    "        dirn, path_len, hex_code = line.split()\n",
    "        plan.append((dirn, int(path_len)))\n",
    "        \n",
    "    return plan\n",
    "\n",
    "def process_plan(plan) -> tuple[list, set]:\n",
    "    perimeter_path = []\n",
    "    current = (0,0)\n",
    "    perimeter_path.append(current)\n",
    "    interior_candidates = set()\n",
    "    \n",
    "    for instr_num, (dirn_char, path_len) in enumerate(plan):\n",
    "        # logger.debug(f\"[{instr_num}]: {(dirn_char, path_len, hex_code)}\")\n",
    "        dirn = VectorDicts.DIRS[dirn_char]\n",
    "        for step in range(path_len):\n",
    "            current = (current[0]+dirn[0], current[1]+dirn[1])\n",
    "            perimeter_path.append(current)\n",
    "            \n",
    "            if instr_num>0 and step==0: # turn executed\n",
    "                # After the turn, the last three moves will represent three squares in a 2x2 grid.\n",
    "                # The remaining square will represent an interior point\n",
    "                assert len(perimeter_path) >= 3, \"We must have at least three squares if we've made a turn\"\n",
    "                last_three = perimeter_path[-3:]\n",
    "            \n",
    "                for y in range(min(y for x, y in last_three), max(y for x, y in last_three)+1):\n",
    "                    for x in range(min(x for x, y in last_three), max(x for x, y in last_three)+1):\n",
    "                        if (x, y) not in perimeter_path:\n",
    "                            interior_candidates.add((x, y))\n",
    "                            break\n",
    "    \n",
    "    return perimeter_path, interior_candidates\n",
    "\n",
    "def get_bounds(perimeter_path: list[tuple[int,int]]) -> tuple[tuple, tuple]:\n",
    "    min_x = min(perimeter_path, key=lambda p: p[0])[0]\n",
    "    max_x = max(perimeter_path, key=lambda p: p[0])[0]\n",
    "    min_y = min(perimeter_path, key=lambda p: p[1])[1]\n",
    "    max_y = max(perimeter_path, key=lambda p: p[1])[1]\n",
    "    \n",
    "    return ((min_x, min_y), (max_x, max_y)) # tl, br\n",
    "\n",
    "def flood_fill(perimeter_set, interior_candidates: set[tuple], bounds: tuple[tuple, tuple]) -> set[tuple]:\n",
    "    min_x, min_y = bounds[0]\n",
    "    max_x, max_y = bounds[1]\n",
    "    exterior = set()\n",
    "    interior = set()\n",
    "\n",
    "    logger.debug(f\"Processing {len(interior_candidates)} interior candidates.\") \n",
    "    for point in interior_candidates:\n",
    "        if point in interior or point in exterior:\n",
    "            continue # this point is in a region we've done already\n",
    "            \n",
    "        region = set()\n",
    "        queue = deque()\n",
    "        queue.append(point)\n",
    "        explored = set()\n",
    "        explored.add(point)\n",
    "        is_interior = True # assume interior point\n",
    "    \n",
    "        while queue and is_interior:\n",
    "            current = queue.popleft()\n",
    "            \n",
    "            if current in interior:\n",
    "                break\n",
    "            \n",
    "            if current not in perimeter_set:\n",
    "                region.add(current)\n",
    "            \n",
    "            neighbours = [(current[0]+dx, current[1]+dy) for dx,dy in (VectorDicts.DIRS.values())]\n",
    "            for neighbour in neighbours:\n",
    "                if min_x <= neighbour[0] <= max_x and min_y <= neighbour[1] <= max_y: # within bounds\n",
    "                    if neighbour not in perimeter_set: # this is a valid region point\n",
    "                        if neighbour not in explored:\n",
    "                            queue.append(neighbour)\n",
    "                            explored.add(neighbour)\n",
    "                else: # outside of bounds so mark the region as external\n",
    "                    is_interior = False\n",
    "                    break\n",
    "        \n",
    "        if is_interior:              \n",
    "            interior.update(region)\n",
    "            logger.debug(f\"Updated all_interior with {len(region)} points.\")\n",
    "        else:\n",
    "            exterior.update(region)\n",
    "            logger.debug(f\"Updated exterior with {len(region)} points.\")\n",
    "            \n",
    "    return interior \n",
    "\n",
    "def plot_path(path: list[tuple], inside: set[tuple]=set()):\n",
    "    # Extract x and y values from the path\n",
    "    loop_x_values = [point[0] for point in path]\n",
    "    loop_y_values = [point[1] for point in path]\n",
    "    \n",
    "    # Extract x and y values from the inside set\n",
    "    inside_x_values = [point[0] for point in inside]\n",
    "    inside_y_values = [point[1] for point in inside]\n",
    "\n",
    "    # Plot the line and scatter graphs\n",
    "    plt.plot(loop_x_values, loop_y_values, \n",
    "             marker=MarkerStyle('o'), linestyle='-', color=\"blue\", label=\"Loop\")\n",
    "        \n",
    "    plt.scatter(inside_x_values, inside_y_values, \n",
    "                marker=MarkerStyle('x'), color=\"red\", label=\"Inside\")\n",
    "    \n",
    "    plt.title('Path Plot')\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "    plt.gca().set_aspect('equal', adjustable='box') # set equal scale \n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data) -> int:\n",
    "    plan = parse_plan(data)\n",
    "    perimeter_path, interior_candidates = process_plan(plan)\n",
    "    perimeter_set = set(perimeter_path)\n",
    "\n",
    "    bounds = get_bounds(perimeter_path)\n",
    "    all_interior = flood_fill(perimeter_set, interior_candidates, bounds)\n",
    "    plot_path(perimeter_path, all_interior)\n",
    "    \n",
    "    return len(perimeter_set) + len(all_interior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"R 6 (#70c710)\n",
    "D 5 (#0dc571)\n",
    "L 2 (#5713f0)\n",
    "D 2 (#d2c081)\n",
    "R 2 (#59c680)\n",
    "D 2 (#411b91)\n",
    "L 5 (#8ceee2)\n",
    "U 2 (#caa173)\n",
    "L 1 (#1b58a2)\n",
    "U 2 (#caa171)\n",
    "R 2 (#7807d2)\n",
    "U 3 (#a77fa3)\n",
    "L 2 (#015232)\n",
    "U 2 (#7a21e3)\"\"\")\n",
    "sample_answers = [62]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 18 Part 2\n",
    "\n",
    "Uh oh. The colour and instruction parameters need to be swapped!! We need to extract the correct instructions from the hex codes.\n",
    "\n",
    "For each hex code:\n",
    "\n",
    "- First five digits = hex value of distance in m\n",
    "- Last digit = direction, where `0 = R`, `1 = D`, `2 = L`, ` 3 = U`\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "Even with the sample data, we're told that our lagoon will hold `952408144115` cubic metres of lava.  So clearly we have far too many points to go storing them in sets.  Our Part 1 solution isn't going to scale! We need to do something smarter.\n",
    "\n",
    "We can use math!  Here are some key formulae:\n",
    "\n",
    "- [Shoelace Formula](https://en.wikipedia.org/wiki/Shoelace_formula) - to calculate the area of any polygon, given the _consecutive coordinates_ of its vertices. One great thing about this formula is that it even works for self-overlapping / self-intersecting polygons!\n",
    "\n",
    "$$\n",
    "A = \\frac{1}{2} \\left| \\sum_{i=1}^{n} x_i (y_{i+1} - y_{i-1}) \\right|\n",
    "$$\n",
    "\n",
    "- [Pick's Theorem](https://en.wikipedia.org/wiki/Pick%27s_theorem) - to calculate the number of interior points for an enclosed polygon.\n",
    "\n",
    "$$\n",
    "A = i + \\frac{b}{2} - 1\n",
    "$$\n",
    "\n",
    "However, our vertex coordinates are at the centre of 1x1 grid cells. Why? Because we start at the centre of a 1x1 cell, and then we dig the perimeter. So, from our sample input:\n",
    "\n",
    "```text\n",
    "#######\n",
    "#######\n",
    "#######\n",
    "..#####\n",
    "..#####\n",
    "#######\n",
    "#####..\n",
    "#######\n",
    ".######\n",
    ".######\n",
    "```\n",
    "\n",
    "Let's use Matplotlib to draw a more accurate representation of the dig plan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path(path: list[tuple], inside: set[tuple]=set()):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Function to add a 1x1 square with the point at its center\n",
    "    def add_square(x, y, colour, fill=False):\n",
    "        square = Rectangle((x - 0.5, y - 0.5), 1, 1, fill=fill, edgecolor=colour, facecolor=colour)\n",
    "        ax.add_patch(square)\n",
    "\n",
    "    # Plot each point in the path as a square\n",
    "    for point in path:\n",
    "        add_square(point[0], point[1], 'blue')\n",
    "\n",
    "    # Plot each point in the inside set as a square\n",
    "    for point in inside:\n",
    "        add_square(point[0], point[1], 'red', fill=True)\n",
    "\n",
    "    # Extract x and y values for vertices\n",
    "    path_x_values = [point[0] for point in path]\n",
    "    path_y_values = [point[1] for point in path]\n",
    "    inside_x_values = [point[0] for point in inside]\n",
    "    inside_y_values = [point[1] for point in inside]\n",
    "    \n",
    "    # Plot the actual vertex points\n",
    "    ax.scatter(path_x_values, path_y_values, color=\"blue\", zorder=5)\n",
    "    ax.scatter(inside_x_values, inside_y_values, color=\"blue\", zorder=5)\n",
    "    \n",
    "    # Set limits for x and y axis\n",
    "    all_x_values = [point[0] for point in path] + [point[0] for point in inside]\n",
    "    all_y_values = [point[1] for point in path] + [point[1] for point in inside]\n",
    "\n",
    "    ax.set_xlim(min(all_x_values) - 1, max(all_x_values) + 1)\n",
    "    ax.set_ylim(min(all_y_values) - 1, max(all_y_values) + 1)\n",
    "\n",
    "    plt.title('Path Plot')\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "sample_input = \"\"\"R 6 (#70c710)\n",
    "D 5 (#0dc571)\n",
    "L 2 (#5713f0)\n",
    "D 2 (#d2c081)\n",
    "R 2 (#59c680)\n",
    "D 2 (#411b91)\n",
    "L 5 (#8ceee2)\n",
    "U 2 (#caa173)\n",
    "L 1 (#1b58a2)\n",
    "U 2 (#caa171)\n",
    "R 2 (#7807d2)\n",
    "U 3 (#a77fa3)\n",
    "L 2 (#015232)\n",
    "U 2 (#7a21e3)\"\"\"\n",
    "\n",
    "plan = parse_plan(sample_input.splitlines())\n",
    "perimeter_path, interior_candidates = process_plan(plan)\n",
    "perimeter_set = set(perimeter_path)\n",
    "\n",
    "bounds = get_bounds(perimeter_path)\n",
    "all_interior = flood_fill(perimeter_set, interior_candidates, bounds)\n",
    "plot_path(perimeter_path, all_interior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like this:\n",
    "\n",
    "![Dig plan](https://aoc.just2good.co.uk/assets/images/lava_lagoon_1-by-1_squares.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our vertex coordinates represent the top left of each cell. But in order to use the _Shoelace Formula_, we need our vertices to be on the _outside_ of each corner. We could adjust our vertices to achieve this, like this:\n",
    "\n",
    "![Dig plan](https://aoc.just2good.co.uk/assets/images/lava_lagoon_1-by-1_squares_corners.png)\n",
    "\n",
    "Or alternatively, we can combine the _Shoelace formula_ with _Pick's Theorem_ to determine the number of _internal coordinates bounded by our polygon_. Either should work!\n",
    "\n",
    "Here's is the approach that combines the _Shoelace formula_ with _Pick's Theorem_:\n",
    "\n",
    "1. Determine the area of the _overall_ polygon, using _Shoelace_.\n",
    "2. Determine the number of perimeter boundary points, which is also the perimeter volume. (Since our perimeter is made up of 1x1 squares.)\n",
    "3. Rearrange _Pick's Theorem_ to make use of this area and the number of boundary points, to determine the number of _internal integer coordinates_, i.e.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "A &= i + \\frac{b}{2} - 1 \\\\\n",
    "\\\\\n",
    "i &= A - \\frac{b}{2} + 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "4. Add the perimeter volume to the number of internal integer coordinates, to get the overall polygon volume.\n",
    "\n",
    "To implement this:\n",
    "\n",
    "- I've created a new `parse_plan_hex(input_data)` function, which now uses the hex codes to obtain the instructions.\n",
    "- This time, I use a function `process_turns(plan)`, which returns all the successive coordinates of each vertex that makes up our polygon.\n",
    "- I pass the resulting list of vertices (my `polygon`) to a new function called `shoelace_area()`, which calculates the overall area of the polygon. This just implementes the equation above.\n",
    "- Next, I need to determine the number of boundary points in the perimeter. This happens to also be the total area of the perimeter, since the perimeter is made up of squares that are 1-by-1. I do this with a `perimeter_length(polygon)` function.\n",
    "- Then I calculate the interior points, using my `interior_points(area, boundary_points)`. Again, this just implements the equation above.\n",
    "- Finally, I add the `interior_points` to the `boundary_points` to get the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_plan_hex(data) -> list[tuple]:\n",
    "    \"\"\" \n",
    "    Parse input data and convert into a list of instructions like this:\n",
    "    [('R', 461937), ('D', 56407), ...]\n",
    "    \"\"\"\n",
    "    dirs = { 0: \"R\", 1: \"D\", 2: \"L\", 3: \"U\" }\n",
    "    \n",
    "    plan:list[tuple] = []\n",
    "    for line in data:\n",
    "        instr = line[-7:-1]\n",
    "        dirn = dirs[int(instr[-1])]\n",
    "        path_len = int(instr[0:-1], base=16)\n",
    "        plan.append((dirn, int(path_len)))\n",
    "        \n",
    "    return plan\n",
    "\n",
    "def process_turns(plan) -> list[tuple[int,int]]:\n",
    "    \"\"\" \n",
    "    Process the plan instructions, and return the perimeter path, which contains only the vertices of the polygon. E.g.\n",
    "    [(0, 0), (461937, 0), (461937, 56407), (818608, 56407), ...]\n",
    "    \"\"\"\n",
    "    # initialise, from current\n",
    "    current = (0,0)\n",
    "    path:list[tuple[int,int]] = [current]\n",
    "\n",
    "    for dirn_char, path_len in plan:\n",
    "        dirn = VectorDicts.DIRS[dirn_char]\n",
    "        current = (current[0]+dirn[0]*path_len, current[1]+dirn[1]*path_len)\n",
    "        path.append(current)\n",
    "\n",
    "    return path\n",
    "\n",
    "def shoelace_area(polygon: list[tuple[int,int]]) -> int:\n",
    "    total = 0\n",
    "    for i, (x,y) in enumerate(polygon):\n",
    "        next_index = (i+1) % len(polygon)\n",
    "        prev_index = i-1\n",
    "        total += x*(polygon[next_index][1] - polygon[prev_index][1])\n",
    "        \n",
    "    return abs(total) // 2\n",
    "\n",
    "def perimeter_length(polygon: list[tuple[int,int]]) -> int:\n",
    "    \"\"\" The total length of all the edges of this polygon. This is equivalent to the number of boundary points. \"\"\"\n",
    "    total = 0\n",
    "    for i, (x,y) in enumerate(polygon):\n",
    "        next_index = (i+1) % len(polygon)\n",
    "        total += abs(polygon[next_index][0]-x) + abs(polygon[next_index][1]-y) # there will only ever be an x or y component\n",
    "        \n",
    "    return total\n",
    "\n",
    "def interior_points(area: int, boundary_points: int):\n",
    "    return area - (boundary_points // 2) + 1\n",
    "\n",
    "def total_area(polygon: list[tuple[int,int]]) -> int:\n",
    "    \"\"\" Return total area of the polygon, including the perimeter.\n",
    "    Combine Shoelace formula and Pick's theorem to determine internal integer points of the polygon.\n",
    "    Then add the total number of points that make up the perimeter.\n",
    "\n",
    "    Args:\n",
    "        plan (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        int: _description_\n",
    "    \"\"\"\n",
    "    polygon_area = shoelace_area(polygon)\n",
    "    boundary_points = perimeter_length(polygon)\n",
    "    interior_area = interior_points(polygon_area, boundary_points)\n",
    "    return interior_area + boundary_points    \n",
    "\n",
    "def plot_path(perimeter: list[tuple]):\n",
    "    # Extract x and y values from the perimeter\n",
    "    perimeter_x_values = [point[0] for point in perimeter]\n",
    "    perimeter_y_values = [point[1] for point in perimeter]\n",
    "    \n",
    "    # Plot the perimeter as a line\n",
    "    plt.plot(perimeter_x_values, perimeter_y_values, \n",
    "             marker=MarkerStyle('o'), linestyle='-', color=\"blue\", label=\"Perimeter\")\n",
    "\n",
    "    # Fill the inside of the perimeter\n",
    "    plt.fill(perimeter_x_values, perimeter_y_values, color=\"red\", alpha=0.8)  # Adjust alpha for transparency\n",
    "\n",
    "    plt.title('Path Plot')\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "    plt.gca().set_aspect('equal', adjustable='box')  # Set equal scale \n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(data) -> int:\n",
    "    plan = parse_plan(data)\n",
    "    perimeter_path = process_turns(plan)    \n",
    "    area = total_area(perimeter_path)\n",
    "    logger.debug(f\"Part 1: {area=}\")\n",
    "    plot_path(perimeter_path)\n",
    "\n",
    "    plan = parse_plan_hex(data)\n",
    "    perimeter_path = process_turns(plan)    \n",
    "    area = total_area(perimeter_path)\n",
    "    logger.debug(f\"Part 2: {area=}\") \n",
    "    plot_path(perimeter_path)       \n",
    "    \n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"R 6 (#70c710)\n",
    "D 5 (#0dc571)\n",
    "L 2 (#5713f0)\n",
    "D 2 (#d2c081)\n",
    "R 2 (#59c680)\n",
    "D 2 (#411b91)\n",
    "L 5 (#8ceee2)\n",
    "U 2 (#caa173)\n",
    "L 1 (#1b58a2)\n",
    "U 2 (#caa171)\n",
    "R 2 (#7807d2)\n",
    "U 3 (#a77fa3)\n",
    "L 2 (#015232)\n",
    "U 2 (#7a21e3)\"\"\")\n",
    "sample_answers = [952408144115]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "It's easy enough to plot the new lagoon for Part 2.  With my real data, it looks like this:\n",
    "\n",
    "![Dig plan - Part 2](https://aoc.just2good.co.uk/assets/images/lava_lagoon_real_pt2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 19: Aplenty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"19\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 19 Part 1\n",
    "\n",
    "The parts are being organised...\n",
    "\n",
    "- x: Extremely cool looking\n",
    "- m: Musical (it makes a noise when you hit it)\n",
    "- a: Aerodynamic\n",
    "- s: Shiny\n",
    "\n",
    "Then the parts are sent through a series of named workflows. Each workflow has a list of rules which determine where the part goes, based on the _first condition that is true_.\n",
    "\n",
    "Sample input:\n",
    "\n",
    "```text\n",
    "px{a<2006:qkq,m>2090:A,rfg}\n",
    "pv{a>1716:R,A}\n",
    "lnx{m>1548:A,A}\n",
    "rfg{s<537:gd,x>2440:R,A}\n",
    "qs{s>3448:A,lnx}\n",
    "qkq{x<1416:A,crn}\n",
    "crn{x>2662:A,R}\n",
    "in{s<1351:px,qqz}\n",
    "qqz{s>2770:qs,m<1801:hdj,R}\n",
    "gd{a>3333:R,R}\n",
    "hdj{m>838:A,pv}\n",
    "\n",
    "{x=787,m=2655,a=1222,s=2876}\n",
    "{x=1679,m=44,a=2067,s=496}\n",
    "{x=2036,m=264,a=79,s=2244}\n",
    "{x=2461,m=1339,a=466,s=291}\n",
    "{x=2127,m=1623,a=2188,s=1013}\n",
    "```\n",
    "\n",
    "Here we have a list of workflows, then a list of part ratings. Parts always start with workflow `in`.\n",
    "\n",
    "- `A` = Accepted\n",
    "- `R` = Rejected\n",
    "\n",
    "**Sort through all of the parts you've been given; what do you get if you add together all of the rating numbers for all of the parts that ultimately get accepted?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "I've created a `Workflow` class that represents each workflow in our input. I.e.\n",
    "\n",
    "- It contains a `name` for that workflow.\n",
    "- It contains a `list` of `tuples` that represent the `rules``. Each rule takes the form: `(condition, next)`, where:\n",
    "  - `condition` could be a comparison (like `a<2006`) or simply `True` (to represent the last rule which always applied if reached).\n",
    "  - `next` is one of: the next workflow, or `A` (accepted) or `R` (rejected).\n",
    "\n",
    "- It has a `parse_condition()` [static method](https://aoc.just2good.co.uk/python/classes#methods-1). This takes the specified condition (the first member of the _rule_ tuple), and splits it into its three components. I.e. left (e.g. `a`), operator (e.g. `<`), and right (e.g. `2006`).\n",
    "- Finally, our `Workflow` has an `execute()` method. This is used to push a given `part` through the `Workflow`. This method iterates through each `rule` in `rules`. It evaluates each condition, passing the in the actual values from the `part`. \n",
    "  - If the condition evaluates to `True`, then we return the next `Workflow`/`A`/`R`.\n",
    "  - If the condition evaluates to `False` then we move on to the next rule in hte workflow.\n",
    "\n",
    "Finally, to solve for Part 1:\n",
    "\n",
    "- Parse the input. The first block represents the workflows, and the second block represents parts with their _\"xmas\"_ category values.\n",
    "  - Store the workflows in a dictionary, keyed by `Workflow name`.\n",
    "  - Store the parts in a list. Each _part_ is represented as a dictionary that maps the _\"xmas\"_ categories to their values.\n",
    "- Create an `accepted` list, where we store all parts that are accepted by our workflows.\n",
    "- Iterate over each part. For each:\n",
    "  - Pass it through all the workflows, starting with _\"in\"_.\n",
    "  - Continue looping through workflows until the next state returned is either `A` or `R`. In either case, we're done with this part. If `A`, then add this part to our list. If `R`, do nothing.\n",
    "  - Otherwise, the next state is the next `Workflow`.  So execute the next `Workflow`.\n",
    "\n",
    "- Finally, add up all the part values (which are all the dictionary values) of each part, which gives a single value per part. Then add up all _these_ values to give the final answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Workflow():\n",
    "    \"\"\" \n",
    "    A Workflow is a list of rules that we must apply to a part. \n",
    "    Each rule maps a condition to another workflow.\n",
    "    Rules are executed in order.  \n",
    "    We determine the next available workflow based on the first rule that evaluates to True.\n",
    "    \"\"\"\n",
    "    name: str # e.g. \"in\", \"qqz\"\n",
    "    \n",
    "    # [ {condition: next_flow }, ...]\n",
    "    # For any given condition (if not True or False), the first operand is a part category, \n",
    "    # and the second operand is an int value\n",
    "    rules: list[tuple[str, str]] \n",
    "    \n",
    "    ops = {\n",
    "        \">\": operator.gt,\n",
    "        \"<\": operator.lt,\n",
    "    }\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_condition(condition):\n",
    "        \"\"\" Returns left_operand, operator, right_operand for a given condition \"\"\"\n",
    "        op = next(op for op in Workflow.ops if op in condition)\n",
    "        left_operand, right_operand = condition.split(op)\n",
    "        return left_operand, op, int(right_operand)\n",
    "    \n",
    "    def execute(self, part: dict):\n",
    "        \"\"\" Execute rules in order, for this part. Return the matching next workflow. \"\"\"\n",
    "        for condition, next_flow in self.rules:\n",
    "            if condition[0] in \"xmas\":\n",
    "                left, op, right = self.parse_condition(condition)\n",
    "                part_val = part[left]\n",
    "                res = Workflow.ops[op](part_val, right)\n",
    "            else:\n",
    "                res = True\n",
    "            \n",
    "            if res:\n",
    "                return next_flow\n",
    "        \n",
    "        assert False, \"At least one condition must be True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(data: str) -> tuple[dict[str,Workflow], list[dict[str,int]]]:\n",
    "    \"\"\" The input contains two blocks: workflows, and parts.\n",
    "    Parse the workflows into a dict of Workflow objects.\n",
    "    Parse the parts into a list of part dictionaries. \"\"\"\n",
    "    flow_lines, part_lines = [block.splitlines() for block in data.split(\"\\n\\n\")]\n",
    "    \n",
    "    workflows = {}\n",
    "    for flow_line in flow_lines:\n",
    "        flow_name, flow_rules = flow_line.split(\"{\")\n",
    "        flow_rules = flow_rules.strip(\"}\") # remove trailing }\n",
    "        flow_rules = [flow_rule for flow_rule in flow_rules.split(\",\")]\n",
    "        \n",
    "        new_rules = [] # Dua protocol\n",
    "        for rule in flow_rules:\n",
    "            if \":\" in rule:\n",
    "                new_rules.append(tuple(rule.split(\":\")))\n",
    "            else:  # final condition is always true\n",
    "                new_rules.append((\"True\", rule))\n",
    "                \n",
    "        workflows[flow_name] = Workflow(flow_name, new_rules)\n",
    "    \n",
    "    parts = []\n",
    "    for part_line in part_lines:\n",
    "        part_line = part_line[1:-1] # strip off the leading and trailing brackets\n",
    "        components = part_line.split(\",\")\n",
    "        cat_vals = {}\n",
    "        for component in components:\n",
    "            cat, cat_val = component.split(\"=\")\n",
    "            cat_vals[cat] = int(cat_val)\n",
    "        \n",
    "        parts.append(cat_vals)\n",
    "        \n",
    "    return workflows, parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    workflows, parts = parse_input(data)\n",
    "    \n",
    "    accepted:list[dict[str, int]] = [] # store accepted parts\n",
    "    for part in parts: \n",
    "        current_flow = workflows[\"in\"]\n",
    "        while True: # loop until next state is A or R, which means we're done with workflows for this part\n",
    "            workflow_out = current_flow.execute(part)\n",
    "            if workflow_out in (\"A\", \"R\"):\n",
    "                if workflow_out == \"A\":\n",
    "                    accepted.append(part)\n",
    "                break # we're done with this part\n",
    "            \n",
    "            current_flow = workflows[workflow_out] # otherwise, move on to the next workflow\n",
    "            \n",
    "    return sum(sum(part.values()) for part in accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"px{a<2006:qkq,m>2090:A,rfg}\n",
    "pv{a>1716:R,A}\n",
    "lnx{m>1548:A,A}\n",
    "rfg{s<537:gd,x>2440:R,A}\n",
    "qs{s>3448:A,lnx}\n",
    "qkq{x<1416:A,crn}\n",
    "crn{x>2662:A,R}\n",
    "in{s<1351:px,qqz}\n",
    "qqz{s>2770:qs,m<1801:hdj,R}\n",
    "gd{a>3333:R,R}\n",
    "hdj{m>838:A,pv}\n",
    "\n",
    "{x=787,m=2655,a=1222,s=2876}\n",
    "{x=1679,m=44,a=2067,s=496}\n",
    "{x=2036,m=264,a=79,s=2244}\n",
    "{x=2461,m=1339,a=466,s=291}\n",
    "{x=2127,m=1623,a=2188,s=1013}\"\"\")\n",
    "\n",
    "sample_answers = [19114]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 19 Part 2\n",
    "\n",
    "Rather than push parts through the workflows, we need to determine which combinations of category ratings will be accepted or rejected.\n",
    "\n",
    "Each category rating can have an int value from 1 to 4000 (inclusive).\n",
    "\n",
    "**Consider only your list of workflows; the list of part ratings that the Elves wanted you to sort is no longer relevant. How many distinct combinations of ratings will be accepted by the Elves' workflows?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "I've defined a recursive function called `count_ranges()`. It's purpose is to count the total number of distinct accepted part ratings. It works like this:\n",
    "\n",
    "- It takes three parameters:\n",
    "  - A dictionary that maps _xmas_ categories to a each start range. The values are tuples representing the inclusive `(low, high)` values of each range. Initially, the ranges will be defined as 1-4000 for each category.\n",
    "  - The current workflow name, which could be `A` for _accepted_ and `R` for _rejected_.\n",
    "  - The dictionary of all the workflows, which we simply use for mapping workflow name to actual `Workflow`.\n",
    "\n",
    "- Our base case:\n",
    "  - Returns `0` if the workflow is `R`.\n",
    "  - If the next workflow is `A`, then all the current ranges are accepted. So take the product of all _xmas_ ranges and return it.  E.g. if each of _xmas_ had a range from 901-1000 inclusive, then we would be accepting `100*100*100*100` distinct combinations of ratings.\n",
    "\n",
    "- Next, we set `total` to 0, which accumulates the count of accepted combinations as we process the rules and recursively process workflows.\n",
    "- Now we iterate through each rule `(condition, next_flow)` in the current workflow. Recall that we should exit once a condition evaluates to True, and move on to the associated next workflow. Moving onto the next workflow is achieved by calling the function recursively, with the next workflow and updated ranges.\n",
    "  - If the current condition is a comparison involving an _xmas_ category (e.g. `a<1716`), then we split the condition into three parts: _left_, _operator_ (i.e. `<` or `>`), and _right_. The left part will always be a _category_, and the right part will always be an integer value.\n",
    "  - Then we get the current range for the category component. I.e. from the ranges that were passed to the function, and using the category that was retrieved from the condition.\n",
    "  - The operator and right value are then used to split the current range into two parts: a subrange where the condition holds true, and a subrange where the condition does not hold.\n",
    "  - For each subrange, if the true subrange is not empty, this means that this range has met the condition, and we need to pass the range to the next workflow.\n",
    "  - If the true subrange is empty, this means there are no values within the current range of the category that satisfy the condition. So we need to move on to check the next condition in the `Workflow`.\n",
    "  - If the false subrange is empty, then there are no values left that do not meet the condition. Since the condition of the current rule encompasses all possible values in the range, there's no need to evaluate subsequent rules in the current workflow. Thus, we break from the loop. The function can safely proceed to process the true subrange (if not empty) in the next workflow or finalize the count if the decision is \"Accepted\" or \"Rejected\".\n",
    "- The final rule is always `True` and acts as the fallback condition for the `Workflow`. This condition will make a recursive call to the next workflow. \n",
    "\n",
    "![Splitting ranges through workflows](https://aoc.just2good.co.uk/assets/images/2019_range_splitting.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ranges(ranges:dict[str, tuple[int,int]], workflow_name: str, workflows: dict[str, Workflow]) -> int:\n",
    "    \"\"\" Count total number of distinct accepted part ratings numbers.\n",
    "\n",
    "    Args:\n",
    "        ranges (dict[str, tuple[int,int]]): Range for a given category, as (low, high) inclusive.\n",
    "        workflow_name (str): Name of a workflow.\n",
    "        workflows (dict[str, Workflow]): dictionary of all our workflows, keyed by name\n",
    "    \"\"\"\n",
    "    logger.debug(f\"{workflow_name=}\")\n",
    "        \n",
    "    # Base case\n",
    "    if workflow_name == \"R\": # rejected count\n",
    "        return 0\n",
    "    \n",
    "    if workflow_name == \"A\": # accepted count\n",
    "        # product of all the ranges\n",
    "        logger.debug(f\"Accepted {ranges=}\")\n",
    "        return math.prod((high-low+1) for low, high in ranges.values())\n",
    "            \n",
    "    workflow = workflows[workflow_name]\n",
    "    total = 0\n",
    "    for condition, next_flow in workflow.rules: # process rules for this workflow\n",
    "        if condition[0] in \"xmas\": # We need to split the range into two segments\n",
    "            cat, op, right_val = Workflow.parse_condition(condition) # e.g. a, <, 2006\n",
    "            low, high = ranges[cat] # current inclusive range for this category\n",
    "            \n",
    "            # split the current range based on this this condition\n",
    "            # E.g. with current range 1,4000:\n",
    "            #      a<1716 means split into 1-1715 (true), 1716-4000 (false)\n",
    "            #      a>1716 means split into 1-1716 (false), 1717-4000 (true)\n",
    "            \n",
    "            # True for condition: we're done with this workflow, so recurse to the next\n",
    "            true_for_condition = (low, right_val - 1) if op == \"<\" else (right_val + 1, high)\n",
    "            \n",
    "            # False for condition: we need to try the next rule in this workflow\n",
    "            false_for_condition = (right_val, high) if op == \"<\" else (low, right_val)\n",
    "            \n",
    "            # Check if the condition splits are NOT empty\n",
    "            # First, check if true component non-empty. \n",
    "            # These will need to be processed by subseqauent rules.\n",
    "            if true_for_condition[0] <= true_for_condition[1]: \n",
    "                # for any True in this range, we're done with this workflow, so recurse to next workflow\n",
    "                ranges_copy = dict(ranges) # make a copy of ranges\n",
    "                ranges_copy[cat] = true_for_condition # pass through the new, true range\n",
    "                total += count_ranges(ranges_copy, next_flow, workflows) \n",
    "            \n",
    "            if false_for_condition[0] <= false_for_condition[1]: # false half non-empty\n",
    "                # for any False in this range, we need to move to the next rule in THIS workflow\n",
    "                ranges = dict(ranges) \n",
    "                ranges[cat] = false_for_condition # pass through the new, false range\n",
    "            else: # false half is empty, so nothing left to do in this workflow\n",
    "                break\n",
    "        else: # we're at the \"True\" rule in our workflow\n",
    "            assert condition == \"True\", \"We must be at the final condition.\"\n",
    "            total += count_ranges(ranges, next_flow, workflows) # recurse to next workflow\n",
    "            \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    workflows, _ = parse_input(data)\n",
    "    \n",
    "    ranges = { cat: (1, 4000) for cat in \"xmas\" }\n",
    "    logger.debug(ranges)\n",
    "    accepted = count_ranges(ranges, workflow_name=\"in\", workflows=workflows)\n",
    "    \n",
    "    return accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_answers = [167409079868000]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 20: Pulse Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"20\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 20 Part 1\n",
    "\n",
    "Modules communicate using pulses.  \n",
    "\n",
    "- There are two types of pulses: `high` and `low`. \n",
    "- For any given module, each pulse is sent to a list of destination modules. \n",
    "- _Flip-flop_ modules (prefix `%`) are either on or off.  \n",
    "  - They are initially off. \n",
    "  - If it receives a `low` pulse it flips. When it flips on, it sends a `high` pulse. When it flips off, it sends a `low` pulse.\n",
    "  - If it receives a `high`, it does nothing.\n",
    "- _Conjunction_ modules (prefix `&`) remember the type of pulse received from each of its inputs. They initially default to remembering `low` pulse. When it receives a pulse, it updates its memory state, and then:\n",
    "  - If all inputs remembered are `high`, it sends a `low`.\n",
    "  - Otherwise it sends a `high`.\n",
    "- There is one _broadcast_ module. When it receives a pulse, it sends the same pulse to all of its destinations.\n",
    "- There is a _button_ module. When pressed, it sends `low` to _broadcast_.\n",
    "- Modules are processed in the order they are sent. (So, breadth first, rather than depth first.)\n",
    "\n",
    "Sample configuration:\n",
    "\n",
    "```text\n",
    "broadcaster -> a, b, c\n",
    "%a -> b\n",
    "%b -> c\n",
    "%c -> inv\n",
    "&inv -> a\n",
    "```\n",
    "\n",
    "**Consult your module configuration; determine the number of low pulses and high pulses that would be sent after pushing the button 1000 times, waiting for all pulses to be fully handled after each push of the button. What do you get if you multiply the total number of low pulses sent by the total number of high pulses sent?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "This is perfect for some OO programming!\n",
    "\n",
    "I've implemented an abstract class called `Module`. It is _abstract_ because it must be extended by concrete subclasses, and those subclasses must implement the abstract methods `send_pulse()` and `pulse_received()`.\n",
    "\n",
    "The 'Module' abstract class implements some default properties and behaviour that are common to the various specific module types:\n",
    "\n",
    "- It defines a module `id`.\n",
    "- It contains a list of `inputs`, and a method to add an input.\n",
    "- It contains a list of `outputs`, and a method to an add output.\n",
    "- It maintains counts of `low_sent` pulses and `high_sent` pulses.\n",
    "- It has an internal `_send_pulse(pulse_type)` method. This calls the `pulse_received()` method against each module in this module's `outputs` list. It also increments the relevant _sent counter_.\n",
    "\n",
    "Here, I've defined a subclass for each module type, i.e.\n",
    "\n",
    "- `FlipFlop` - This maintains internal state, and inverts its state (and sends a matching pulse) if it receives a low pulse.\n",
    "- `Conjunction` - This maintains remembers the last pulse received by each of its inputs, and stores these values in a dictionary. It sends a _low_ pulse if all of its rmembered pulses are _high_.\n",
    "- `Broadcaster` - This forwards on any pulse received to all _outputs_.\n",
    "- `Button` - This sends a low pulse to the `broadcaster`.\n",
    "- `Output` - This simply stores the last received pulse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Module(abc.ABC):\n",
    "    id: str\n",
    "    inputs: list[Module] = field(default_factory=list)\n",
    "    outputs: list[Module] = field(default_factory=list)\n",
    "    low_sent: int = 0\n",
    "    high_sent: int = 0\n",
    "\n",
    "    def add_input(self, module: Module):\n",
    "        self.inputs.append(module)\n",
    "\n",
    "    def add_output(self, module: Module):\n",
    "        self.outputs.append(module)\n",
    "\n",
    "    def _send_pulse(self, pulse: int):\n",
    "        # logger.debug(f\"{self.id} -> {pulse} -> {[mod.id for mod in self.outputs]}\")\n",
    "        for mod in self.outputs:\n",
    "            if pulse == 0:\n",
    "                self.low_sent += 1\n",
    "            else:\n",
    "                self.high_sent += 1\n",
    "            mod.pulse_received(self, pulse)\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def send_pulse(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def pulse_received(self, in_module: Module, pulse: int):\n",
    "        pass\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        input_ids = [input_module.id for input_module in self.inputs]\n",
    "        output_ids = [output_module.id for output_module in self.outputs]\n",
    "        return f\"Module(id={self.id}, inputs={input_ids}, outputs={output_ids})\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}(id={self.id},low_sent={self.low_sent},high_sent={self.high_sent})\"\n",
    "\n",
    "\n",
    "class FlipFlop(Module):\n",
    "    state:bool = False # initially off\n",
    "\n",
    "    def send_pulse(self):\n",
    "        pulse = 1 if self.state else 0\n",
    "        self._send_pulse(pulse)\n",
    "\n",
    "    def pulse_received(self, in_module: Module, pulse: int):\n",
    "        if pulse == 0:\n",
    "            self.state = not self.state\n",
    "            self.send_pulse()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{super().__str__()}, state={self.state}\"\n",
    "\n",
    "class Conjunction(Module):\n",
    "    state: dict[str, int] = {}\n",
    "\n",
    "    def add_input(self, module: Module):\n",
    "        super().add_input(module)\n",
    "        self.state[module.id] = 0\n",
    "\n",
    "    def pulse_received(self, in_module: Module, pulse: int):\n",
    "        self.state[in_module.id] = pulse\n",
    "        self.send_pulse()\n",
    "\n",
    "    def send_pulse(self):\n",
    "        input_mod_ids = [input_mod.id for input_mod in self.inputs]\n",
    "        pulse = 0 if all(self.state[id] for id in input_mod_ids) else 1\n",
    "        self._send_pulse(pulse)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{super().__str__()}, state={self.state}\"\n",
    "\n",
    "class Broadcaster(Module):\n",
    "    received:int\n",
    "\n",
    "    def pulse_received(self, in_module: Module, pulse: int):\n",
    "        self.received = pulse\n",
    "        self.send_pulse()\n",
    "    \n",
    "    def send_pulse(self):\n",
    "        self._send_pulse(self.received)\n",
    "\n",
    "class Button(Module):\n",
    "    def send_pulse(self):\n",
    "        self._send_pulse(0) # always sends 0 to broadcast\n",
    "\n",
    "    def pulse_received(self, in_module: Module, pulse: int):\n",
    "        pass\n",
    "\n",
    "    def push(self):\n",
    "        self.send_pulse()\n",
    "  \n",
    "class Output(Module):\n",
    "    received:int\n",
    "\n",
    "    def send_pulse(self):\n",
    "        pass\n",
    "\n",
    "    def pulse_received(self, in_module: Module, pulse: int):\n",
    "        self.received = pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_modules(data: list[str]) -> dict[str, Module]:\n",
    "    modules:dict[str, Module] = {}\n",
    "\n",
    "    # create the modules\n",
    "    for line in data:\n",
    "        mod_part, outputs_part = line.split(\" -> \")\n",
    "        if mod_part[0] == \"%\":\n",
    "            modules[mod_part[1:]] = FlipFlop(mod_part[1:])\n",
    "        elif mod_part[0] == \"&\":\n",
    "            modules[mod_part[1:]] = Conjunction(mod_part[1:])\n",
    "        else:\n",
    "            assert mod_part == \"broadcaster\", \"This must be a broadcaster module\"\n",
    "            modules[mod_part] = Broadcaster(mod_part)\n",
    "\n",
    "    # now register inputs and outputs\n",
    "    for line in data:\n",
    "        mod_part, outputs_part = line.split(\" -> \")\n",
    "        if mod_part == \"broadcaster\":\n",
    "            module = modules[mod_part]\n",
    "        else:\n",
    "            module = modules[mod_part[1:]]\n",
    "\n",
    "        output_names = [name.strip() for name in outputs_part.split(\",\")]\n",
    "\n",
    "        # check for outputs that aren't inputs\n",
    "        for output_name in output_names:\n",
    "            if output_name not in modules:\n",
    "                modules[output_name] = Output(output_name)\n",
    "\n",
    "            module.add_output(modules[output_name])\n",
    "            modules[output_name].add_input(module)\n",
    "            \n",
    "    return modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(modules: dict[str, Module]):\n",
    "    button = Button(\"button\")\n",
    "    modules[button.id] = button\n",
    "    button.add_output(modules[\"broadcaster\"])\n",
    "    for _ in range(1000):\n",
    "        button.push()\n",
    "\n",
    "    low_sent = sum(module.low_sent for module in modules.values())\n",
    "    high_sent = sum(module.high_sent for module in modules.values())\n",
    "    logger.debug(f\"{low_sent=}, {high_sent=}\")\n",
    "    prod = low_sent*high_sent\n",
    "    logger.debug(f\"{prod=}\")\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"broadcaster -> a, b, c\n",
    "%a -> b\n",
    "%b -> c\n",
    "%c -> inv\n",
    "&inv -> a\"\"\")\n",
    "\n",
    "sample_inputs.append(\"\"\"broadcaster -> a\n",
    "%a -> inv, con\n",
    "&inv -> b\n",
    "%b -> con\n",
    "&con -> output\"\"\")\n",
    "\n",
    "sample_answers = [32000000, 11687500]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_modules = parse_modules(curr_input.splitlines())\n",
    "    validate(solve_part1(curr_modules), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "modules = parse_modules(input_data)\n",
    "soln = solve_part1(modules)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 20 Part 2\n",
    "\n",
    "In Part 1, it transpired that _rx_ was only an output.\n",
    "\n",
    "In Part 2, we're told that _rx_ turns on when a single low pulse is sent to rx.\n",
    "\n",
    "**Reset all modules to their default states. Waiting for all pulses to be fully handled after each button press, what is the fewest number of button presses required to deliver a single low pulse to the module named rx?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "First, I tried brute force. (A long shot, I know!) Push the button until a low pulse arrives at _rx_.\n",
    "\n",
    "Conclusion: this takes 30s to execute 1m button presses, and still doesn't exit.  So, the number could be huge, and this solution probably isn't viable. I need to be smarter!\n",
    "\n",
    "Plan B...\n",
    "\n",
    "I need to understand the inputs to _rx_ and try to understand what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(modules: dict[str, Module]):\n",
    "    # Create the button and associate with the broadcaster\n",
    "    button = Button(\"button\")\n",
    "    modules[button.id] = button\n",
    "    button.add_output(modules[\"broadcaster\"])\n",
    "    \n",
    "    rx: Output = cast(Output, modules[\"rx\"])\n",
    "    assert len(rx.outputs) == 0, \"Module rx should have no outputs\"\n",
    "    \n",
    "    rx_inputs = rx.inputs\n",
    "    logger.debug(f\"{rx_inputs}\")\n",
    "\n",
    "    # button_presses = 0\n",
    "    # while True:\n",
    "    #     button.push()\n",
    "    #     button_presses += 1\n",
    "    #     if rx.received == 0:\n",
    "    #         break\n",
    "\n",
    "    #     if button_presses == 50000:\n",
    "    #         assert False, \"This is going to take a while\"\n",
    "\n",
    "    # return button_presses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "modules = parse_modules(input_data) # reset modules states\n",
    "soln = solve_part2(modules)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 21: Step Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"21\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 21 Part 1\n",
    "\n",
    "Ha ha!  An elf wants to get his steps in for the day, and wants us to help him determine which plots he can reach exactly with his remaining 64 steps!!\n",
    "\n",
    "```text\n",
    "...........\n",
    ".....###.#.\n",
    ".###.##..#.\n",
    "..#.#...#..\n",
    "....#.#....\n",
    ".##..S####.\n",
    ".##..#...#.\n",
    ".......##..\n",
    ".##.#.####.\n",
    ".##..##.##.\n",
    "...........\n",
    "```\n",
    "\n",
    "We have:\n",
    "\n",
    "- `S` - the start position. Which is also a garden plot.\n",
    "- `.` - a garden plot\n",
    "- `#` - a rock, which blocks the way\n",
    "\n",
    "We can travel N, E, S, W _and_ we can backtrack.\n",
    "\n",
    "Starting from the garden plot marked S on your map, how many garden plots could the Elf reach in exactly 64 steps?\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- I read in the data and convert to a 2D grid, where each row contains elements, and each element contains a single character.\n",
    "- Then I read through the grid, to find the `S` and mark its location as tuple of `(x, y)`.\n",
    "- Now I can do a [BFS](https://aoc.just2good.co.uk/python/shortest_paths) to flood-fill the available locations we can move to.\n",
    "\n",
    "Initially I decided to store `(location, steps taken)` in my seen state, since there are multiple ways to arrive at the same location. But I wanted to allow for backtracking, because we're allowed to go back to locations we've been to before. However, I then realised that I can simply store every location previously visited. _Why is this true?_ It is true because:\n",
    "  - If we arrive at any location and we have an _even_ number of steps remaining, then we can _always_ get back to this location on our last step. So if this condition is met, this location is a valid final location.\n",
    "  - If we arrive at any location and we have an _odd_ number of steps remaining, then there's no way to get back to this location on our last step. That's because for every _n_ steps we move away from our current location, we need to move _n_ steps back for this location to one of solution locations.  But _2n_ will _always_ be an even number. There's no way to travel _2n_ squares with an odd number of steps remaining.\n",
    "  - So to conclude: any location we visit will either be a valid solution location, or impossible to reach on our last step. In either case, we can mark it as seen and never revisit.\n",
    "\n",
    "My implementation:\n",
    "\n",
    "- The queue itself is a `deque`, since this is an efficient structure in Python for implementing a queue with frequent appending and popping.\n",
    "- I retrieve the height of the grid, and assert it is also the width.\n",
    "- I add my starting location `(0, 0)` to the queue.\n",
    "- Then I iterate until the queue is empty:\n",
    "  - I pop from the queue, to retrieve the current location and remaining steps.\n",
    "  - As noted above, if we have an even number of steps remaining, then the current location is a valid end state, so store in our `answer` set.\n",
    "  - If we have any steps remaining, we now decrement the number of available steps by 1. Then we identify all the valid neighbours (within the grid). For any valid neighbour that isn't a rock (`#`), we can add it to the queue.\n",
    "  - When we've used up all the available steps, we will stop adding neighbours to the queue, so the queue will eventually be empty.\n",
    "- Finally, we can count how many locations were in the `answer` set.\n",
    "  \n",
    "**And some visualisation:**\n",
    "\n",
    "I've plotted the solution using [matplotlib](https://aoc.just2good.co.uk/python/matplotlib). I've converted the grid to a [NumPy](https://aoc.just2good.co.uk/python/numpy) array, since this makes it really easy to plot.\n",
    "\n",
    "![2023 Day 21 Part 1 Sample](https://aoc.just2good.co.uk/assets/images/2023d21_pt1_sample_plot.png)\n",
    "\n",
    "![2023 Day 21 Part 1 Sample](https://aoc.just2good.co.uk/assets/images/2023d21_pt1_real_plot.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(grid, start: tuple[int,int], steps_available: int) -> set[tuple]:\n",
    "    \"\"\" Determine all the locations we can reach in exactly the number of steps available. \n",
    "    When steps_available > 0:\n",
    "    - If steps_available is odd, there is no way to get back to this location in the steps available. \n",
    "      This location should be marked as seen.\n",
    "    - If steps_available is even, then we can ALWAYS get back to this space in the steps available.\n",
    "      This location should be marked as seen, but also as part of our solution set. \"\"\"\n",
    "    # store (location, steps remaining)\n",
    "    queue: deque[tuple[tuple[int,int], int]] =  deque([(start, steps_available)])\n",
    "    seen = set() \n",
    "    answer: set[tuple] = set() # the number of locations we can get to in the required number of steps\n",
    "\n",
    "    assert len(grid) == len(grid[0]), \"The grid should be square\"\n",
    "    side_len = len(grid)\n",
    "    \n",
    "    while queue:\n",
    "        current, steps_available = queue.popleft()\n",
    "\n",
    "        if steps_available >= 0:\n",
    "            if steps_available % 2 == 0: # we can always get back to this location in an even number of steps\n",
    "                answer.add(current) # so this location will be possible in our target number of steps\n",
    "            \n",
    "            if steps_available > 0: # get next possible location\n",
    "                steps_available -= 1\n",
    "                neighbours = ((current[0]+dx,current[1]+dy) for dx,dy in (VectorDicts.DIRS.values()))\n",
    "                for neighbour in neighbours:\n",
    "                    if neighbour in seen or grid[neighbour[1]][neighbour[0]] == \"#\":\n",
    "                        continue\n",
    "                    if 0 <= neighbour[0] < side_len and 0 <= neighbour[1] < side_len:\n",
    "                        queue.append((neighbour, steps_available))\n",
    "                        seen.add(neighbour)\n",
    "                        \n",
    "    return answer\n",
    "\n",
    "def plot(grid, start, visited: set):\n",
    "    # Map the characters to numbers: S -> 0, # -> 1, . -> 2, O -> 3\n",
    "    char_to_num = {'S': 0, '#': 1, '.': 2, 'O': 3}\n",
    "    cmap = mcolors.ListedColormap(['black', 'red', 'blue', 'yellow'])\n",
    "    numeric_grid = [[char_to_num[char] for char in row] for row in grid]\n",
    "        \n",
    "    # Convert to a NumPy array for better handling by Matplotlib\n",
    "    numeric_grid = np.array(numeric_grid)\n",
    "\n",
    "    for (ci,ri) in visited: # update visited\n",
    "        numeric_grid[ri][ci] = 3\n",
    "    numeric_grid[start[1],start[0]] = 0 # update start\n",
    "    \n",
    "    # Create custom patches for the legend\n",
    "    labels = ['Start', 'Rock', 'Plot', 'Reachable']\n",
    "    colors = ['black', 'red', 'blue', 'yellow']\n",
    "    patches = [mpatches.Patch(color=colors[i], label=labels[i]) for i in range(len(colors))]\n",
    "\n",
    "    plt.imshow(numeric_grid, cmap=cmap)\n",
    "    plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data, steps_available=64):\n",
    "    grid = [[char for char in row] for row in data]\n",
    "    logger.debug(\"\\n\" + \"\\n\".join(''.join(row) for row in grid))\n",
    "    \n",
    "    # Find the start\n",
    "    start: Optional[tuple[int,int]] = None\n",
    "\n",
    "    # Find start, and also assert length == 1 by assinging to single value tuple    \n",
    "    (start, ) = [(ri, ci) for ri, row in enumerate(grid)\n",
    "                          for ci, char in enumerate(row) if char == \"S\"]\n",
    "    \n",
    "    answer = bfs(grid, start, steps_available)\n",
    "    plot(grid, start, visited=answer)\n",
    "    logger.debug(f\"We have {len(answer)} final locations.\")\n",
    "    \n",
    "    return len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"...........\n",
    ".....###.#.\n",
    ".###.##..#.\n",
    "..#.#...#..\n",
    "....#.#....\n",
    ".##..S####.\n",
    ".##..#...#.\n",
    ".......##..\n",
    ".##.#.####.\n",
    ".##..##.##.\n",
    "...........\"\"\")\n",
    "sample_answers = [16]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines(), steps_available=6), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln_64 = solve_part1(input_data, steps_available=64)\n",
    "logger.info(f\"Part 1 soln_64={soln_64}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 21 Part 2\n",
    "\n",
    "Oh, the elf needs to get in **26501365 steps**, not 64. _Sad times_. And **the grid repeats infinitely** in each direction. (Repeated `S` just become `.`, obviously.)\n",
    "\n",
    "I'm guessing the current BFS won't scale. _Surprise._\n",
    "\n",
    "#### Visualising the Infinite Grid\n",
    "\n",
    "I note that the real data has additional properties that aren't true for the sample data. Depending on how you go about solving the problem, these factors may or may not be relevant. Here are some key properties of our real data:\n",
    "\n",
    "1. Our start location is in the centre of the grid.\n",
    "1. The edges are all empty. I.e. they are garden plots.\n",
    "1. Both the row and the column of our `S` location are both also empty. (This is not true for the sample data!)\n",
    "\n",
    "Let's imagine that the last property applied to the sample grid:\n",
    "\n",
    "```text\n",
    "...........\n",
    "......##.#.\n",
    ".###..#..#.\n",
    "..#.#...#..\n",
    "....#.#....\n",
    ".....S.....\n",
    ".##......#.\n",
    ".......##..\n",
    ".##.#.####.\n",
    ".##...#.##.\n",
    "...........\n",
    "```\n",
    "\n",
    "I.e. it looks like this:\n",
    "\n",
    "![2023 Day 21 Part 2 New Sample Tile](https://aoc.just2good.co.uk/assets/images/2023d21_pt2_new_sample_tile.png)\n",
    "\n",
    "These properties are useful, because in our infinite grid made up of many replicated tiles, we can always walk the empty channels (I'll call them _highways_) to get to an adjacent tile.\n",
    "\n",
    "This makes it a bit more obvious:\n",
    "\n",
    "![2023 Day 21 Part 2 New Sample Tile - Highways](https://aoc.just2good.co.uk/assets/images/2023d21_pt2_new_sample_tile_highways.png)\n",
    "\n",
    "Here, I've replicated the above tile to form a 5x5 grid of tiles, with our original grid at the centre:\n",
    "\n",
    "![2023 Day 21 Part 2 New Sample Tiles](https://aoc.just2good.co.uk/assets/images/2023d21_pt2_new_sample_tiles.png)\n",
    "\n",
    "As an aside, here's how I plotted these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tiles(data):\n",
    "    grid = [[char for char in row] for row in data]\n",
    "    grid_side_len = len(grid) # Size of the original grid\n",
    "    scale_factor = 3 # to scale up the tiles so I can insert a thin border between them\n",
    "    center_index = grid_side_len // 2\n",
    "    tiles_width = 5\n",
    "    \n",
    "    # First, set the center row and column\n",
    "    for i in range(grid_side_len):\n",
    "        grid[center_index][i] = 'C'  # Center row\n",
    "        grid[i][center_index] = 'C'  # Center column\n",
    "    \n",
    "    # Then, set the edges\n",
    "    for i in range(grid_side_len):\n",
    "        grid[0][i] = 'E'\n",
    "        grid[-1][i] = 'E'\n",
    "        grid[i][0] = 'E'\n",
    "        grid[i][-1] = 'E'\n",
    "        \n",
    "    grid[center_index][center_index] = 'S'\n",
    "\n",
    "    char_to_num = {'S': 0, '.': 1, '#': 2, 'C': 3, 'E': 3, 'G': 4}\n",
    "    cmap = mcolors.ListedColormap(['black', 'red', 'blue', 'yellow'])\n",
    "    numeric_grid = np.array([[char_to_num.get(char, 0) for char in row] for row in grid])\n",
    "    expanded_grid = np.repeat(np.repeat(numeric_grid, scale_factor, axis=0), scale_factor, axis=1)\n",
    "\n",
    "    # Create custom patches for the legend\n",
    "    colors = ['red', 'blue', 'yellow']\n",
    "    labels = ['Blocked', 'Empty plot', 'Empty highway']\n",
    "    patches = [mpatches.Patch(color=colors[i], label=labels[i]) for i in range(len(colors))]\n",
    "    \n",
    "    # plot single tile\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"Single Grid Tile\")\n",
    "    ax.imshow(expanded_grid, cmap=cmap, interpolation='nearest') # the interpolation helps with colour bleed\n",
    "    ax.axis(\"off\")\n",
    "    plt.subplots_adjust(right=0.8) # Adjust the subplot to make room for the legend\n",
    "    plt.legend(handles=patches, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.show()  \n",
    "\n",
    "    # Now we'll plot the repeating grid...\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    grid[center_index][center_index] = 'C'\n",
    "    numeric_grid = np.array([[char_to_num.get(char, 0) for char in row] for row in grid])\n",
    "    expanded_grid = np.repeat(np.repeat(numeric_grid, scale_factor, axis=0), scale_factor, axis=1)\n",
    "    tiled_grid = np.tile(expanded_grid, (tiles_width, tiles_width))\n",
    "    \n",
    "    expanded_len = grid_side_len * scale_factor\n",
    "    tiles_len = expanded_len*tiles_width\n",
    "    tiles_center = tiles_len // 2\n",
    "    tiled_grid[tiles_center-1:tiles_center + 2, tiles_center-1:tiles_center + 2] = 0\n",
    "    \n",
    "    for i in range(tiles_len):\n",
    "        for j in range(tiles_len):\n",
    "            mdist = abs(i - tiles_center) + abs(j - tiles_center)\n",
    "            if mdist == expanded_len // 2:\n",
    "                tiled_grid[i-1:i+1, j-1:j+1] = 4  # 4 corresponds to green in the colormap    \n",
    "            if mdist > 0 and mdist % expanded_len == expanded_len // 2:\n",
    "                tiled_grid[i-1:i+1, j-1:j+1] = 4  # 4 corresponds to green in the colormap    \n",
    "    \n",
    "    # Insert black borders (zeros) between tiles\n",
    "    border_width = 1 \n",
    "    for i in range(1, 5):\n",
    "        tiled_grid = np.insert(tiled_grid, i * expanded_len + (i - 1) * border_width, 0, axis=0)\n",
    "        tiled_grid = np.insert(tiled_grid, i * expanded_len + (i - 1) * border_width, 0, axis=1)\n",
    "    \n",
    "    cmap = mcolors.ListedColormap(['black', 'red', 'blue', 'yellow', 'green'])\n",
    "    ax.set_title(\"Infinitely Expanding Tiles\")    \n",
    "    plt.subplots_adjust(right=0.8) # Adjust the subplot to make room for the legend\n",
    "    plt.legend(handles=patches, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(tiled_grid, cmap=cmap, interpolation='nearest')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# Modified to clear the row and column where S lives\n",
    "modified_sample = \"\"\"...........\n",
    "......##.#.\n",
    ".###..#..#.\n",
    "..#.#...#..\n",
    "....#.#....\n",
    ".....S.....\n",
    ".##......#.\n",
    ".......##..\n",
    ".##.#.####.\n",
    ".##...#.##.\n",
    "...........\"\"\"\n",
    "\n",
    "plot_tiles(modified_sample.splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've also added green points that illustrate where we land on the last step, if the number of steps available to us is one half of the tile length, or subsequently, any additional tile length away. These are represented as _diamonds_ of reachable distance. \n",
    "\n",
    "- The entire perimeter of the inners diamond is exactly reached after _tile_size // 2_ steps.\n",
    "- Each successive diamond is reached after exactly _tile_size_ more steps.\n",
    "\n",
    "#### Problem Specifics\n",
    "\n",
    "Now let's examine the real data...\n",
    "\n",
    "- It has an initial grid width of 131 and it is a square grid. This is our central tile.\n",
    "- Consequently, the number of steps to get from the centre to the edge is 65.\n",
    "- We're asked to determine all positions reachable with 26501365 steps.\n",
    "  - Note that `26501365 // 131 == 202300`. I.e. this is the number of tile lengths that we can move away from the centre in a straight line, given this number of steps. It can't be coincidence that this puzzle is from AoC 2023!!\n",
    "  - Also, `26501365 % 131 == 65`.  So, we can move exactly 202300 and one half complete tile distances from the centre.\n",
    "- Comparing to the green diamonds above:\n",
    "  - `65` steps would take us to the edge of the first diamond.\n",
    "  - `65 + 131` steps would take us to the edge of the second diamond.\n",
    "  - `65 + (2*131)` steps would take us to the edge of the third diamond.\n",
    "\n",
    "_If we ignored the blocked squares_ (i.e. the rocks), then we could easily calculate the total number of positions reachable for a given number of steps: it would be the area of our diamond (which is a square) divided by 2, since we know that we can't we can't reach even squares with an odd number of steps available. I.e.\n",
    "\n",
    "$$p = \\frac{(2n + 1)^2}{2}$$\n",
    "\n",
    "Here $p$ is the number of reachable plots, and $n$ is the number of steps. Since $n$ is how many steps we can take in any direction, the total width of our square is the sum $n$ in opposite directions (e.g. right + left), plus the square we start in. Hence $(2n + 1)$. Once we have the length of a side, we simply square this number to get the area of our square.\n",
    "\n",
    "#### Quadratic Relationshiop\n",
    "\n",
    "Crucially, it's important to note that **the relationship between the number of locations ($p$) and the number of steps ($n$) is quadratic.** (Which intuitively makes sense, since the area is given by a square.)\n",
    "\n",
    "Alas, we can't just use the formula above, because we can't ignore the configuration of our tiles. I.e. we can't ignore all the rocks!! Eliminating certain locations (i.e. the rocks)  cannot introduce higher-order terms to our equsetion, so the most general form will be a standard quadratic, i.e.\n",
    "\n",
    "$$p = an^2 + bn + c$$\n",
    "\n",
    "Here, $p$ will the total number of reachable positions, $n$ is our available steps, and $a$, $b$ and $c$ are the coefficients.\n",
    "\n",
    "We know we need a quadratic equation, but we don't yet know what the coefficients are. _What to do?_\n",
    "\n",
    "We also know that we can't simply BFS for 26501365 steps, because that will never complete and our computer will blow up.\n",
    "\n",
    "But, there is a cool way to determine the coefficients of a quadratic formula, if you have three points from a quadratic plot to work with. And we can get three such points!! The technique is called the _Three Point Formula_ and it is described at these links:\n",
    "\n",
    "- [Determining Quadratic Functions](https://sites.math.washington.edu/~conroy/m120-general/quadraticFunctionAlgebra.pdf)\n",
    "- [Equation of Parabola Given 3 Points](https://www.youtube.com/watch?v=ohc1futhFYM)\n",
    "- [3 Point Equation Worked Example](https://www.mathway.com/popular-problems/Finite%20Math/618194)\n",
    "- [3 Point Equation Calculator](https://www.mathcelebrity.com/3ptquad.php)\n",
    "\n",
    "Three valid points will be the number of steps that represent our first, second and third diamonds. So, for our actual input data, this means:\n",
    "\n",
    "- $n$ = `65` steps\n",
    "- $n$ = `65 + 131 = 196` steps\n",
    "- $n$ = `65 + (2*131) = 327` steps\n",
    "\n",
    "#### BFS to Get Quadratic Coefficients Using Three Point Formula\n",
    "\n",
    "We can do a BFS with this number of steps.  But first, we need to modify our BFS to allow us to expand beyond a single tile.  I.e. such that we can cross from one tile to an adjacent tile. The BFS can be modified to allow this as follows:\n",
    "\n",
    "- Instead of storing start position and steps available in our FIFO queue, now we store: tile coordinate, position in tile, and steps remaining.  The first tile would have a tile coordinate of `(0,0)`. So the tile to the right would be `(1,0)`, the tile below would be `(0,1)`, and so on.\n",
    "- When we retrieve the neighbours of the current point, if the neighbour's coordinates fall outside of the grid boundary, then we update the tile coordinate, _and_ then offset the current coordinate _within_ the tile. For example, if we move off the current tile to the tile on the left, then the `x` coordinate _within_ the tile will now be `-1` and outside of the grid boundaryies. So we add the tile width to this `x` coordinate such that the x coordinate is `width-1`, which is a valid coordinate within the grid boundaries.\n",
    "\n",
    "That's pretty much all we need to do to the BFS. My new function is called `multi_tile_bfs()` (This modified BFS will still work for Part 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_tile_bfs(grid, start: tuple[int,int], steps_available: int) -> int:\n",
    "    \"\"\" Modified BFS that now also includes a tile coordinate as part of state. \n",
    "    Args:\n",
    "        grid (_type_): 2D grid of chars\n",
    "        start (tuple[int,int]): start location in the grid\n",
    "        steps_available (int): steps available\n",
    "        \n",
    "    Returns int: count of valid locations to land on, when we've run out of steps\n",
    "    \"\"\"\n",
    "    steps_remaining = steps_available\n",
    "    current_tile = (0,0)\n",
    "    # (tile coordinate, location in tile, steps remaining)\n",
    "    queue: deque[tuple[tuple[int,int],tuple[int,int],int]] =  deque([(current_tile, start, steps_remaining)])\n",
    "    \n",
    "    seen = set() # combination of (tile, location)\n",
    "    answer: set[tuple[tuple, tuple]] = set() # the number of locations we can get to in the required number of steps\n",
    "    \n",
    "    side_len = len(grid)\n",
    "    tiles_for_steps = (steps_available // side_len) + 1\n",
    "    logger.debug(f\"{tiles_for_steps=}\")\n",
    "    \n",
    "    while queue:\n",
    "        # When we pop, we have already updated tile and location in the tile to be valid        \n",
    "        current_tile, current_locn, steps_remaining = queue.popleft()\n",
    "        \n",
    "        if steps_remaining >= 0:\n",
    "            if steps_remaining % 2 == 0: # we can always get back to this location in an even number of steps\n",
    "                answer.add((current_tile, current_locn)) # so this location will be possible in our target number of steps\n",
    "            \n",
    "            if steps_remaining > 0: # get next possible location\n",
    "                steps_remaining -= 1\n",
    "                neighbours = [(current_locn[0]+dx,current_locn[1]+dy) for dx,dy in (VectorDicts.DIRS.values())]\n",
    "                for neighbour in neighbours: # update current tile, and offset location in tile by tile width/height, as required\n",
    "                    new_tile = current_tile\n",
    "                    if neighbour[0] < 0: # move to tile on the left\n",
    "                        new_tile = (current_tile[0]-1, current_tile[1])\n",
    "                        neighbour = (neighbour[0]+side_len, neighbour[1])\n",
    "                    if neighbour[0] >= side_len: # move to tile on the right\n",
    "                        new_tile = (current_tile[0]+1, current_tile[1])\n",
    "                        neighbour = (neighbour[0]-side_len, neighbour[1])\n",
    "                    if neighbour[1] < 0: # move to tile above\n",
    "                        new_tile = (current_tile[0], current_tile[1]-1)\n",
    "                        neighbour = (neighbour[0], neighbour[1]+side_len)\n",
    "                    if neighbour[1] >= side_len: # move to tile below\n",
    "                        new_tile = (current_tile[0], current_tile[1]+1)\n",
    "                        neighbour = (neighbour[0], neighbour[1]-side_len)\n",
    "\n",
    "                    if (new_tile, neighbour) in seen or grid[neighbour[1]][neighbour[0]] == \"#\" :\n",
    "                        continue # do nothing\n",
    "                    \n",
    "                    # With max distance of 327, this is 2.5 tiles. So 3 either side should be neough.\n",
    "                    # -3, -2, -1, 0, 1, 2, 3 = 7x7\n",
    "                    if (abs(current_tile[0]) > tiles_for_steps or abs(current_tile[1]) > tiles_for_steps):\n",
    "                        logger.debug(f\"{new_tile=}\")\n",
    "                        assert False, \"Not enough steps to move further out\"\n",
    "                                                        \n",
    "                    queue.append((new_tile, neighbour, steps_remaining))\n",
    "                    seen.add((new_tile, neighbour))\n",
    "                            \n",
    "    return len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reachable_plots(data, steps_available:int):\n",
    "    grid = [[char for char in row] for row in data]\n",
    "    grid_size = len(grid)    \n",
    "    \n",
    "    logger.debug(f\"Grid width={grid_size}\") \n",
    "    assert grid_size == len(grid[0]), \"The grid should be square\"\n",
    "    assert grid_size % 2 == 1, \"The grid size is odd\"\n",
    "\n",
    "    (start, ) = [(ri, ci) for ri, row in enumerate(grid)\n",
    "                          for ci, char in enumerate(row) if char == \"S\"]\n",
    "\n",
    "    assert start[0] == start[1] == grid_size // 2, \"Start is in the middle\"\n",
    "               \n",
    "    # For each location in the original grid (tile 0,0), \n",
    "    # can we reach this same location in other tiles? \n",
    "    answer = multi_tile_bfs(grid, start, steps_available)\n",
    "    logger.debug(f\"We have {answer} final plots for {steps_available} steps.\")\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll test my `multi_grid_BFS()` using the sample input and the sample answers provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "sample_input = \"\"\"\\\n",
    "...........\n",
    ".....###.#.\n",
    ".###.##..#.\n",
    "..#.#...#..\n",
    "....#.#....\n",
    ".##..S####.\n",
    ".##..#...#.\n",
    ".......##..\n",
    ".##.#.####.\n",
    ".##..##.##.\n",
    "...........\"\"\"\n",
    "\n",
    "step_counts = [6, 10, 20, 50, 100, 500]\n",
    "sample_answers = [16, 50, 216, 1594, 6536, 167004]\n",
    "\n",
    "for sample_step_count, sample_answer in zip(step_counts, sample_answers):\n",
    "    validate(reachable_plots(sample_input.splitlines(), sample_step_count), sample_answer)\n",
    "\n",
    "step_counts = [64, 65, 196, 327] # 64 is just to check it matches what we had before\n",
    "\n",
    "validate(reachable_plots(input_data, step_counts[0]), soln_64)\n",
    "\n",
    "plots = [(step_count, reachable_plots(input_data, step_count)) for step_count in step_counts[1:]]\n",
    "logger.info(f\"{plots=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If those all give the right numbers (and they do) then we're ready to BFS our real data. As determined before, we need to BFS for step values of `65`, `196`, and `327`. But first, I also test that my new BFS gives the same answer with `64` steps as we achieved for Part 1. This helps me get confidence that I haven't broken my BFS for the large grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_counts = [64, 65, 196, 327] # 64 is just to check it matches what we had before\n",
    "\n",
    "validate(reachable_plots(input_data, step_counts[0]), soln_64)\n",
    "\n",
    "plot_counts = [(step_count, reachable_plots(input_data, step_count)) for step_count in step_counts[1:]]\n",
    "logger.info(f\"{plots=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call my three numbers $P(0)$, $P(1)$ and $P(2)$. Each can be represented as a quadratic:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x) &= ax^2 + bx + c \\nonumber \\\\\n",
    "\\nonumber \\\\\n",
    "\\text{Therefore:} \\nonumber \\\\\n",
    "P(0) &= a.(65)^2 + b.(65) + c \\nonumber \\\\\n",
    "P(1) &= a.(196)^2 + b.(196) + c \\nonumber \\\\\n",
    "P(2) &= a.(327)^2 + b.(327) + c \\nonumber \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We can rearrange these formulae to come up with a standard set of equations to determine the coefficients $a$, $b$ and $c$. (We have three unknowns, so we need three equations to combine.)\n",
    "\n",
    "To find $c$, we can subtitute 0 for $x$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(0) &= a.(0)^2 + b.(0) + c \\\\\n",
    "c &= P(0)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We can then substitute and combine the equations to solve for $b$ and $c$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "b &= \\frac{(4.P(1) - 3.P(0) - P(2))}{2} \\\\\n",
    "a &= (P(1) - P(0) - b) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So this will give us the actual coefficients. Note that these coefficients are only valid for our _real data_ grid, since these coefficients are calculated based on our specific grid sizes and resulting _diamond_ sizes.\n",
    "\n",
    "But what value to use for $x$? Here, we want the number of whole tile lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_quadratic(data, plot_counts: list[int], steps:int):\n",
    "    \"\"\" Return the total number of reachable plots in a specified number of steps, \n",
    "    by calculating the answer to the quadratic formula. \n",
    "    Here we calculate the coefficients a, b and c by using three sample values,\n",
    "    obtained from a smaller grid.\n",
    "\n",
    "    Args:\n",
    "        data (_type_): The original grid tile.\n",
    "        plot_counts (list[int]): The plot counts determined for small step counts.\n",
    "        steps (int): The number of steps we must take.\n",
    "    \"\"\"\n",
    "    grid = [[char for char in row] for row in data]\n",
    "    grid_size = len(grid)\n",
    "\n",
    "    # determine coefficients\n",
    "    c = plot_counts[0]\n",
    "    b = (4*plot_counts[1] - 3*plot_counts[0] - plot_counts[2]) // 2\n",
    "    a = plot_counts[1] - plot_counts[0] - b\n",
    "    \n",
    "    x = (steps - grid_size//2) // grid_size # number of whole tile lengths\n",
    "    return a*x**2 + b*x + c\n",
    "\n",
    "ans = solve_quadratic(input_data, plot_counts=[ct[1] for ct in plot_counts], steps=26501365)\n",
    "logger.info(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful resources:\n",
    "\n",
    "- [Reddit 2023 Day 21 Megathread](https://www.reddit.com/r/adventofcode/comments/18nevo3/2023_day_21_solutions/)\n",
    "- [Geometric solution - Useful sketches](https://github.com/villuna/aoc23/wiki/A-Geometric-solution-to-advent-of-code-2023,-day-21)\n",
    "- [Ian's YouTube Walkthrough with useful commentary on the quadratic](https://www.youtube.com/watch?v=99Mjs1i0JxU&lc=UgxwS0greNfsrFXYPA14AaABAg.9ydjxdKIlaC9ydpDNgSwyb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 22: Sand Slabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"22\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 22 Part 1\n",
    "\n",
    "We need to disintegrate bricks of sand into free flowing sand. The bricks are falling into a stack.\n",
    "\n",
    "We have a snaptshot of the bricks whilst they were falling. The example looks like this:\n",
    "\n",
    "```text\n",
    "1,0,1~1,2,1\n",
    "0,0,2~2,0,2\n",
    "0,2,3~2,2,3\n",
    "0,0,4~0,2,4\n",
    "2,0,5~2,2,5\n",
    "0,1,6~2,1,6\n",
    "1,1,8~1,1,9\n",
    "```\n",
    "\n",
    "- Each row represents two 3D coordinates, `x,y,z`. Each coordinate is a cube. Thus, each brick can be represented as a number of cubes.\n",
    "  - The z-axis extends up into their air, whereas the x and y axes represent a plane at any given value of z.\n",
    "  - 2,2,2~2,2,2: This is a single cube brick.\n",
    "  - 0,0,10~1,0,10: This is a two cube brick, oriented horizontally. I.e. the x axis has coordinates 0 and 1.\n",
    "  - 0,0,1~0,0,10: This is a 10-cube brick, oriented vertically. I.e. the y axis is from 1 to 10 inclusive.\n",
    "- The ground is at `z=0`.\n",
    "- The lowest possible z coordinate of a brick is 1.\n",
    "- The input shows the order the bricks fell. I.e. FIFO with the first at the top. \n",
    "- Some bricks are still falling through the air!! For example, there is a one unit z gap between the last two bricks.\n",
    "- Bricks always fall with constant orientation. I.e. only their z value will change as they fall.\n",
    "\n",
    "_Oh god.  It's Jenga!_\n",
    "\n",
    "**Figure how the blocks will settle based on the snapshot. Once they've settled, consider disintegrating a single brick; how many bricks could be safely chosen as the one to get disintegrated?**\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "We need to:\n",
    "\n",
    "- Determine the configuration of the bricks once they've settled.\n",
    "- Determine which bricks then support other bricks.\n",
    "- We can disintegrate any bricks that are not the sole support of another brick.\n",
    "\n",
    "Approach:\n",
    "\n",
    "- I create `Brick` class, to store the state of each brick. As a minimum, our brick needs `(x,y,z)` tuples that represent the two opposite coordinates.\n",
    "- I parse the input data, and convert each row into a `Brick`. This is easy enough, since we just split at the `~` to get the two sets of coordinates that we will use for our pair of tuples.\n",
    "- Next, I add `min_for_axis()` and `max_for_axis()` methods to my `Brick` class. These methods determine the minimum and maximum values for the axis specified, where `0 = x`, `1 = y`, `2 = z`.\n",
    "- We can go through each `Brick` and determine the minima and maxima for `x` and `y`, which gives us the overall `x,y` area that all our bricks fall within.  Think of this as representing the overall horizontal and vertical widths of our Jenga tower.\n",
    "- Next, I want to create a 2D grid for this area, that stores the maximum height (`z` value) that has been achieved in our stack so far. I do this by creating a [NumPy](https://aoc.just2good.co.uk/python/numpy) grid called `height_map` with the required dimensions, and initialising all values to `0` initially.  I.e. the flat surface that we start with.\n",
    "- Now the fun part... It's time to drop the bricks!! A brick falls down through the air, but the coordinates it occupies in the `x,y` plane remains constant. Think of it as a falling down a rectangular groove.\n",
    "  - First... It's crucial to _sort_ them in ascending `z` order! This is because we want to be able to drop a brick and check for bricks below it. And we want to assume that the bricks are settling in `z` order, i.e. that no bricks that come _later_ in the input can contain bricks that are of lower height than our current brick. In the sample data, they are already sorted this way. But in the real data, this isn't the case.  (This delayed me getting the right answer for a while!!)\n",
    "  - So I've added a `__lt__()` method to my `Brick` class, which allows me to sort on the `z` value.  In Python, implementing `__lt__()` in your class is typically sufficient to allow sorting of classes using standard sort functions.\n",
    "  - Next, I want to determine the _xy area_ occupied by my current brick. So I've implemented an `xy_area()` method. This simply returns the two opposite coordinates of the xy rectangle.\n",
    "  - Then, I determine what is the current highest point (`z` value) of my `height_map`, for the section of section of the grid that corresponds to my brick's `xy_area`. This is because the section might contain any number of existing bricks. And one might be taller than others.  But we only care about the tallest point in the section.  Our new brick will end up sitting _on top_ of the tallest point.\n",
    "  - I then update my brick's lowest `z` value to be equal to this previous highest point, plus `1`.\n",
    "  - Next, I need to update the `height_map` such that the entire `xy_area` section has a height value that is equal to the prevous maximum height, plus the height of our `Brick`. So now, our `height_map` is up to date and includes the new `Brick`.\n",
    "\n",
    "That's it for settling the brick into place.\n",
    "\n",
    "All that remains is to determine which existing bricks (which I call _base bricks_) our new brick sits on.  I do this by:\n",
    "\n",
    "- Adding our newly laid `Brick` into a dictionary that contains a set of all bricks at a given `z` level.\n",
    "- Then, for our newly laid `Brick`, I determine if my brick's `xy_area` intersects with any of the bricks in the set for the `z` level we've just landed on top of.  To perform the intersection check, I've added a method to my `Brick` called `area_intersects()`.  It works by:\n",
    "  - Checking if the right edge of either brick is to the left of the left edge of the other brick. If so, these don't intersect.\n",
    "  - And then doing the same check with the y axis.\n",
    "- If there is an intersection, then this new brick is sitting on top of one or more base bricks. I add these base bricks to a `brick_to_base_bricks` dictionary, which maps this current `Brick` to a set of `Base` bricks.\n",
    "\n",
    "- So we can build a `Brick` class that knows how to determine its own `x,y` space, and can also check for the intersection with another brick's `x,y` space. If the two bricks intersect for any given value of `z` then the falling brick can not descend to this `z` level, since it would hit another brick.\n",
    "\n",
    "Lastly, to solve for Part 1, we just want to get all the _base_ bricks, where they are the one and only member of a `brick_to_base_bricks` set. Where this is true, this base brick is alone, and there are no other bricks supporting this particular brick. I've labelled these as `critical_base_bricks`. We just subtract this number from the total number of bricks, in order to get the bricks that can safely be disintegrated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True) # so it's immutable and we can store it in a set\n",
    "class Brick():\n",
    "    \"\"\" A brick is a cuboid. It is represented by two opposite corners, which are each tuples of (x,y,z). \"\"\"\n",
    "    \n",
    "    corner_1: tuple[int,int,int]\n",
    "    corner_2: tuple[int,int,int]\n",
    "    \n",
    "    def __lt__(self, other: Brick):\n",
    "        return self.min_for_axis(2) < other.min_for_axis(2)\n",
    "    \n",
    "    def max_for_axis(self, axis: int):\n",
    "        \"\"\" The maximum value for this axis. \"\"\"\n",
    "        return self._axis_limit(max, axis)\n",
    "    \n",
    "    def min_for_axis(self, axis: int):\n",
    "        \"\"\" The minimum value for this axis. \"\"\"\n",
    "        return self._axis_limit(min, axis)\n",
    "    \n",
    "    def _axis_limit(self, op: Callable, axis: int):\n",
    "        assert 0 <= axis < 3, \"Valid axes are 0, 1, 2 for x, y, z, respectively\"\n",
    "        return op(self.corner_1[axis], self.corner_2[axis])\n",
    "    \n",
    "    def update_z(self, new_bottom_z: int) -> Brick:\n",
    "        \"\"\" Update the z values of this brick, by setting a new min z value. \"\"\"\n",
    "        z_delta = self.min_for_axis(2) - new_bottom_z\n",
    "        return Brick((self.corner_1[0], self.corner_1[1], self.corner_1[2] - z_delta), \n",
    "                     (self.corner_2[0], self.corner_2[1], self.corner_2[2] - z_delta))\n",
    "    \n",
    "    def height(self) -> int:\n",
    "        \"\"\" The height of this brick, i.e. inclusive z length \"\"\"\n",
    "        return (self.max_for_axis(2)-self.min_for_axis(2) + 1)\n",
    "    \n",
    "    def xy_area(self):\n",
    "        \"\"\" Return the x,y area occupied by this brick, as a tuple of ((corner),(corner)) \"\"\"\n",
    "        return ((self.min_for_axis(0), (self.min_for_axis(1))), \n",
    "                (self.max_for_axis(0), (self.max_for_axis(1))))\n",
    "        \n",
    "    def area_intersects(self, other: Brick) -> bool:\n",
    "        \"\"\" Determine if the xy_area of this brick intersects with the xy_area of another brick. \"\"\"\n",
    "        self_x1, self_y1 = self.xy_area()[0]\n",
    "        self_x2, self_y2 = self.xy_area()[1]\n",
    "        other_x1, other_y1 = other.xy_area()[0]\n",
    "        other_x2, other_y2 = other.xy_area()[1]\n",
    "        \n",
    "        # Check if one brick is to the left of the other\n",
    "        if self_x2 < other_x1 or other_x2 < self_x1:\n",
    "            return False\n",
    "\n",
    "        # Check if one brick is above the other\n",
    "        if self_y2 < other_y1 or other_y2 < self_y1:\n",
    "            return False\n",
    "\n",
    "        return True        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bricks(data: list[str]) -> list[Brick]:    \n",
    "    bricks = []\n",
    "    for line in data:\n",
    "        corner_1, corner_2 = line.split(\"~\")\n",
    "        (x1, y1, z1) = [int(val) for val in corner_1.split(\",\")]\n",
    "        (x2, y2, z2) = [int(val) for val in corner_2.split(\",\")]\n",
    "        bricks.append(Brick((x1, y1, z1), (x2, y2, z2)))\n",
    "        \n",
    "    return bricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    bricks = parse_bricks(data) # in drop order\n",
    "    bricks.sort() # naughty real input... Not in ascending z order!!\n",
    "    bricks_at_level: dict[int,set[Brick]] = defaultdict(set) # { 5: { brick_4, brick5 }}\n",
    "    upper_to_base_bricks: dict[Brick,set[Brick]] = defaultdict(set) # store the bricks supported directly by this break { brick_1: { brick_2, brick3, ... }, ... }\n",
    "    \n",
    "    min_x = max_x = 0\n",
    "    min_y = max_y = 0\n",
    "    \n",
    "    # let's get the overall xy area occupied by our stack\n",
    "    for brick in bricks:\n",
    "        min_x = min(brick.min_for_axis(0), min_x)\n",
    "        max_x = max(brick.max_for_axis(0), max_x)\n",
    "        min_y = min(brick.min_for_axis(1), min_y)\n",
    "        max_y = max(brick.max_for_axis(1), max_y)\n",
    "    \n",
    "    assert min_x == min_y == 0, \"Our area has min x,y at 0,0\"\n",
    "    logger.debug(f\"Min (x,y) = ({min_x}, {min_y})\")\n",
    "    logger.debug(f\"Max (x,y) = ({max_x}, {max_y})\")\n",
    "    \n",
    "    # Initialise to a flat surface\n",
    "    height_map = np.zeros((max_y-min_y+1, max_x-min_x+1), dtype=np.int32)\n",
    "    \n",
    "    # Settle the bricks\n",
    "    for brick in bricks:\n",
    "        (x1, y1), (x2, y2) = brick.xy_area() # the x,y area this brick occupies\n",
    "        old_max_height = int(np.max(height_map[y1:y2+1, x1:x2+1])) # Retrieve the max height in that section\n",
    "        brick.update_z(old_max_height+1) # place the brick here, i.e. immediatey above the max height\n",
    "        new_max_height = old_max_height + brick.height()\n",
    "        height_map[y1:y2+1, x1:x2+1] = new_max_height # update the height of this section\n",
    "        bricks_at_level[new_max_height].add(brick) # include this brick in bricks that make up the new max level\n",
    "        \n",
    "        # what bricks does this brick sit on?\n",
    "        # Get all the bricks that were at the previous height, and work out which ones intersect\n",
    "        upper_to_base_bricks[brick].update([base_brick for base_brick in bricks_at_level[old_max_height] \n",
    "                                                       if base_brick.area_intersects(brick)])\n",
    "    \n",
    "    critical_bricks = set() # base bricks that solely support an upper brick, i.e. where an upper brick has ONLY ONE base brick\n",
    "    base_to_upper_bricks = { brick: set() for brick in bricks }\n",
    "    \n",
    "    for brick in bricks:\n",
    "        if len(upper_to_base_bricks[brick]) == 1: # is this upper brick depending on ONLY 1 base brick?\n",
    "            (base_brick, ) = upper_to_base_bricks[brick]\n",
    "            critical_bricks.add(base_brick)\n",
    "        \n",
    "        # Otherwise, this upper brick has multiple base bricks\n",
    "        for base_brick in upper_to_base_bricks[brick]:\n",
    "            base_to_upper_bricks[base_brick].add(brick)\n",
    "\n",
    "    assert len(upper_to_base_bricks) == len(base_to_upper_bricks) == len(bricks) # every brick is mapped to base and uppers    \n",
    "    # for brick in bricks:\n",
    "    #     logger.debug(f\"{brick}\")\n",
    "    #     logger.debug(f\"Base to upper: {base_to_upper_bricks[brick]}\")\n",
    "    #     logger.debug(f\"Upper to base: {upper_to_base_bricks[brick]}\")\n",
    "    \n",
    "    safe_bricks = len(bricks) - len(critical_bricks)\n",
    "    logger.debug(f\"{safe_bricks=}\")\n",
    "    \n",
    "    return safe_bricks, upper_to_base_bricks, base_to_upper_bricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "1,0,1~1,2,1\n",
    "0,0,2~2,0,2\n",
    "0,2,3~2,2,3\n",
    "0,0,4~0,2,4\n",
    "2,0,5~2,2,5\n",
    "0,1,6~2,1,6\n",
    "1,1,8~1,1,9\"\"\")\n",
    "sample_answers = [5]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines())[0], curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "safe_brick_count, upper_to_base_bricks, base_to_upper_bricks = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={safe_brick_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 22 Part 2\n",
    "\n",
    "We need to determine how many other bricks would fall, if a given brick is disintegrated.\n",
    "\n",
    "**For each brick, determine how many other bricks would fall if that brick were disintegrated. What is the sum of the number of other bricks that would fall?**\n",
    "\n",
    "Well, this was _inevitable!!_\n",
    "\n",
    "**My solution:**\n",
    "\n",
    "- From top to bottom, we can work out how many bricks would fall, if a given brick is removed.\n",
    "- I guess we need a recursion!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data, upper_to_base_bricks: dict[Brick, set], base_to_upper_bricks: dict[Brick, set]):\n",
    "    bricks = parse_bricks(data) # in drop order\n",
    "    bricks.sort() # naughty real input... Not in ascending z order!!\n",
    "    \n",
    "    total = 0\n",
    "    for brick in upper_to_base_bricks:\n",
    "        queue = deque(upper for upper in base_to_upper_bricks[brick] if len(upper_to_base_bricks[upper]) == 1)\n",
    "        falling = set(queue) # also seen\n",
    "        falling.add(brick)\n",
    "        \n",
    "        while queue:\n",
    "            brick = queue.popleft()\n",
    "            for base in base_to_upper_bricks[brick]- falling:\n",
    "                if upper_to_base_bricks[base] <= falling:\n",
    "                    queue.append(base)\n",
    "                    falling.add(base)\n",
    "                    \n",
    "        total += len(falling) - 1\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_answers = [7]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    curr_safe, curr_upper_to_base_bricks, curr_base_to_upper_bricks = solve_part1(curr_input.splitlines())\n",
    "    validate(solve_part2(curr_input.splitlines(), curr_upper_to_base_bricks, curr_base_to_upper_bricks), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data, upper_to_base_bricks, base_to_upper_bricks)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 23: A Long Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"23\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 23 Part 1\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [\"abcdef\"]\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 23 Part 2\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [\"abcdef\"]\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day n: title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"n\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day n Part 1\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [\"abcdef\"]\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day n Part 2\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = [\"abcdef\"]\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ana-aoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
