{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "This notebook contains my solutions for **<a href=\"https://adventofcode.com/2024\" target=\"_blank\">Advent of Code 2024</a>**.\n",
    "\n",
    "A few notes...\n",
    "- The source for this notebook source lives in my GitHub repo, <a href=\"https://github.com/derailed-dash/Advent-of-Code/blob/master/src/AoC_2024/Dazbo's_Advent_of_Code_2024.ipynb\" target=\"_blank\">here</a>.\n",
    "- You can run this Notebook wherever you like. For example, you could...\n",
    "  - Run it locally, in your own Jupyter environment.\n",
    "  - Run it in a cloud-based Jupyter environment, with no setup required on your part!  For example, with **Google Colab**: <br><br><a href=\"https://colab.research.google.com/github/derailed-dash/Advent-of-Code/blob/master/src/AoC_2024/Dazbo's_Advent_of_Code_2024.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Google Colab\"/></a><br>\n",
    "  - For more ways to run Jupyter Notebooks, check out [my guide](https://medium.com/python-in-plain-english/five-ways-to-run-jupyter-labs-and-notebooks-23209f71e5c0).\n",
    "- **To run the notebook, execute the cells in the [Setup](#Setup) section, as described below. Then you can run the code for any given day.**\n",
    "- Be mindful that the first time you run this notebook, you will need to **obtain your AoC session key** and store it, if you have not done so already. This allows the notebook to automatically retrieve your input data. (See the guidance in the **[Get Access to Your AoC Data](#Get-Access-to-Your-AoC-Data)** section for details.)\n",
    "- Use the navigation menu on the left to jump to any particular day.\n",
    "- All of my AoC solutions are documented in my <a href=\"https://aoc.just2good.co.uk/\" target=\"_blank\">AoC Python Walkthrough site</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3PMQJRrR38P",
    "tags": []
   },
   "source": [
    "# Setup\n",
    "\n",
    "You need to run all cells in this section, before running any particular day solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWxsAMaXTGEQ"
   },
   "source": [
    "## Packages and Imports\n",
    "\n",
    "Here we use `pip` to install the packages used by my solutions in this event. After installing the packages, you may need to restart your Jupyter kernel in order for the packages to be detected and remove any linting errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Dgeww1rMrkQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --no-cache-dir \\\n",
    "    jupyterlab-lsp ipykernel ipywidgets \\\n",
    "    matplotlib pandas networkx  sympy \\\n",
    "    dazbo-commons \\\n",
    "    colorama python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5Ki_HvOJUWk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import ast\n",
    "import copy\n",
    "import heapq\n",
    "import logging\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "import platform\n",
    "import re\n",
    "from collections import Counter, deque, defaultdict, namedtuple\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from enum import Enum, auto\n",
    "from functools import cache, reduce\n",
    "from itertools import combinations, count, cycle, permutations, product\n",
    "from getpass import getpass\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import dazbo_commons as dc  # my own utility library, which includes things like coloured logging\n",
    "import requests\n",
    "import sympy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from colorama import Fore, Back, Style\n",
    "from dotenv import load_dotenv\n",
    "from IPython.core.display import Markdown\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZNTgtGzUImv",
    "tags": []
   },
   "source": [
    "## Logging and Output\n",
    "\n",
    "Set up a new logger that uses `ColouredFormatter`, such that we have coloured logging.  The log colour depends on the logging level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwzjfUFCKhXe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup logger\n",
    "YEAR = 2024\n",
    "APP_NAME = \"aoc\" + str(YEAR)\n",
    "logger = dc.retrieve_console_logger(APP_NAME)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.info(\"Logger initialised.\")\n",
    "logger.debug(\"Debugging enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages\n",
    "\n",
    "- [ffmpeg](https://ffmpeg.org/): in order to render video output, i.e. for visualisations.\n",
    "- graphviz: for visualising graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_command(command):\n",
    "    \"\"\"Run a shell command and print its output in real-time.\"\"\"\n",
    "    process = subprocess.Popen(\n",
    "        command, \n",
    "        shell=True, \n",
    "        stdout=subprocess.PIPE, \n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "    \n",
    "    # Read and print the output line by line\n",
    "    if process.stdout is not None:\n",
    "        for line in iter(process.stdout.readline, b''):\n",
    "            logger.info(line.decode().strip())\n",
    "        process.stdout.close()\n",
    "        \n",
    "    process.wait()\n",
    "    \n",
    "def install_software(appname: str):\n",
    "    os_name = platform.system()\n",
    "    logger.info(f\"Installing {appname} on {os_name}...\")\n",
    "    \n",
    "    # Mapping operating systems to their respective installation commands\n",
    "    command_map = {\n",
    "        \"Windows\": f\"winget install {appname} --silent --no-upgrade\",\n",
    "        \"Linux\": f\"apt -qq -y install {appname}\",\n",
    "        \"Darwin\": f\"brew install {appname}\"\n",
    "    }\n",
    "    command = command_map.get(os_name)\n",
    "    if command:\n",
    "        run_command(command)\n",
    "    else:\n",
    "        logger.error(f\"Unsupported operating system: {os_name}\")\n",
    "\n",
    "def check_installed(app_exec: str) -> bool:    \n",
    "    appname, *arg = app_exec.split()\n",
    "    arg = \" \".join(arg)\n",
    "    logger.debug(f\"Checking if {appname} is installed\")\n",
    "    \n",
    "    try:\n",
    "        output = subprocess.check_output([appname, arg], stderr=subprocess.STDOUT)\n",
    "        logger.debug(f\"{appname} version: {output.decode().strip()}\")\n",
    "        logger.debug(f\"{appname} is already installed.\")\n",
    "        return True\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "        logger.debug(f\"{appname} is not installed or absent from path.\")\n",
    "        \n",
    "    return False\n",
    "\n",
    "apps = [ (\"ffmpeg\", \"ffmpeg -version\"),\n",
    "         (\"graphviz\", \"dot --version\") ]\n",
    "          \n",
    "for app_install, app_exec in apps:\n",
    "    if not check_installed(app_exec):\n",
    "        install_software(app_install)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9A24B4MSyhT"
   },
   "source": [
    "## Load Helpers and Useful Classes\n",
    "\n",
    "Now we load a bunch of helper functions and classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPOsmENmYf8h",
    "tags": []
   },
   "source": [
    "### Locations\n",
    "\n",
    "Where any input and output files get stored.\n",
    "\n",
    "<img src=\"https://aoc.just2good.co.uk/assets/images/notebook-content-screenshot.png\" width=\"320\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14ISscMTadAO"
   },
   "source": [
    "### Retrieve the Input Data\n",
    "\n",
    "This works by using your unique session cookie to retrieve your input data. E.g. from a URL like:\n",
    "\n",
    "`https://adventofcode.com/2024/day/1/input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwP0r3BAaxjt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Retrieving input data\n",
    "##################################################################\n",
    "\n",
    "def write_puzzle_input_file(year: int, day, locations: dc.Locations):\n",
    "    \"\"\" Use session key to obtain user's unique data for this year and day.\n",
    "    Only retrieve if the input file does not already exist.\n",
    "    Return True if successful.\n",
    "    Requires env: AOC_SESSION_COOKIE, which can be set from the .env.\n",
    "    \"\"\"\n",
    "    if os.path.exists(locations.input_file):\n",
    "        logger.debug(\"%s already exists\", os.path.basename(locations.input_file))\n",
    "        return os.path.basename(locations.input_file)\n",
    "\n",
    "    session_cookie = os.getenv('AOC_SESSION_COOKIE')\n",
    "    if not session_cookie:\n",
    "        raise ValueError(\"Could not retrieve session cookie.\")\n",
    "\n",
    "    logger.info('Session cookie retrieved: %s...%s', session_cookie[0:6], session_cookie[-6:])\n",
    "\n",
    "    # Create input folder, if it doesn't exist\n",
    "    if not locations.input_dir.exists():\n",
    "        locations.input_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    url = f\"https://adventofcode.com/{year}/day/{day}/input\"\n",
    "    \n",
    "    # Don't think we need to set a user-agent\n",
    "    # headers = {\n",
    "    #     \"User-Agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'\n",
    "    # }\n",
    "    cookies = { \n",
    "        \"session\": session_cookie\n",
    "    }\n",
    "    response = requests.get(url, cookies=cookies, timeout=5)\n",
    "\n",
    "    data = \"\"\n",
    "    if response.status_code == 200:\n",
    "        data = response.text\n",
    "\n",
    "        with open(locations.input_file, 'w') as file:\n",
    "            logger.debug(\"Writing input file %s\", os.path.basename(locations.input_file))\n",
    "            file.write(data)\n",
    "            return data\n",
    "    else:\n",
    "        raise ValueError(f\"Unable to retrieve input data.\\n\" +\n",
    "                         f\"HTTP response: {response.status_code}\\n\" +\n",
    "                         f\"{response.reason}: {response.content.decode('utf-8').strip()}\")\n",
    "        \n",
    "def show_day_link(day):\n",
    "    day_link = f\"#### See [Day {day}](https://adventofcode.com/{YEAR}/day/{day}).\"\n",
    "    display(Markdown(day_link))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yakibhW73Rqi"
   },
   "source": [
    "### Testing\n",
    "\n",
    "A really simple function for testing that our solution produces the expected test output. If the `validate()` call fails, then execution will stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6nbd6WMryWi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(test, answer):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        test: the answer given by our solution\n",
    "        answer: the expected answer, e.g. from instructions\n",
    "    \"\"\"\n",
    "    if test != answer:\n",
    "        raise AssertionError(f\"{test} != {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bcBQkP0a2zA"
   },
   "source": [
    "### Useful Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8sU4Ez_bBKl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# POINTS, VECTORS AND GRIDS\n",
    "#################################################################\n",
    "\n",
    "Point = namedtuple(\"Point\", [\"x\", \"y\"])\n",
    "\n",
    "Point.__add__ = lambda self, other: Point(self.x + other.x, self.y + other.y)\n",
    "Point.__sub__ = lambda self, other: Point(self.x - other.x, self.y - other.y) \n",
    "\n",
    "def yield_neighbours(self, include_diagonals=True, include_self=False):\n",
    "    \"\"\" Generator to yield neighbouring Points \"\"\"\n",
    "\n",
    "    deltas: list\n",
    "    if not include_diagonals:\n",
    "        deltas = [vector.value for vector in Vectors if abs(vector.value.x) != abs(vector.value.y)]\n",
    "    else:\n",
    "        deltas = [vector.value for vector in Vectors]\n",
    "\n",
    "    if include_self:\n",
    "        deltas.append(Point(0, 0))\n",
    "\n",
    "    for delta in deltas:\n",
    "        yield self + delta\n",
    "\n",
    "def neighbours(self, include_diagonals=True, include_self=False):\n",
    "    return list(yield_neighbours(self, include_diagonals, include_self))\n",
    "\n",
    "def get_specific_neighbours(self, directions):\n",
    "    return [self + vector.value for vector in list(directions)]\n",
    "\n",
    "def manhattan_distance(a_point: Point):\n",
    "    return sum(abs(coord) for coord in asdict(a_point).values())\n",
    "\n",
    "def manhattan_distance_from(self, other):\n",
    "    diff = self - other\n",
    "    return manhattan_distance(diff)\n",
    "\n",
    "Point.yield_neighbours = yield_neighbours\n",
    "Point.neighbours = neighbours\n",
    "Point.get_specific_neighbours = get_specific_neighbours\n",
    "Point.manhattan_distance = staticmethod(manhattan_distance)\n",
    "Point.manhattan_distance_from = manhattan_distance_from\n",
    "Point.__repr__ = lambda self: f\"P({self.x},{self.y})\" \n",
    "\n",
    "class Vectors(Enum):\n",
    "    \"\"\" Enumeration of 8 directions.\n",
    "    Note: y axis increments in the North direction, i.e. N = (0, 1) \"\"\"\n",
    "    N = Point(0, 1)\n",
    "    NE = Point(1, 1)\n",
    "    E = Point(1, 0)\n",
    "    SE = Point(1, -1)\n",
    "    S = Point(0, -1)\n",
    "    SW = Point(-1, -1)\n",
    "    W = Point(-1, 0)\n",
    "    NW = Point(-1, 1)\n",
    "\n",
    "    @property\n",
    "    def y_inverted(self):\n",
    "        \"\"\" Return vector, but with y-axis inverted. I.e. N = (0, -1) \"\"\"\n",
    "        x, y = self.value\n",
    "        return Point(x, -y)\n",
    "\n",
    "class VectorDicts():\n",
    "    \"\"\" Contains constants for Vectors \"\"\"\n",
    "    ARROWS = {\n",
    "        '^': Vectors.N.value,\n",
    "        '>': Vectors.E.value,\n",
    "        'v': Vectors.S.value,\n",
    "        '<': Vectors.W.value\n",
    "    }\n",
    "\n",
    "    DIRS = {\n",
    "        'U': Vectors.N.value,\n",
    "        'R': Vectors.E.value,\n",
    "        'D': Vectors.S.value,\n",
    "        'L': Vectors.W.value\n",
    "    }\n",
    "\n",
    "    NINE_BOX: dict[str, tuple[int, int]] = {\n",
    "        # x, y vector for adjacent locations\n",
    "        'tr': (1, 1),\n",
    "        'mr': (1, 0),\n",
    "        'br': (1, -1),\n",
    "        'bm': (0, -1),\n",
    "        'bl': (-1, -1),\n",
    "        'ml': (-1, 0),\n",
    "        'tl': (-1, 1),\n",
    "        'tm': (0, 1)\n",
    "    }\n",
    "\n",
    "class Grid():\n",
    "    \"\"\" 2D grid of point values. \"\"\"\n",
    "    def __init__(self, grid_array: list) -> None:\n",
    "        self._array = [list(row) for row in grid_array.copy()]\n",
    "        self._width = len(self._array[0])\n",
    "        self._height = len(self._array)\n",
    "        \n",
    "        self._all_points = [Point(x,y) for y in range(self._height) for x in range(self._width)]\n",
    "\n",
    "    def value_at_point(self, point: Point):\n",
    "        \"\"\" The value at this point \"\"\"\n",
    "        return self._array[point.y][point.x]\n",
    "\n",
    "    def set_value_at_point(self, point: Point, value):\n",
    "        self._array[point.y][point.x] = value\n",
    "\n",
    "    def valid_location(self, point: Point) -> bool:\n",
    "        \"\"\" Check if a location is within the grid \"\"\"\n",
    "        if (0 <= point.x < self._width and  0 <= point.y < self._height):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def width(self):\n",
    "        \"\"\" Array width (cols) \"\"\"\n",
    "        return self._width\n",
    "\n",
    "    @property\n",
    "    def height(self):\n",
    "        \"\"\" Array height (rows) \"\"\"\n",
    "        return self._height\n",
    "\n",
    "    def all_points(self) -> list[Point]:\n",
    "        return self._all_points\n",
    "\n",
    "    def rows_as_str(self):\n",
    "        \"\"\" Return the grid \"\"\"\n",
    "        return [\"\".join(str(char) for char in row) for row in self._array]\n",
    "\n",
    "    def cols_as_str(self):\n",
    "        \"\"\" Render columns as str. Returns: list of str \"\"\"\n",
    "        cols_list = list(zip(*self._array))\n",
    "        return [\"\".join(str(char) for char in col) for col in cols_list]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Grid(size={self.width}*{self.height})\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"\\n\".join(\"\".join(map(str, row)) for row in self._array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xNijk6xbCVa"
   },
   "source": [
    "### Useful Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DT5FSYliC9wp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# CONSOLE STUFF\n",
    "#################################################################\n",
    "\n",
    "def cls():\n",
    "    \"\"\" Clear console \"\"\"\n",
    "    os.system('cls' if os.name=='nt' else 'clear')\n",
    "\n",
    "#################################################################\n",
    "# USEFUL FUNCTIONS\n",
    "#################################################################\n",
    "\n",
    "def binary_search(target, low:int, high:int, func, *func_args, reverse_search=False):\n",
    "    \"\"\" Generic binary search function that takes a target to find,\n",
    "    low and high values to start with, and a function to run, plus its args.\n",
    "    Implicitly returns None if the search is exceeded. \"\"\"\n",
    "\n",
    "    res = None  # just set it to something that isn't the target\n",
    "    candidate = 0  # initialise; we'll set it to the mid point in a second\n",
    "\n",
    "    while low < high:  # search exceeded\n",
    "        candidate = int((low+high) // 2)  # pick mid-point of our low and high\n",
    "        res = func(candidate, *func_args) # run our function, whatever it is\n",
    "        logger.debug(\"%d -> %d\", candidate, res)\n",
    "        if res == target:\n",
    "            return candidate  # solution found\n",
    "\n",
    "        comp = operator.lt if not reverse_search else operator.gt\n",
    "        if comp(res, target):\n",
    "            low = candidate\n",
    "        else:\n",
    "            high = candidate\n",
    "\n",
    "def merge_intervals(intervals: list[list]) -> list[list]:\n",
    "    \"\"\" Takes intervals in the form [[a, b][c, d][d, e]...]\n",
    "    Intervals can overlap.  Compresses to minimum number of non-overlapping intervals. \"\"\"\n",
    "    intervals.sort()\n",
    "    stack = []\n",
    "    stack.append(intervals[0])\n",
    "\n",
    "    for interval in intervals[1:]:\n",
    "        # Check for overlapping interval\n",
    "        if stack[-1][0] <= interval[0] <= stack[-1][-1]:\n",
    "            stack[-1][-1] = max(stack[-1][-1], interval[-1])\n",
    "        else:\n",
    "            stack.append(interval)\n",
    "\n",
    "    return stack\n",
    "\n",
    "@cache\n",
    "def get_factors(num: int) -> set[int]:\n",
    "    \"\"\" Gets the factors for a given number. Returns a set[int] of factors.\n",
    "        # E.g. when num=8, factors will be 1, 2, 4, 8 \"\"\"\n",
    "    factors = set()\n",
    "\n",
    "    # Iterate from 1 to sqrt of 8,\n",
    "    # since a larger factor of num must be a multiple of a smaller factor already checked\n",
    "    for i in range(1, int(num**0.5) + 1):  # e.g. with num=8, this is range(1, 3)\n",
    "        if num % i == 0: # if it is a factor, then dividing num by it will yield no remainder\n",
    "            factors.add(i)  # e.g. 1, 2\n",
    "            factors.add(num//i)  # i.e. 8//1 = 8, 8//2 = 4\n",
    "\n",
    "    return factors\n",
    "\n",
    "def to_base_n(number: int, base: int):\n",
    "    \"\"\" Convert any integer number into a base-n string representation of that number.\n",
    "    E.g. to_base_n(38, 5) = 123\n",
    "\n",
    "    Args:\n",
    "        number (int): The number to convert\n",
    "        base (int): The base to apply\n",
    "\n",
    "    Returns:\n",
    "        [str]: The string representation of the number\n",
    "    \"\"\"\n",
    "    ret_str = \"\"\n",
    "    curr_num = number\n",
    "    while curr_num:\n",
    "        ret_str = str(curr_num % base) + ret_str\n",
    "        curr_num //= base\n",
    "\n",
    "    return ret_str if number > 0 else \"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env Clear\n",
    "\n",
    "Only run the next cell if you want to manually clear your session key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del os.environ['AOC_SESSION_COOKIE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y68fv1BebLsG"
   },
   "source": [
    "# Days\n",
    "\n",
    "Here you'll find a template to build a solution for a given day, and then the solutions for all days in this event.\n",
    "\n",
    "To copy the template day, select all the cells in the `Day n` template, add a new cell at the end, and then paste the cells there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 1: Historian Hysteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"1\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 1 Part 1\n",
    "\n",
    "We're told: historically significant locations are listed by a unique number called the location ID. The Historians have split into two groups, and each group has created their own list of locations.\n",
    "\n",
    "Our puzzle input is the two lists; i.e. presented as two columns of numbers. We need to reconcile the differences. E.g.\n",
    "\n",
    "```text\n",
    "3   4\n",
    "4   3\n",
    "2   5\n",
    "1   3\n",
    "3   9\n",
    "3   3\n",
    "```\n",
    "\n",
    "Goal:\n",
    "\n",
    "- Pair the smallest number in the two lists, and measure the difference.\n",
    "- Then the second smallest number from each list, and so on.\n",
    "- Return the sum of differences.\n",
    "\n",
    "**What is the total distance between your lists?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "1. Build two lists by splitting each line into two numbers. We can easily do this by [reading each line](https://aoc.just2good.co.uk/python/reading_files), and calling the `split()` function, which automatically splits on the whitespace between the numbers. For each row, we now end up with two numbers, but returned as string values. So we use [map()](https://aoc.just2good.co.uk/python/map-filter-reduce) to turn the strings into integer types. Now we have a pair of integer numbers for each line, which we wrap in a tuple and return in a [list comprehension](https://aoc.just2good.co.uk/python/comprehensions). I.e. one list containing tuples, which are each a pair of integers. Finally, we use the [zip()](https://aoc.just2good.co.uk/python/zip) function to turn the list of tuples pairs into a pair of lists: one list for left column, and one list for the right column.\n",
    "1. Sort the two lists, such that the smallest number in each column comes first, and so on.\n",
    "1. Find the absolute difference between each pair of numbers, and sum these differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def process_data(data) -> tuple[list[int], list[int]]:\n",
    "    items = [tuple(map(int, line.split())) for line in data] # returns list of tuples, e.g. [(3, 5), ...]\n",
    "    list1, list2 = zip(*items) # list of all lefts, plus list of all rights\n",
    "    return sorted(list1), sorted(list2)\n",
    "\n",
    "def solve_part1(data) -> int:\n",
    "    list1, list2 = process_data(tuple(data))\n",
    "    \n",
    "    diff = 0\n",
    "    for item1, item2 in zip(list1, list2):\n",
    "        diff += abs(item2 - item1)\n",
    "        \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "3   4\n",
    "4   3\n",
    "2   5\n",
    "1   3\n",
    "3   9\n",
    "3   3\n",
    "\"\"\")\n",
    "sample_answers = [11]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 1 Part 2\n",
    "\n",
    "Figure out exactly how often each number from the left list appears in the right list. Calculate a total similarity score by adding up each number in the left list after multiplying it by the number of times that number appears in the right list.\n",
    "\n",
    "**What is their similarity score?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "1. For each item in list1, count how many times it appears in list2.\n",
    "1. Add the product of the item and the count to our score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    list1, list2 = process_data(tuple(data))\n",
    "    \n",
    "    score = 0\n",
    "    for item in list1:\n",
    "        item_count = list2.count(item)\n",
    "        score += item * item_count\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sample_answers = [31]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Solutions\n",
    "\n",
    "We could also solve using [Numpy](https://aoc.just2good.co.uk/python/numpy). This will be more efficient for large arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(data) -> int:\n",
    "    sorted_lists = process_data(tuple(data))\n",
    "    \n",
    "    # Create two Numpy arrays\n",
    "    list1 = np.array(sorted_lists[0])\n",
    "    list2 = np.array(sorted_lists[1])\n",
    "    \n",
    "    diff = np.sum(np.abs(list2-list1)) # The sum of item diffs\n",
    "    logger.info(f\"{diff=}\")\n",
    "    \n",
    "    similarity_score = 0\n",
    "    for item in list1:\n",
    "        item_count = (list2 == item).sum() # How many times the item appears in list2\n",
    "        similarity_score += item * item_count\n",
    "        \n",
    "    logger.info(f\"{similarity_score=}\")\n",
    "    \n",
    "solve(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 2: Red-Nosed Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"2\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 2 Part 1\n",
    "\n",
    "Our data is a set of reports. Each line is one report. Each report contains a list of numbers called levels. Like this:\n",
    "\n",
    "```text\n",
    "7 6 4 2 1\n",
    "1 2 7 8 9\n",
    "9 7 6 2 1\n",
    "1 3 2 4 5\n",
    "8 6 4 4 1\n",
    "1 3 6 7 9\n",
    "```\n",
    "\n",
    "Reports are safe if:\n",
    "\n",
    "- The levels are either all increasing or all decreasing\n",
    "- And any two adjacent levels must differ by at least 1 and at most 3.\n",
    "\n",
    "**How many reports are safe?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- Split each record into a list of int values, called `levels`.\n",
    "- Create `is_safe()` function which:\n",
    "  - Creates a list of difference values - called `diffs` - by subtracting `levels` with offset 1 from `levels`.\n",
    "  - Then, use the `all` iterator operator function to check if our condition is true for every diff in `diffs`.\n",
    "  - The condition is: that every diff is positive and `<=MAX_DIFF` or every diff is negative and `>=MAX_DIFF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_safe(levels: list[int], max_diff: int) -> bool:\n",
    "    \"\"\" Determine if a record - i.e. a list of levels - is safe.\n",
    "    Do this by determining the differences between each level in the record.\n",
    "    Check if the differences are all positive and within the max, \n",
    "    or all negative and within the max. \"\"\"\n",
    "    \n",
    "    # Create pairs of levels from successive levels\n",
    "    # For each pair, substract second from first to get the difference\n",
    "    diffs = [first-second for first, second in zip(levels, levels[1:])]\n",
    "    \n",
    "    return (all(0 < diff <= max_diff for diff in diffs) or \n",
    "            all(-max_diff <= diff < 0 for diff in diffs))\n",
    "\n",
    "def solve_part1(data):\n",
    "    safe_count = 0\n",
    "    for report in data:\n",
    "        levels = list(map(int, report.split()))\n",
    "        if is_safe(levels, 3):\n",
    "            safe_count += 1\n",
    "    \n",
    "    return safe_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "7 6 4 2 1\n",
    "1 2 7 8 9\n",
    "9 7 6 2 1\n",
    "1 3 2 4 5\n",
    "8 6 4 4 1\n",
    "1 3 6 7 9\"\"\")\n",
    "sample_answers = [2]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 2 Part 2\n",
    "\n",
    "We now have a _Problem Dampener_, which means we can tolerate a single bad level in any given record.\n",
    "\n",
    "So we must try removing levels from records, and then testing if the report is safe.\n",
    "\n",
    "**How many reports are now safe?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "Same as before, but this time we will iterate through the index values of each record, and remove that level from the record. I.e.\n",
    "\n",
    "- Loop through each index value for the record.\n",
    "- For the current index value, concatenate the levels up to this index with the levels after this index. Thus, we always end up with a list that is one shorter than the original list. (Note that trimming off the first or last level will never make a safe record _unsafe_.)\n",
    "- Pass shortened list to our `is_safe()` function.\n",
    "- If the shortened record is safe, then we can add this record to our counter and move on to the next record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    safe_count = 0\n",
    "    for report in data:\n",
    "        levels = list(map(int, report.split()))\n",
    "\n",
    "        # Slice out one level at a time, and check if the new record is safe\n",
    "        for idx in range(len(levels)):\n",
    "            # Take levels up this idx, and concatenate with levels AFTER this idx\n",
    "            trimmed_levels = levels[:idx] + levels[idx+1:]\n",
    "            if is_safe(trimmed_levels, 3):\n",
    "                safe_count += 1\n",
    "                break\n",
    "    \n",
    "    return safe_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "7 6 4 2 1\n",
    "1 2 7 8 9\n",
    "9 7 6 2 1\n",
    "1 3 2 4 5\n",
    "8 6 4 4 1\n",
    "1 3 6 7 9\"\"\")\n",
    "sample_answers = [4]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 3: Mull It Over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"3\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3 Part 1\n",
    "\n",
    "A shop computer is trying to run a program, but its memory - the puzzle input - is corrupted.\n",
    "\n",
    "It should be doing instructions like:\n",
    "\n",
    "- `mul(X,Y)` where `X` and `Y` are 1-3 digit numbers.\n",
    "\n",
    "Our instructions:\n",
    "\n",
    "- There are many invalid characters which should be ignored.\n",
    "- If an invalid character is part of a `mul()` instruction, then the whole instruction does nothing.\n",
    "- Scan the corrupted memory for uncorrupted mul instructions.\n",
    "\n",
    "**What do you get if you add up all of the results of the multiplications?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "We can just use [regex](https://aoc.just2good.co.uk/python/regex).\n",
    "\n",
    "- Use a regex pattern to identify substrints that match the required input format.\n",
    "- Use the regex `finditer()` to retrieve all non-overlapping matches.\n",
    "- The `matches.groups()` retrieves the captured groups, i.e. the digits themselves. We identify capture groups by placing each digit in brackets in the pattern string.\n",
    "- Then, multiply the two digits together, as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    # match all \"mul(x,y)\"\n",
    "    matches = re.finditer(r\"mul\\((\\d{1,3}),(\\d{1,3})\\)\", data)\n",
    "    \n",
    "    ans = 0\n",
    "    for match in matches:\n",
    "        val_x, val_y = match.groups()\n",
    "        ans += int(val_x)*int(val_y)\n",
    "        \n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"xmul(2,4)%&mul[3,7]!@^do_not_mul(5,5)+mul(32,64]then(mul(11,8)mul(8,5))\"\"\")\n",
    "sample_answers = [161]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3 Part 2\n",
    "\n",
    "Now we also want to handle intact conditional statements. We need to handle:\n",
    "\n",
    "- `do()` which enables future `mul` instructions\n",
    "- `don't()` which disables future `mul` instructions.\n",
    "\n",
    "We start enabled.\n",
    "\n",
    "**What is the sum of just the enabled multiplications?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- Okay, we start `enabled`.\n",
    "- Whilst `enabled==True`, everything up to the next `don't()` should be parsed for `mul()` instructions.\n",
    "- When we hit a `don't()`, we set `enabled=False`.\n",
    "- Now, everything up to the next `do()` should be ignored.\n",
    "- When we hit a `do()`, we set `enabled=True` again.\n",
    "\n",
    "I'm shocked... This worked first time with no bugs!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data: str):\n",
    "    # match all \"mul(x,y)\"\n",
    "    matcher = re.compile(r\"mul\\((\\d{1,3}),(\\d{1,3})\\)\")\n",
    "    \n",
    "    remaining_program = data\n",
    "    enabled = True # We start enabled\n",
    "    ans = 0\n",
    "    while remaining_program:\n",
    "        if enabled:\n",
    "            # split into the part before the next \"don't()\", and everything afterwards\n",
    "            this_part, _, remaining_program = remaining_program.partition(r\"don't()\")\n",
    "        \n",
    "            for match in matcher.finditer(this_part):\n",
    "                val_x, val_y = match.groups()\n",
    "                ans += int(val_x)*int(val_y)\n",
    "            \n",
    "            enabled = False\n",
    "        else:\n",
    "            # split into the part before the next \"do()\", and everything afterwards\n",
    "            this_part, _, remaining_program = remaining_program.partition(r\"do()\")\n",
    "            enabled = True\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"xmul(2,4)&mul[3,7]!^don't()_mul(5,5)+mul(32,64](mul(11,8)undo()?mul(8,5))\"\"\")\n",
    "sample_answers = [48]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 4: Ceres Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"4\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 4 Part 1\n",
    "\n",
    "We have a word search! We need to find every instance of the word `XMAS`. The string can be found horizontally, vertically, diagonally, and in forward/reverse directions.\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- Create a dictinary to count how many times a given character is part of a matched word. Why did I do this?\n",
    "  - Firstly, we can use this dictionary to determine if any given character in the grid has been matched in a word. This makes it easy to print a grid that only shows matched characters. Useful for debugging!\n",
    "  - Secondly, I thought Part 2 might be asking where we have characters that are matched more than once, i.e. where words cross. This dict would have made it super easy for me to determine that. Alas, my guess was wrong!\n",
    "- Now move through each location in the grid, and stop whenever we find the `X` of `XMAS`.\n",
    "- Having identified the starting `X`, now iterate through all 8 possible directions.\n",
    "- For each direction, first determine if the full word can fit in the grid, i.e. that we don't get cut off by a grid edge.\n",
    "- If the word can fit, we then move one char at a time in the current direction, and test if the characters match the remaining characters in our word. \n",
    "- If all characters match, then we've matched the word and we can increment that `matches` counter.  But also, increment the counts for each character in this word.\n",
    "- Now, render a visualisation of the grid, showing a `.` whenever the count at this location is 0, else show the character at this location.#\n",
    "- Finally, return the total number of `matches`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    match_word = \"XMAS\"\n",
    "    matched_posn_counts = defaultdict(int) # increment whenever this index is in a matched word\n",
    "\n",
    "    grid_width = len(data[0])\n",
    "    grid_height = len(data)\n",
    "\n",
    "    matches = 0\n",
    "\n",
    "    # Iterate through all positions in the grid\n",
    "    for row_idx in range(grid_height):\n",
    "        for col_idx in range(grid_width):\n",
    "            # Find the X (first char)\n",
    "            if data[row_idx][col_idx] == match_word[0]:\n",
    "                # Now we want to expand in all directions\n",
    "                for direction in Vectors: # Loop through all directions\n",
    "\n",
    "                    # Check if the full word can be within the grid bounds\n",
    "                    chars_left = len(match_word)-1\n",
    "                    if not (0 <= (col_idx + chars_left*direction.value[0]) < grid_width):\n",
    "                        continue # try next direction\n",
    "                    if not (0 <= (row_idx + chars_left*direction.value[1]) < grid_height):\n",
    "                        continue # try next direction\n",
    "\n",
    "                    found_word = True\n",
    "\n",
    "                    # Test remaining letters in this direction\n",
    "                    for steps, char in enumerate(match_word[1:], start=1):\n",
    "                        new_row_idx = row_idx + steps*direction.value[1]\n",
    "                        new_col_idx = col_idx + steps*direction.value[0]\n",
    "                        if data[new_row_idx][new_col_idx] != char:\n",
    "                            found_word = False\n",
    "                            break\n",
    "\n",
    "                    if found_word:\n",
    "                        # Mark these all word locations as matched\n",
    "                        for steps, char in enumerate(match_word):\n",
    "                            new_row_idx = row_idx + steps*direction.value[1]\n",
    "                            new_col_idx = col_idx + steps*direction.value[0]\n",
    "                            matched_posn_counts[(new_col_idx, new_row_idx)] += 1\n",
    "                        \n",
    "                        matches += 1\n",
    "    \n",
    "    grid_rows = []\n",
    "    for row_idx in range(grid_height):\n",
    "        row_str = \"\"\n",
    "        for col_idx in range(grid_width):\n",
    "            row_str += data[row_idx][col_idx] if matched_posn_counts[(col_idx, row_idx)] > 0 else \".\"\n",
    "        \n",
    "        grid_rows.append(row_str)\n",
    "    \n",
    "    grid_vis = \"\\n\".join(grid_rows)\n",
    "    logger.info(f\"\\n{grid_vis}\")\n",
    "\n",
    "    return matches\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "MMMSXXMASM\n",
    "MSAMXMSMSA\n",
    "AMXSXMAAMM\n",
    "MSAMASMSMX\n",
    "XMASAMXAMM\n",
    "XXAMMXXAMA\n",
    "SMSMSASXSS\n",
    "SAXAMASAAA\n",
    "MAMMMXMMMM\n",
    "MXMXAXMASX\"\"\")\n",
    "sample_answers = [18]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")\n",
    "### Day 4 Part 2\n",
    "\n",
    "Quite different for part 2! Now we need to find any any X shape that contains \"MAS\" twice. E.g. a configuration like this:\n",
    "\n",
    "```text\n",
    "M.S\n",
    ".A.\n",
    "M.S\n",
    "```\n",
    "\n",
    "Observations:\n",
    "\n",
    "- The centre character will always be `A`.\n",
    "- The `M` and `S` characters each need to appear twice in the X.\n",
    "- The `MAS` must be spelled diagonally. So if `M` is in one corner, then `S` will be in the opposite corner.\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- Set up a moveable X grid, by storing a list of vectors that represent the corners: NE, SE, SW, NW.\n",
    "- Move the X through every possible location in the grid. We'll start by matching the `A` at the centre of the grid. For this reason, we should start at position `(1, 1)`, we will we will always stop one row / column before any given edge.\n",
    "- Having matched an `A`, determine the coordinates of the four corners.\n",
    "- Check that the four corners contain each remaining character (i.e. `M` or `S`) twice. If so, this location is a candidate.\n",
    "- If we've found a candidate, determine the char in the top-right corner. Then determine if the char in the bottom-left corner is the _other_ end character in our word. If it is, then we've got a match. Why? Because if we've verified this diagonal, then by previously verifying the character counts, we know that the other diagonal is also satisfied.\n",
    "\n",
    "And that's it! It's really quick too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    match_word = \"MAS\"\n",
    "    center = match_word[1] # `A`\n",
    "    ends = match_word[0] + match_word[-1] # `MS`\n",
    "\n",
    "    grid_width = len(data[0])\n",
    "    grid_height = len(data)\n",
    "\n",
    "    matches = 0\n",
    "\n",
    "    corner_vecs = [Vectors.NE.value,\n",
    "                   Vectors.SE.value,\n",
    "                   Vectors.SW.value,\n",
    "                   Vectors.NW.value]\n",
    "\n",
    "    # Traverse the grid, but always inset by 1\n",
    "    for row_num in range(1, grid_height-1):\n",
    "        for col_num in range(1, grid_width-1):\n",
    "            current_centre = data[row_num][col_num]\n",
    "            # Does middle of the X contain the A of \"MAS\"?\n",
    "            if current_centre == center:\n",
    "                corners = [(col_num+dx, row_num+dy) for dx, dy in corner_vecs]\n",
    "                corner_chars = [data[y][x] for x, y in corners]\n",
    "\n",
    "                # Check that each end char appears in the X exactly twice\n",
    "                if all(corner_chars.count(char) == 2 for char in ends):\n",
    "                    # if top right char is the opposite end char to bottom left char, we're matched\n",
    "                    tr_char = data[corners[0][1]][corners[0][0]]\n",
    "                    bl_char = data[corners[2][1]][corners[2][0]]\n",
    "                    tr_match_idx = ends.index(tr_char)\n",
    "                    if bl_char == ends[(len(ends)-tr_match_idx)-1]:\n",
    "                        matches += 1\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "MMMSXXMASM\n",
    "MSAMXMSMSA\n",
    "AMXSXMAAMM\n",
    "MSAMASMSMX\n",
    "XMASAMXAMM\n",
    "XXAMMXXAMA\n",
    "SMSMSASXSS\n",
    "SAXAMASAAA\n",
    "MAMMMXMMMM\n",
    "MXMXAXMASX\"\"\")\n",
    "sample_answers = [9]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 5: Print Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"5\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 5 Part 1\n",
    "\n",
    "Out input is in two blocks:\n",
    "\n",
    "1. The page order rules - one rule per line. These are pairs of rules, e.g. `47|53`. This means that `if` an update contains *both* of these page numbers, then page `47` must be printed at some point *before* `53`.\n",
    "1. The specified page numbers required in a particular update - one update set per line.\n",
    "\n",
    "The sample input:\n",
    "\n",
    "```text\n",
    "47|53\n",
    "97|13\n",
    "97|61\n",
    "97|47\n",
    "75|29\n",
    "61|13\n",
    "75|53\n",
    "29|13\n",
    "97|29\n",
    "53|29\n",
    "61|53\n",
    "97|53\n",
    "61|29\n",
    "47|13\n",
    "75|47\n",
    "97|75\n",
    "47|61\n",
    "75|61\n",
    "47|29\n",
    "75|13\n",
    "53|13\n",
    "\n",
    "75,47,61,53,29\n",
    "97,61,53,29,13\n",
    "75,29,13\n",
    "75,97,47,61,53\n",
    "61,13,29\n",
    "97,13,75,29,47\n",
    "```\n",
    "\n",
    "**What is the sum of middle page numbers from only the updates are correctly ordered?**\n",
    "\n",
    "#### Observations\n",
    "\n",
    "Rules for a given update:\n",
    "\n",
    "- For any page number N, there must NOT be a rule `B|N` for any `B` that comes AFTER it.\n",
    "- For any page number N, there must NOT be a rule `N|A` for any `A` that comes BEFORE it.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- The rules appear to be a complete set, meaning that there wil be a rule for _every_ possible pair of pages. Or, to put it another way: if `A|B` and `B|C`, then there will always be a rule `A|C`. This rule will be provided; we do not have to derive it implicitly.\n",
    "- A given update does necessarily include every page and therefore does not need to include every rule.\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- For some reason, I just felt like a class would be a neater way to manage our rules and updates, so I've gone with a `PageOrdering` class.\n",
    "- This includes a `_process_data()` method, which takes in the puzzle data and:\n",
    "  - Splits into two blocks - the first block for the rules and the second block for the updates.\n",
    "  - For the rules, I create `required_before` and `required_after` [defaultdicts](https://aoc.just2good.co.uk/python/defaultdict), of type list.\n",
    "  - Every time we find a number on the left of the rule, we add the number on the right to the corresponding `required_after` list.\n",
    "  - Every time we find a number on the right of the rule, we add the number on the left to the corresponding `required_before` list.\n",
    "  - For the updates, I turn each line into a list of int values.\n",
    "- Next, the `_is_correctly_ordered(update)` method. This is the heart of the Part 1 solution. We:\n",
    "  - Iterate through each position for a given update.\n",
    "  - For a given position we build up a set of all the pages that were found before it, and all the pages found after it.\n",
    "  - Now get the set of all pages that are required before our page, and the set of all pages that are required after our page.\n",
    "  - Finally, we can just use the [set](https://aoc.just2good.co.uk/python/sets) `intersect()` (shorthand of `&`) to determine if any of the pages found before are required after, and if any of the pages found after are required before. In either case, our update is NOT correctly ordered.\n",
    "- Then implement `get_updates_correctly_ordered()`, which loops through each update and checks it using the method above.\n",
    "- Finally, we'll create `sum_middles()` which takes a list of updates, and adds up the middle value from each one.\n",
    "\n",
    "That's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageOrdering():\n",
    "    \n",
    "    def __init__(self, data: str) -> None:\n",
    "        \n",
    "        required_after, required_before, updates = self._process_data(data)\n",
    "        self._required_after = required_after\n",
    "        self._required_before = required_before\n",
    "        self._updates = updates\n",
    "    \n",
    "    @property\n",
    "    def updates(self):\n",
    "        return self._updates\n",
    "\n",
    "    def _process_data(self, data: str):\n",
    "        \"\"\" Parse input data to determine rules and updates \"\"\"\n",
    "        required_after = defaultdict(set)\n",
    "        required_before = defaultdict(set)\n",
    "        updates = [] \n",
    "        \n",
    "        # split into blocks.\n",
    "        rules_block, updates_block = data.split(\"\\n\\n\") \n",
    "        \n",
    "        # build two-way adjacency dictionary\n",
    "        for rule in rules_block.splitlines():\n",
    "            x, y = list(map(int, rule.split(\"|\")))\n",
    "            required_after[x].add(y)\n",
    "            required_before[y].add(x)\n",
    "        \n",
    "        # Turn updates block into list of lists\n",
    "        updates = [[int(x) for x in update_line.split(\",\")] for update_line in updates_block.splitlines()]\n",
    "        \n",
    "        return required_after, required_before, updates\n",
    "    \n",
    "    @staticmethod\n",
    "    def sum_middles(updates: list[list[int]]) -> int:\n",
    "        \"\"\" Get the sum of the middle values from the supplied updates \"\"\"\n",
    "        sum_of_middle_pages = 0\n",
    "        for update in updates:\n",
    "            middle = update[(len(update)//2)]\n",
    "            sum_of_middle_pages += middle\n",
    "            \n",
    "        return sum_of_middle_pages\n",
    "    \n",
    "    def get_updates_correctly_ordered(self) -> list[list[int]]:\n",
    "        \"\"\" Return all the updates that are correctly ordered \"\"\"\n",
    "        return [update for update in self._updates if self._is_correctly_ordered(update)]\n",
    "    \n",
    "    def get_updates_incorrectly_ordered(self) -> list[list[int]]:\n",
    "        \"\"\" Return all the updates that are incorrectly ordered \"\"\"\n",
    "        return [update for update in self._updates if not self._is_correctly_ordered(update)]\n",
    "    \n",
    "    def fix_incorrect_update(self, update: list[int]) -> list[int]:\n",
    "        \"\"\" Sort an incorrectly sorted update into the correct order, using the rules \"\"\"\n",
    "        \n",
    "        bad_update = set(update) # Turn our list into a set, so we can intersect later\n",
    "        required_posn_for_page = dict() # { page_num1: posn1; page_num2: posn2, ...}\n",
    "        \n",
    "        for page in update: # iterate through all pages in the update\n",
    "            # Using the rules, determine the set of all pages that must be before this page\n",
    "            # Then intersect with the pages that are in our update\n",
    "            # The length of the intersect describes how many pages in THIS update must be before this page\n",
    "            # This gives us the location that this page SHOULD be in this update\n",
    "            required_before_page = self._required_before[page] & bad_update\n",
    "            required_posn_for_page[page] = len(required_before_page)\n",
    "        \n",
    "        # Sort our dict based on the lengths and return just the page numbers\n",
    "        return [page for (page, posn) in sorted(required_posn_for_page.items(), \n",
    "                key=lambda item: item[1])]\n",
    "        \n",
    "    def _is_correctly_ordered(self, update: list[int]):\n",
    "        \"\"\" Determine if the update is correctly ordered by checking the rules \"\"\"\n",
    "        \n",
    "        # E.g. 75,97,47,61,53\n",
    "        for idx in range(len(update)): # iterate through all positions in this update\n",
    "            current_page = update[idx] # e.g. 75\n",
    "            before = set(update[:idx]) # get all the pages BEFORE this page in our update\n",
    "            after = set(update[idx+1:]) # get all the pages AFTER this page in our update, e.g. 97,47,61,53\n",
    "            \n",
    "            required_before_page = self._required_before[current_page] # E.g. 97|75\n",
    "            if intersect := after & required_before_page: # Any pages found after, that are required before?\n",
    "                return False\n",
    "            \n",
    "            required_after_page = self._required_after[current_page]\n",
    "            if intersect := before & required_after_page: # Any pages found before, that are required after?\n",
    "                return False\n",
    "            \n",
    "        return True          \n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"PageOrdering(rules_len={len(self._required_before)},updates_len={len(self._updates)})\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"\\n\".join(\",\".join(map(str, update_row)) for update_row in self._updates)        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    page_ordering = PageOrdering(data)\n",
    "    correctly_ordered_updates = page_ordering.get_updates_correctly_ordered()\n",
    "    return page_ordering.sum_middles(correctly_ordered_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "47|53\n",
    "97|13\n",
    "97|61\n",
    "97|47\n",
    "75|29\n",
    "61|13\n",
    "75|53\n",
    "29|13\n",
    "97|29\n",
    "53|29\n",
    "61|53\n",
    "97|53\n",
    "61|29\n",
    "47|13\n",
    "75|47\n",
    "97|75\n",
    "47|61\n",
    "75|61\n",
    "47|29\n",
    "75|13\n",
    "53|13\n",
    "\n",
    "75,47,61,53,29\n",
    "97,61,53,29,13\n",
    "75,29,13\n",
    "75,97,47,61,53\n",
    "61,13,29\n",
    "97,13,75,29,47\"\"\")\n",
    "sample_answers = [143]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 5 Part 2\n",
    "\n",
    "For each of the incorrectly-ordered updates, use the page ordering rules to put the page numbers in the right order.\n",
    "\n",
    "**What is the sum of middle page numbers from only the updates that have been fixed?**\n",
    "\n",
    "First, we need to determine all the updates that are incorrectly ordered. We can do this with a trivial update to this line:\n",
    "\n",
    "```python\n",
    "    return [update for update in self._updates if self._is_correctly_ordered(update)]\n",
    "```\n",
    "\n",
    "We just add `not`, and then wrap with a new method:\n",
    "\n",
    "```python\n",
    "    def get_updates_incorrectly_ordered(self) -> list[list[int]]:\n",
    "        \"\"\" Return all the updates that are incorrectly ordered \"\"\"\n",
    "        return [update for update in self._updates if not self._is_correctly_ordered(update)]\n",
    "```\n",
    "\n",
    "Now we need a method to sort every incorrectly ordered update.  I've created a method `fix_incorrect_update()`. It works like this:\n",
    "\n",
    "- Create a set from the bad update.\n",
    "- Create a dictionary that stores the _required_ position for each page in the bad update.\n",
    "- Now iterate through every page in the bad update. And for each:\n",
    "  - Start by determining ALL the pages that must come before this page, according to the list of rules. \n",
    "  - From this set of pages, we only care about the ones that are present in our bad update. So we intersect between these two sets. So now we know exactly how many pages from our bad set SHOULD be before the current page.\n",
    "  - Store the length of the intersect set as the value for this page, in the `required_posn_for_page` dictionary.\n",
    "- Once we've done this for every page in the bad update, we now have a dictionary that has the unique REQUIRED index location for every page in the update. So we finally just sort based on the index location, to return the required pages in the correct order.\n",
    "- Then for each of this fixed updates, just locate the middles as before and sum them.\n",
    "\n",
    "This was fun!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    page_ordering = PageOrdering(data)\n",
    "    incorrectly_ordered_updates = page_ordering.get_updates_incorrectly_ordered()\n",
    "    \n",
    "    fixed_updates = []\n",
    "    for incorrect_update in incorrectly_ordered_updates:\n",
    "        fixed_updates.append(page_ordering.fix_incorrect_update(incorrect_update))\n",
    "        \n",
    "    return page_ordering.sum_middles(fixed_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "47|53\n",
    "97|13\n",
    "97|61\n",
    "97|47\n",
    "75|29\n",
    "61|13\n",
    "75|53\n",
    "29|13\n",
    "97|29\n",
    "53|29\n",
    "61|53\n",
    "97|53\n",
    "61|29\n",
    "47|13\n",
    "75|47\n",
    "97|75\n",
    "47|61\n",
    "75|61\n",
    "47|29\n",
    "75|13\n",
    "53|13\n",
    "\n",
    "75,47,61,53,29\n",
    "97,61,53,29,13\n",
    "75,29,13\n",
    "75,97,47,61,53\n",
    "61,13,29\n",
    "97,13,75,29,47\"\"\")\n",
    "sample_answers = [123]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 6: Guard Gallivant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"6\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 6 Part 1\n",
    "\n",
    "We have a grid with empty spaces `.`, obstacles `#`, and our guard, poining in a particular direction, e.g. `^`. E.g.\n",
    "\n",
    "```text\n",
    "....#.....\n",
    ".........#\n",
    "..........\n",
    "..#.......\n",
    ".......#..\n",
    "..........\n",
    ".#..^.....\n",
    "........#.\n",
    "#.........\n",
    "......#...\n",
    "```\n",
    "\n",
    "Our guard moves one space at a time until hitting an obstacle, and then always turns right. \n",
    "\n",
    "**Including the guard's starting position, how many distinct positions will the guard visit before leaving the mapped area?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "Here I'm going to use my reusable `Grid` class because it already knows how to determine height and width, and how to check if a given location will be out of bounds of the grid.  I'm also using my reusable `Point` namedtuple, since this allows me to represent 2D coordinates using a more intuitive syntax like `point.x` rather than `point[0]`.\n",
    "\n",
    "I make a new `GuardMap` class by extending `Grid`. Things to note:\n",
    "\n",
    "- It contains class attributes that represent spaces, obstacles.\n",
    "- It contains a dictionary to map our four directors to vectors.\n",
    "- We have a `DIRECTIONS` string with our four directions. We can keep track of the index of our current direction, such that we simply increment this index whenever we want to turn right.\n",
    "- Start by iterating through all locations in the grid until we find a direction symbol, e.g. `^`. This is the location of our guard.\n",
    "- We store any locations we've visited in a dictionary that maps the location to the latest direction. We don't need this to solve the problem, but it does mean I can use this dictionary to visualise the path taken by our guard.\n",
    "- Now we provide a `move()` method that will be called repeatedly, until our guard exits the grid. In this method:\n",
    "  - Start a loop. And in this loop...\n",
    "  - Determine the next location by adding the current guard position to the vector corresponding to the current direction.\n",
    "  - If this next location takes us out-of-bounds, then we've exited the grid.\n",
    "  - Otherwise, get the value at this location. If it's a space, we just update our location and we're done.\n",
    "  - If it's an obstacle, then we need to rotate right by updating our direction index. And then continue the loop and try again.\n",
    "- Finally, to solve the problem, we just return the length of the dictionary that stores all the locations we've visited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuardMap(Grid):\n",
    "    SPACE = \".\"\n",
    "    OBSTACLE = \"#\"\n",
    "    \n",
    "    DIRECTIONS = \"^>v<\" # Each successive direction is the result of turning right (i.e. 90 degrees)\n",
    "    DIRECTIONS_MAP = {\n",
    "        '^': Point(0, -1),\n",
    "        '>': Point(1, 0),\n",
    "        'v': Point(0, 1),\n",
    "        '<': Point(-1, 0)\n",
    "    }\n",
    "    \n",
    "    def __init__(self, grid_array: list):\n",
    "        super().__init__(grid_array)\n",
    "        \n",
    "        self._guard_location = self._locate_guard()\n",
    "        self._start_location = self._guard_location\n",
    "        \n",
    "        self._guard_direction = self.value_at_point(self._guard_location)\n",
    "        self._directions_idx = GuardMap.DIRECTIONS.index(self._guard_direction)\n",
    "        self._start_direction_idx = self._directions_idx\n",
    "\n",
    "        self._visited_with_direction = set()\n",
    "        self._visited_map = {} # We can use this to print the route\n",
    "        self._in_loop = False\n",
    "                \n",
    "        self._update_visited()\n",
    "        \n",
    "        self._pre_obstacle_added = None\n",
    "    \n",
    "    def reset(self):\n",
    "        self._guard_location = self._start_location\n",
    "        self._guard_direction = self.value_at_point(self._guard_location)\n",
    "        self._directions_idx = self._start_direction_idx\n",
    "        \n",
    "        self._visited_with_direction = set()\n",
    "        self._visited_map: dict[Point, str] = {}\n",
    "        self._in_loop = False\n",
    "                \n",
    "        self._update_visited()\n",
    "        self._clear_obstacle()\n",
    "    \n",
    "    def add_obstacle(self, location: Point):\n",
    "        \"\"\" Add an obstacle at the specified location.\n",
    "        Store this location so we can clear the obstacle later. \"\"\"\n",
    "        self._pre_obstacle_added = (location, self.value_at_point(location))\n",
    "        self.set_value_at_point(location, GuardMap.OBSTACLE)\n",
    "        \n",
    "    def _clear_obstacle(self):\n",
    "        \"\"\" Clear any previously set obstacle. \"\"\"\n",
    "        if self._pre_obstacle_added:\n",
    "            self.set_value_at_point(self._pre_obstacle_added[0], self._pre_obstacle_added[1])\n",
    "    \n",
    "    @property\n",
    "    def in_loop(self) -> bool:\n",
    "        \"\"\" Are we stuck in a loop? \"\"\"\n",
    "        return self._in_loop\n",
    "    \n",
    "    @property\n",
    "    def visited(self):\n",
    "        \"\"\" Visited locations, as a dict of {location: direction, ...} \"\"\"\n",
    "        return self._visited_map\n",
    "    \n",
    "    @property\n",
    "    def distinct_visited_count(self) -> int:\n",
    "        \"\"\" Count of all distinct locations we've visited. \"\"\"\n",
    "        return len(self._visited_map)\n",
    "    \n",
    "    def _update_visited(self):\n",
    "        \"\"\" Update visited locations \"\"\"\n",
    "        \n",
    "        # Update our dict of where we've been\n",
    "        self._visited_map[self._guard_location] = self._guard_direction\n",
    "        \n",
    "        # For loop checking, we need to check if we've seen this location AND this orientation\n",
    "        location_config = (self._guard_location, self._guard_direction)\n",
    "        if location_config in self._visited_with_direction:\n",
    "            self._in_loop = True # We've done this before!\n",
    "        else:\n",
    "            self._visited_with_direction.add(location_config)\n",
    "\n",
    "    def move(self) -> bool:\n",
    "        \"\"\" \n",
    "        Move guard one space in current direction.\n",
    "        If we can't move forward in this direction, make turn and move.\n",
    "        Return True if we move, or False if we leave the map\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Move one step in the direction the guard is pointing\n",
    "            next_point = self._guard_location + GuardMap.DIRECTIONS_MAP[self._guard_direction]\n",
    "            \n",
    "            if not self.valid_location(next_point): # leaving the map?\n",
    "                return False\n",
    "            \n",
    "            # Are we at an obstacle? If so, rotate right and try again\n",
    "            next_value = self.value_at_point(next_point)\n",
    "            if (next_value == GuardMap.OBSTACLE):\n",
    "                # Increment the direction index\n",
    "                self._directions_idx = (self._directions_idx + 1) % len(GuardMap.DIRECTIONS)\n",
    "                self._guard_direction = GuardMap.DIRECTIONS[self._directions_idx]\n",
    "                continue\n",
    "            else: # No obstacle, so we can move to this location\n",
    "                self._guard_location = next_point\n",
    "                self._update_visited()\n",
    "                break # We've successfully moved\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    def _locate_guard(self) -> Point:\n",
    "        for point in self.all_points():\n",
    "            if self.value_at_point(point) in GuardMap.DIRECTIONS:\n",
    "                return point\n",
    "            \n",
    "    def __str__(self) -> str:\n",
    "        row_strs = []\n",
    "        for y, row in enumerate(self._array):\n",
    "            row_list = []\n",
    "            for x, char in enumerate(row):\n",
    "                locn = Point(x,y)\n",
    "                if locn in self._visited_map.keys():\n",
    "                    row_list.extend([Fore.YELLOW, self._visited_map[locn], Fore.RESET])\n",
    "                else:\n",
    "                    row_list.append(char)\n",
    "                    \n",
    "            row_strs.append(\"\".join(row_list))\n",
    "        \n",
    "        return \"\\n\".join(row_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    guard_map = GuardMap(data)\n",
    "    while guard_map.move():\n",
    "        pass\n",
    "\n",
    "    logger.debug(f\"\\n{guard_map}\")  \n",
    "    return guard_map.distinct_visited_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "....#.....\n",
    ".........#\n",
    "..........\n",
    "..#.......\n",
    ".......#..\n",
    "..........\n",
    ".#..^.....\n",
    "........#.\n",
    "#.........\n",
    "......#...\"\"\")\n",
    "sample_answers = [41]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding A Visualisation for Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisGuardMap(GuardMap):\n",
    "    def __init__(self, grid_array: list, animating: bool = True, **kwargs) -> None:\n",
    "        super().__init__(grid_array=grid_array, **kwargs)\n",
    "        \n",
    "        self.animating = animating\n",
    "        if self.animating:\n",
    "            self._plot_info = self._setup_fig()\n",
    "            self._frame_index = 0\n",
    "    \n",
    "    def _setup_fig(self):\n",
    "        \"\"\" Initialise the plot \"\"\"   \n",
    "        my_dpi = 120\n",
    "        fig, axes = plt.subplots(figsize=(1024/my_dpi, 768/my_dpi), dpi=my_dpi, facecolor=\"black\") # set size in pixels\n",
    "\n",
    "        axes.get_xaxis().set_visible(False)\n",
    "        axes.get_yaxis().set_visible(False)\n",
    "        axes.invert_yaxis()\n",
    "        axes.set_aspect('equal') # set x and y to equal aspect\n",
    "        axes.set_facecolor('xkcd:orange')\n",
    "        \n",
    "        min_x, max_x = -0.5, self._width - 0.5\n",
    "        min_y, max_y = -0.5, self._height - 0.5\n",
    "        axes.set_xlim(min_x, max_x)\n",
    "        axes.set_ylim(max_y, min_y)\n",
    "\n",
    "        # dynamically compute the marker size\n",
    "        fig.canvas.draw()\n",
    "        mkr_size = ((axes.get_window_extent().width / (max_x-min_x) * (45/fig.dpi)) ** 2)\n",
    "        \n",
    "        return fig, axes, mkr_size\n",
    "\n",
    "    def animate_step(self, i):\n",
    "        \"\"\" Update the plot for the nth step in the animation. \"\"\"\n",
    "        \n",
    "        if self._frame_index < len(self._visited_map):\n",
    "            self._render_plot()\n",
    "            self._frame_index += 1\n",
    "        return []\n",
    "    \n",
    "    def create_animation(self, output_path='animation.mp4', fps=10):\n",
    "        \"\"\" Create the animation, by calling the animate_step() method to generate frames. \"\"\"\n",
    "        self._plot_info = self._setup_fig()  # Set up the figure for plotting\n",
    "        fig, axes, mkr_size = self._plot_info\n",
    "        \n",
    "        logger.debug(f\"Creating the animation. We have {len(self._visited_map)} frames to render.\")\n",
    "        # Creating the animation\n",
    "        anim = FuncAnimation(fig, \n",
    "                             self.animate_step, \n",
    "                             frames=len(self._visited_map), \n",
    "                             interval=1000/fps, blit=True)\n",
    "\n",
    "        # Save the animation\n",
    "        anim.save(output_path, writer='ffmpeg')\n",
    "\n",
    "    def plot(self):\n",
    "        \"\"\" Show the current plot \"\"\"\n",
    "        self._render_plot(frame_idx=-1)\n",
    "        plt.show()\n",
    "        \n",
    "    def _render_plot(self, frame_idx=None):\n",
    "        \"\"\" Add each new frame. Note that this method should draw should only draw up to a particular state. \n",
    "        If frame_idx is set, it will render the plot at that particular frame. \"\"\"\n",
    "        fig, axes, mkr_size = self._plot_info\n",
    "        axes.clear() # clear for each frame\n",
    "        axes.invert_yaxis()\n",
    "        \n",
    "        # Determine the range of frames to render\n",
    "        last_frame = frame_idx if frame_idx else (self._frame_index + 1)\n",
    "\n",
    "        # Plot visited cells up to the current frame\n",
    "        if self._visited_map:\n",
    "            visited_x, visited_y = zip(*[(point.x, point.y) for point in list(self._visited_map.keys())[:last_frame]])\n",
    "            axes.scatter(visited_x, visited_y, s=mkr_size * 0.5, color=\"white\", label=\"Visited\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1_animated(data):\n",
    "    guard_map = VisGuardMap(data)\n",
    "    while guard_map.move():\n",
    "        pass\n",
    "\n",
    "    out_name=\"animation.mp4\"\n",
    "    output_dir = Path(locations.output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True) \n",
    "    output_file = Path(locations.output_dir, out_name)\n",
    "    guard_map.plot()\n",
    "    guard_map.create_animation(str(output_file), fps=10)\n",
    "\n",
    "    return guard_map.distinct_visited_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "....#.....\n",
    ".........#\n",
    "..........\n",
    "..#.......\n",
    ".......#..\n",
    "..........\n",
    ".#..^.....\n",
    "........#.\n",
    "#.........\n",
    "......#...\"\"\")\n",
    "\n",
    "solve_part1_animated(curr_input.splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 6 Part 2\n",
    "\n",
    "We need to place a single obstruction that causes the guard to get stuck in a loop! We can place the obstruction at any location apart from the starting point.\n",
    "\n",
    "**How many different positions could you choose for this obstruction?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "Firstly, we can only put obstructions in the path the guard walks, otherwise it would be pointless. That means >4000 positions to try. Sounds plausible! So my approach is simply to insert this obstacle into the grid, and then perform the walk. We repeat for every possible location, and count how many times this results in a loop.\n",
    "\n",
    "So:\n",
    "\n",
    "- Add a method to `reset()` the grid, e.g. the guard starting point, the counters, the direction, etc. This is a little more efficient than creating a new Guard\n",
    "- Track whether a location has been visited with a given direction in a set. The set will store tuples of `(Point, direction)`. If we try to visit a previously seen configuration, then we're in a loop, so set an attribute to mark that this grid is now in a loop.\n",
    "- Add a method to add an additional obstacle at a given location. Track the location so that we can clear the obstacle later.\n",
    "- Add a method to clear the added obstacle.\n",
    "\n",
    "Now:\n",
    "\n",
    "- Iterate through all locations in the original loop, as candidates for the obstacle. (Except the starting point.)\n",
    "- Reset the grid, add the obstacle, and then simulate the guard movement as before.\n",
    "- With each movement, check if we're in a loop. If so, exit this loop.\n",
    "\n",
    "This works! But it also takes about 10 seconds to run.  Not the fastest, but not too bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    \n",
    "    # Initial route\n",
    "    guard_map = GuardMap(data)\n",
    "    while guard_map.move():\n",
    "        pass\n",
    "    \n",
    "    # Route taken, excluding starting point\n",
    "    route = [locn for locn in guard_map.visited.keys()][1:]\n",
    "    \n",
    "    loop_locations = 0\n",
    "    \n",
    "    for location in tqdm(route):\n",
    "        guard_map.reset()\n",
    "        guard_map.add_obstacle(location)\n",
    "        while guard_map.move():\n",
    "            if guard_map.in_loop:\n",
    "                loop_locations += 1\n",
    "                break\n",
    "    \n",
    "    logger.debug(f\"Found {loop_locations} loop locations.\")\n",
    "    return loop_locations\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "....#.....\n",
    ".........#\n",
    "..........\n",
    "..#.......\n",
    ".......#..\n",
    "..........\n",
    ".#..^.....\n",
    "........#.\n",
    "#.........\n",
    "......#...\"\"\")\n",
    "sample_answers = [6]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 7: Bridge Repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"7\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 7 Part 1\n",
    "\n",
    "Our input data represents equations with operators missing! E.g.\n",
    "\n",
    "```text\n",
    "190: 10 19\n",
    "3267: 81 40 27\n",
    "83: 17 5\n",
    "156: 15 6\n",
    "7290: 6 8 6 15\n",
    "161011: 16 10 13\n",
    "192: 17 8 14\n",
    "21037: 9 7 18 13\n",
    "292: 11 6 16 20\n",
    "```\n",
    "\n",
    "- Operators are always evaluated left-to-right.\n",
    "- We have two operators to use: `+` and `*`\n",
    "\n",
    "By inserting operator combinations between numbers, determine which equations could possibly be true. **What is their total calibration result?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- First, convert the input data into a list of equations. Each equation will be a `tuple` of two parts: the required answer, and the tuple of all the integer numbers (parameters) of our equation.\n",
    "- For each tuple of numbers on the right of length `n`, there will be `n-1` operators to insert. E.g. with 3 numbers, we need every combination of 2 operators.\n",
    "- Let's use `itertools.product()` to determine the unique arrangements of `n-1` operators, given two operators. We use `product` because it allows us to repeat an operator. E.g. with `+` and `*` there will be four arrangements: `++`, `+*`, `*+`, and `**`. I'm doing this with a function called `get_op_perms()`.\n",
    "- I'm also caching this function. I can do this because the operators are always the same, so the arrangements are determnistic for any given required number of operators.\n",
    "\n",
    "We iterate through each `equation`:\n",
    "\n",
    "- First we get the arrangements of operators.\n",
    "- Then we loop through all arrangements of operators. Remember that each arrangement will be a tuple containing exactly the number of operators required between our numbers.\n",
    "- We apply the operator for each successive pair of numbers, always updating the \"left\" result such that it becomes the input to the next operation. I could do it like this:\n",
    "\n",
    "```python\n",
    "    res = nums[0]  # Initialize with the first number\n",
    "    for i, op in enumerate(op_perm):\n",
    "        res = apply_op((res, nums[i + 1]), op)\n",
    "```\n",
    "\n",
    "But this is a perfect use case for using the [reduce()](https://aoc.just2good.co.uk/python/map-filter-reduce#reduce) function (aka a \"fold\"):\n",
    "\n",
    "```python\n",
    "    res = reduce(lambda acc, op_and_right: apply_op((acc, op_and_right[1]), op_and_right[0]),\n",
    "                 zip(op_perm, nums[1:]), # zip the operator with the next number\n",
    "                 nums[0])  # Start with the first number\n",
    "```\n",
    "\n",
    "The `reduce()` function works by applying the specified function successively to every pair of elements in our list. With each iteration, it stores the result in an \"aggregator\" and then uses this aggregator as the left-hand input to the next iteration.\n",
    "\n",
    "The lambda function itself defines a function with two parameters: the aggregator, and a tuple which contains the current `(operator, right-number)`. Note that we have to specify the initial value of the aggregator, which is the first number in our list.\n",
    "\n",
    "(Now I've done this, I think the first approach is more readable.  But oh well!)\n",
    "\n",
    "This bit is important: **We only require our equation to be valid once. So we should break the loop after adding the equation value to our total.**\n",
    "\n",
    "I've also created a function for applying the operator, called `apply_op()`. This makes use of the in-built `operator` module, which has a number of fuctions like `add()`, `mul()`, etc. This is useful because we can pick the appropriate function based on the `op` string, and pass our two numbers in as parameters to each of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(data) -> list[tuple]:\n",
    "    \"\"\" Return equations in the form: [(answer, numbers), ...] \"\"\"\n",
    "    equations = []\n",
    "    for line in data:\n",
    "        ans, nums = line.split(\":\")\n",
    "        ans = int(ans)\n",
    "        nums = list(map(int, nums.split()))\n",
    "        equations.append((ans, nums))\n",
    "        \n",
    "    return equations\n",
    "\n",
    "@cache\n",
    "def get_op_perms(ops: str, num_parameters: int):\n",
    "    \"\"\" \n",
    "    Return all the ways of ordering our operators for a given number of parameters.\n",
    "    E.g. if ops == \"+*\" and there are 3 parameters, then we need all permutations of 2 operators: \n",
    "    [(\"+\", \"+\"), (\"+\", \"*\"), (\"*\", \"+\"), (\"*\", \"*\")]\n",
    "    \"\"\"\n",
    "    op_perms = list(product(ops, repeat=num_parameters-1))\n",
    "    logger.debug(f\"Number of op perms with {num_parameters-1} insertions: {len(op_perms)}\")\n",
    "    return op_perms\n",
    "    \n",
    "def apply_op(num_pair: tuple[int], op: str) -> int:\n",
    "    match op: # Note Python's implementatiom of switch\n",
    "        case \"+\":\n",
    "            return operator.add(*num_pair)\n",
    "        case \"*\":\n",
    "            return operator.mul(*num_pair)\n",
    "        case \"|\":\n",
    "            return int(\"\".join(str(num) for num in num_pair))\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown operator: {op}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(data, ops):\n",
    "    equations = process_input(data) # [0] is the ans; [1] are the numbers\n",
    "    total = 0\n",
    "    \n",
    "    for equation in tqdm(equations):\n",
    "        nums = equation[1]\n",
    "        \n",
    "        # get a list of operator combinations, with each element being of length n-1\n",
    "        # E.g. with 3 numbers, we'll get: [('+', '+'), ('+', '*'), ('*', '+'), ('*', '*')]\n",
    "        op_perms = get_op_perms(ops, len(nums))\n",
    "\n",
    "        for op_perm in op_perms: # a tuple of operators of length n-1\n",
    "            ans = reduce(lambda acc, op_and_right: apply_op((acc, op_and_right[1]), op_and_right[0]),\n",
    "                         zip(op_perm, nums[1:]), # zip the operator with the next number\n",
    "                         nums[0])  # Start with the first number\n",
    "\n",
    "            if ans == equation[0]:\n",
    "                total += equation[0] \n",
    "                break # we only need one successful result per equestion\n",
    "         \n",
    "    return total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "190: 10 19\n",
    "3267: 81 40 27\n",
    "83: 17 5\n",
    "156: 15 6\n",
    "7290: 6 8 6 15\n",
    "161011: 16 10 13\n",
    "192: 17 8 14\n",
    "21037: 9 7 18 13\n",
    "292: 11 6 16 20\"\"\")\n",
    "sample_answers = [3749]\n",
    "\n",
    "OPERATORS = \"+*\"\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input.splitlines(), OPERATORS), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve(input_data, OPERATORS)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 7 Part 2\n",
    "\n",
    "Oh, surprise.  There's a third operator. The op `||` combines digits from left and right into a single number. E.g. `12 || 345` results in `12345`.\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "It's dead easy to incorporate this. I've just added a new operator to my `apply_op()` function. However, rather than calling it `||`, I've called it `|`. This way, I can just include it in my string of operators: `+*|`.\n",
    "\n",
    "Of course this means that we'll get a lot more arrangements of operators. E.g.\n",
    "\n",
    "| Number of Op Insertions | Arrangements with 2 operators | Arrangements with 3 operators |\n",
    "|---|--|---|\n",
    "| 1 | 2 | 3 |\n",
    "| 2 | 4 | 9 |\n",
    "| 3 | 8 | 27 |\n",
    "| 4 | 16 | 81 |\n",
    "| 5 | 32 | 243 |\n",
    "| 6 | 64 | 729 |\n",
    "\n",
    "So it takes a little while to run. On my laptop this is taking 12 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "190: 10 19\n",
    "3267: 81 40 27\n",
    "83: 17 5\n",
    "156: 15 6\n",
    "7290: 6 8 6 15\n",
    "161011: 16 10 13\n",
    "192: 17 8 14\n",
    "21037: 9 7 18 13\n",
    "292: 11 6 16 20\"\"\")\n",
    "sample_answers = [11387]\n",
    "\n",
    "OPERATORS = \"+*|\"\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input.splitlines(), OPERATORS), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve(input_data, OPERATORS)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 8: Resonant Collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"8\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 8 Part 1\n",
    "\n",
    "Our grid represents a city containing antennae. Each antenna is tuned to a particular frequency given by a single lowercase letter, uppercase letter, or digit. E.g.\n",
    "\n",
    "```text\n",
    "............\n",
    "........0...\n",
    ".....0......\n",
    ".......0....\n",
    "....0.......\n",
    "......A.....\n",
    "............\n",
    "............\n",
    "........A...\n",
    ".........A..\n",
    "............\n",
    "............\n",
    "```\n",
    "\n",
    "- _Antinodes_ are created at any point where two antenna of the same frequenty are aligned, but where one is twice as far away as other. \n",
    "- This means that for any pair of antennas with the same frequency, there are two antinodes, one on either side of them.\n",
    "- An antinode can _can_ occur at locations that contain antennae.\n",
    "\n",
    "**How many unique locations within the bounds of the map contain an antinode?**\n",
    "\n",
    "I'm going to extend my `Grid` class again, to make a `NodeGrid` class.\n",
    "\n",
    "We start by initialing a dictionary containing a set of locations for each antenna when find. Use a `defaultdict(set)` for this, so that we can just add a location, every time we find one for a given frequency.\n",
    "\n",
    "Next, the heart of the problem: my `_update_antinodes()` method:\n",
    "\n",
    "- First, we retrieve the set of antennae locations for a given frequency.\n",
    "- Then, we determine all the pairs of locations for this frequency. Note that these are edges in an undirected graph. The number of edges for a given number of antennae will be:\n",
    "\n",
    "$$\n",
    "  p = \\frac{n(n-1)}{2} \n",
    "$$\n",
    "\n",
    "E.g.\n",
    "\n",
    "| Number of Antennae | Number of Edges |\n",
    "|---|---|\n",
    "| 1 | 0 |\n",
    "| 2 | 1 |\n",
    "| 3 | 3 |\n",
    "| 4 | 6 |\n",
    "| 5 | 10 |\n",
    "\n",
    "(Oooh look! Triangle numbers!)\n",
    "\n",
    "For each pair, I determine the vector between the points. This is my `delta`.\n",
    "\n",
    "Now, to determine the required antinode locations, we need to find the locations that are exactly one delta before the pair, and one delta after the pair. E.g. for two points `X` and `Y`, our antinodes will be found at:\n",
    "\n",
    "`------*----X----Y----*-----------`\n",
    "\n",
    "We can do this by subtracting the delta from `X`, and by adding the delta to `Y`. Or, perhaps more reusable (and this turns out to be quite useful in Part 2!), we can just add two vectors to `X`:\n",
    "\n",
    "1. Add `-1 * delta`\n",
    "1. Add `2 * delta`\n",
    "\n",
    "Each time we add our required number of deltas, check if the new location is within our grid.  If it is, we've found an antinode and we add it to our `_antinodes` set.\n",
    "\n",
    "Pretty simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeGrid(Grid):\n",
    "    def __init__(self, grid_array):\n",
    "        super().__init__(grid_array)\n",
    "        \n",
    "        self._antennae_by_freq: dict[str, set[Point]] = defaultdict(set)\n",
    "        self._populate_antennae()\n",
    "        \n",
    "        self._antinodes: set[Point] = set()\n",
    "    \n",
    "    @property\n",
    "    def antinodes(self):\n",
    "        return self._antinodes\n",
    "    \n",
    "    def _populate_antennae(self):\n",
    "        \"\"\" Populate our dict of antennae locations, as { freq: (loc1, loc2...), freq: (loc1, loc2...), ... }\"\"\"\n",
    "        for point in self._all_points:\n",
    "            val = self.value_at_point(point)\n",
    "            if val != \".\":\n",
    "                self._antennae_by_freq[val].add(point)\n",
    "        \n",
    "        for freq, locations in self._antennae_by_freq.items():\n",
    "            logger.debug(f\"{freq=},{locations=}\")\n",
    "                \n",
    "    def update_antinodes(self, resonant=False):\n",
    "        \"\"\" Find antinodes.\n",
    "        If resonant, these are any multiples of the distance between two nodes\n",
    "        including the nodes themselves.\n",
    "        Otherwise, just one antinode either side of our pair. \"\"\"\n",
    "        \n",
    "        for antenna_freq in self._antennae_by_freq.keys(): # a frequency\n",
    "            antennae = self._antennae_by_freq[antenna_freq]\n",
    "            \n",
    "            if resonant:\n",
    "                # If there are more than two antennae, these will be part of the resonant node set\n",
    "                if len(antennae) > 1:\n",
    "                    self._antinodes.update(antennae)                \n",
    "            \n",
    "            # Get all the undirected edges between these frequencies\n",
    "            edges = list(combinations(antennae, 2))\n",
    "            \n",
    "            # For each edge, calculate the antinodes\n",
    "            for edge in edges:\n",
    "                delta: Point = edge[1] - edge[0]\n",
    "                \n",
    "                for sign in [-1, 1]:\n",
    "                    delta_multiple = 2 if sign == 1 else -1\n",
    "                    \n",
    "                    while True:\n",
    "                        an = edge[0] + Point(delta_multiple*delta.x, \n",
    "                                             delta_multiple*delta.y)\n",
    "                        \n",
    "                        # Check not outside of grid\n",
    "                        if self.valid_location(an):\n",
    "                            self._antinodes.add(an)\n",
    "                        else:\n",
    "                            break # We can't go further in this direction\n",
    "                        \n",
    "                        if not resonant:\n",
    "                            break # We only want the first delta in this direction\n",
    "                        else:\n",
    "                            delta_multiple += sign\n",
    "            \n",
    "    def __str__(self) -> str:\n",
    "        \"\"\" Render the grid. Antinodes are shown in yellow. \"\"\"\n",
    "        row_strs = []\n",
    "        for y, row in enumerate(self._array):\n",
    "            row_list = [] if y > 0 else [Fore.RESET]  # Build a list of characters for each row\n",
    "            for x, char in enumerate(row):\n",
    "                if Point(x, y) in self._antinodes:\n",
    "                    row_list.append(Fore.YELLOW)\n",
    "                    row_list.extend([\"*\" if char == \".\" else char])\n",
    "                    row_list.append(Fore.RESET)\n",
    "                else:\n",
    "                    row_list.append(char)\n",
    "            row_strs.append(\"\".join(row_list))  # Efficiently join the characters\n",
    "\n",
    "        return \"\\n\".join(row_strs) # and the rows        \n",
    "          \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    node_grid = NodeGrid(data)\n",
    "    node_grid.update_antinodes()\n",
    "    logger.debug(f\"\\n{node_grid}\")\n",
    "    \n",
    "    return len(node_grid.antinodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "............\n",
    "........0...\n",
    ".....0......\n",
    ".......0....\n",
    "....0.......\n",
    "......A.....\n",
    "............\n",
    "............\n",
    "........A...\n",
    ".........A..\n",
    "............\n",
    "............\"\"\")\n",
    "sample_answers = [14]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 8 Part 2\n",
    "\n",
    "Now we're told that: _\"an antinode occurs at any grid position exactly in line with at least two antennas of the same frequency, regardless of distance.\"_\n",
    "\n",
    "Actually, what this means is that an antinode can appear at any integer multiple of the distance. E.g.\n",
    "\n",
    "`-*----*----X----Y----*----*----*-`\n",
    "\n",
    "**Important point: the `X` and `Y` are now also antinodes.**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "This is a trivial tweak to my code for part 1. First, let's add a parameter to the function to determine if we're in `resonant` mode or not.\n",
    "\n",
    "And now, instead of just adding deltas `-1` and `2`, I now just add `n` deltas, until the resulting location is out of the grid. I also iterate through signs `[-1, 1]` to determine how to increment the `delta_multiple`, and also to determine where to start, i.e. `-1` or `2` respectively. \n",
    "\n",
    "Also, if we're in `resonant` mode, we mustn't forget to the antennae locations to our set.\n",
    "\n",
    "And that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    node_grid = NodeGrid(data)\n",
    "    node_grid.update_antinodes(resonant=True)\n",
    "    logger.debug(f\"\\n{node_grid}\")\n",
    "    \n",
    "    return len(node_grid.antinodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "............\n",
    "........0...\n",
    ".....0......\n",
    ".......0....\n",
    "....0.......\n",
    "......A.....\n",
    "............\n",
    "............\n",
    "........A...\n",
    ".........A..\n",
    "............\n",
    "............\"\"\")\n",
    "sample_answers = [34]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 9: title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"9\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 9 Part 1\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"abcdef\"\"\")\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 9 Part 2\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"abcdef\"\"\")\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day n: title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"n\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day n Part 1\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"abcdef\"\"\")\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day n Part 2\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"abcdef\"\"\")\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".AoC-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
