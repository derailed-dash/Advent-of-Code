{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "This notebook contains my solutions for **<a href=\"https://adventofcode.com/2024\" target=\"_blank\">Advent of Code 2024</a>**.\n",
    "\n",
    "A few notes...\n",
    "- The source for this notebook source lives in my GitHub repo, <a href=\"https://github.com/derailed-dash/Advent-of-Code/blob/master/src/AoC_2024/Dazbo's_Advent_of_Code_2024.ipynb\" target=\"_blank\">here</a>.\n",
    "- You can run this Notebook wherever you like. For example, you could...\n",
    "  - Run it locally, in your own Jupyter environment.\n",
    "  - Run it in a cloud-based Jupyter environment, with no setup required on your part!  For example, with **Google Colab**: <br><br><a href=\"https://colab.research.google.com/github/derailed-dash/Advent-of-Code/blob/master/src/AoC_2024/Dazbo's_Advent_of_Code_2024.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Google Colab\"/></a><br>\n",
    "  - For more ways to run Jupyter Notebooks, check out [my guide](https://medium.com/python-in-plain-english/five-ways-to-run-jupyter-labs-and-notebooks-23209f71e5c0).\n",
    "- **To run the notebook, execute the cells in the [Setup](#Setup) section, as described below. Then you can run the code for any given day.**\n",
    "- Be mindful that the first time you run this notebook, you will need to **obtain your AoC session key** and store it, if you have not done so already. This allows the notebook to automatically retrieve your input data. (See the guidance in the **[Get Access to Your AoC Data](#Get-Access-to-Your-AoC-Data)** section for details.)\n",
    "- Use the navigation menu on the left to jump to any particular day.\n",
    "- All of my AoC solutions are documented in my <a href=\"https://aoc.just2good.co.uk/\" target=\"_blank\">AoC Python Walkthrough site</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3PMQJRrR38P",
    "tags": []
   },
   "source": [
    "# Setup\n",
    "\n",
    "You need to run all cells in this section, before running any particular day solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWxsAMaXTGEQ"
   },
   "source": [
    "## Packages and Imports\n",
    "\n",
    "Here we use `pip` to install the packages used by my solutions in this event. After installing the packages, you may need to restart your Jupyter kernel in order for the packages to be detected and remove any linting errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Dgeww1rMrkQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --no-cache-dir \\\n",
    "    jupyterlab-lsp ipykernel ipywidgets \\\n",
    "    matplotlib pandas networkx  sympy \\\n",
    "    dazbo-commons \\\n",
    "    colorama python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5Ki_HvOJUWk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import ast\n",
    "import copy\n",
    "import heapq\n",
    "import logging\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "import platform\n",
    "import re\n",
    "from collections import Counter, deque, defaultdict\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from enum import Enum, auto\n",
    "from functools import cache, reduce\n",
    "from itertools import combinations, count, cycle, permutations, product, groupby\n",
    "from getpass import getpass\n",
    "from numbers import Number\n",
    "from pathlib import Path\n",
    "from typing import NamedTuple, ClassVar\n",
    "\n",
    "# Third-party imports\n",
    "import dazbo_commons as dc  # my own utility library, which includes things like coloured logging\n",
    "import requests\n",
    "import sympy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from colorama import Fore, Back, Style\n",
    "from dotenv import load_dotenv\n",
    "from IPython.core.display import Markdown\n",
    "from IPython.display import display\n",
    "from IPython.display import Video\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZNTgtGzUImv",
    "tags": []
   },
   "source": [
    "## Logging and Output\n",
    "\n",
    "Set up a new logger that uses `ColouredFormatter`, such that we have coloured logging.  The log colour depends on the logging level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwzjfUFCKhXe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup logger\n",
    "YEAR = 2024\n",
    "APP_NAME = \"aoc\" + str(YEAR)\n",
    "logger = dc.retrieve_console_logger(APP_NAME)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.info(\"Logger initialised.\")\n",
    "logger.debug(\"Debugging enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages\n",
    "\n",
    "- [ffmpeg](https://ffmpeg.org/): in order to render video output, i.e. for visualisations.\n",
    "- graphviz: for visualising graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_command(command):\n",
    "    \"\"\"Run a shell command and print its output in real-time.\"\"\"\n",
    "    process = subprocess.Popen(\n",
    "        command, \n",
    "        shell=True, \n",
    "        stdout=subprocess.PIPE, \n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "    \n",
    "    # Read and print the output line by line\n",
    "    if process.stdout is not None:\n",
    "        for line in iter(process.stdout.readline, b''):\n",
    "            logger.info(line.decode().strip())\n",
    "        process.stdout.close()\n",
    "        \n",
    "    process.wait()\n",
    "    \n",
    "def install_software(appname: str):\n",
    "    os_name = platform.system()\n",
    "    logger.info(f\"Installing {appname} on {os_name}...\")\n",
    "    \n",
    "    # Mapping operating systems to their respective installation commands\n",
    "    command_map = {\n",
    "        \"Windows\": f\"winget install {appname} --silent --no-upgrade\",\n",
    "        \"Linux\": f\"apt -qq -y install {appname}\",\n",
    "        \"Darwin\": f\"brew install {appname}\"\n",
    "    }\n",
    "    command = command_map.get(os_name)\n",
    "    if command:\n",
    "        run_command(command)\n",
    "    else:\n",
    "        logger.error(f\"Unsupported operating system: {os_name}\")\n",
    "\n",
    "def check_installed(app_exec: str) -> bool:    \n",
    "    appname, *arg = app_exec.split()\n",
    "    arg = \" \".join(arg)\n",
    "    logger.debug(f\"Checking if {appname} is installed\")\n",
    "    \n",
    "    try:\n",
    "        output = subprocess.check_output([appname, arg], stderr=subprocess.STDOUT)\n",
    "        logger.debug(f\"{appname} version: {output.decode().strip()}\")\n",
    "        logger.debug(f\"{appname} is already installed.\")\n",
    "        return True\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "        logger.debug(f\"{appname} is not installed or absent from path.\")\n",
    "        \n",
    "    return False\n",
    "\n",
    "apps = [ (\"ffmpeg\", \"ffmpeg -version\"),\n",
    "         (\"graphviz\", \"dot --version\") ]\n",
    "          \n",
    "for app_install, app_exec in apps:\n",
    "    if not check_installed(app_exec):\n",
    "        install_software(app_install)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9A24B4MSyhT"
   },
   "source": [
    "## Load Helpers and Useful Classes\n",
    "\n",
    "Now we load a bunch of helper functions and classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPOsmENmYf8h",
    "tags": []
   },
   "source": [
    "### Locations\n",
    "\n",
    "Where any input and output files get stored.\n",
    "\n",
    "<img src=\"https://aoc.just2good.co.uk/assets/images/notebook-content-screenshot.png\" width=\"320\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14ISscMTadAO"
   },
   "source": [
    "### Retrieve the Input Data\n",
    "\n",
    "This works by using your unique session cookie to retrieve your input data. E.g. from a URL like:\n",
    "\n",
    "`https://adventofcode.com/2024/day/1/input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwP0r3BAaxjt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Retrieving input data\n",
    "##################################################################\n",
    "\n",
    "def write_puzzle_input_file(year: int, day, locations: dc.Locations):\n",
    "    \"\"\" Use session key to obtain user's unique data for this year and day.\n",
    "    Only retrieve if the input file does not already exist.\n",
    "    Return True if successful.\n",
    "    Requires env: AOC_SESSION_COOKIE, which can be set from the .env.\n",
    "    \"\"\"\n",
    "    if os.path.exists(locations.input_file):\n",
    "        logger.debug(\"%s already exists\", os.path.basename(locations.input_file))\n",
    "        return os.path.basename(locations.input_file)\n",
    "\n",
    "    session_cookie = os.getenv('AOC_SESSION_COOKIE')\n",
    "    if not session_cookie:\n",
    "        raise ValueError(\"Could not retrieve session cookie.\")\n",
    "\n",
    "    logger.info('Session cookie retrieved: %s...%s', session_cookie[0:6], session_cookie[-6:])\n",
    "\n",
    "    # Create input folder, if it doesn't exist\n",
    "    if not locations.input_dir.exists():\n",
    "        locations.input_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    url = f\"https://adventofcode.com/{year}/day/{day}/input\"\n",
    "    \n",
    "    # Don't think we need to set a user-agent\n",
    "    # headers = {\n",
    "    #     \"User-Agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'\n",
    "    # }\n",
    "    cookies = { \n",
    "        \"session\": session_cookie\n",
    "    }\n",
    "    response = requests.get(url, cookies=cookies, timeout=5)\n",
    "\n",
    "    data = \"\"\n",
    "    if response.status_code == 200:\n",
    "        data = response.text\n",
    "\n",
    "        with open(locations.input_file, 'w') as file:\n",
    "            logger.debug(\"Writing input file %s\", os.path.basename(locations.input_file))\n",
    "            file.write(data)\n",
    "            return data\n",
    "    else:\n",
    "        raise ValueError(f\"Unable to retrieve input data.\\n\" +\n",
    "                         f\"HTTP response: {response.status_code}\\n\" +\n",
    "                         f\"{response.reason}: {response.content.decode('utf-8').strip()}\")\n",
    "        \n",
    "def show_day_link(day):\n",
    "    day_link = f\"#### See [Day {day}](https://adventofcode.com/{YEAR}/day/{day}).\"\n",
    "    display(Markdown(day_link))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yakibhW73Rqi"
   },
   "source": [
    "### Testing\n",
    "\n",
    "A really simple function for testing that our solution produces the expected test output. If the `validate()` call fails, then execution will stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6nbd6WMryWi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(test, answer):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        test: the answer given by our solution\n",
    "        answer: the expected answer, e.g. from instructions\n",
    "    \"\"\"\n",
    "    if test != answer:\n",
    "        raise AssertionError(f\"{test} != {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bcBQkP0a2zA"
   },
   "source": [
    "### Useful Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8sU4Ez_bBKl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# POINTS, VECTORS AND GRIDS\n",
    "#################################################################\n",
    "\n",
    "Point = NamedTuple(\"Point\", [(\"x\", Number), (\"y\", Number)])\n",
    "\n",
    "Point.__add__ = lambda self, other: Point(self.x + other.x, self.y + other.y)\n",
    "Point.__sub__ = lambda self, other: Point(self.x - other.x, self.y - other.y)\n",
    "Point.__mul__ = lambda self, scalar: Point(self.x * scalar, self.y * scalar)\n",
    "Point.__rmul__ = lambda self, scalar: self * scalar # for when int comes first\n",
    "\n",
    "def yield_neighbours(self, include_diagonals=True, include_self=False):\n",
    "    \"\"\" Generator to yield neighbouring Points \"\"\"\n",
    "\n",
    "    deltas: list\n",
    "    if not include_diagonals:\n",
    "        deltas = [vector.value for vector in Vectors if abs(vector.value.x) != abs(vector.value.y)]\n",
    "    else:\n",
    "        deltas = [vector.value for vector in Vectors]\n",
    "\n",
    "    if include_self:\n",
    "        deltas.append(Point(0, 0))\n",
    "\n",
    "    for delta in deltas:\n",
    "        yield self + delta\n",
    "\n",
    "def neighbours(self, include_diagonals=True, include_self=False) -> list[Point]:\n",
    "    return list(yield_neighbours(self, include_diagonals, include_self))\n",
    "\n",
    "def get_specific_neighbours(self, directions) -> list[Point]:\n",
    "    return [self + vector.value for vector in list(directions)]\n",
    "\n",
    "def manhattan_distance(a_point: Point):\n",
    "    return sum(abs(coord) for coord in asdict(a_point).values())\n",
    "\n",
    "def manhattan_distance_from(self, other):\n",
    "    diff = self - other\n",
    "    return manhattan_distance(diff)\n",
    "\n",
    "Point.yield_neighbours = yield_neighbours\n",
    "Point.neighbours = neighbours\n",
    "Point.get_specific_neighbours = get_specific_neighbours\n",
    "Point.manhattan_distance = staticmethod(manhattan_distance)\n",
    "Point.manhattan_distance_from = manhattan_distance_from\n",
    "Point.__repr__ = lambda self: f\"P({self.x},{self.y})\" \n",
    "\n",
    "class Vectors(Enum):\n",
    "    \"\"\" Enumeration of 8 directions.\n",
    "    Note: y axis increments in the North direction, i.e. N = (0, 1) \"\"\"\n",
    "    N = Point(0, 1)\n",
    "    NE = Point(1, 1)\n",
    "    E = Point(1, 0)\n",
    "    SE = Point(1, -1)\n",
    "    S = Point(0, -1)\n",
    "    SW = Point(-1, -1)\n",
    "    W = Point(-1, 0)\n",
    "    NW = Point(-1, 1)\n",
    "\n",
    "    @property\n",
    "    def y_inverted(self):\n",
    "        \"\"\" Return vector, but with y-axis inverted. I.e. N = (0, -1) \"\"\"\n",
    "        x, y = self.value\n",
    "        return Point(x, -y)\n",
    "\n",
    "class VectorDicts():\n",
    "    \"\"\" Contains constants for Vectors \"\"\"\n",
    "    ARROWS = {\n",
    "        '^': Vectors.N.value,\n",
    "        '>': Vectors.E.value,\n",
    "        'v': Vectors.S.value,\n",
    "        '<': Vectors.W.value\n",
    "    }\n",
    "\n",
    "    DIRS = {\n",
    "        'U': Vectors.N.value,\n",
    "        'R': Vectors.E.value,\n",
    "        'D': Vectors.S.value,\n",
    "        'L': Vectors.W.value\n",
    "    }\n",
    "\n",
    "    NINE_BOX: dict[str, tuple[int, int]] = {\n",
    "        # x, y vector for adjacent locations\n",
    "        'tr': (1, 1),\n",
    "        'mr': (1, 0),\n",
    "        'br': (1, -1),\n",
    "        'bm': (0, -1),\n",
    "        'bl': (-1, -1),\n",
    "        'ml': (-1, 0),\n",
    "        'tl': (-1, 1),\n",
    "        'tm': (0, 1)\n",
    "    }\n",
    "\n",
    "class Grid():\n",
    "    \"\"\" 2D grid of point values. \"\"\"\n",
    "    def __init__(self, grid_array: list) -> None:\n",
    "        self._array = [list(row) for row in grid_array.copy()]\n",
    "        self._width = len(self._array[0])\n",
    "        self._height = len(self._array)\n",
    "        \n",
    "        self._all_points = [Point(x,y) for y in range(self._height) for x in range(self._width)]\n",
    "\n",
    "    def value_at_point(self, point: Point):\n",
    "        \"\"\" The value at this point \"\"\"\n",
    "        return self._array[point.y][point.x]\n",
    "\n",
    "    def set_value_at_point(self, point: Point, value):\n",
    "        self._array[point.y][point.x] = value\n",
    "\n",
    "    def valid_location(self, point: Point) -> bool:\n",
    "        \"\"\" Check if a location is within the grid \"\"\"\n",
    "        if (0 <= point.x < self._width and  0 <= point.y < self._height):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def width(self):\n",
    "        \"\"\" Array width (cols) \"\"\"\n",
    "        return self._width\n",
    "\n",
    "    @property\n",
    "    def height(self):\n",
    "        \"\"\" Array height (rows) \"\"\"\n",
    "        return self._height\n",
    "\n",
    "    def all_points(self) -> list[Point]:\n",
    "        return self._all_points\n",
    "\n",
    "    def rows_as_str(self):\n",
    "        \"\"\" Return the grid \"\"\"\n",
    "        return [\"\".join(str(char) for char in row) for row in self._array]\n",
    "\n",
    "    def cols_as_str(self):\n",
    "        \"\"\" Render columns as str. Returns: list of str \"\"\"\n",
    "        cols_list = list(zip(*self._array))\n",
    "        return [\"\".join(str(char) for char in col) for col in cols_list]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Grid(size={self.width}*{self.height})\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"\\n\".join(\"\".join(map(str, row)) for row in self._array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xNijk6xbCVa"
   },
   "source": [
    "### Useful Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DT5FSYliC9wp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# CONSOLE STUFF\n",
    "#################################################################\n",
    "\n",
    "def cls():\n",
    "    \"\"\" Clear console \"\"\"\n",
    "    os.system('cls' if os.name=='nt' else 'clear')\n",
    "\n",
    "#################################################################\n",
    "# USEFUL FUNCTIONS\n",
    "#################################################################\n",
    "\n",
    "def binary_search(target, low:int, high:int, func, *func_args, reverse_search=False):\n",
    "    \"\"\" Generic binary search function that takes a target to find,\n",
    "    low and high values to start with, and a function to run, plus its args.\n",
    "    Implicitly returns None if the search is exceeded. \"\"\"\n",
    "\n",
    "    res = None  # just set it to something that isn't the target\n",
    "    candidate = 0  # initialise; we'll set it to the mid point in a second\n",
    "\n",
    "    while low < high:  # search exceeded\n",
    "        candidate = int((low+high) // 2)  # pick mid-point of our low and high\n",
    "        res = func(candidate, *func_args) # run our function, whatever it is\n",
    "        logger.debug(\"%d -> %d\", candidate, res)\n",
    "        if res == target:\n",
    "            return candidate  # solution found\n",
    "\n",
    "        comp = operator.lt if not reverse_search else operator.gt\n",
    "        if comp(res, target):\n",
    "            low = candidate\n",
    "        else:\n",
    "            high = candidate\n",
    "\n",
    "def merge_intervals(intervals: list[list]) -> list[list]:\n",
    "    \"\"\" Takes intervals in the form [[a, b][c, d][d, e]...]\n",
    "    Intervals can overlap.  Compresses to minimum number of non-overlapping intervals. \"\"\"\n",
    "    intervals.sort()\n",
    "    stack = []\n",
    "    stack.append(intervals[0])\n",
    "\n",
    "    for interval in intervals[1:]:\n",
    "        # Check for overlapping interval\n",
    "        if stack[-1][0] <= interval[0] <= stack[-1][-1]:\n",
    "            stack[-1][-1] = max(stack[-1][-1], interval[-1])\n",
    "        else:\n",
    "            stack.append(interval)\n",
    "\n",
    "    return stack\n",
    "\n",
    "@cache\n",
    "def get_factors(num: int) -> set[int]:\n",
    "    \"\"\" Gets the factors for a given number. Returns a set[int] of factors.\n",
    "        # E.g. when num=8, factors will be 1, 2, 4, 8 \"\"\"\n",
    "    factors = set()\n",
    "\n",
    "    # Iterate from 1 to sqrt of 8,\n",
    "    # since a larger factor of num must be a multiple of a smaller factor already checked\n",
    "    for i in range(1, int(num**0.5) + 1):  # e.g. with num=8, this is range(1, 3)\n",
    "        if num % i == 0: # if it is a factor, then dividing num by it will yield no remainder\n",
    "            factors.add(i)  # e.g. 1, 2\n",
    "            factors.add(num//i)  # i.e. 8//1 = 8, 8//2 = 4\n",
    "\n",
    "    return factors\n",
    "\n",
    "def to_base_n(number: int, base: int):\n",
    "    \"\"\" Convert any integer number into a base-n string representation of that number.\n",
    "    E.g. to_base_n(38, 5) = 123\n",
    "\n",
    "    Args:\n",
    "        number (int): The number to convert\n",
    "        base (int): The base to apply\n",
    "\n",
    "    Returns:\n",
    "        [str]: The string representation of the number\n",
    "    \"\"\"\n",
    "    ret_str = \"\"\n",
    "    curr_num = number\n",
    "    while curr_num:\n",
    "        ret_str = str(curr_num % base) + ret_str\n",
    "        curr_num //= base\n",
    "\n",
    "    return ret_str if number > 0 else \"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env Clear\n",
    "\n",
    "Only run the next cell if you want to manually clear your session key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del os.environ['AOC_SESSION_COOKIE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y68fv1BebLsG"
   },
   "source": [
    "# Days\n",
    "\n",
    "Here you'll find a template to build a solution for a given day, and then the solutions for all days in this event.\n",
    "\n",
    "To copy the template day, select all the cells in the `Day n` template, add a new cell at the end, and then paste the cells there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 1: Historian Hysteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"1\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 1 Part 1\n",
    "\n",
    "We're told: historically significant locations are listed by a unique number called the location ID. The Historians have split into two groups, and each group has created their own list of locations.\n",
    "\n",
    "Our puzzle input is the two lists; i.e. presented as two columns of numbers. We need to reconcile the differences. E.g.\n",
    "\n",
    "```text\n",
    "3   4\n",
    "4   3\n",
    "2   5\n",
    "1   3\n",
    "3   9\n",
    "3   3\n",
    "```\n",
    "\n",
    "Goal:\n",
    "\n",
    "- Pair the smallest number in the two lists, and measure the difference.\n",
    "- Then the second smallest number from each list, and so on.\n",
    "- Return the sum of differences.\n",
    "\n",
    "**What is the total distance between your lists?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "1. Build two lists by splitting each line into two numbers. We can easily do this by [reading each line](https://aoc.just2good.co.uk/python/reading_files), and calling the `split()` function, which automatically splits on the whitespace between the numbers. For each row, we now end up with two numbers, but returned as string values. So we use [map()](https://aoc.just2good.co.uk/python/map-filter-reduce) to turn the strings into integer types. Now we have a pair of integer numbers for each line, which we wrap in a tuple and return in a [list comprehension](https://aoc.just2good.co.uk/python/comprehensions). I.e. one list containing tuples, which are each a pair of integers. Finally, we use the [zip()](https://aoc.just2good.co.uk/python/zip) function to turn the list of tuples pairs into a pair of lists: one list for left column, and one list for the right column.\n",
    "1. Sort the two lists, such that the smallest number in each column comes first, and so on.\n",
    "1. Find the absolute difference between each pair of numbers, and sum these differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def process_data(data) -> tuple[list[int], list[int]]:\n",
    "    items = [tuple(map(int, line.split())) for line in data] # returns list of tuples, e.g. [(3, 5), ...]\n",
    "    list1, list2 = zip(*items) # list of all lefts, plus list of all rights\n",
    "    return sorted(list1), sorted(list2)\n",
    "\n",
    "def solve_part1(data) -> int:\n",
    "    list1, list2 = process_data(tuple(data))\n",
    "    \n",
    "    diff = 0\n",
    "    for item1, item2 in zip(list1, list2):\n",
    "        diff += abs(item2 - item1)\n",
    "        \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "3   4\n",
    "4   3\n",
    "2   5\n",
    "1   3\n",
    "3   9\n",
    "3   3\n",
    "\"\"\")\n",
    "sample_answers = [11]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 1 Part 2\n",
    "\n",
    "Figure out exactly how often each number from the left list appears in the right list. Calculate a total similarity score by adding up each number in the left list after multiplying it by the number of times that number appears in the right list.\n",
    "\n",
    "**What is their similarity score?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "1. For each item in list1, count how many times it appears in list2.\n",
    "1. Add the product of the item and the count to our score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    list1, list2 = process_data(tuple(data))\n",
    "    \n",
    "    score = 0\n",
    "    for item in list1:\n",
    "        item_count = list2.count(item)\n",
    "        score += item * item_count\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sample_answers = [31]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Solutions\n",
    "\n",
    "We could also solve using [Numpy](https://aoc.just2good.co.uk/python/numpy). This will be more efficient for large arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _solve(data) -> int:\n",
    "    sorted_lists = process_data(tuple(data))\n",
    "    \n",
    "    # Create two Numpy arrays\n",
    "    list1 = np.array(sorted_lists[0])\n",
    "    list2 = np.array(sorted_lists[1])\n",
    "    \n",
    "    diff = np.sum(np.abs(list2-list1)) # The sum of item diffs\n",
    "    logger.info(f\"{diff=}\")\n",
    "    \n",
    "    similarity_score = 0\n",
    "    for item in list1:\n",
    "        item_count = (list2 == item).sum() # How many times the item appears in list2\n",
    "        similarity_score += item * item_count\n",
    "        \n",
    "    logger.info(f\"{similarity_score=}\")\n",
    "    \n",
    "_solve(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 2: Red-Nosed Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"2\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 2 Part 1\n",
    "\n",
    "Our data is a set of reports. Each line is one report. Each report contains a list of numbers called levels. Like this:\n",
    "\n",
    "```text\n",
    "7 6 4 2 1\n",
    "1 2 7 8 9\n",
    "9 7 6 2 1\n",
    "1 3 2 4 5\n",
    "8 6 4 4 1\n",
    "1 3 6 7 9\n",
    "```\n",
    "\n",
    "Reports are safe if:\n",
    "\n",
    "- The levels are either all increasing or all decreasing\n",
    "- And any two adjacent levels must differ by at least 1 and at most 3.\n",
    "\n",
    "**How many reports are safe?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- Split each record into a list of int values, called `levels`.\n",
    "- Create `is_safe()` function which:\n",
    "  - Creates a list of difference values - called `diffs` - by subtracting `levels` with offset 1 from `levels`.\n",
    "  - Then, use the `all` iterator operator function to check if our condition is true for every diff in `diffs`.\n",
    "  - The condition is: that every diff is positive and `<=MAX_DIFF` or every diff is negative and `>=MAX_DIFF`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_safe(levels: list[int], max_diff: int) -> bool:\n",
    "    \"\"\" Determine if a record - i.e. a list of levels - is safe.\n",
    "    Do this by determining the differences between each level in the record.\n",
    "    Check if the differences are all positive and within the max, \n",
    "    or all negative and within the max. \"\"\"\n",
    "    \n",
    "    # Create pairs of levels from successive levels\n",
    "    # For each pair, substract second from first to get the difference\n",
    "    diffs = [first-second for first, second in zip(levels, levels[1:])]\n",
    "    \n",
    "    return (all(0 < diff <= max_diff for diff in diffs) or \n",
    "            all(-max_diff <= diff < 0 for diff in diffs))\n",
    "\n",
    "def solve_part1(data):\n",
    "    safe_count = 0\n",
    "    for report in data:\n",
    "        levels = list(map(int, report.split()))\n",
    "        if is_safe(levels, 3):\n",
    "            safe_count += 1\n",
    "    \n",
    "    return safe_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "7 6 4 2 1\n",
    "1 2 7 8 9\n",
    "9 7 6 2 1\n",
    "1 3 2 4 5\n",
    "8 6 4 4 1\n",
    "1 3 6 7 9\"\"\")\n",
    "sample_answers = [2]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 2 Part 2\n",
    "\n",
    "We now have a _Problem Dampener_, which means we can tolerate a single bad level in any given record.\n",
    "\n",
    "So we must try removing levels from records, and then testing if the report is safe.\n",
    "\n",
    "**How many reports are now safe?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "Same as before, but this time we will iterate through the index values of each record, and remove that level from the record. I.e.\n",
    "\n",
    "- Loop through each index value for the record.\n",
    "- For the current index value, concatenate the levels up to this index with the levels after this index. Thus, we always end up with a list that is one shorter than the original list. (Note that trimming off the first or last level will never make a safe record _unsafe_.)\n",
    "- Pass shortened list to our `is_safe()` function.\n",
    "- If the shortened record is safe, then we can add this record to our counter and move on to the next record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    safe_count = 0\n",
    "    for report in data:\n",
    "        levels = list(map(int, report.split()))\n",
    "\n",
    "        # Slice out one level at a time, and check if the new record is safe\n",
    "        for idx in range(len(levels)):\n",
    "            # Take levels up this idx, and concatenate with levels AFTER this idx\n",
    "            trimmed_levels = levels[:idx] + levels[idx+1:]\n",
    "            if is_safe(trimmed_levels, 3):\n",
    "                safe_count += 1\n",
    "                break\n",
    "    \n",
    "    return safe_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "7 6 4 2 1\n",
    "1 2 7 8 9\n",
    "9 7 6 2 1\n",
    "1 3 2 4 5\n",
    "8 6 4 4 1\n",
    "1 3 6 7 9\"\"\")\n",
    "sample_answers = [4]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 3: Mull It Over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"3\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3 Part 1\n",
    "\n",
    "A shop computer is trying to run a program, but its memory - the puzzle input - is corrupted.\n",
    "\n",
    "It should be doing instructions like:\n",
    "\n",
    "- `mul(X,Y)` where `X` and `Y` are 1-3 digit numbers.\n",
    "\n",
    "Our instructions:\n",
    "\n",
    "- There are many invalid characters which should be ignored.\n",
    "- If an invalid character is part of a `mul()` instruction, then the whole instruction does nothing.\n",
    "- Scan the corrupted memory for uncorrupted mul instructions.\n",
    "\n",
    "**What do you get if you add up all of the results of the multiplications?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "We can just use [regex](https://aoc.just2good.co.uk/python/regex).\n",
    "\n",
    "- Use a regex pattern to identify substrints that match the required input format.\n",
    "- Use the regex `finditer()` to retrieve all non-overlapping matches.\n",
    "- The `matches.groups()` retrieves the captured groups, i.e. the digits themselves. We identify capture groups by placing each digit in brackets in the pattern string.\n",
    "- Then, multiply the two digits together, as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    # match all \"mul(x,y)\"\n",
    "    matches = re.finditer(r\"mul\\((\\d{1,3}),(\\d{1,3})\\)\", data)\n",
    "    \n",
    "    ans = 0\n",
    "    for match in matches:\n",
    "        val_x, val_y = match.groups()\n",
    "        ans += int(val_x)*int(val_y)\n",
    "        \n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"xmul(2,4)%&mul[3,7]!@^do_not_mul(5,5)+mul(32,64]then(mul(11,8)mul(8,5))\"\"\")\n",
    "sample_answers = [161]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3 Part 2\n",
    "\n",
    "Now we also want to handle intact conditional statements. We need to handle:\n",
    "\n",
    "- `do()` which enables future `mul` instructions\n",
    "- `don't()` which disables future `mul` instructions.\n",
    "\n",
    "We start enabled.\n",
    "\n",
    "**What is the sum of just the enabled multiplications?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- Okay, we start `enabled`.\n",
    "- Whilst `enabled==True`, everything up to the next `don't()` should be parsed for `mul()` instructions.\n",
    "- When we hit a `don't()`, we set `enabled=False`.\n",
    "- Now, everything up to the next `do()` should be ignored.\n",
    "- When we hit a `do()`, we set `enabled=True` again.\n",
    "\n",
    "I'm shocked... This worked first time with no bugs!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data: str):\n",
    "    # match all \"mul(x,y)\"\n",
    "    matcher = re.compile(r\"mul\\((\\d{1,3}),(\\d{1,3})\\)\")\n",
    "    \n",
    "    remaining_program = data\n",
    "    enabled = True # We start enabled\n",
    "    ans = 0\n",
    "    while remaining_program:\n",
    "        if enabled:\n",
    "            # split into the part before the next \"don't()\", and everything afterwards\n",
    "            this_part, _, remaining_program = remaining_program.partition(r\"don't()\")\n",
    "        \n",
    "            for match in matcher.finditer(this_part):\n",
    "                val_x, val_y = match.groups()\n",
    "                ans += int(val_x)*int(val_y)\n",
    "            \n",
    "            enabled = False\n",
    "        else:\n",
    "            # split into the part before the next \"do()\", and everything afterwards\n",
    "            this_part, _, remaining_program = remaining_program.partition(r\"do()\")\n",
    "            enabled = True\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"xmul(2,4)&mul[3,7]!^don't()_mul(5,5)+mul(32,64](mul(11,8)undo()?mul(8,5))\"\"\")\n",
    "sample_answers = [48]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 4: Ceres Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"4\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 4 Part 1\n",
    "\n",
    "We have a word search! We need to find every instance of the word `XMAS`. The string can be found horizontally, vertically, diagonally, and in forward/reverse directions.\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- Create a dictinary to count how many times a given character is part of a matched word. Why did I do this?\n",
    "  - Firstly, we can use this dictionary to determine if any given character in the grid has been matched in a word. This makes it easy to print a grid that only shows matched characters. Useful for debugging!\n",
    "  - Secondly, I thought Part 2 might be asking where we have characters that are matched more than once, i.e. where words cross. This dict would have made it super easy for me to determine that. Alas, my guess was wrong!\n",
    "- Now move through each location in the grid, and stop whenever we find the `X` of `XMAS`.\n",
    "- Having identified the starting `X`, now iterate through all 8 possible directions.\n",
    "- For each direction, first determine if the full word can fit in the grid, i.e. that we don't get cut off by a grid edge.\n",
    "- If the word can fit, we then move one char at a time in the current direction, and test if the characters match the remaining characters in our word. \n",
    "- If all characters match, then we've matched the word and we can increment that `matches` counter.  But also, increment the counts for each character in this word.\n",
    "- Now, render a visualisation of the grid, showing a `.` whenever the count at this location is 0, else show the character at this location.#\n",
    "- Finally, return the total number of `matches`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    match_word = \"XMAS\"\n",
    "    matched_posn_counts = defaultdict(int) # increment whenever this index is in a matched word\n",
    "\n",
    "    grid_width = len(data[0])\n",
    "    grid_height = len(data)\n",
    "\n",
    "    matches = 0\n",
    "\n",
    "    # Iterate through all positions in the grid\n",
    "    for row_idx in range(grid_height):\n",
    "        for col_idx in range(grid_width):\n",
    "            # Find the X (first char)\n",
    "            if data[row_idx][col_idx] == match_word[0]:\n",
    "                # Now we want to expand in all directions\n",
    "                for direction in Vectors: # Loop through all directions\n",
    "\n",
    "                    # Check if the full word can be within the grid bounds\n",
    "                    chars_left = len(match_word)-1\n",
    "                    if not (0 <= (col_idx + chars_left*direction.value[0]) < grid_width):\n",
    "                        continue # try next direction\n",
    "                    if not (0 <= (row_idx + chars_left*direction.value[1]) < grid_height):\n",
    "                        continue # try next direction\n",
    "\n",
    "                    found_word = True\n",
    "\n",
    "                    # Test remaining letters in this direction\n",
    "                    for steps, char in enumerate(match_word[1:], start=1):\n",
    "                        new_row_idx = row_idx + steps*direction.value[1]\n",
    "                        new_col_idx = col_idx + steps*direction.value[0]\n",
    "                        if data[new_row_idx][new_col_idx] != char:\n",
    "                            found_word = False\n",
    "                            break\n",
    "\n",
    "                    if found_word:\n",
    "                        # Mark these all word locations as matched\n",
    "                        for steps, char in enumerate(match_word):\n",
    "                            new_row_idx = row_idx + steps*direction.value[1]\n",
    "                            new_col_idx = col_idx + steps*direction.value[0]\n",
    "                            matched_posn_counts[(new_col_idx, new_row_idx)] += 1\n",
    "                        \n",
    "                        matches += 1\n",
    "    \n",
    "    grid_rows = []\n",
    "    for row_idx in range(grid_height):\n",
    "        row_str = \"\"\n",
    "        for col_idx in range(grid_width):\n",
    "            row_str += data[row_idx][col_idx] if matched_posn_counts[(col_idx, row_idx)] > 0 else \".\"\n",
    "        \n",
    "        grid_rows.append(row_str)\n",
    "    \n",
    "    grid_vis = \"\\n\".join(grid_rows)\n",
    "    logger.info(f\"\\n{grid_vis}\")\n",
    "\n",
    "    return matches\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "MMMSXXMASM\n",
    "MSAMXMSMSA\n",
    "AMXSXMAAMM\n",
    "MSAMASMSMX\n",
    "XMASAMXAMM\n",
    "XXAMMXXAMA\n",
    "SMSMSASXSS\n",
    "SAXAMASAAA\n",
    "MAMMMXMMMM\n",
    "MXMXAXMASX\"\"\")\n",
    "sample_answers = [18]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")\n",
    "### Day 4 Part 2\n",
    "\n",
    "Quite different for part 2! Now we need to find any any X shape that contains \"MAS\" twice. E.g. a configuration like this:\n",
    "\n",
    "```text\n",
    "M.S\n",
    ".A.\n",
    "M.S\n",
    "```\n",
    "\n",
    "Observations:\n",
    "\n",
    "- The centre character will always be `A`.\n",
    "- The `M` and `S` characters each need to appear twice in the X.\n",
    "- The `MAS` must be spelled diagonally. So if `M` is in one corner, then `S` will be in the opposite corner.\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- Set up a moveable X grid, by storing a list of vectors that represent the corners: NE, SE, SW, NW.\n",
    "- Move the X through every possible location in the grid. We'll start by matching the `A` at the centre of the grid. For this reason, we should start at position `(1, 1)`, we will we will always stop one row / column before any given edge.\n",
    "- Having matched an `A`, determine the coordinates of the four corners.\n",
    "- Check that the four corners contain each remaining character (i.e. `M` or `S`) twice. If so, this location is a candidate.\n",
    "- If we've found a candidate, determine the char in the top-right corner. Then determine if the char in the bottom-left corner is the _other_ end character in our word. If it is, then we've got a match. Why? Because if we've verified this diagonal, then by previously verifying the character counts, we know that the other diagonal is also satisfied.\n",
    "\n",
    "And that's it! It's really quick too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    match_word = \"MAS\"\n",
    "    center = match_word[1] # `A`\n",
    "    ends = match_word[0] + match_word[-1] # `MS`\n",
    "\n",
    "    grid_width = len(data[0])\n",
    "    grid_height = len(data)\n",
    "\n",
    "    matches = 0\n",
    "\n",
    "    corner_vecs = [Vectors.NE.value,\n",
    "                   Vectors.SE.value,\n",
    "                   Vectors.SW.value,\n",
    "                   Vectors.NW.value]\n",
    "\n",
    "    # Traverse the grid, but always inset by 1\n",
    "    for row_num in range(1, grid_height-1):\n",
    "        for col_num in range(1, grid_width-1):\n",
    "            current_centre = data[row_num][col_num]\n",
    "            # Does middle of the X contain the A of \"MAS\"?\n",
    "            if current_centre == center:\n",
    "                corners = [(col_num+dx, row_num+dy) for dx, dy in corner_vecs]\n",
    "                corner_chars = [data[y][x] for x, y in corners]\n",
    "\n",
    "                # Check that each end char appears in the X exactly twice\n",
    "                if all(corner_chars.count(char) == 2 for char in ends):\n",
    "                    # if top right char is the opposite end char to bottom left char, we're matched\n",
    "                    tr_char = data[corners[0][1]][corners[0][0]]\n",
    "                    bl_char = data[corners[2][1]][corners[2][0]]\n",
    "                    tr_match_idx = ends.index(tr_char)\n",
    "                    if bl_char == ends[(len(ends)-tr_match_idx)-1]:\n",
    "                        matches += 1\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "MMMSXXMASM\n",
    "MSAMXMSMSA\n",
    "AMXSXMAAMM\n",
    "MSAMASMSMX\n",
    "XMASAMXAMM\n",
    "XXAMMXXAMA\n",
    "SMSMSASXSS\n",
    "SAXAMASAAA\n",
    "MAMMMXMMMM\n",
    "MXMXAXMASX\"\"\")\n",
    "sample_answers = [9]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 5: Print Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"5\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 5 Part 1\n",
    "\n",
    "Out input is in two blocks:\n",
    "\n",
    "1. The page order rules - one rule per line. These are pairs of rules, e.g. `47|53`. This means that `if` an update contains *both* of these page numbers, then page `47` must be printed at some point *before* `53`.\n",
    "1. The specified page numbers required in a particular update - one update set per line.\n",
    "\n",
    "The sample input:\n",
    "\n",
    "```text\n",
    "47|53\n",
    "97|13\n",
    "97|61\n",
    "97|47\n",
    "75|29\n",
    "61|13\n",
    "75|53\n",
    "29|13\n",
    "97|29\n",
    "53|29\n",
    "61|53\n",
    "97|53\n",
    "61|29\n",
    "47|13\n",
    "75|47\n",
    "97|75\n",
    "47|61\n",
    "75|61\n",
    "47|29\n",
    "75|13\n",
    "53|13\n",
    "\n",
    "75,47,61,53,29\n",
    "97,61,53,29,13\n",
    "75,29,13\n",
    "75,97,47,61,53\n",
    "61,13,29\n",
    "97,13,75,29,47\n",
    "```\n",
    "\n",
    "**What is the sum of middle page numbers from only the updates are correctly ordered?**\n",
    "\n",
    "#### Observations\n",
    "\n",
    "Rules for a given update:\n",
    "\n",
    "- For any page number N, there must NOT be a rule `B|N` for any `B` that comes AFTER it.\n",
    "- For any page number N, there must NOT be a rule `N|A` for any `A` that comes BEFORE it.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- The rules appear to be a complete set, meaning that there wil be a rule for _every_ possible pair of pages. Or, to put it another way: if `A|B` and `B|C`, then there will always be a rule `A|C`. This rule will be provided; we do not have to derive it implicitly.\n",
    "- A given update does necessarily include every page and therefore does not need to include every rule.\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- For some reason, I just felt like a class would be a neater way to manage our rules and updates, so I've gone with a `PageOrdering` class.\n",
    "- This includes a `_process_data()` method, which takes in the puzzle data and:\n",
    "  - Splits into two blocks - the first block for the rules and the second block for the updates.\n",
    "  - For the rules, I create `required_before` and `required_after` [defaultdicts](https://aoc.just2good.co.uk/python/defaultdict), of type list.\n",
    "  - Every time we find a number on the left of the rule, we add the number on the right to the corresponding `required_after` list.\n",
    "  - Every time we find a number on the right of the rule, we add the number on the left to the corresponding `required_before` list.\n",
    "  - For the updates, I turn each line into a list of int values.\n",
    "- Next, the `_is_correctly_ordered(update)` method. This is the heart of the Part 1 solution. We:\n",
    "  - Iterate through each position for a given update.\n",
    "  - For a given position we build up a set of all the pages that were found before it, and all the pages found after it.\n",
    "  - Now get the set of all pages that are required before our page, and the set of all pages that are required after our page.\n",
    "  - Finally, we can just use the [set](https://aoc.just2good.co.uk/python/sets) `intersect()` (shorthand of `&`) to determine if any of the pages found before are required after, and if any of the pages found after are required before. In either case, our update is NOT correctly ordered.\n",
    "- Then implement `get_updates_correctly_ordered()`, which loops through each update and checks it using the method above.\n",
    "- Finally, we'll create `sum_middles()` which takes a list of updates, and adds up the middle value from each one.\n",
    "\n",
    "That's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageOrdering():\n",
    "    \n",
    "    def __init__(self, data: str) -> None:\n",
    "        \n",
    "        required_after, required_before, updates = self._process_data(data)\n",
    "        self._required_after = required_after\n",
    "        self._required_before = required_before\n",
    "        self._updates = updates\n",
    "    \n",
    "    @property\n",
    "    def updates(self):\n",
    "        return self._updates\n",
    "\n",
    "    def _process_data(self, data: str):\n",
    "        \"\"\" Parse input data to determine rules and updates \"\"\"\n",
    "        required_after = defaultdict(set)\n",
    "        required_before = defaultdict(set)\n",
    "        updates = [] \n",
    "        \n",
    "        # split into blocks.\n",
    "        rules_block, updates_block = data.split(\"\\n\\n\") \n",
    "        \n",
    "        # build two-way adjacency dictionary\n",
    "        for rule in rules_block.splitlines():\n",
    "            x, y = list(map(int, rule.split(\"|\")))\n",
    "            required_after[x].add(y)\n",
    "            required_before[y].add(x)\n",
    "        \n",
    "        # Turn updates block into list of lists\n",
    "        updates = [[int(x) for x in update_line.split(\",\")] for update_line in updates_block.splitlines()]\n",
    "        \n",
    "        return required_after, required_before, updates\n",
    "    \n",
    "    @staticmethod\n",
    "    def sum_middles(updates: list[list[int]]) -> int:\n",
    "        \"\"\" Get the sum of the middle values from the supplied updates \"\"\"\n",
    "        sum_of_middle_pages = 0\n",
    "        for update in updates:\n",
    "            middle = update[(len(update)//2)]\n",
    "            sum_of_middle_pages += middle\n",
    "            \n",
    "        return sum_of_middle_pages\n",
    "    \n",
    "    def get_updates_correctly_ordered(self) -> list[list[int]]:\n",
    "        \"\"\" Return all the updates that are correctly ordered \"\"\"\n",
    "        return [update for update in self._updates if self._is_correctly_ordered(update)]\n",
    "    \n",
    "    def get_updates_incorrectly_ordered(self) -> list[list[int]]:\n",
    "        \"\"\" Return all the updates that are incorrectly ordered \"\"\"\n",
    "        return [update for update in self._updates if not self._is_correctly_ordered(update)]\n",
    "    \n",
    "    def fix_incorrect_update(self, update: list[int]) -> list[int]:\n",
    "        \"\"\" Sort an incorrectly sorted update into the correct order, using the rules \"\"\"\n",
    "        \n",
    "        bad_update = set(update) # Turn our list into a set, so we can intersect later\n",
    "        required_posn_for_page = dict() # { page_num1: posn1; page_num2: posn2, ...}\n",
    "        \n",
    "        for page in update: # iterate through all pages in the update\n",
    "            # Using the rules, determine the set of all pages that must be before this page\n",
    "            # Then intersect with the pages that are in our update\n",
    "            # The length of the intersect describes how many pages in THIS update must be before this page\n",
    "            # This gives us the location that this page SHOULD be in this update\n",
    "            required_before_page = self._required_before[page] & bad_update\n",
    "            required_posn_for_page[page] = len(required_before_page)\n",
    "        \n",
    "        # Sort our dict based on the lengths and return just the page numbers\n",
    "        return [page for (page, posn) in sorted(required_posn_for_page.items(), \n",
    "                key=lambda item: item[1])]\n",
    "        \n",
    "    def _is_correctly_ordered(self, update: list[int]):\n",
    "        \"\"\" Determine if the update is correctly ordered by checking the rules \"\"\"\n",
    "        \n",
    "        # E.g. 75,97,47,61,53\n",
    "        for idx in range(len(update)): # iterate through all positions in this update\n",
    "            current_page = update[idx] # e.g. 75\n",
    "            before = set(update[:idx]) # get all the pages BEFORE this page in our update\n",
    "            after = set(update[idx+1:]) # get all the pages AFTER this page in our update, e.g. 97,47,61,53\n",
    "            \n",
    "            required_before_page = self._required_before[current_page] # E.g. 97|75\n",
    "            if intersect := after & required_before_page: # Any pages found after, that are required before?\n",
    "                return False\n",
    "            \n",
    "            required_after_page = self._required_after[current_page]\n",
    "            if intersect := before & required_after_page: # Any pages found before, that are required after?\n",
    "                return False\n",
    "            \n",
    "        return True          \n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"PageOrdering(rules_len={len(self._required_before)},updates_len={len(self._updates)})\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"\\n\".join(\",\".join(map(str, update_row)) for update_row in self._updates)        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    page_ordering = PageOrdering(data)\n",
    "    correctly_ordered_updates = page_ordering.get_updates_correctly_ordered()\n",
    "    return page_ordering.sum_middles(correctly_ordered_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "47|53\n",
    "97|13\n",
    "97|61\n",
    "97|47\n",
    "75|29\n",
    "61|13\n",
    "75|53\n",
    "29|13\n",
    "97|29\n",
    "53|29\n",
    "61|53\n",
    "97|53\n",
    "61|29\n",
    "47|13\n",
    "75|47\n",
    "97|75\n",
    "47|61\n",
    "75|61\n",
    "47|29\n",
    "75|13\n",
    "53|13\n",
    "\n",
    "75,47,61,53,29\n",
    "97,61,53,29,13\n",
    "75,29,13\n",
    "75,97,47,61,53\n",
    "61,13,29\n",
    "97,13,75,29,47\"\"\")\n",
    "sample_answers = [143]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 5 Part 2\n",
    "\n",
    "For each of the incorrectly-ordered updates, use the page ordering rules to put the page numbers in the right order.\n",
    "\n",
    "**What is the sum of middle page numbers from only the updates that have been fixed?**\n",
    "\n",
    "First, we need to determine all the updates that are incorrectly ordered. We can do this with a trivial update to this line:\n",
    "\n",
    "```python\n",
    "    return [update for update in self._updates if self._is_correctly_ordered(update)]\n",
    "```\n",
    "\n",
    "We just add `not`, and then wrap with a new method:\n",
    "\n",
    "```python\n",
    "    def get_updates_incorrectly_ordered(self) -> list[list[int]]:\n",
    "        \"\"\" Return all the updates that are incorrectly ordered \"\"\"\n",
    "        return [update for update in self._updates if not self._is_correctly_ordered(update)]\n",
    "```\n",
    "\n",
    "Now we need a method to sort every incorrectly ordered update.  I've created a method `fix_incorrect_update()`. It works like this:\n",
    "\n",
    "- Create a set from the bad update.\n",
    "- Create a dictionary that stores the _required_ position for each page in the bad update.\n",
    "- Now iterate through every page in the bad update. And for each:\n",
    "  - Start by determining ALL the pages that must come before this page, according to the list of rules. \n",
    "  - From this set of pages, we only care about the ones that are present in our bad update. So we intersect between these two sets. So now we know exactly how many pages from our bad set SHOULD be before the current page.\n",
    "  - Store the length of the intersect set as the value for this page, in the `required_posn_for_page` dictionary.\n",
    "- Once we've done this for every page in the bad update, we now have a dictionary that has the unique REQUIRED index location for every page in the update. So we finally just sort based on the index location, to return the required pages in the correct order.\n",
    "- Then for each of this fixed updates, just locate the middles as before and sum them.\n",
    "\n",
    "This was fun!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    page_ordering = PageOrdering(data)\n",
    "    incorrectly_ordered_updates = page_ordering.get_updates_incorrectly_ordered()\n",
    "    \n",
    "    fixed_updates = []\n",
    "    for incorrect_update in incorrectly_ordered_updates:\n",
    "        fixed_updates.append(page_ordering.fix_incorrect_update(incorrect_update))\n",
    "        \n",
    "    return page_ordering.sum_middles(fixed_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "47|53\n",
    "97|13\n",
    "97|61\n",
    "97|47\n",
    "75|29\n",
    "61|13\n",
    "75|53\n",
    "29|13\n",
    "97|29\n",
    "53|29\n",
    "61|53\n",
    "97|53\n",
    "61|29\n",
    "47|13\n",
    "75|47\n",
    "97|75\n",
    "47|61\n",
    "75|61\n",
    "47|29\n",
    "75|13\n",
    "53|13\n",
    "\n",
    "75,47,61,53,29\n",
    "97,61,53,29,13\n",
    "75,29,13\n",
    "75,97,47,61,53\n",
    "61,13,29\n",
    "97,13,75,29,47\"\"\")\n",
    "sample_answers = [123]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 6: Guard Gallivant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"6\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 6 Part 1\n",
    "\n",
    "We have a grid with empty spaces `.`, obstacles `#`, and our guard, poining in a particular direction, e.g. `^`. E.g.\n",
    "\n",
    "```text\n",
    "....#.....\n",
    ".........#\n",
    "..........\n",
    "..#.......\n",
    ".......#..\n",
    "..........\n",
    ".#..^.....\n",
    "........#.\n",
    "#.........\n",
    "......#...\n",
    "```\n",
    "\n",
    "Our guard moves one space at a time until hitting an obstacle, and then always turns right. \n",
    "\n",
    "**Including the guard's starting position, how many distinct positions will the guard visit before leaving the mapped area?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "Here I'm going to use my reusable `Grid` class because it already knows how to determine height and width, and how to check if a given location will be out of bounds of the grid.  I'm also using my reusable `Point` namedtuple, since this allows me to represent 2D coordinates using a more intuitive syntax like `point.x` rather than `point[0]`.\n",
    "\n",
    "I make a new `GuardMap` class by extending `Grid`. Things to note:\n",
    "\n",
    "- It contains class attributes that represent spaces, obstacles.\n",
    "- It contains a dictionary to map our four directors to vectors.\n",
    "- We have a `DIRECTIONS` string with our four directions. We can keep track of the index of our current direction, such that we simply increment this index whenever we want to turn right.\n",
    "- Start by iterating through all locations in the grid until we find a direction symbol, e.g. `^`. This is the location of our guard.\n",
    "- We store any locations we've visited in a dictionary that maps the location to the latest direction. We don't need this to solve the problem, but it does mean I can use this dictionary to visualise the path taken by our guard.\n",
    "- Now we provide a `move()` method that will be called repeatedly, until our guard exits the grid. In this method:\n",
    "  - Start a loop. And in this loop...\n",
    "  - Determine the next location by adding the current guard position to the vector corresponding to the current direction.\n",
    "  - If this next location takes us out-of-bounds, then we've exited the grid.\n",
    "  - Otherwise, get the value at this location. If it's a space, we just update our location and we're done.\n",
    "  - If it's an obstacle, then we need to rotate right by updating our direction index. And then continue the loop and try again.\n",
    "- Finally, to solve the problem, we just return the length of the dictionary that stores all the locations we've visited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuardMap(Grid):\n",
    "    SPACE = \".\"\n",
    "    OBSTACLE = \"#\"\n",
    "    \n",
    "    DIRECTIONS = \"^>v<\" # Each successive direction is the result of turning right (i.e. 90 degrees)\n",
    "    DIRECTIONS_MAP = {\n",
    "        '^': Point(0, -1),\n",
    "        '>': Point(1, 0),\n",
    "        'v': Point(0, 1),\n",
    "        '<': Point(-1, 0)\n",
    "    }\n",
    "    \n",
    "    def __init__(self, grid_array: list):\n",
    "        super().__init__(grid_array)\n",
    "        \n",
    "        self._all_obstacles = set()\n",
    "        self._update_all_obstacles()\n",
    "        \n",
    "        self._guard_location = self._locate_guard()\n",
    "        self._start_location = self._guard_location\n",
    "        \n",
    "        self._guard_direction = self.value_at_point(self._guard_location)\n",
    "        self._directions_idx = GuardMap.DIRECTIONS.index(self._guard_direction)\n",
    "        self._start_direction_idx = self._directions_idx\n",
    "\n",
    "        self._visited_with_direction = set()\n",
    "        self._visited_map = {} # We can use this to print the route\n",
    "        self._visited: list[tuple[Point, str]] = [] # To track our route, if we need it\n",
    "        self._in_loop = False\n",
    "                \n",
    "        self._update_visited()\n",
    "        \n",
    "        self._pre_obstacle_added = None\n",
    "    \n",
    "    def reset(self):        \n",
    "        self._guard_location = self._start_location\n",
    "        self._guard_direction = self.value_at_point(self._guard_location)\n",
    "        self._directions_idx = self._start_direction_idx\n",
    "        \n",
    "        self._visited_with_direction = set()\n",
    "        self._visited_map: dict[Point, str] = {}\n",
    "        self._visited = []\n",
    "        self._in_loop = False\n",
    "                \n",
    "        self._update_visited()\n",
    "        self._clear_obstacle()\n",
    "    \n",
    "    def add_obstacle(self, location: Point):\n",
    "        \"\"\" Add an obstacle at the specified location.\n",
    "        Store this location so we can clear the obstacle later. \"\"\"\n",
    "        self._pre_obstacle_added = (location, self.value_at_point(location))\n",
    "        self.set_value_at_point(location, GuardMap.OBSTACLE)\n",
    "        \n",
    "    def _clear_obstacle(self):\n",
    "        \"\"\" Clear any previously set obstacle. \"\"\"\n",
    "        if self._pre_obstacle_added:\n",
    "            self.set_value_at_point(self._pre_obstacle_added[0], self._pre_obstacle_added[1])\n",
    "    \n",
    "    @property\n",
    "    def in_loop(self) -> bool:\n",
    "        \"\"\" Are we stuck in a loop? \"\"\"\n",
    "        return self._in_loop\n",
    "    \n",
    "    @property\n",
    "    def visited(self):\n",
    "        \"\"\" Visited locations, as a dict of {location: direction, ...} \"\"\"\n",
    "        return self._visited_map\n",
    "    \n",
    "    @property\n",
    "    def distinct_visited_count(self) -> int:\n",
    "        \"\"\" Count of all distinct locations we've visited. \"\"\"\n",
    "        return len(self._visited_map)\n",
    "    \n",
    "    def _update_visited(self):\n",
    "        \"\"\" Update visited locations \"\"\"\n",
    "        \n",
    "        location_config = (self._guard_location, self._guard_direction)\n",
    "        \n",
    "        # Update our dict of where we've been\n",
    "        self._visited_map[self._guard_location] = self._guard_direction\n",
    "        self._visited.append(location_config)\n",
    "        \n",
    "        # For loop checking, we need to check if we've seen this location AND this orientation\n",
    "        if location_config in self._visited_with_direction:\n",
    "            self._in_loop = True # We've done this before!\n",
    "        else:\n",
    "            self._visited_with_direction.add(location_config)\n",
    "\n",
    "    def _update_all_obstacles(self):\n",
    "        self._all_obstacles = set()\n",
    "        \n",
    "        for point in self._all_points:\n",
    "            if self.value_at_point(point) == GuardMap.OBSTACLE:\n",
    "                self._all_obstacles.add(point)         \n",
    "\n",
    "    def move(self) -> bool:\n",
    "        \"\"\" \n",
    "        Move guard one space in current direction.\n",
    "        If we can't move forward in this direction, make turn and move.\n",
    "        Return True if we move, or False if we leave the map\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Move one step in the direction the guard is pointing\n",
    "            next_point = self._guard_location + GuardMap.DIRECTIONS_MAP[self._guard_direction]\n",
    "            \n",
    "            if not self.valid_location(next_point): # leaving the map?\n",
    "                return False\n",
    "            \n",
    "            # Are we at an obstacle? If so, rotate right and try again\n",
    "            next_value = self.value_at_point(next_point)\n",
    "            if (next_value == GuardMap.OBSTACLE):\n",
    "                # Increment the direction index\n",
    "                self._directions_idx = (self._directions_idx + 1) % len(GuardMap.DIRECTIONS)\n",
    "                self._guard_direction = GuardMap.DIRECTIONS[self._directions_idx]\n",
    "                continue\n",
    "            else: # No obstacle, so we can move to this location\n",
    "                self._guard_location = next_point\n",
    "                self._update_visited()\n",
    "                break # We've successfully moved\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    def _locate_guard(self) -> Point:\n",
    "        for point in self.all_points():\n",
    "            if self.value_at_point(point) in GuardMap.DIRECTIONS:\n",
    "                return point\n",
    "            \n",
    "    def __str__(self) -> str:\n",
    "        row_strs = []\n",
    "        for y, row in enumerate(self._array):\n",
    "            row_list = []\n",
    "            for x, char in enumerate(row):\n",
    "                locn = Point(x,y)\n",
    "                if locn in self._visited_map.keys():\n",
    "                    row_list.extend([Fore.YELLOW, self._visited_map[locn], Fore.RESET])\n",
    "                else:\n",
    "                    row_list.append(char)\n",
    "                    \n",
    "            row_strs.append(\"\".join(row_list))\n",
    "        \n",
    "        return \"\\n\".join(row_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    guard_map = GuardMap(data)\n",
    "    while guard_map.move():\n",
    "        pass\n",
    "\n",
    "    logger.debug(f\"\\n{guard_map}\")  \n",
    "    return guard_map.distinct_visited_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "....#.....\n",
    ".........#\n",
    "..........\n",
    "..#.......\n",
    ".......#..\n",
    "..........\n",
    ".#..^.....\n",
    "........#.\n",
    "#.........\n",
    "......#...\"\"\")\n",
    "sample_answers = [41]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Visualisation for Part 1\n",
    "\n",
    "My VisGuardMap extends GuardMap. It animates the path of the guard in the grid.\n",
    "\n",
    "- `create_animation()` sets up the animation using matplotlib's `FuncAnimation`. \n",
    "- It initializes a plot showing obstacles and creates empty scatter plots for each movement direction. \n",
    "- The key is `animate_step`, called for each frame. It iterates through the `_visited` list, which stores visited grid points and their associated directions up to the current frame (`n`). \n",
    "- For each direction, it updates the corresponding scatter plot with the coordinates of newly visited points. \n",
    "- FuncAnimation then compiles these frames into an animation, saved as a video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"https://aoc.just2good.co.uk/assets/media/anim_2024d06_sample.mp4\"\n",
    "Video(url=path, width=640, height=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisGuardMap(GuardMap):\n",
    "    def __init__(self, grid_array: list, animating: bool = True, **kwargs) -> None:\n",
    "        super().__init__(grid_array=grid_array, **kwargs)\n",
    "        \n",
    "        self.animating = animating\n",
    "        if self.animating:\n",
    "            self._plot_info = self._setup_fig()\n",
    "            self._frame_index = 0\n",
    "    \n",
    "    def _setup_fig(self):\n",
    "        \"\"\" Initialise the plot \"\"\"   \n",
    "        my_dpi = 120\n",
    "        fig, axes = plt.subplots(figsize=(1024/my_dpi, 768/my_dpi), dpi=my_dpi, facecolor=\"black\") # set size in pixels\n",
    "\n",
    "        axes.get_xaxis().set_visible(True)\n",
    "        axes.get_yaxis().set_visible(True)\n",
    "        axes.tick_params(axis='both', colors='white')  # Change tick color\n",
    "        axes.xaxis.label.set_color('white')  # Change x-axis label color\n",
    "        axes.yaxis.label.set_color('white')  # Change y-axis label color\n",
    "        axes.invert_yaxis()\n",
    "        \n",
    "        axes.set_aspect('equal') # set x and y to equal aspect\n",
    "        axes.set_facecolor('xkcd:orange')\n",
    "        \n",
    "        min_x, max_x = -0.5, self._width - 0.5\n",
    "        min_y, max_y = -0.5, self._height - 0.5\n",
    "        axes.set_xlim(min_x, max_x)\n",
    "        axes.set_ylim(max_y, min_y)\n",
    "\n",
    "        # dynamically compute the marker size\n",
    "        fig.canvas.draw()\n",
    "        mkr_size = ((axes.get_window_extent().width / (max_x-min_x) * (45/fig.dpi)) ** 2)\n",
    "\n",
    "        # Plot the obstacles\n",
    "        obst_x, obst_y = zip(*[(point.x, point.y) for point in self._all_obstacles])\n",
    "        axes.scatter(obst_x, obst_y, marker=\"*\", s=mkr_size*0.5, color=\"black\", label=\"Obstacle\")\n",
    "        \n",
    "        # Prepare empty scatter plots - one for each direction\n",
    "        visited_scatters = {dirn: axes.scatter([], [], marker=dirn, s=mkr_size * 0.5, color=\"white\", label=f\"Visited {dirn}\")\n",
    "                            for dirn in VisGuardMap.DIRECTIONS}\n",
    "        \n",
    "        return fig, axes, mkr_size, visited_scatters\n",
    "\n",
    "    def create_animation(self, output_folder: Path, file_name: str, fps=10):\n",
    "        \"\"\" Create the animation, by calling the animate_step() method for each frame. \"\"\"\n",
    "        self._plot_info = self._setup_fig()  # Set up the figure for plotting\n",
    "        fig, axes, mkr_size, visited_scatter = self._plot_info\n",
    "\n",
    "        # Creating the animation   \n",
    "        logger.debug(f\"Creating the animation. We have {len(self._visited_map)} frames to render.\")\n",
    "        anim = FuncAnimation(fig, \n",
    "                             self.animate_step,\n",
    "                             frames=len(self._visited), \n",
    "                             interval=1000/fps, blit=True)\n",
    "\n",
    "        # Save the animation\n",
    "        output_folder.mkdir(exist_ok=True)\n",
    "        output_path = Path(locations.output_dir, file_name)\n",
    "        anim.save(output_path, writer='ffmpeg')\n",
    "        \n",
    "        # Close the figure to prevent inline display in Jupyter Notebook\n",
    "        plt.close(fig)\n",
    "\n",
    "    def animate_step(self, n):\n",
    "        \"\"\" Add a frame for the nth step in the animation. \"\"\"\n",
    "\n",
    "        if n > 0:\n",
    "            if n % 100 == 0:\n",
    "                logger.debug(f\"Rendering frame {n}...\")\n",
    "                \n",
    "        # Update each scatter plot with points of the corresponding direction\n",
    "        for dirn in VisGuardMap.DIRECTIONS:\n",
    "            # Add the points to be shown in this frame, for this direction\n",
    "            new_points = [(point.x, point.y) for point, d in self._visited[:n+1] if d == dirn]\n",
    "            if new_points:\n",
    "                x, y = zip(*new_points)\n",
    "                # update the positions of the points in the scatter plot\n",
    "                self._plot_info[3][dirn].set_offsets(list(zip(x, y)))\n",
    "        \n",
    "        return [scatter for scatter in self._plot_info[3].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1_animated(data, name, fps):\n",
    "    guard_map = VisGuardMap(data)\n",
    "    while guard_map.move():\n",
    "        pass\n",
    "\n",
    "    guard_map.create_animation(output_folder=locations.output_dir, \n",
    "                               file_name=name, \n",
    "                               fps=fps)\n",
    "\n",
    "    return guard_map.distinct_visited_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_input = \"\"\"\\\n",
    "....#.....\n",
    ".........#\n",
    "..........\n",
    "..#.......\n",
    ".......#..\n",
    "..........\n",
    ".#..^.....\n",
    "........#.\n",
    "#.........\n",
    "......#...\"\"\"\n",
    "\n",
    "file_name = \"anim_2024d06_sample.mp4\"\n",
    "soln = solve_part1_animated(sample_input.splitlines(), name=file_name, fps=15)\n",
    "logger.info(f\"Part 1 soln={soln}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the Sample Data Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"anim_2024d06_sample.mp4\"\n",
    "Video(Path(locations.output_dir, file_name), embed=True, width=640, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Render the Animation for the Real Input\n",
    "\n",
    "Careful... With over 4000 frames, this will take a little over a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"anim_2024d06_real.mp4\"\n",
    "solve_part1_animated(input_data, name=file_name, fps=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the Real Data Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"anim_2024d06_real.mp4\"\n",
    "Video(Path(locations.output_dir, file_name), embed=True, width=640, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 6 Part 2\n",
    "\n",
    "We need to place a single obstruction that causes the guard to get stuck in a loop! We can place the obstruction at any location apart from the starting point.\n",
    "\n",
    "**How many different positions could you choose for this obstruction?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "Firstly, we can only put obstructions in the path the guard walks, otherwise it would be pointless. That means >4000 positions to try. Sounds plausible! So my approach is simply to insert this obstacle into the grid, and then perform the walk. We repeat for every possible location, and count how many times this results in a loop.\n",
    "\n",
    "So:\n",
    "\n",
    "- Add a method to `reset()` the grid, e.g. the guard starting point, the counters, the direction, etc. This is a little more efficient than creating a new Guard\n",
    "- Track whether a location has been visited with a given direction in a set. The set will store tuples of `(Point, direction)`. If we try to visit a previously seen configuration, then we're in a loop, so set an attribute to mark that this grid is now in a loop.\n",
    "- Add a method to add an additional obstacle at a given location. Track the location so that we can clear the obstacle later.\n",
    "- Add a method to clear the added obstacle.\n",
    "\n",
    "Now:\n",
    "\n",
    "- Iterate through all locations in the original loop, as candidates for the obstacle. (Except the starting point.)\n",
    "- Reset the grid, add the obstacle, and then simulate the guard movement as before.\n",
    "- With each movement, check if we're in a loop. If so, exit this loop.\n",
    "\n",
    "This works! But it also takes about 10 seconds to run.  Not the fastest, but not too bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    \n",
    "    # Initial route\n",
    "    guard_map = GuardMap(data)\n",
    "    while guard_map.move():\n",
    "        pass\n",
    "    \n",
    "    # Route taken, excluding starting point\n",
    "    route = [locn for locn in guard_map.visited.keys()][1:]\n",
    "    \n",
    "    loop_locations = 0\n",
    "    \n",
    "    for location in tqdm(route):\n",
    "        guard_map.reset()\n",
    "        guard_map.add_obstacle(location)\n",
    "        while guard_map.move():\n",
    "            if guard_map.in_loop:\n",
    "                loop_locations += 1\n",
    "                break\n",
    "    \n",
    "    logger.debug(f\"Found {loop_locations} loop locations.\")\n",
    "    return loop_locations\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "....#.....\n",
    ".........#\n",
    "..........\n",
    "..#.......\n",
    ".......#..\n",
    "..........\n",
    ".#..^.....\n",
    "........#.\n",
    "#.........\n",
    "......#...\"\"\")\n",
    "sample_answers = [6]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 7: Bridge Repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"7\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 7 Part 1\n",
    "\n",
    "Our input data represents equations with operators missing! E.g.\n",
    "\n",
    "```text\n",
    "190: 10 19\n",
    "3267: 81 40 27\n",
    "83: 17 5\n",
    "156: 15 6\n",
    "7290: 6 8 6 15\n",
    "161011: 16 10 13\n",
    "192: 17 8 14\n",
    "21037: 9 7 18 13\n",
    "292: 11 6 16 20\n",
    "```\n",
    "\n",
    "- Operators are always evaluated left-to-right.\n",
    "- We have two operators to use: `+` and `*`\n",
    "\n",
    "By inserting operator combinations between numbers, determine which equations could possibly be true. **What is their total calibration result?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- First, convert the input data into a list of equations. Each equation will be a `tuple` of two parts: the required answer, and the tuple of all the integer numbers (parameters) of our equation.\n",
    "- For each tuple of numbers on the right of length `n`, there will be `n-1` operators to insert. E.g. with 3 numbers, we need every combination of 2 operators.\n",
    "- Let's use `itertools.product()` to determine the unique arrangements of `n-1` operators, given two operators. We use `product` because it allows us to repeat an operator. E.g. with `+` and `*` there will be four arrangements: `++`, `+*`, `*+`, and `**`. I'm doing this with a function called `get_op_perms()`.\n",
    "- I'm also caching this function. I can do this because the operators are always the same, so the arrangements are deterministic for any given required number of operators.\n",
    "\n",
    "We iterate through each `equation`:\n",
    "\n",
    "- First we get the arrangements of operators.\n",
    "- Then we loop through all arrangements of operators. Remember that each arrangement will be a tuple containing exactly the number of operators required between our numbers.\n",
    "- We apply the operator for each successive pair of numbers, always updating the \"left\" result such that it becomes the input to the next operation. I could do it like this:\n",
    "\n",
    "```python\n",
    "    res = nums[0]  # Initialize with the first number\n",
    "    for i, op in enumerate(op_perm):\n",
    "        res = apply_op((res, nums[i + 1]), op)\n",
    "```\n",
    "\n",
    "But this is a perfect use case for using the [reduce()](https://aoc.just2good.co.uk/python/map-filter-reduce#reduce) function (aka a \"fold\"):\n",
    "\n",
    "```python\n",
    "    res = reduce(lambda acc, op_and_right: apply_op((acc, op_and_right[1]), op_and_right[0]),\n",
    "                 zip(op_perm, nums[1:]), # zip the operator with the next number\n",
    "                 nums[0])  # Start with the first number\n",
    "```\n",
    "\n",
    "The `reduce()` function works by applying the specified function successively to every pair of elements in our list. With each iteration, it stores the result in an \"aggregator\" and then uses this aggregator as the left-hand input to the next iteration.\n",
    "\n",
    "The lambda function itself defines a function with two parameters: the aggregator, and a tuple which contains the current `(operator, right-number)`. Note that we have to specify the initial value of the aggregator, which is the first number in our list.\n",
    "\n",
    "(Now I've done this, I think the first approach is more readable.  But oh well!)\n",
    "\n",
    "This bit is important: **We only require our equation to be valid once. So we should break the loop after adding the equation value to our total.**\n",
    "\n",
    "I've also created a function for applying the operator, called `apply_op()`. This makes use of the in-built `operator` module, which has a number of fuctions like `add()`, `mul()`, etc. This is useful because we can pick the appropriate function based on the `op` string, and pass our two numbers in as parameters to each of these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(data) -> list[tuple]:\n",
    "    \"\"\" Return equations in the form: [(answer, numbers), ...] \"\"\"\n",
    "    equations = []\n",
    "    for line in data:\n",
    "        ans, nums = line.split(\":\")\n",
    "        ans = int(ans)\n",
    "        nums = list(map(int, nums.split()))\n",
    "        equations.append((ans, nums))\n",
    "        \n",
    "    return equations\n",
    "\n",
    "@cache\n",
    "def get_op_perms(ops: str, num_parameters: int):\n",
    "    \"\"\" \n",
    "    Return all the ways of ordering our operators for a given number of parameters.\n",
    "    E.g. if ops == \"+*\" and there are 3 parameters, then we need all permutations of 2 operators: \n",
    "    [(\"+\", \"+\"), (\"+\", \"*\"), (\"*\", \"+\"), (\"*\", \"*\")]\n",
    "    \"\"\"\n",
    "    op_perms = list(product(ops, repeat=num_parameters-1))\n",
    "    logger.debug(f\"Number of op perms with {num_parameters-1} insertions: {len(op_perms)}\")\n",
    "    return op_perms\n",
    "    \n",
    "def apply_op(num_pair: tuple[int], op: str) -> int:\n",
    "    match op: # Note Python's implementatiom of switch\n",
    "        case \"+\":\n",
    "            return operator.add(*num_pair)\n",
    "        case \"*\":\n",
    "            return operator.mul(*num_pair)\n",
    "        case \"|\":\n",
    "            return int(\"\".join(str(num) for num in num_pair))\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown operator: {op}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _solve(data, ops):\n",
    "    equations = process_input(data) # [0] is the ans; [1] are the numbers\n",
    "    total = 0\n",
    "    \n",
    "    for equation in tqdm(equations):\n",
    "        nums = equation[1]\n",
    "        \n",
    "        # get a list of operator combinations, with each element being of length n-1\n",
    "        # E.g. with 3 numbers, we'll get: [('+', '+'), ('+', '*'), ('*', '+'), ('*', '*')]\n",
    "        op_perms = get_op_perms(ops, len(nums))\n",
    "\n",
    "        for op_perm in op_perms: # a tuple of operators of length n-1\n",
    "            ans = reduce(lambda acc, op_and_right: apply_op((acc, op_and_right[1]), op_and_right[0]),\n",
    "                         zip(op_perm, nums[1:]), # zip the operator with the next number\n",
    "                         nums[0])  # Start with the first number\n",
    "\n",
    "            if ans == equation[0]:\n",
    "                total += equation[0] \n",
    "                break # we only need one successful result per equestion\n",
    "         \n",
    "    return total\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "190: 10 19\n",
    "3267: 81 40 27\n",
    "83: 17 5\n",
    "156: 15 6\n",
    "7290: 6 8 6 15\n",
    "161011: 16 10 13\n",
    "192: 17 8 14\n",
    "21037: 9 7 18 13\n",
    "292: 11 6 16 20\"\"\")\n",
    "sample_answers = [3749]\n",
    "\n",
    "OPERATORS = \"+*\"\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input.splitlines(), OPERATORS), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve(input_data, OPERATORS)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 7 Part 2\n",
    "\n",
    "Oh, surprise.  There's a third operator. The op `||` combines digits from left and right into a single number. E.g. `12 || 345` results in `12345`.\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "It's dead easy to incorporate this. I've just added a new operator to my `apply_op()` function. However, rather than calling it `||`, I've called it `|`. This way, I can just include it in my string of operators: `+*|`.\n",
    "\n",
    "Of course this means that we'll get a lot more arrangements of operators. E.g.\n",
    "\n",
    "| Number of Op Insertions | Arrangements with 2 operators | Arrangements with 3 operators |\n",
    "|---|--|---|\n",
    "| 1 | 2 | 3 |\n",
    "| 2 | 4 | 9 |\n",
    "| 3 | 8 | 27 |\n",
    "| 4 | 16 | 81 |\n",
    "| 5 | 32 | 243 |\n",
    "| 6 | 64 | 729 |\n",
    "\n",
    "So it takes a little while to run. On my laptop this is taking 12 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "190: 10 19\n",
    "3267: 81 40 27\n",
    "83: 17 5\n",
    "156: 15 6\n",
    "7290: 6 8 6 15\n",
    "161011: 16 10 13\n",
    "192: 17 8 14\n",
    "21037: 9 7 18 13\n",
    "292: 11 6 16 20\"\"\")\n",
    "sample_answers = [11387]\n",
    "\n",
    "OPERATORS = \"+*|\"\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input.splitlines(), OPERATORS), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve(input_data, OPERATORS)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 8: Resonant Collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"8\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 8 Part 1\n",
    "\n",
    "Our grid represents a city containing antennae. Each antenna is tuned to a particular frequency given by a single lowercase letter, uppercase letter, or digit. E.g.\n",
    "\n",
    "```text\n",
    "............\n",
    "........0...\n",
    ".....0......\n",
    ".......0....\n",
    "....0.......\n",
    "......A.....\n",
    "............\n",
    "............\n",
    "........A...\n",
    ".........A..\n",
    "............\n",
    "............\n",
    "```\n",
    "\n",
    "- _Antinodes_ are created at any point where two antenna of the same frequenty are aligned, but where one is twice as far away as other. \n",
    "- This means that for any pair of antennas with the same frequency, there are two antinodes, one on either side of them.\n",
    "- An antinode can _can_ occur at locations that contain antennae.\n",
    "\n",
    "**How many unique locations within the bounds of the map contain an antinode?**\n",
    "\n",
    "I'm going to extend my `Grid` class again, to make a `NodeGrid` class.\n",
    "\n",
    "We start by initialing a dictionary containing a set of locations for each antenna when find. Use a `defaultdict(set)` for this, so that we can just add a location, every time we find one for a given frequency.\n",
    "\n",
    "Next, the heart of the problem: my `_update_antinodes()` method:\n",
    "\n",
    "- First, we retrieve the set of antennae locations for a given frequency.\n",
    "- Then, we determine all the pairs of locations for this frequency. Note that these are edges in an undirected graph. We can do this with `itertools.combinations(antennae, 2)`. The number of edges for a given number of antennae will be:\n",
    "\n",
    "$$\n",
    "  p = \\frac{n(n-1)}{2} \n",
    "$$\n",
    "\n",
    "E.g.\n",
    "\n",
    "| Number of Antennae | Number of Edges |\n",
    "|---|---|\n",
    "| 1 | 0 |\n",
    "| 2 | 1 |\n",
    "| 3 | 3 |\n",
    "| 4 | 6 |\n",
    "| 5 | 10 |\n",
    "\n",
    "(Oooh look! Triangle numbers!)\n",
    "\n",
    "For each pair, I determine the vector between the points. This is my `delta`.\n",
    "\n",
    "Now, to determine the required antinode locations, we need to find the locations that are exactly one delta before the pair, and one delta after the pair. E.g. for two points `X` and `Y`, our antinodes will be found at:\n",
    "\n",
    "`------*----X----Y----*-----------`\n",
    "\n",
    "We can do this by subtracting the delta from `X`, and by adding the delta to `Y`. Or, perhaps more reusable (and this turns out to be quite useful in Part 2!), we can just add two vectors to `X`:\n",
    "\n",
    "1. Add `-1 * delta`\n",
    "1. Add `2 * delta`\n",
    "\n",
    "Each time we add our required number of deltas, check if the new location is within our grid.  If it is, we've found an antinode and we add it to our `_antinodes` set.\n",
    "\n",
    "Pretty simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeGrid(Grid):\n",
    "    def __init__(self, grid_array):\n",
    "        super().__init__(grid_array)\n",
    "        \n",
    "        self._antennae_by_freq: dict[str, set[Point]] = defaultdict(set)\n",
    "        self._populate_antennae()\n",
    "        \n",
    "        self._antinodes: set[Point] = set()\n",
    "    \n",
    "    @property\n",
    "    def antinodes(self):\n",
    "        return self._antinodes\n",
    "    \n",
    "    def _populate_antennae(self):\n",
    "        \"\"\" Populate our dict of antennae locations, as { freq: (loc1, loc2...), freq: (loc1, loc2...), ... }\"\"\"\n",
    "        for point in self._all_points:\n",
    "            val = self.value_at_point(point)\n",
    "            if val != \".\":\n",
    "                self._antennae_by_freq[val].add(point)\n",
    "        \n",
    "        for freq, locations in self._antennae_by_freq.items():\n",
    "            logger.debug(f\"{freq=},{locations=}\")\n",
    "                \n",
    "    def update_antinodes(self, resonant=False):\n",
    "        \"\"\" Find antinodes.\n",
    "        If resonant, these are any multiples of the distance between two nodes\n",
    "        including the nodes themselves.\n",
    "        Otherwise, just one antinode either side of our pair. \"\"\"\n",
    "        \n",
    "        for antenna_freq in self._antennae_by_freq.keys(): # a frequency\n",
    "            antennae = self._antennae_by_freq[antenna_freq]\n",
    "            \n",
    "            if resonant:\n",
    "                # If there are more than two antennae, these will be part of the resonant node set\n",
    "                if len(antennae) > 1:\n",
    "                    self._antinodes.update(antennae)                \n",
    "            \n",
    "            # Get all the undirected edges between these frequencies\n",
    "            edges = list(combinations(antennae, 2))\n",
    "            \n",
    "            # For each edge, calculate the antinodes\n",
    "            for edge in edges:\n",
    "                delta: Point = edge[1] - edge[0]\n",
    "                \n",
    "                for sign in [-1, 1]:\n",
    "                    delta_multiple = 2 if sign == 1 else -1\n",
    "                    \n",
    "                    while True:\n",
    "                        an = edge[0] + Point(delta_multiple*delta.x, \n",
    "                                             delta_multiple*delta.y)\n",
    "                        \n",
    "                        # Check not outside of grid\n",
    "                        if self.valid_location(an):\n",
    "                            self._antinodes.add(an)\n",
    "                        else:\n",
    "                            break # We can't go further in this direction\n",
    "                        \n",
    "                        if not resonant:\n",
    "                            break # We only want the first delta in this direction\n",
    "                        else:\n",
    "                            delta_multiple += sign\n",
    "            \n",
    "    def __str__(self) -> str:\n",
    "        \"\"\" Render the grid. Antinodes are shown in yellow. \"\"\"\n",
    "        row_strs = []\n",
    "        for y, row in enumerate(self._array):\n",
    "            row_list = [] if y > 0 else [Fore.RESET]  # Build a list of characters for each row\n",
    "            for x, char in enumerate(row):\n",
    "                if Point(x, y) in self._antinodes:\n",
    "                    row_list.append(Fore.YELLOW)\n",
    "                    row_list.extend([\"*\" if char == \".\" else char])\n",
    "                    row_list.append(Fore.RESET)\n",
    "                else:\n",
    "                    row_list.append(char)\n",
    "            row_strs.append(\"\".join(row_list))  # Efficiently join the characters\n",
    "\n",
    "        return \"\\n\".join(row_strs) # and the rows        \n",
    "          \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    node_grid = NodeGrid(data)\n",
    "    node_grid.update_antinodes()\n",
    "    logger.debug(f\"\\n{node_grid}\")\n",
    "    \n",
    "    return len(node_grid.antinodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "............\n",
    "........0...\n",
    ".....0......\n",
    ".......0....\n",
    "....0.......\n",
    "......A.....\n",
    "............\n",
    "............\n",
    "........A...\n",
    ".........A..\n",
    "............\n",
    "............\"\"\")\n",
    "sample_answers = [14]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 8 Part 2\n",
    "\n",
    "Now we're told that: _\"an antinode occurs at any grid position exactly in line with at least two antennas of the same frequency, regardless of distance.\"_\n",
    "\n",
    "Actually, what this means is that an antinode can appear at any integer multiple of the distance. E.g.\n",
    "\n",
    "`-*----*----X----Y----*----*----*-`\n",
    "\n",
    "**Important point: the `X` and `Y` are now also antinodes.**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "This is a trivial tweak to my code for part 1. First, let's add a parameter to the function to determine if we're in `resonant` mode or not.\n",
    "\n",
    "And now, instead of just adding deltas `-1` and `2`, I now just add `n` deltas, until the resulting location is out of the grid. I also iterate through signs `[-1, 1]` to determine how to increment the `delta_multiple`, and also to determine where to start, i.e. `-1` or `2` respectively. \n",
    "\n",
    "Also, if we're in `resonant` mode, we mustn't forget to the antennae locations to our set.\n",
    "\n",
    "And that's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    node_grid = NodeGrid(data)\n",
    "    node_grid.update_antinodes(resonant=True)\n",
    "    logger.debug(f\"\\n{node_grid}\")\n",
    "    \n",
    "    return len(node_grid.antinodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "............\n",
    "........0...\n",
    ".....0......\n",
    ".......0....\n",
    "....0.......\n",
    "......A.....\n",
    "............\n",
    "............\n",
    "........A...\n",
    ".........A..\n",
    "............\n",
    "............\"\"\")\n",
    "sample_answers = [34]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 9: Disk Fragmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"9\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 9 Part 1\n",
    "\n",
    "We're asked to defragment a disk map, given a compressed format in a single line where:\n",
    "\n",
    "- Alternate single digits represent blocks of file, followed by blocks of space.\n",
    "- The first digit will be a file.\n",
    "- Each file is allocated an ID number, based on their position before defragmenting. These are zero indexed, so the first digit correponds to file 0.\n",
    "\n",
    "So the compressed line `12345` would expand to `0..111....22222`.\n",
    "\n",
    "And this compressed line:\n",
    "\n",
    "```text\n",
    "2333133121414131402\n",
    "```\n",
    "\n",
    "... expands to:\n",
    "\n",
    "```text\n",
    "00...111...2...333.44.5555.6666.777.888899\n",
    "```\n",
    "\n",
    "We must move file blocks, one at a time, from the end of the disk to the leftmost free pace block. E.g.\n",
    "\n",
    "```text\n",
    "00...111...2...333.44.5555.6666.777.888899\n",
    "009..111...2...333.44.5555.6666.777.88889.\n",
    "0099.111...2...333.44.5555.6666.777.8888..\n",
    "00998111...2...333.44.5555.6666.777.888...\n",
    "009981118..2...333.44.5555.6666.777.88....\n",
    "0099811188.2...333.44.5555.6666.777.8.....\n",
    "009981118882...333.44.5555.6666.777.......\n",
    "0099811188827..333.44.5555.6666.77........\n",
    "00998111888277.333.44.5555.6666.7.........\n",
    "009981118882777333.44.5555.6666...........\n",
    "009981118882777333644.5555.666............\n",
    "00998111888277733364465555.66.............\n",
    "0099811188827773336446555566..............\n",
    "```\n",
    "\n",
    "**Determine the filesystem checksum by multiplying each block position with the file ID it contains, and adding these.**\n",
    "\n",
    "#### My Solution Approach\n",
    "\n",
    "It took me a little while to establish how to represent the data. Representing the exapnded disk is easy enough. But my method of storing hte locations of spaces and files... seems possibly overly complicated. Oh well!\n",
    "\n",
    "- Let's create a `DiskDefragmenter` class.\n",
    "- This stores a `_disk_blocks` attribute, which is a simply a list representing all the blocks in the disk. Each element will either contain a `file_id` or a `None` for an empty block.\n",
    "- I'm also storing `_files` and `_spaces`, which are each a list containing lists. Each of the sub-lists represent a start position for the file or space, followed by the size of the file or space (in blocks).\n",
    "\n",
    "The `initialise_map()` method takes the compressed disk line, and expands it. This is simple enough.\n",
    "\n",
    "The `defrag_by_blocks()` method moves our blocks from the end of the file, one block at a time.\n",
    "\n",
    "- We start by popping the block at the end. Pop until the block returned is not a space.\n",
    "- Take the popped block - which has the value of a file_id - and insert it into the first available space.\n",
    "- I use `_spaces` to quickly determine the next available space we can use. In retrospect, it would probably have been easier to simply use a comprehension to return the list of spaces from `_disk_blocks`, and directly insert into each space. But I didn't do that!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiskDefragmenter():\n",
    "    def __init__(self, data: str):\n",
    "        self._disk_blocks = [] # Each element represents a block. Each block is either a file_id or None\n",
    "        self._files: list[list[int, int]] = [] # [ [file start, file sz], ... }\n",
    "        self._spaces: list[list[int, int]] = [] # [ [block start, space sz], ... }\n",
    "        \n",
    "        self._initialise_map(data)\n",
    "    \n",
    "    @property\n",
    "    def expanded(self):\n",
    "        return self._expanded\n",
    "    \n",
    "    def _initialise_map(self, data: str):\n",
    "        \"\"\" Expand compressed disk format to expanded format.\n",
    "        - Odd digits are the number of blocks of file_id, where file_id always increments by 1\n",
    "        - Even digits are the number of blocks of empty space between the files.\n",
    "        E.g.\n",
    "        12345 -> 0..111....22222 \n",
    "        \"\"\"\n",
    "        \n",
    "        data = data.strip()\n",
    "        \n",
    "        file_id = 0\n",
    "        next_block = 0\n",
    "        for idx, val in enumerate(data):\n",
    "            sz = int(val)\n",
    "            if idx % 2 == 0: # File posn\n",
    "                list_target = self._files\n",
    "                append_val = file_id\n",
    "                file_id += 1\n",
    "                assert sz > 0, \"File can not be 0 size\"\n",
    "            else: # Spaces\n",
    "                list_target = self._spaces\n",
    "                append_val = None\n",
    "                \n",
    "            if sz > 0: # We can have 0-length spaces\n",
    "                list_target.append([next_block, sz])\n",
    "                next_block += sz\n",
    "                self._disk_blocks.extend([append_val] * sz)\n",
    "                                      \n",
    "    def defrag_by_blocks(self):\n",
    "        \"\"\" Move one block at a time, from the end, to the first available space. \"\"\"\n",
    "        \n",
    "        while self._spaces: # Continue until we've run out of spaces\n",
    "            next_space_idx, next_space_sz = self._spaces[0]\n",
    "            \n",
    "            last_block = self._disk_blocks.pop()\n",
    "            while not last_block: # Check if it's not a space at the end\n",
    "                _, last_space_sz = self._spaces[-1]\n",
    "                if last_space_sz > 1:\n",
    "                    self._spaces[-1][1] = last_space_sz - 1\n",
    "                else: # if only one remaining space, pop it\n",
    "                    self._spaces.pop(-1)\n",
    "                    \n",
    "                last_block = self._disk_blocks.pop()\n",
    "            \n",
    "            # Now move the block    \n",
    "            self._disk_blocks[next_space_idx] = last_block\n",
    "            if next_space_sz > 1: # increment the location of this space, and reduce its size\n",
    "                self._spaces[0][0] = next_space_idx + 1\n",
    "                self._spaces[0][1] = next_space_sz - 1\n",
    "            else: # pop this space from the front of our list\n",
    "                self._spaces.pop(0)\n",
    "    \n",
    "    def defrag_by_files(self):\n",
    "        \"\"\" Move files into first available space that can accommodate the whole file. \n",
    "        Start with highest file_id. \"\"\"\n",
    "        moved = True\n",
    "        \n",
    "        while moved:\n",
    "            moved = False\n",
    "            for file_idx, file in enumerate(reversed(self._files)): # get them in reverse order\n",
    "                file_start, file_sz = file\n",
    "                \n",
    "                # Find first space where this will fit\n",
    "                for space_idx, space in enumerate(self._spaces):\n",
    "                    space_start, space_sz = space\n",
    "                    \n",
    "                    # If our space comes after our file, we need to leave the file where it is!\n",
    "                    if space_start >= file_start:\n",
    "                        break\n",
    "                    \n",
    "                    if space_sz >= file_sz: # Check if the file will fit in the space\n",
    "                        for block_idx in range(file_sz): # Move each block of this file\n",
    "                            block = self._disk_blocks[file_start+block_idx]\n",
    "                            self._disk_blocks[space_start+block_idx] = block\n",
    "                            self._disk_blocks[file_start+block_idx] = None\n",
    "                        \n",
    "                        # Eliminate the old file reference                        \n",
    "                        self._files.pop(len(self._files) - file_idx - 1)\n",
    "                        \n",
    "                        # Determine where we should insert the file reference in self._files\n",
    "                        next_block = space_start + space_sz # The next block after this space\n",
    "                        for inner_file_idx in range(len(self._files)):\n",
    "                            inner_file_start = self._files[inner_file_idx][0]\n",
    "                            if inner_file_start == next_block: # we should insert here\n",
    "                                new_file = [space_start, file_sz]\n",
    "                                self._files.insert(inner_file_idx, new_file) \n",
    "                                break \n",
    "\n",
    "                        if space_sz == file_sz: # If this space has been complete used\n",
    "                            self._spaces.pop(space_idx)\n",
    "                        else: # Otherwise adjust the space start and size\n",
    "                            self._spaces[space_idx][0] = space_start + file_sz\n",
    "                            self._spaces[space_idx][1] = space_sz - file_sz\n",
    "                        \n",
    "                        moved = True\n",
    "                        break # break from space loop\n",
    "                    else:\n",
    "                        continue # Continue space loop\n",
    "                \n",
    "                if moved:\n",
    "                    break # We've moved a file. Exit file loop. Start again...\n",
    "                \n",
    "            # Finished looping through files\n",
    "                    \n",
    "    def checksum(self) -> int:\n",
    "        \"\"\" Checksum is given by sum(block_idx * block_value) \"\"\"\n",
    "        return sum((idx * int(val) for idx, val \n",
    "                                   in enumerate(self._disk_blocks)\n",
    "                                   if val is not None and str(val).isdigit()))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f\"DiskDefragmenter(\\n\" +\n",
    "                f\"   {self._disk_blocks=},\\n\" +\n",
    "                f\"   {self._files=},\\n\" +\n",
    "                f\"   {self._spaces=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    df = DiskDefragmenter(data)\n",
    "    logger.debug(f\"Pre-defragmentation: {df}\")\n",
    "    df.defrag_by_blocks()\n",
    "    logger.debug(f\"Post-defrag: {df}\")\n",
    "    \n",
    "    return df.checksum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"2333133121414131402\")\n",
    "sample_answers = [1928]\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 9 Part 2\n",
    "\n",
    "Moving by blocks is causing fragmentation of files. This is bad! So now, instead of moving blocks, we're going to move whole files.\n",
    "\n",
    "- Process each file, starting with highest file ID.\n",
    "- Move the whole file to the leftmost space that can accommodate the file.\n",
    "- If no space can accommodate a file, then this file does not move.\n",
    "- Continue until no further files can be moved.\n",
    "\n",
    "E.g. this\n",
    "\n",
    "```text\n",
    "2333133121414131402\n",
    "```\n",
    "\n",
    "... expands to:\n",
    "\n",
    "```text\n",
    "00...111...2...333.44.5555.6666.777.888899\n",
    "```\n",
    "\n",
    "And file movements look like this:\n",
    "\n",
    "```text\n",
    "00...111...2...333.44.5555.6666.777.888899\n",
    "0099.111...2...333.44.5555.6666.777.8888..\n",
    "0099.1117772...333.44.5555.6666.....8888..\n",
    "0099.111777244.333....5555.6666.....8888..\n",
    "00992111777.44.333....5555.6666.....8888..\n",
    "```\n",
    "\n",
    "#### My Solution\n",
    "\n",
    "I've added a `defrag_by_files()` method. This method:\n",
    "\n",
    "- Iterates through `self._files` from the right. Recall that each element is a tuple of `(file_id, size)`.\n",
    "- Determine the first space that this file will fit in.\n",
    "- Pop the file and insert it at this location. We work out where to insert the file by looking for the existing member of `self._files` which has a start block equal to the next block after the current group of spaces.\n",
    "\n",
    "This solution takes just under 2s to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    df = DiskDefragmenter(data)\n",
    "    logger.debug(f\"Pre-defragmentation: {df}\")\n",
    "    df.defrag_by_files()\n",
    "    logger.debug(f\"Post-defrag: {df}\")\n",
    "    \n",
    "    return df.checksum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"2333133121414131402\")\n",
    "sample_answers = [2858]\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 10: Hoof It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"10\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 10 Part 1\n",
    "\n",
    "We have a topographic map indicating the height at each position, with a scale from 0 (lowest) to 9 (highest). E.g.\n",
    "\n",
    "```text\n",
    "89010123\n",
    "78121874\n",
    "87430965\n",
    "96549874\n",
    "45678903\n",
    "32019012\n",
    "01329801\n",
    "10456732\n",
    "```\n",
    "\n",
    "We want to determine a hiking trail, i.e. a path that starts at 0, ends at 9, and increases by 1 with each step. We can only move orthogonally. Each such trail has a trailhead - the start at position 0. A trailhead can be the origin of multiple trails.  A trailhead's score is the number of trails from that trailhead.\n",
    "\n",
    "**What is the sum of the scores of all trailheads on your topographic map?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "Clearly, we need a [BFS flood fill](https://aoc.just2good.co.uk/python/shortest_paths)!#\n",
    "\n",
    "- First, let's get all the possible trail starting points, which I've stored as `_origins`.\n",
    "- Next, I've implemented a method called `get_trails_for_origin()`. We run this for every origin, to see if it returns a valid trail. It's a fairly standard BFS, so:\n",
    "  - We queue up our origin, i.e. a location with value of `0`.\n",
    "  - Next, pop this off the queue and check its value.\n",
    "  - Then we determine all valid neighbours from this origin; i.e. adjacent squares that are within the grid.\n",
    "  - For each neighbour, we check if we've seen this before, and if not, we add it to the queue.\n",
    "  - Then we repeat. Each time we pop off the queue, we check if the popped value was `9`. If so, then we've found a trailend.\n",
    "  - We return the trailends, and count them to give the score for this origin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trail(Grid):\n",
    "    GOAL = 9\n",
    "    \n",
    "    def __init__(self, grid_array):\n",
    "        self._array = [list(map(int, row)) for row in grid_array.copy()]\n",
    "        self._width = len(self._array[0])\n",
    "        self._height = len(self._array)\n",
    "        \n",
    "        self._all_points = [Point(x,y) for y in range(self._height) for x in range(self._width)]\n",
    "        self._origins = [point for point in self._all_points if self.value_at_point(point) == 0]\n",
    "    \n",
    "    @property\n",
    "    def origins(self) -> list[Point]:\n",
    "        \"\"\" Return all locations with value of 0 \"\"\"\n",
    "        return self._origins\n",
    "    \n",
    "    def get_trails_for_origin(self, origin: Point) -> tuple[set, dict]:\n",
    "        \"\"\" Returns all the trailends we can reach from this origin - this is the score we require \"\"\"\n",
    "                \n",
    "        frontier: deque[Point] = deque() # Very efficient for FIFO queueing\n",
    "        frontier.append(origin)\n",
    "    \n",
    "        seen = set()\n",
    "        seen.add(origin)\n",
    "        trailends = set()\n",
    "        \n",
    "        while frontier:\n",
    "            current:Point = frontier.popleft() # BFS\n",
    "            current_val = self.value_at_point(current)\n",
    "            \n",
    "            if current_val == Trail.GOAL:\n",
    "                trailends.add(current)\n",
    "                continue # no point in finding neighbours of a trail end\n",
    "            \n",
    "            # Get valid neighbours\n",
    "            neighbours = [neighbour for neighbour in current.neighbours(include_diagonals=False) \n",
    "                                                  if (self.valid_location(neighbour) and \n",
    "                                                      self.value_at_point(neighbour) == current_val + 1)]\n",
    "            \n",
    "            for next in neighbours:\n",
    "                if next not in seen:\n",
    "                    frontier.append(next)\n",
    "                    seen.add(next) \n",
    "        \n",
    "        return trailends\n",
    "    \n",
    "    def get_distinct_trails_for_origin(self, origin: Point) -> tuple[set, dict]:\n",
    "        \"\"\" Return:\n",
    "        - ALL the distinct paths to reach ALL trailends from this origin \n",
    "        - A dict that contains a set of each possible points in the trail that can lead to the next point \n",
    "        \"\"\"\n",
    "        \n",
    "        frontier: deque[Point] = deque() \n",
    "        \n",
    "        frontier.append(origin)\n",
    "        came_from = defaultdict(set) # Now each location can be preceeded by a set of locations\n",
    "        came_from[origin] = set() # How many locations led to this location\n",
    "        trailends = set()\n",
    "        \n",
    "        neighbours: list[Point]\n",
    "        \n",
    "        while frontier:\n",
    "            current:Point = frontier.popleft() # BFS\n",
    "            current_val = self.value_at_point(current)\n",
    "            \n",
    "            if current_val == Trail.GOAL:\n",
    "                trailends.add(current)\n",
    "                continue # no point in finding neighbours of a trail end\n",
    "            \n",
    "            # Orthogonal neighbours to this point, that are within bounds and with increment of exactly 1\n",
    "            neighbours = [neighbour for neighbour in current.neighbours(include_diagonals=False) \n",
    "                                                  if (self.valid_location(neighbour) and \n",
    "                                                      self.value_at_point(neighbour) == current_val + 1)]\n",
    "            \n",
    "            for next in neighbours:\n",
    "                if next not in came_from:\n",
    "                    frontier.append(next)\n",
    "                \n",
    "                # Crucially, we now add this regardless of whether next already in came_from\n",
    "                # Because there's more than one way to get to a given point\n",
    "                came_from[next].add(current) \n",
    "        \n",
    "        return trailends, came_from\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_distinct_paths(trailends: set[Point], origin: Point, came_from: dict) -> list:\n",
    "        \"\"\" Return ALL paths from origin to trailend, for each trailend \"\"\"\n",
    "      \n",
    "        paths = []\n",
    "        stack = [] # stores tuples of (current_point, path_so_far)\n",
    "\n",
    "        # Initialize the stack with all trailends\n",
    "        for trailend in trailends:\n",
    "            stack.append((trailend, [trailend]))\n",
    "\n",
    "        while stack:\n",
    "            current, path = stack.pop()\n",
    "\n",
    "            # If we reach the origin, add the reversed path to the results\n",
    "            if current == origin:\n",
    "                paths.append(path[::-1])  # Reverse the path to get origin -> trailend\n",
    "                continue\n",
    "\n",
    "            # Push all predecessors of the current point onto the stack\n",
    "            for predecessor in came_from.get(current, set()):\n",
    "                stack.append((predecessor, path + [predecessor]))\n",
    "\n",
    "        return paths\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    trail = Trail(data)\n",
    "    logger.debug(f\"\\n{trail}\")\n",
    "    logger.debug(f\"Origins: {trail.origins}\")\n",
    "    \n",
    "    scores_sum = 0\n",
    "    for trail_num, origin in enumerate(trail.origins):\n",
    "        trailends = trail.get_trails_for_origin(origin)\n",
    "        logger.debug(f\"Score for {trail_num} starting at {origin}: {len(trailends)}\")        \n",
    "        scores_sum += len(trailends)\n",
    "    \n",
    "    return scores_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "89010123\n",
    "78121874\n",
    "87430965\n",
    "96549874\n",
    "45678903\n",
    "32019012\n",
    "01329801\n",
    "10456732\"\"\")\n",
    "sample_answers = [36]\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 10 Part 2\n",
    "\n",
    "Now we have a new method to score the trails, called `rating`. A `rating` is the number of distinct hiking trails which begin at that trailhead. So:\n",
    "\n",
    "- A given trailhead can have `n` trailends, and this gives us the `score`.\n",
    "- But there could be multiple ways to reach any given trailend. These distinct paths are the `rating`.\n",
    "\n",
    "**What is the sum of the ratings of all trailheads?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "Here I've created a new version of the BFS flood fill, called `get_distinct_trails_for_origin()`. The main change is that this method uses a dictionary called `came_from` that maps each point to ALL preceeding points (as a set), on the way to the trailend. Then I've created `get_distinct_paths()` which enables me to use a DFS to determine all unique paths based on this `came_from` dict. And the number of paths gives us the answer we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    trail = Trail(data)\n",
    "    logger.debug(f\"\\n{trail}\")\n",
    "    logger.debug(f\"Origins: {trail.origins}\")\n",
    "    \n",
    "    scores_sum = 0\n",
    "    for trail_num, origin in enumerate(trail.origins):\n",
    "        trailends, came_from = trail.get_distinct_trails_for_origin(origin)\n",
    "        paths = trail.get_distinct_paths(trailends, origin, came_from)\n",
    "        logger.debug(f\"Origin {trail_num}: rating={len(paths)}\")\n",
    "        scores_sum += len(paths)\n",
    "    \n",
    "    return scores_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "89010123\n",
    "78121874\n",
    "87430965\n",
    "96549874\n",
    "45678903\n",
    "32019012\n",
    "01329801\n",
    "10456732\"\"\")\n",
    "sample_answers = [81]\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input.splitlines()), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 11: Plutonian Pebbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"11\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 11 Part 1\n",
    "\n",
    "We have stones arranged in a line. Each stone has a number engraved on it. But the stones change with each blink.\n",
    "\n",
    "The rules:\n",
    "\n",
    "- If the stone is engraved with the number 0, it is replaced by a stone engraved with the number 1.\n",
    "- If the stone is engraved with a number that has an even number of digits, it is replaced by two stones. The left half of the digits are engraved on the new left stone, and the right half of the digits are engraved on the new right stone. (The new numbers don't keep extra leading zeroes: 1000 would become stones 10 and 0.)\n",
    "- If none of the other rules apply, the stone is replaced by a new stone; the old stone's number multiplied by 2024 is engraved on the new stone.\n",
    "\n",
    "**How many stones will you have after blinking 25 times?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "This part is very easy! We can just simulate what happens with each blink.\n",
    "\n",
    "- First, store the initial list of stones as a `list` of `int`, in an instance variable called `_stones`.\n",
    "- The `_blink_for_stone()` method takes a single stone, and returns the values of the resulting one or two stones, based on the rules. \n",
    "- Our `blink()` method simply calls `_blink_for_stone()` for each stone. The result is stored back in `_stones`.\n",
    "\n",
    "Now, we just run `blink()` as many times as required. The instance variable `_stones` will always contain the values of all the resulting stones. To answer part 1, we just count the length of the `_stones` list.\n",
    "\n",
    "Too easy. I have a very bad feeling about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stones():\n",
    "    def __init__(self, data: str):\n",
    "        self._stones = list(map(int, data.split()))\n",
    "    \n",
    "    @property\n",
    "    def stones(self) -> int:\n",
    "        return self._stones\n",
    "    \n",
    "    def blink(self):\n",
    "        \"\"\" Simulate a single blink, updating our list of stones with the result. \n",
    "        This method does not scale to a lage number of blinks. \"\"\"\n",
    "\n",
    "        new_stones = []\n",
    "        for stone in self._stones:\n",
    "            new_stones.extend(Stones._blink_for_stone(stone))\n",
    "        \n",
    "        self._stones = new_stones\n",
    "    \n",
    "    def count_total_stones_for_blinks(self, blinks: int):\n",
    "        \"\"\" Return total count of stones after blinking required number of times. \"\"\"\n",
    "\n",
    "        count = 0\n",
    "        for stone in self._stones: # We only use this property for the initial call\n",
    "            count += Stones._count_stones_for_blinks(stone, blinks)\n",
    "\n",
    "        return count\n",
    "\n",
    "    @staticmethod\n",
    "    @cache\n",
    "    def _count_stones_for_blinks(stone: int, blinks: int) -> int:\n",
    "        \"\"\" Count stones after binking n times, for this stone. \n",
    "        This is recursive. \"\"\"\n",
    "\n",
    "        # base case\n",
    "        if blinks == 0:\n",
    "            return 1 # we return the count of this stone - always 1\n",
    "        \n",
    "        count = 0\n",
    "        new_stones = Stones._blink_for_stone(stone)\n",
    "        for new_stone in new_stones:\n",
    "            count += Stones._count_stones_for_blinks(new_stone, blinks - 1)\n",
    "\n",
    "        return count\n",
    "\n",
    "    @staticmethod\n",
    "    @cache\n",
    "    def _blink_for_stone(stone: int) -> list[int]:\n",
    "        match stone:\n",
    "            case 0:\n",
    "                return [1]\n",
    "            case x if len(str(x)) % 2 == 0:\n",
    "                str_val = str(stone)\n",
    "                middle = len(str_val) // 2\n",
    "                left, right = int(str_val[:middle]), int(str_val[middle:])\n",
    "                return [left, right]\n",
    "            case _:\n",
    "                return [stone * 2024]\n",
    "    \n",
    "    def __str__(self):\n",
    "        stones = \" \".join(list(map(str, self._stones)))\n",
    "        return f\"Stones ({len(self.stones)}): {stones}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    BLINKS = 25\n",
    "    stones = Stones(data)\n",
    "    logger.debug(stones)\n",
    "    \n",
    "    for _ in range(BLINKS):\n",
    "        stones.blink()\n",
    "\n",
    "    return len(stones.stones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"125 17\")\n",
    "sample_answers = [55312]\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 11 Part 2\n",
    "\n",
    "**How many stones if we blink 75 times?**\n",
    "\n",
    "I was afraid of this. **Our solution won't scale.** It grinds to a halt at around 40 blinks. We need a smarter way to track the number of stones.\n",
    "\n",
    "Let's examine the pattern more closely:\n",
    "\n",
    "```text\n",
    "Initial arrangement:\n",
    "125 17\n",
    "\n",
    "After 1 blink:\n",
    "253000 1 7\n",
    "\n",
    "After 2 blinks:\n",
    "253 0 2024 14168\n",
    "\n",
    "After 3 blinks:\n",
    "512072 1 20 24 28676032\n",
    "\n",
    "After 4 blinks:\n",
    "512 72 2024 2 0 2 4 2867 6032\n",
    "\n",
    "After 5 blinks:\n",
    "1036288 7 2 20 24 4048 1 4048 8096 28 67 60 32\n",
    "\n",
    "After 6 blinks:\n",
    "2097446912 14168 4048 2 0 2 4 40 48 2024 40 48 80 96 2 8 6 7 6 0 3 2\n",
    "```\n",
    "\n",
    "Let's list what we know and what we can see:\n",
    "\n",
    "- The order of stones DOES NOT MATTER when blinking.\n",
    "- The stones are independent. What happens to one stone does not affect any other stones.\n",
    "- We don't really care about the actual values of the stones at the end. We only care how many stones there are.\n",
    "- An odd-length number will always get multiplied by 2024. Eventually, this will result in a even-length number.\n",
    "- An even length number will always result in two equal-length numbers.\n",
    "- An even length number that is a power of 2 will always reduce down to single digit stones, e.g. `8 -> 4 -> 2 -> 1`\n",
    "- For any single-digit starting number, we see a recurring pattern:\n",
    "\n",
    "| Start | Cycle 1 | Cycle 2 | Cycle 3 | Cycle 4 | Cycle 5 |\n",
    "|-|-|-|-|-|-|\n",
    "| 0 | 1     | 2024      | 20, 24             | 4 x Back to Start |                   |\n",
    "| 1 | 2024  | 20, 24    | 4 x Back to Start  |                   |                   |\n",
    "| 2 | 4048  | 40, 48    | 4 x Back to Start  |                   |                   |\n",
    "| 3 | 6072  | 60, 72    | 4 x Back to Start  |                   |                   |\n",
    "| 4\t| 8096\t| 80, 96\t| 4 x Back to Start  |                   |                   |\n",
    "| 5\t| 10120\t| 20482880\t| 2048, 2880         | 20, 48, 28, 80    | 8 x Back to Start |\n",
    "| 6\t| 12144\t| 24579456\t| 2457, 9456         | 24, 57, 94, 56    | 8 x Back to Start |\n",
    "| 7\t| 14168\t| 28676032\t| 2867, 6032         | 28, 67, 60, 32    | 8 x Back to Start |\n",
    "| 8\t| 16192\t| 32772608\t| 3277, 2608         | 32, 77, 26, 08    | 8 x Back to Start |\n",
    "| 9\t| 18216\t| 36869184\t| 3686, 9184         | 36, 86, 91, 84    | 8 x Back to Start |\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- Since the pattern is deterministic, we can calculate the resulting stones from any single digit stone after n blinks. We can cache these results, i.e. if we blink `n` times for a stone with value `x`, then we will always end up with the same set of resulting stones.\n",
    "- Furthermore, we can use [recursion](https://aoc.just2good.co.uk/python/recursion) because:\n",
    "  - If we have no blinks left, we can return a count of 1 for the current stone.\n",
    "  - If we have blinks left, we can apply our transformation on our current stone, then pass the resulting stone(s) along with `n-1` blinks into our recursive function.\n",
    "\n",
    "- Our `count_total_stones_for_blinks()` is the main entry point for the Part 2 solution. It iterates through each stone in `_stones` and recursively calcualtes the resulting number of stones for each.\n",
    "- Our `_count_stones_for_blinks()` method determines the resulting number of stones after `n` blinks for a given starting stone. It is recursive, and returns exactly 1 stone for each stone, once we're out of blinks. But if we have blinks left, it applies the same `_blink_for_stone()` method that we created in Part 1. This returns one or two stones, which are passed back into the recursive function.\n",
    "\n",
    "Okay, not too bad.  And it runs crazy fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data, blinks: int):\n",
    "    stones = Stones(data)\n",
    "    logger.debug(stones)\n",
    "    \n",
    "    count = stones.count_total_stones_for_blinks(blinks)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# First, test it still gives the same result with 25\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"125 17\")\n",
    "sample_answers = [55312]\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input, 25), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "soln = solve_part2(input_data, 75)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 12: Garden Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"12\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 12 Part 1\n",
    "\n",
    "We need to erect fences around regions in a garden. Garden plots are squares, indicated by a single letter, e.g.\n",
    "\n",
    "```text\n",
    "AAAA\n",
    "BBCD\n",
    "BBCC\n",
    "EEEC\n",
    "```\n",
    "\n",
    "- A region corresponds to connected plots of the same letter. \n",
    "- The **perimeter** is given by the number of sides of of each plot that are not connected to a plot of the same region.\n",
    "- We can have multiple regions of the same type.\n",
    "- A region can CONTAIN another region. This means that the perimeter of these internal regions also contributes to its overall perimeter!\n",
    "\n",
    "We're told: the **price** of fence required for a region is found by multiplying that region's area by its perimeter.\n",
    "\n",
    "**What is the total price of fencing all regions on your map?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "- I'll represent the garden as a grid, extending my `Grid` class.\n",
    "- Determine regions: add a method that does a standard [BFS flood fill](https://aoc.just2good.co.uk/python/shortest_paths), for each plot that is not yet allocated to a region.\n",
    "- When we do the flood fill, store the plots that make up the region, but also determine the length of the perimeter. We can do this by determining the number of neighbours for a given plot that not _valid_, where a _valid_ neighbour is one that is of the same _type_ and within the bounds. If the neighbour is not _valid_, then this neighbour creates a perimeter boundary. For example:\n",
    "\n",
    "```text\n",
    "     1111\n",
    "    1RRRR1\n",
    "    1RRRR2\n",
    "     12RRR1\n",
    "      1R21 \n",
    "       1 \n",
    "```\n",
    "\n",
    "- The result of the flood fill is all the properties we need to creata a `Region` object. \n",
    "\n",
    " Not too bad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Region():\n",
    "    \"\"\" A collection of contiguous garden plots of the same type \"\"\"\n",
    "    plot_type: str\n",
    "    plots: set[Point]\n",
    "    perimeter: int\n",
    "    perimeter_edges: dict[Point, set[Point]]\n",
    "    \n",
    "    @property\n",
    "    def area(self) -> int:\n",
    "        return len(self.plots)\n",
    "    \n",
    "    @property\n",
    "    def price(self) -> int:\n",
    "        \"\"\" Price is calculated as area * perimeter \"\"\"\n",
    "        return self.area * self.perimeter\n",
    "    \n",
    "    def price_using_sides(self) -> int:\n",
    "        \"\"\" Price is calcualted as area * number of sides \"\"\"\n",
    "        return self.area * self._calculate_sides()\n",
    "    \n",
    "    def _calculate_sides(self) -> int:\n",
    "        \"\"\" Determine how many sides this region has.\n",
    "        We have four sets of edge plots, each containing all plots facing N, E, S and W respectively.\n",
    "        Use a BFS for each plot to determine which plots are connected; \n",
    "        thus splitting our single set into distinct sub-regions.\n",
    "        Each sub-region represents a single side. \n",
    "        \"\"\"\n",
    "        sides = 0\n",
    "        \n",
    "        # Iterate over sets for N, E, S, W...\n",
    "        for side in self.perimeter_edges.values(): # All plots facing a particular direction\n",
    "            seen = set()\n",
    "            \n",
    "            for point in side:\n",
    "                if point not in seen:\n",
    "                    sides += 1 # This plot is in a new side\n",
    "                    \n",
    "                    # Here we use BFS to flood fill all members of the same side\n",
    "                    q = deque([point])\n",
    "                    while q:\n",
    "                        current = q.popleft()\n",
    "                        if current in seen:\n",
    "                            continue # Stop us indefinitely queuing neighbours!\n",
    "                        \n",
    "                        seen.add(current) # Add this connected plot to seen\n",
    "                        for neighbour in current.neighbours(include_diagonals=False):\n",
    "                            if neighbour in side: # Adjacent, so part of SAME side\n",
    "                                q.append(neighbour)\n",
    "        \n",
    "        return sides\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"Region(type={self.plot_type},area={self.area},perimeter={self.perimeter},price={self.price})\"\n",
    "    \n",
    "class Garden(Grid):\n",
    "    \"\"\" A garden is composed of multiple regions. These are irregular polygons where\n",
    "    each region contains plants of the same type. Note that regions can enclose regions \"\"\"\n",
    "    \n",
    "    DIRECTIONS = [Vectors.N.value, Vectors.E.value, Vectors.S.value, Vectors.W.value]\n",
    "    \n",
    "    def __init__(self, grid_array):\n",
    "        super().__init__(grid_array)\n",
    "        self._regions = self._find_regions()\n",
    "    \n",
    "    @property\n",
    "    def regions(self):\n",
    "        return self._regions\n",
    "    \n",
    "    def _find_regions(self):\n",
    "        \"\"\" Determine all the regions in our grid by performing a flood fill from each point. \"\"\"\n",
    "        regions: list[Region] = []\n",
    "        seen = set()\n",
    "        \n",
    "        for point in self._all_points:\n",
    "            if point in seen:\n",
    "                continue # We've done this one\n",
    "            \n",
    "            region_type = self.value_at_point(point)\n",
    "            region_plots, perimeter, perimeter_edges = self._flood_fill_for_origin(point)\n",
    "            region = Region(region_type, region_plots, perimeter, perimeter_edges)\n",
    "            regions.append(region)\n",
    "            \n",
    "            seen.update(region_plots) # mark every plot in this region as seen\n",
    "            \n",
    "        return regions\n",
    "            \n",
    "    def _flood_fill_for_origin(self, origin: Point):\n",
    "        \"\"\" Determine the region associated with this point. \n",
    "        I.e. all the connected points of the same plot type. \"\"\"\n",
    "\n",
    "        region_type = self.value_at_point(origin)\n",
    "\n",
    "        frontier: deque[Point] = deque()\n",
    "        frontier.append(origin)\n",
    "\n",
    "        seen = set()\n",
    "        seen.add(origin)\n",
    "        \n",
    "        plots = set()\n",
    "        perimeter = 0\n",
    "        \n",
    "        # For part 2 - track all the perimeter squares facing in each direction\n",
    "        perimeter_edges = {}\n",
    "        for dirn in Garden.DIRECTIONS: # N, E, S, W\n",
    "            perimeter_edges[dirn] = set()\n",
    "        \n",
    "        while frontier:\n",
    "            current:Point = frontier.popleft() # BFS\n",
    "            current_val = self.value_at_point(current)\n",
    "            \n",
    "            if current_val == region_type: # This plot is in our region\n",
    "                plots.add(current)\n",
    "            \n",
    "            for dirn in Garden.DIRECTIONS: # Get the neighbours, one direction at a time\n",
    "                neighbour = current + dirn\n",
    "\n",
    "                # If the neighbour is valid and of same type, it's in the same region so queue it\n",
    "                if self.valid_location(neighbour) and self.value_at_point(neighbour) == region_type:\n",
    "                    if neighbour not in seen:\n",
    "                        frontier.append(neighbour)\n",
    "                        seen.add(neighbour)\n",
    "\n",
    "                else: # this neighbour represents a perimeter\n",
    "                    perimeter += 1\n",
    "                    perimeter_edges[dirn].add(current) # Add the current plot as a perimeter plot\n",
    "        \n",
    "        return plots, perimeter, perimeter_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(garden: Garden):\n",
    "    total_price = 0\n",
    "    for region in garden.regions:\n",
    "        logger.debug(f\"{region}\")\n",
    "        total_price += region.price\n",
    "    \n",
    "    return total_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "RRRRIICCFF\n",
    "RRRRIICCCF\n",
    "VVRRRCCFFF\n",
    "VVRCCCJFFF\n",
    "VVVVCJJCFE\n",
    "VVIVCCJJEE\n",
    "VVIIICJJEE\n",
    "MIIIIIJJEE\n",
    "MIIISIJEEE\n",
    "MMMISSJEEE\"\"\")\n",
    "sample_answers = [1930]\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    sample_garden = Garden(curr_input.splitlines())\n",
    "    validate(solve_part1(sample_garden), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "garden = Garden(input_data)\n",
    "soln = solve_part1(garden)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 12 Part 2\n",
    "\n",
    "Pricing has changed! Instead of using the perimeter to calculate the price, we need to use the number of sides each region has. Each straight section of fence counts as a side, regardless of how long it is.\n",
    "\n",
    "**What is the new total price of fencing all regions on your map?**\n",
    "\n",
    "Urgh. This was horrible. The challenge is working out which plots make up sides.\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "I've modified my `_flood_fill_for_origin()` method so that in addition to returning the plots that make up a region and the perimeter value, we now also return a dictionary which is made up of:\n",
    "\n",
    "- The four direction (N, E, S, W) vectors, as keys\n",
    "- Each mapped to a set of perimeter plots that are facing in that direction.\n",
    "\n",
    "It's easy to do this, since we can simply store the current plot location, if its neighbour in a particular direction (e.g. north) is _not valid_. I.e. if the neighbour is out of bounds or is not of the same plot type.\n",
    "\n",
    "Imagine we're processing this region in our BFS flood fill:\n",
    "\n",
    "```text\n",
    "...........\n",
    ".RRRR......\n",
    ".RRRR.RRR..\n",
    "...RRRRR...\n",
    "...RRRR....\n",
    "...R.......\n",
    "...........\n",
    "```\n",
    "\n",
    "Then our four sets will contain only those plots that have invalid/empty neighbours above/right/below/left, like this:\n",
    "\n",
    "```text\n",
    "NORTH        EAST         SOUTH        WEST\n",
    "...........  ...........  ...........  ...........\n",
    ".RRRR......  .***R......  .****......  .R***......\n",
    ".****.RRR..  .***R.**R..  .RR**.**R..  .R***.R**..\n",
    "...**R**...  ...****R...  ...****R...  ...R****...\n",
    "...****....  ...***R....  ...*RRR....  ...R***....\n",
    "...*.......  ...R.......  ...R.......  ...R.......\n",
    "...........  ...........  ...........  ...........\n",
    "```\n",
    "\n",
    "Let's modify our `Region` class so that it requires this dictionary of sets for construction. Now we add a new method to the `Region` class called `_calculate_sides()`. This works by simply by performing a BFS flood fill for each of our four sets. This allows us to split our set of direction-facing plots into unconnected sub-regions. \n",
    "\n",
    "In the example above, we end up turning our single map of north-facing plots into three distinct sub-regions (i.e. the separate groups of `R`). And the count of these sub-regions is the number of north-facing sides.\n",
    "\n",
    "Once we do this in all four directions, we'll have estabished all the separate sides facing those four directions.\n",
    "\n",
    "And we're done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(garden: Garden):\n",
    "    return sum(region.price_using_sides() for region in garden.regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "RRRRIICCFF\n",
    "RRRRIICCCF\n",
    "VVRRRCCFFF\n",
    "VVRCCCJFFF\n",
    "VVVVCJJCFE\n",
    "VVIVCCJJEE\n",
    "VVIIICJJEE\n",
    "MIIIIIJJEE\n",
    "MIIISIJEEE\n",
    "MMMISSJEEE\"\"\")\n",
    "sample_answers = [1206]\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    sample_garden = Garden(curr_input.splitlines())\n",
    "    validate(solve_part2(sample_garden), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "soln = solve_part2(garden)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 13: Claw Contraption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"13\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 13 Part 1\n",
    "\n",
    "Our claw machines each have two buttons with different costs:\n",
    "\n",
    "- A costs 3 tokens\n",
    "- B costs 1 token\n",
    "\n",
    "Each button moves the claw a specific number of units in the X and Y directions. Our input describes the specific location we need to reach to win the prize. E.g.\n",
    "\n",
    "```text\n",
    "Button A: X+94, Y+34\n",
    "Button B: X+22, Y+67\n",
    "Prize: X=8400, Y=5400\n",
    "\n",
    "Button A: X+26, Y+66\n",
    "Button B: X+67, Y+21\n",
    "Prize: X=12748, Y=12176\n",
    "\n",
    "Button A: X+17, Y+86\n",
    "Button B: X+84, Y+37\n",
    "Prize: X=7870, Y=6450\n",
    "\n",
    "Button A: X+69, Y+23\n",
    "Button B: X+27, Y+71\n",
    "Prize: X=18641, Y=10279\n",
    "```\n",
    "\n",
    "The instructions give us an upper limit on button presses per button, per machine: 100.\n",
    "\n",
    "**What is the fewest tokens you would have to spend to win all possible prizes?**\n",
    "\n",
    "#### Solution Approach\n",
    "\n",
    "This seems like a great opportunity to use [SymPy](https://medium.com/python-in-plain-english/solving-mathematical-problems-in-python-with-sympy-5f138c0deaef)!\n",
    "\n",
    "- First, for each claw machine we can represent the important data has three points: A, B, and prize. Let's create a `Claw` class to store these three points.\n",
    "- For processing the input data, I first split the input into blocks of 3 lines each. And for each line, I then use a bit of trivial [regex](https://aoc.just2good.co.uk/python/regex) to extract the two numbers per line. I convert these number pairs to points, and then use these points to construct a `Claw` object.\n",
    "\n",
    "Next, the fun bit!! \n",
    "\n",
    "We know that we need `a` button presses and `b` button presses, to reach the prize point `p`. So we express this as two linear equations:\n",
    "\n",
    "$$\n",
    "a \\cdot x_{a} + b \\cdot x_{b} = x_{p} \\\\\n",
    "a \\cdot y_{a} + b \\cdot y_{b} = y_{p}\n",
    "$$\n",
    "\n",
    "Here $x_{a}$ is the x component of the `a` vector, $y_{a}$ is the y component of the `a` vector, and so on. This is saying, to reach the x location of point `p`, we need `a` presses + `b` presses.  And to reach the y location of point `p`, we need the same number `a` presses and `b` presses. So we must solve for where `a` and `b` are the same for these two equations. \n",
    "\n",
    "SymPy is great for this! I've created a `_solve()` method in the `Claw` class, which uses SymPy to solve for the two linear equations.\n",
    "\n",
    "For SymPy, I've named the variables like this: \n",
    "\n",
    "$$\n",
    "ax = x_{a} \\\\\n",
    "bx = x_{b} \\\\\n",
    "px = x_{p} \\\\[1em]\n",
    "ay = y_{a} \\\\\n",
    "by = y_{b} \\\\\n",
    "py = y_{p}\n",
    "$$\n",
    "\n",
    "Now we can just set up a pair of linear equations like this:\n",
    "\n",
    "```python\n",
    "            sympy.Eq(a*ax + b*bx, px)\n",
    "            sympy.Eq(a*ay + b*by, py)\n",
    "```\n",
    "\n",
    "This method returns a list of solutions, where each list contains a tuple of `(a_presses, b_presses)`.\n",
    "\n",
    "Finally, I implement a `cost()` method, which determines the smallest `(a_presses * A_COST) + (b_presses * B_COST)` for all possible solutions. And that's it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Claw():\n",
    "    A_COST = 3\n",
    "    B_COST = 1\n",
    "    \n",
    "    btn_a: Point\n",
    "    btn_b: Point\n",
    "    prize: Point\n",
    "    \n",
    "    def cost(self) -> int:\n",
    "        \"\"\" Given one or more combinations of a+b button presses that get us to the prize point,\n",
    "        determine the combination with the lowest cost. \"\"\"\n",
    "        \n",
    "        solutions = self._solve()\n",
    "        if solutions:\n",
    "            return min(a * Claw.A_COST + b * Claw.B_COST for (a, b) in solutions)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _solve(self) -> list:\n",
    "        \"\"\" Solve for two linear equations, to determine a and b:\n",
    "        a*ax + b*bx = px\n",
    "        a*ay + b*by = py\n",
    "        \"\"\"\n",
    "        a, b =sympy.symbols(\"a, b\", integer=True)\n",
    "        \n",
    "        ax, bx, px = self.btn_a.x, self.btn_b.x, self.prize.x\n",
    "        ay, by, py = self.btn_a.y, self.btn_b.y, self.prize.y\n",
    "        \n",
    "        equations = [\n",
    "            sympy.Eq(a*ax + b*bx, px), \n",
    "            sympy.Eq(a*ay + b*by, py)\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            solution_list = []\n",
    "            solutions = sympy.solve(equations, (a, b)) # Solve\n",
    "            \n",
    "            # Empty list if no solution; dict if one solution; list of dicts if multiple solutions\n",
    "            if solutions: \n",
    "                # Convert to a list, so we can iterate through solutions consistently\n",
    "                if isinstance(solutions, dict):\n",
    "                    solutions = [solutions]\n",
    "\n",
    "                for solution in solutions:\n",
    "                    solution_list.append((solution[a], solution[b]))\n",
    "                    \n",
    "            return solution_list\n",
    "                \n",
    "        except (sympy.SympifyError, IndexError) as e:\n",
    "            logger.error(f\"Could not find a solution. Original exception: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(data, part2):\n",
    "    blocks = data.split(\"\\n\\n\")\n",
    "    \n",
    "    claws = []\n",
    "    for block in blocks:\n",
    "        points = [Point(*map(int, re.search(r\"(\\d+).*?(\\d+)\", line).groups())) for line in block.splitlines()]\n",
    "        \n",
    "        # For part 2\n",
    "        if part2:\n",
    "            points[2] = Point(points[2].x + 10000000000000, points[2].y + 10000000000000)\n",
    "            \n",
    "        claws.append(Claw(*points))\n",
    "    \n",
    "    return claws\n",
    "    \n",
    "def solve(data, part2=False):\n",
    "    claws = parse_input(data, part2)\n",
    "    \n",
    "    tokens = 0\n",
    "    for claw in claws:\n",
    "        logger.debug(claw)\n",
    "        cost = claw.cost()\n",
    "        logger.debug(f\"{cost}\")\n",
    "        \n",
    "        if cost:\n",
    "            tokens += cost\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "Button A: X+94, Y+34\n",
    "Button B: X+22, Y+67\n",
    "Prize: X=8400, Y=5400\n",
    "\n",
    "Button A: X+26, Y+66\n",
    "Button B: X+67, Y+21\n",
    "Prize: X=12748, Y=12176\n",
    "\n",
    "Button A: X+17, Y+86\n",
    "Button B: X+84, Y+37\n",
    "Prize: X=7870, Y=6450\n",
    "\n",
    "Button A: X+69, Y+23\n",
    "Button B: X+27, Y+71\n",
    "Prize: X=18641, Y=10279\"\"\")\n",
    "sample_answers = [480]\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "soln = solve(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 13 Part 2\n",
    "\n",
    "Eek! We're told to add `10000000000000` to both the x and y components of our target point. This makes a target a LONG WAY AWAY!!\n",
    "\n",
    "**What is the fewest tokens you would have to spend to win all possible prizes?**\n",
    "\n",
    "How will SymPy cope with this?\n",
    "\n",
    "It turns out... EASILY!!\n",
    "\n",
    "For part 2, the only change I've made is to add a parameter to our `parse_input()` method, to flag if we're in Part 2. If so, we add the required number to our prize point x and y coordinates. Other than that, the solution is EXACTLY THE SAME!\n",
    "\n",
    "It solves in under 5s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "Button A: X+94, Y+34\n",
    "Button B: X+22, Y+67\n",
    "Prize: X=8400, Y=5400\n",
    "\n",
    "Button A: X+26, Y+66\n",
    "Button B: X+67, Y+21\n",
    "Prize: X=12748, Y=12176\n",
    "\n",
    "Button A: X+17, Y+86\n",
    "Button B: X+84, Y+37\n",
    "Prize: X=7870, Y=6450\n",
    "\n",
    "Button A: X+69, Y+23\n",
    "Button B: X+27, Y+71\n",
    "Prize: X=18641, Y=10279\"\"\")\n",
    "sample_answers = [875318608908] # It turns out 875318608908 is answer needed for sample in Part 2\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve(curr_input, part2=True), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "soln = solve(input_data, part2=True)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day 14: Restroom Redoubt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"14\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 14 Part 1\n",
    "\n",
    "We need to avoid a swarm of robots! Our input is their current positions and velocities, e.g.\n",
    "\n",
    "```text\n",
    "p=0,4 v=3,-3\n",
    "p=6,3 v=-1,-3\n",
    "p=10,3 v=-1,2\n",
    "p=2,0 v=2,-1\n",
    "p=0,0 v=1,3\n",
    "p=3,0 v=-2,-2\n",
    "p=7,6 v=-1,-3\n",
    "p=3,0 v=-1,-2\n",
    "p=9,3 v=2,3\n",
    "p=7,3 v=-1,2\n",
    "p=2,4 v=2,-3\n",
    "p=9,5 v=-3,-3\n",
    "```\n",
    "\n",
    "- Tile positions are given as x,y relative to left and top walls, respectively. \n",
    "- Velocities are given as tiles per second, in both the x and y directions. Thus, they are vectors.\n",
    "- We're told that the space occupied by the robots is 101 tiles wide, and 103 tiles tall.\n",
    "- Robots _can_ occupy the same tile at the same time. So a given tile can contain multiple robots.\n",
    "- Robots can teleport! I.e. when they reach an edge, they teleport into the opposite edge.\n",
    "\n",
    "We're told to:\n",
    "\n",
    "- Split the area into 4 quadrants, AFTER eliminating the middle row and middle column.\n",
    "- Count the robots in each quadrant.\n",
    "- Multiply the four quadrant counts to give us a number called the _safety factor_.\n",
    "\n",
    "**What will the safety factor be after exactly 100 seconds have elapsed?**\n",
    "\n",
    "#### Solution Overview\n",
    "\n",
    "- First, parse the input data to determine position and velocity of each robot. Note that the regex needs to cope with negative velocity components.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Robot:\n",
    "    posn: Point\n",
    "    velocity: Point\n",
    "    \n",
    "    # Instance variable to store the initial position\n",
    "    initial_posn: Point = field(init=False)\n",
    "    \n",
    "    # Class variables\n",
    "    width: ClassVar[int] = 0\n",
    "    height: ClassVar[int] = 0\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\" Set initial_posn after initialization \"\"\"\n",
    "        self.initial_posn = self.posn\n",
    "        \n",
    "    def posn_at_t(self, t: int) -> Point:\n",
    "        \"\"\" Return the position at time t \"\"\"\n",
    "        new_x = (self.initial_posn.x + t*self.velocity.x) % Robot.width\n",
    "        new_y = (self.initial_posn.y + t*self.velocity.y) % Robot.height\n",
    "        return Point(new_x, new_y)\n",
    "    \n",
    "    def move(self) -> Point:\n",
    "        \"\"\" Increment the current position by the velocity vector \"\"\"\n",
    "        new_x = (self.posn.x + self.velocity.x) % Robot.width\n",
    "        new_y = (self.posn.y + self.velocity.y) % Robot.height\n",
    "        self.posn = Point(new_x, new_y)\n",
    "        return self.posn\n",
    "\n",
    "def parse_input(data):\n",
    "    \"\"\" Parse data like: p=0,4 v=3,-3 \"\"\"\n",
    "    robots = []\n",
    "    for line in data:\n",
    "        px,py,vx,vy = list(map(int, re.search(r\"p=(\\d+),(\\d+) v=(-?\\d+),(-?\\d+)\", line).groups()))\n",
    "        robots.append(Robot(Point(px,py), Point(vx,vy)))\n",
    "        \n",
    "    return robots\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_quadrants(new_posns, mid_col, mid_row) -> dict:\n",
    "    \"\"\" Split the grid quadrants. \n",
    "    Return the dict of { quadrant: count of robots } \"\"\"\n",
    "    quadrants = defaultdict(int)\n",
    "    for col_half in [0, 1]: # left then right\n",
    "        col_start = (mid_col+1) * col_half\n",
    "        \n",
    "        for row_half in [0, 1]: # top then bottom\n",
    "            row_start = (mid_row+1) * row_half\n",
    "            \n",
    "            for r in range(row_start, row_start+mid_row):\n",
    "                for c in range(col_start, col_start+mid_col):\n",
    "                    current_point = Point(c,r)\n",
    "                    if current_point in new_posns:\n",
    "                        quadrants[(col_half, row_half)] += new_posns[current_point]\n",
    "    \n",
    "    return quadrants\n",
    "\n",
    "def solve_part1(data, width: int, height: int) -> int:\n",
    "    TIME = 100\n",
    "    MID_COL = width // 2\n",
    "    MID_ROW = height // 2\n",
    "    \n",
    "    Robot.width = width\n",
    "    Robot.height = height\n",
    "    \n",
    "    robots = parse_input(data)\n",
    "    \n",
    "    new_posns = defaultdict(int)\n",
    "    for robot in robots:\n",
    "        new_posn = robot.posn_at_t(t=TIME)\n",
    "        new_posns[new_posn] += 1\n",
    "    \n",
    "    logger.info(f\"\\n{render_grid(width, height, new_posns, MID_COL, MID_ROW)}\")\n",
    "    \n",
    "    quadrants = determine_quadrants(new_posns, MID_COL, MID_ROW)\n",
    "\n",
    "    # (0, 0) = TL, (0, 1): BL, (1, 0): TR, (1, 1): BR\n",
    "    for quadrant, robot_count in quadrants.items():\n",
    "        logger.debug(f\"{quadrant}:{robot_count}\")\n",
    "    \n",
    "    safety_factor = math.prod(quadrants.values())\n",
    "    return safety_factor\n",
    "\n",
    "def render_grid(width, height, new_posns, mid_col=None, mid_row=None) -> str:\n",
    "    rows_list = [] \n",
    "    for r in range(height):\n",
    "        if mid_row and r == mid_row:\n",
    "            cols_for_row = width*[\" \"]\n",
    "        else:\n",
    "            cols_for_row = []\n",
    "            for c in range(width):\n",
    "                if mid_col and c == mid_col:\n",
    "                    cols_for_row.append(\" \")\n",
    "                else:\n",
    "                    current_point = Point(c,r)\n",
    "                    if current_point in new_posns:\n",
    "                        if isinstance(new_posns, dict):             \n",
    "                            cols_for_row.append(str(new_posns[current_point]))\n",
    "                        else:\n",
    "                            cols_for_row.append(\"*\")\n",
    "                    else:\n",
    "                        cols_for_row.append(\".\")\n",
    "                \n",
    "        rows_list.append(\"\".join(cols_for_row))\n",
    "    \n",
    "    return \"\\n\".join(rows_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"\\\n",
    "p=0,4 v=3,-3\n",
    "p=6,3 v=-1,-3\n",
    "p=10,3 v=-1,2\n",
    "p=2,0 v=2,-1\n",
    "p=0,0 v=1,3\n",
    "p=3,0 v=-2,-2\n",
    "p=7,6 v=-1,-3\n",
    "p=3,0 v=-1,-2\n",
    "p=9,3 v=2,3\n",
    "p=7,3 v=-1,2\n",
    "p=2,4 v=2,-3\n",
    "p=9,5 v=-3,-3\"\"\")\n",
    "sample_answers = [12]\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input.splitlines(), width=11, height=7), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data, width=101, height=103)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 14 Part 2\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_contiguous_points(cols_with_robots, min_contiguous):\n",
    "    \"\"\"Check if there are at least `min_contiguous` contiguous points. \"\"\"\n",
    "    \n",
    "    cols_with_robots.sort() # Sort into ascending column values\n",
    "\n",
    "    count = 1  # Track the current contiguous count\n",
    "    for i in range(1, len(cols_with_robots)):\n",
    "        if cols_with_robots[i] == cols_with_robots[i - 1] + 1:\n",
    "            count += 1\n",
    "            if count >= min_contiguous:\n",
    "                return True\n",
    "        else:\n",
    "            count = 1  # Reset count if sequence breaks\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data, width: int, height: int):\n",
    "    MIN_CONTIGUOUS_ROBOTS = 10\n",
    "    \n",
    "    Robot.width = width\n",
    "    Robot.height = height\n",
    "    robots = parse_input(data)\n",
    "\n",
    "    MAX_ITERATIONS = 100000 # I have no idea how many iterations we're going to need!\n",
    "    \n",
    "    for t in tqdm(range(MAX_ITERATIONS)):\n",
    "        posns = [robot.move() for robot in robots] # Make one move\n",
    "        \n",
    "        for r in range(height):\n",
    "            cols_with_robots = [posn.x for posn in posns if posn.y == r]\n",
    "            if has_contiguous_points(cols_with_robots, min_contiguous=MIN_CONTIGUOUS_ROBOTS):\n",
    "                logger.info(f\"\\n{render_grid(width, height, posns)}\")\n",
    "                return t \n",
    "            \n",
    "    raise RuntimeError(f\"Unable to find the easter gg after {MAX_ITERATIONS} iterations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "soln = solve_part2(input_data, width=101, height=103)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day n: title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"n\" # replace with actual number (without leading digit)\n",
    "show_day_link(DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2024d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day n Part 1\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"abcdef\"\"\")\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day n Part 2\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"abcdef\"\"\")\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".aoc-conda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
