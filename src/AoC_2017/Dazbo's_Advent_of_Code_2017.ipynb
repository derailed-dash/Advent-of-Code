{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "This notebook contains my solutions for **<a href=\"https://adventofcode.com/2017\" target=\"_blank\">Advent of Code 2017</a>**.\n",
    "\n",
    "A few notes...\n",
    "- The source for this notebook source lives in my GitHub repo, <a href=\"https://github.com/derailed-dash/Advent-of-Code/blob/master/src/AoC_2017/Dazbo's_Advent_of_Code_2017.ipynb\" target=\"_blank\">here</a>.\n",
    "- You can run this Notebook wherever you like. For example, you could...\n",
    "  - Run it locally, in your own Jupyter environment.\n",
    "  - Run it in a cloud-based Jupyter environment, with no setup required on your part!  For example, <a href=\"https://colab.research.google.com/github/derailed-dash/Advent-of-Code/blob/master/src/AoC_2017/Dazbo's_Advent_of_Code_2017.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Google Colab\"/></a>\n",
    "- **To run the notebook, execute the cells in the [Setup](#Setup) section, as described below. Then you can run the code for any given day.**\n",
    "- Be mindful that the first time you run this notebook, you will need to **obtain your AoC session key** and store it, if you have not done so already. This allows the notebook to automatically retrieve your input data. (See the guidance in the **[Get Access to Your AoC Data](#Get-Access-to-Your-AoC-Data)** section for details.)\n",
    "- Use the navigation menu on the left to jump to any particular day.\n",
    "- All of my AoC solutions are documented in my <a href=\"https://aoc.just2good.co.uk/\" target=\"_blank\">AoC Python Walkthrough site</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3PMQJRrR38P",
    "tags": []
   },
   "source": [
    "# Setup\n",
    "\n",
    "You need to run all cells in this section, before running any particular day solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWxsAMaXTGEQ"
   },
   "source": [
    "## Packages and Imports\n",
    "\n",
    "Here we use `pip` to install the packages used by my solutions in this event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Dgeww1rMrkQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --no-cache-dir jupyterlab-lsp networkx dazbo-commons python-dotenv ipykernel sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5Ki_HvOJUWk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import ast\n",
    "from collections import Counter, deque, defaultdict\n",
    "import copy\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from enum import Enum, auto\n",
    "from functools import cache, reduce\n",
    "import heapq\n",
    "from itertools import permutations, combinations, count, cycle\n",
    "import logging\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "import platform\n",
    "import re\n",
    "import sympy\n",
    "import requests\n",
    "\n",
    "import dazbo_commons as dc # my own utility library, which includes things like coloured logging\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass\n",
    "from IPython.display import display\n",
    "from IPython.core.display import Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZNTgtGzUImv",
    "tags": []
   },
   "source": [
    "## Logging and Output\n",
    "\n",
    "Set up a new logger that uses `ColouredFormatter`, such that we have coloured logging.  The log colour depends on the logging level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwzjfUFCKhXe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup logger\n",
    "YEAR = 2017\n",
    "APP_NAME = \"aoc\" + str(YEAR)\n",
    "logger = dc.retrieve_console_logger(APP_NAME)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.info(\"Logger initialised.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages\n",
    "\n",
    "- [ffmpeg](https://ffmpeg.org/): in order to render video output, i.e. for visualisations.\n",
    "- graphviz: for visualising graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_command(command):\n",
    "    \"\"\"Run a shell command and print its output in real-time.\"\"\"\n",
    "    process = subprocess.Popen(\n",
    "        command, \n",
    "        shell=True, \n",
    "        stdout=subprocess.PIPE, \n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "    \n",
    "    # Read and print the output line by line\n",
    "    if process.stdout is not None:\n",
    "        for line in iter(process.stdout.readline, b''):\n",
    "            logger.info(line.decode().strip())\n",
    "        process.stdout.close()\n",
    "        \n",
    "    process.wait()\n",
    "    \n",
    "def install_software():\n",
    "    os_name = platform.system()\n",
    "    logger.info(f\"Installing packages on {os_name}...\")\n",
    "    if os_name == \"Windows\":\n",
    "        run_command(\"winget install ffmpeg --silent --no-upgrade\")\n",
    "        run_command(\"winget install graphviz --silent --no-upgrade\")\n",
    "    elif os_name == \"Linux\":\n",
    "        run_command(\"apt-get -qq update && apt-get -qq -y install ffmpeg\")\n",
    "        run_command(\"apt -qq -y install graphviz\")\n",
    "    elif os_name == \"Darwin\":\n",
    "        run_command(\"brew install ffmpeg\")\n",
    "        run_command(\"brew install graphviz\")\n",
    "    else:\n",
    "        logger.error(f\"Unsupported operating system: {os_name}\")\n",
    "\n",
    "try:\n",
    "    logger.debug(\"Checking if ffmpeg is installed\")\n",
    "    output = subprocess.check_output([\"ffmpeg\", \"-version\"])\n",
    "    logger.debug(f\"ffmpeg version: {output.decode().strip()}\")\n",
    "    mpeg_installed = True\n",
    "    logger.debug(\"ffmpeg is already installed.\")\n",
    "except subprocess.CalledProcessError:\n",
    "    logger.debug(\"ffmpeg is not installed.\")\n",
    "    mpeg_installed = False\n",
    "\n",
    "if not mpeg_installed:\n",
    "    install_software()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking `ffmpeg` version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Note that installed applications may not be immediately available after first installing.\\n\" \\\n",
    "            \"It may be necessary to relaunch the notebook environment.\")\n",
    "\n",
    "!ffmpeg -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y61RhVrHSjVA"
   },
   "source": [
    "## Get Access to Your AoC Data\n",
    "\n",
    "Now provide your unique AoC session key, in order to download your input data. You can get this by:\n",
    "1. Logging into [Advent of Code](https://adventofcode.com/).\n",
    "1. From your browser, open Developer Tools. (In Chrome, you can do this by pressing F12.)\n",
    "1. Open the `Application` tab.\n",
    "1. Storage -> Cookies -> https://adventofcode.com\n",
    "1. Copy the value associated with the cookie called `session`.\n",
    "1. Once you've determiend your session key, I recommend you store it in a file called `.env`, in your `Advent-of-Code` folder, like this: \\\n",
    "`AOC_SESSION_COOKIE=536...your-own-session-key...658` \\\n",
    "This notebook will try to retrieve the key from that location.  If it is unable to retrieve the key, it will prompt you to enter your key in the cell below.\n",
    "\n",
    "![Finding the session cookie](https://aoc.just2good.co.uk/assets/images/aoc-cookie.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dc.get_envs_from_file() # read env variables from a .env file, if we can find one\n",
    "except ValueError as e:\n",
    "    logger.error(f\"Problem reading env file:\\n{e}\")    \n",
    "\n",
    "if os.getenv('AOC_SESSION_COOKIE'):\n",
    "    logger.info('Session cookie retrieved: %s...%s', os.environ['AOC_SESSION_COOKIE'][0:6], os.environ['AOC_SESSION_COOKIE'][-6:])\n",
    "else: # it's not in our environment variables, so we'll need to input the value\n",
    "    os.environ['AOC_SESSION_COOKIE'] = getpass('Enter AoC session key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9A24B4MSyhT"
   },
   "source": [
    "## Load Helpers and Useful Classes\n",
    "\n",
    "Now we load a bunch of helper functions and classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPOsmENmYf8h",
    "tags": []
   },
   "source": [
    "### Locations\n",
    "\n",
    "Where any input and output files get stored.\n",
    "\n",
    "<img src=\"https://aoc.just2good.co.uk/assets/images/notebook-content-screenshot.png\" width=\"320\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VK27bcGiK0_M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Paths and Locations\n",
    "#################################################################\n",
    "\n",
    "# locations = dc.get_locations(script_name=\"\")\n",
    "\n",
    "# @dataclass\n",
    "# class Locations:\n",
    "#     \"\"\" Dataclass for storing various location properties \"\"\"\n",
    "#     script_name: str\n",
    "#     script_dir: Path\n",
    "#     input_dir: Path\n",
    "#     output_dir: Path\n",
    "#     input_file: Path\n",
    "\n",
    "# def get_locations(script_name, folder=\"\") -> Locations:\n",
    "#     \"\"\" Set various paths, based on the location of the calling script. \"\"\"\n",
    "#     current_directory = os.getcwd()\n",
    "#     script_dir = Path(Path().resolve(), folder, script_name)\n",
    "#     input_dir = Path(script_dir, \"input\")\n",
    "#     output_dir = Path(script_dir, \"output\")\n",
    "#     input_file = Path(input_dir, \"input.txt\")\n",
    "\n",
    "#     return Locations(script_name, script_dir,\n",
    "#                      input_dir,\n",
    "#                      output_dir,\n",
    "#                      input_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14ISscMTadAO"
   },
   "source": [
    "### Retrieve the Input Data\n",
    "\n",
    "This works by using your unique session cookie to retrieve your input data. E.g. from a URL like:\n",
    "\n",
    "`https://adventofcode.com/2015/day/1/input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwP0r3BAaxjt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Retrieving input data\n",
    "##################################################################\n",
    "\n",
    "def write_puzzle_input_file(year: int, day, locations: dc.Locations):\n",
    "    \"\"\" Use session key to obtain user's unique data for this year and day.\n",
    "    Only retrieve if the input file does not already exist.\n",
    "    Return True if successful.\n",
    "    Requires env: AOC_SESSION_COOKIE, which can be set from the .env.\n",
    "    \"\"\"\n",
    "    if os.path.exists(locations.input_file):\n",
    "        logger.debug(\"%s already exists\", os.path.basename(locations.input_file))\n",
    "        return os.path.basename(locations.input_file)\n",
    "\n",
    "    session_cookie = os.getenv('AOC_SESSION_COOKIE')\n",
    "    if not session_cookie:\n",
    "        raise ValueError(\"Could not retrieve session cookie.\")\n",
    "\n",
    "    logger.info('Session cookie retrieved: %s...%s', session_cookie[0:6], session_cookie[-6:])\n",
    "\n",
    "    # Create input folder, if it doesn't exist\n",
    "    if not locations.input_dir.exists():\n",
    "        locations.input_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    url = f\"https://adventofcode.com/{year}/day/{day}/input\"\n",
    "    \n",
    "    # Don't think we need to set a user-agent\n",
    "    # headers = {\n",
    "    #     \"User-Agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'\n",
    "    # }\n",
    "    cookies = { \n",
    "        \"session\": session_cookie\n",
    "    }\n",
    "    response = requests.get(url, cookies=cookies, timeout=5)\n",
    "\n",
    "    data = \"\"\n",
    "    if response.status_code == 200:\n",
    "        data = response.text\n",
    "\n",
    "        with open(locations.input_file, 'w') as file:\n",
    "            logger.debug(\"Writing input file %s\", os.path.basename(locations.input_file))\n",
    "            file.write(data)\n",
    "            return data\n",
    "    else:\n",
    "        raise ValueError(f\"Unable to retrieve input data.\\n\" +\n",
    "                         f\"HTTP response: {response.status_code}\\n\" +\n",
    "                         f\"{response.reason}: {response.content.decode('utf-8').strip()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yakibhW73Rqi"
   },
   "source": [
    "### Testing\n",
    "\n",
    "A really simple function for testing that our solution produces the expected test output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6nbd6WMryWi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(test, answer):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        test: the answer given by our solution\n",
    "        answer: the expected answer, e.g. from instructions\n",
    "    \"\"\"\n",
    "    if test != answer:\n",
    "        raise AssertionError(f\"{test} != {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bcBQkP0a2zA"
   },
   "source": [
    "### Useful Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8sU4Ez_bBKl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# POINTS, VECTORS AND GRIDS\n",
    "#################################################################\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Point:\n",
    "    \"\"\" Class for storing a point x,y coordinate \"\"\"\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "    def __add__(self, other: Point):\n",
    "        return Point(self.x + other.x, self.y + other.y)\n",
    "\n",
    "    def __mul__(self, other: Point):\n",
    "        \"\"\" (x, y) * (a, b) = (xa, yb) \"\"\"\n",
    "        return Point(self.x * other.x, self.y * other.y)\n",
    "\n",
    "    def __sub__(self, other: Point):\n",
    "        return self + Point(-other.x, -other.y)\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        # Arbitrary comparison logic\n",
    "        return (self.x, self.y) < (other.x, other.y)\n",
    "    \n",
    "    def yield_neighbours(self, include_diagonals=True, include_self=False):\n",
    "        \"\"\" Generator to yield neighbouring Points \"\"\"\n",
    "\n",
    "        deltas: list\n",
    "        if not include_diagonals:\n",
    "            deltas = [vector.value for vector in Vectors if abs(vector.value[0]) != abs(vector.value[1])]\n",
    "        else:\n",
    "            deltas = [vector.value for vector in Vectors]\n",
    "\n",
    "        if include_self:\n",
    "            deltas.append((0, 0))\n",
    "\n",
    "        for delta in deltas:\n",
    "            yield Point(self.x + delta[0], self.y + delta[1])\n",
    "\n",
    "    def neighbours(self, include_diagonals=True, include_self=False) -> list[Point]:\n",
    "        \"\"\" Return all the neighbours, with specified constraints.\n",
    "        It wraps the generator with a list. \"\"\"\n",
    "        return list(self.yield_neighbours(include_diagonals, include_self))\n",
    "\n",
    "    def get_specific_neighbours(self, directions: list[Vectors]) -> list[Point]:\n",
    "        \"\"\" Get neighbours, given a specific list of allowed locations \"\"\"\n",
    "        return [(self + Point(*vector.value)) for vector in list(directions)]\n",
    "\n",
    "    @staticmethod\n",
    "    def manhattan_distance(a_point: Point) -> int:\n",
    "        \"\"\" Return the Manhattan distance value of this vector \"\"\"\n",
    "        return sum(abs(coord) for coord in asdict(a_point).values())\n",
    "\n",
    "    def manhattan_distance_from(self, other: Point) -> int:\n",
    "        \"\"\" Manhattan distance between this Vector and another Vector \"\"\"\n",
    "        diff = self-other\n",
    "        return Point.manhattan_distance(diff)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"P({self.x},{self.y})\"\n",
    "\n",
    "class Vectors(Enum):\n",
    "    \"\"\" Enumeration of 8 directions.\n",
    "    Note: y axis increments in the North direction, i.e. N = (0, 1) \"\"\"\n",
    "    N = (0, 1)\n",
    "    NE = (1, 1)\n",
    "    E = (1, 0)\n",
    "    SE = (1, -1)\n",
    "    S = (0, -1)\n",
    "    SW = (-1, -1)\n",
    "    W = (-1, 0)\n",
    "    NW = (-1, 1)\n",
    "\n",
    "    @property\n",
    "    def y_inverted(self):\n",
    "        \"\"\" Return vector, but with y-axis inverted. I.e. N = (0, -1) \"\"\"\n",
    "        x, y = self.value\n",
    "        return (x, -y)\n",
    "\n",
    "class VectorDicts():\n",
    "    \"\"\" Contains constants for Vectors \"\"\"\n",
    "    ARROWS = {\n",
    "        '^': Vectors.N.value,\n",
    "        '>': Vectors.E.value,\n",
    "        'v': Vectors.S.value,\n",
    "        '<': Vectors.W.value\n",
    "    }\n",
    "\n",
    "    DIRS = {\n",
    "        'U': Vectors.N.value,\n",
    "        'R': Vectors.E.value,\n",
    "        'D': Vectors.S.value,\n",
    "        'L': Vectors.W.value\n",
    "    }\n",
    "\n",
    "    NINE_BOX: dict[str, tuple[int, int]] = {\n",
    "        # x, y vector for adjacent locations\n",
    "        'tr': (1, 1),\n",
    "        'mr': (1, 0),\n",
    "        'br': (1, -1),\n",
    "        'bm': (0, -1),\n",
    "        'bl': (-1, -1),\n",
    "        'ml': (-1, 0),\n",
    "        'tl': (-1, 1),\n",
    "        'tm': (0, 1)\n",
    "    }\n",
    "\n",
    "class Grid():\n",
    "    \"\"\" 2D grid of point values. \"\"\"\n",
    "    def __init__(self, grid_array: list) -> None:\n",
    "        self._array = grid_array\n",
    "        self._width = len(self._array[0])\n",
    "        self._height = len(self._array)\n",
    "\n",
    "    def value_at_point(self, point: Point) -> int:\n",
    "        \"\"\" The value at this point \"\"\"\n",
    "        return self._array[point.y][point.x]\n",
    "\n",
    "    def set_value_at_point(self, point: Point, value: int):\n",
    "        self._array[point.y][point.x] = value\n",
    "\n",
    "    def valid_location(self, point: Point) -> bool:\n",
    "        \"\"\" Check if a location is within the grid \"\"\"\n",
    "        if (0 <= point.x < self._width and  0 <= point.y < self._height):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def width(self):\n",
    "        \"\"\" Array width (cols) \"\"\"\n",
    "        return self._width\n",
    "\n",
    "    @property\n",
    "    def height(self):\n",
    "        \"\"\" Array height (rows) \"\"\"\n",
    "        return self._height\n",
    "\n",
    "    def all_points(self) -> list[Point]:\n",
    "        points = [Point(x, y) for x in range(self.width) for y in range(self.height)]\n",
    "        return points\n",
    "\n",
    "    def rows_as_str(self):\n",
    "        \"\"\" Return the grid \"\"\"\n",
    "        return [\"\".join(str(char) for char in row) for row in self._array]\n",
    "\n",
    "    def cols_as_str(self):\n",
    "        \"\"\" Render columns as str. Returns: list of str \"\"\"\n",
    "        cols_list = list(zip(*self._array))\n",
    "        return [\"\".join(str(char) for char in col) for col in cols_list]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Grid(size={self.width}*{self.height})\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"\\n\".join(\"\".join(map(str, row)) for row in self._array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xNijk6xbCVa"
   },
   "source": [
    "### Useful Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DT5FSYliC9wp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# CONSOLE STUFF\n",
    "#################################################################\n",
    "\n",
    "def cls():\n",
    "    \"\"\" Clear console \"\"\"\n",
    "    os.system('cls' if os.name=='nt' else 'clear')\n",
    "\n",
    "#################################################################\n",
    "# USEFUL FUNCTIONS\n",
    "#################################################################\n",
    "\n",
    "def binary_search(target, low:int, high:int, func, *func_args, reverse_search=False):\n",
    "    \"\"\" Generic binary search function that takes a target to find,\n",
    "    low and high values to start with, and a function to run, plus its args.\n",
    "    Implicitly returns None if the search is exceeded. \"\"\"\n",
    "\n",
    "    res = None  # just set it to something that isn't the target\n",
    "    candidate = 0  # initialise; we'll set it to the mid point in a second\n",
    "\n",
    "    while low < high:  # search exceeded\n",
    "        candidate = int((low+high) // 2)  # pick mid-point of our low and high\n",
    "        res = func(candidate, *func_args) # run our function, whatever it is\n",
    "        logger.debug(\"%d -> %d\", candidate, res)\n",
    "        if res == target:\n",
    "            return candidate  # solution found\n",
    "\n",
    "        comp = operator.lt if not reverse_search else operator.gt\n",
    "        if comp(res, target):\n",
    "            low = candidate\n",
    "        else:\n",
    "            high = candidate\n",
    "\n",
    "def merge_intervals(intervals: list[list]) -> list[list]:\n",
    "    \"\"\" Takes intervals in the form [[a, b][c, d][d, e]...]\n",
    "    Intervals can overlap.  Compresses to minimum number of non-overlapping intervals. \"\"\"\n",
    "    intervals.sort()\n",
    "    stack = []\n",
    "    stack.append(intervals[0])\n",
    "\n",
    "    for interval in intervals[1:]:\n",
    "        # Check for overlapping interval\n",
    "        if stack[-1][0] <= interval[0] <= stack[-1][-1]:\n",
    "            stack[-1][-1] = max(stack[-1][-1], interval[-1])\n",
    "        else:\n",
    "            stack.append(interval)\n",
    "\n",
    "    return stack\n",
    "\n",
    "@cache\n",
    "def get_factors(num: int) -> set[int]:\n",
    "    \"\"\" Gets the factors for a given number. Returns a set[int] of factors.\n",
    "        # E.g. when num=8, factors will be 1, 2, 4, 8 \"\"\"\n",
    "    factors = set()\n",
    "\n",
    "    # Iterate from 1 to sqrt of 8,\n",
    "    # since a larger factor of num must be a multiple of a smaller factor already checked\n",
    "    for i in range(1, int(num**0.5) + 1):  # e.g. with num=8, this is range(1, 3)\n",
    "        if num % i == 0: # if it is a factor, then dividing num by it will yield no remainder\n",
    "            factors.add(i)  # e.g. 1, 2\n",
    "            factors.add(num//i)  # i.e. 8//1 = 8, 8//2 = 4\n",
    "\n",
    "    return factors\n",
    "\n",
    "def to_base_n(number: int, base: int):\n",
    "    \"\"\" Convert any integer number into a base-n string representation of that number.\n",
    "    E.g. to_base_n(38, 5) = 123\n",
    "\n",
    "    Args:\n",
    "        number (int): The number to convert\n",
    "        base (int): The base to apply\n",
    "\n",
    "    Returns:\n",
    "        [str]: The string representation of the number\n",
    "    \"\"\"\n",
    "    ret_str = \"\"\n",
    "    curr_num = number\n",
    "    while curr_num:\n",
    "        ret_str = str(curr_num % base) + ret_str\n",
    "        curr_num //= base\n",
    "\n",
    "    return ret_str if number > 0 else \"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env Clear\n",
    "\n",
    "Only run the next cell if you want to manually clear your session key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del os.environ['AOC_SESSION_COOKIE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y68fv1BebLsG"
   },
   "source": [
    "# Days\n",
    "\n",
    "Here you'll find a template to build a solution for a given day, and then the solutions for all days in this event.\n",
    "\n",
    "To copy the template day, select all the cells in the `Day n` template, add a new cell at the end, and then paste the cells there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FT4HLZLwevr"
   },
   "source": [
    "## Day 1: Inverse Captcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VoMC3MaJ1I9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = 1\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNvM0hOF0tBR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = dc.get_locations(d_name)\n",
    "for attribute, value in vars(locations).items():\n",
    "    logger.debug(f\"{attribute}: {value}\")\n",
    "\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = f.read().strip()\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAh6_AWRbYPo"
   },
   "source": [
    "### Day 1 Part 1\n",
    "\n",
    "The time is 25ms to midnight, and we're inside the computer that prints the _Naughty or Nice_ list! Each day in this year's challenge brings us 1ms closer to midnight.\n",
    "\n",
    "Today, we have to solve a Captcha to prove that we're _not_ human.\n",
    "\n",
    "Sum all digits that match the next digit in a circular list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omfr-hKq_Kyq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sum_match_digits(data, offset: int) -> int:\n",
    "    circular_digits = data + data\n",
    "    logger.debug(circular_digits)\n",
    "    total = 0\n",
    "    for i in range(len(data)):\n",
    "        if circular_digits[i] == circular_digits[i+offset]:\n",
    "            total += int(circular_digits[i])\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhWomZ6ewNi-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def part1(data) -> int:\n",
    "    return sum_match_digits(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uw4xFe7R7jf0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"91212129\"\"\")\n",
    "sample_answers = [9]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(part1(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6ARzwH_AHU0"
   },
   "source": [
    "### Day 1 Part 2\n",
    "\n",
    "Sum all the digits that match a digit that is exactly halfway along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uju3nPBKx9RW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def part2(data) -> int:\n",
    "    half = len(data)//2\n",
    "    logger.debug(\"Half=%s\", half)\n",
    "    return sum_match_digits(data, half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcJdRHyK8TRY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"12131415\"\"\")\n",
    "sample_answers = [4]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(part2(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = part2(input_data)\n",
    "logger.info(\"Part 2: total=%d\", soln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poXq9ao40tAm"
   },
   "source": [
    "## Day 2: Corruption Checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONNCiHUsJY98",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = 2\n",
    "day_link = f\"See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yN5DrfkD3nVL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = f.read().splitlines()\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjXkDtXs0tBS"
   },
   "source": [
    "### Day 2 Part 1\n",
    "\n",
    "We neeed to calculate the spreadsheet's checksum.\n",
    "\n",
    "For each row, determine the difference between the largest value and the smallest value; the checksum is the sum of all of these differences.\n",
    "\n",
    "The input data is multiple lines.  The data can be split by either space or tab. I'll use regex to split on either. This returns a list of str values for each row.  Then I'll map these str values to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "854PR2kB0tBS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def part1(data) -> int:\n",
    "    \"\"\" Process each line. Get the largest and smallest int values from each line.\n",
    "    Determine the difference.\n",
    "    Sum the differences to give the checksum. \"\"\"\n",
    "\n",
    "    checksum = 0\n",
    "    for row in data:\n",
    "        vals = list(map(int, re.split(r'[\\t ]+', row))) # split on either tab or space\n",
    "        checksum += max(vals) - min(vals)\n",
    "\n",
    "    return checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbN7qjTS0tBT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part1(\"\"\"5 1 9 5\n",
    "7 5 3\n",
    "2 4 6 8\"\"\".splitlines()), 18) # test with sample data\n",
    "\n",
    "soln = part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AbGpopH0tBT"
   },
   "source": [
    "### Day 2 Part 2\n",
    "\n",
    "The new goal is to find the only two numbers in each row where one evenly divides the other - that is, where the result of the division operation is a whole number. They would like you to find those numbers on each line, divide them, and add up each line's result.\n",
    "\n",
    "Here I use `itertools.combinations` to return pairs of numbers from each row.\n",
    "\n",
    "E.g.\n",
    "[5, 9, 2, 8] -> (5, 9) (5, 2) (5, 8) (9, 2) (9, 8) (2, 8)\n",
    "\n",
    "Note that reverse pairs are not included in `combinations`. If you want reverse pairs, use `permutations` instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkUzEQ-90tBT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def part2(data) -> int:\n",
    "    \"\"\" Process each line. Find the only two pairs of numbers where one is divisible by the other.\n",
    "    Perform the division.\n",
    "    Sum the quotients to give the checksum. \"\"\"\n",
    "\n",
    "    checksum = 0\n",
    "    for row in data:\n",
    "        vals = list(map(int, re.split(r'[\\t ]+', row))) # split on either tab or space\n",
    "        logger.debug(vals)\n",
    "        for num1, num2 in combinations(vals, 2): # get all pairs of numbers, in one direction only\n",
    "            if num1 % num2 == 0: # check if divisible\n",
    "                checksum += num1 // num2\n",
    "            elif num2 % num1 == 0: # check if divisible in opposite direction\n",
    "                checksum += num2 // num1\n",
    "\n",
    "    return checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOVJ3YH40tBU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part2(\"\"\"5 9 2 8\n",
    "9 4 7 3\n",
    "3 8 6 5\"\"\".splitlines()), 9) # test with sample data\n",
    "\n",
    "soln = part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYTo0doWGtij"
   },
   "source": [
    "## Day 3: Spiral Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhGyVz5bIzi4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = 3\n",
    "day_link = f\"See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DtijnUvGtij",
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = int(f.read())\n",
    "\n",
    "logger.info(\"Input data:\\n%d\", input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3 Part 1\n",
    "\n",
    "We're presented with a 2D grid of spiral numbers, like this:\n",
    "\n",
    "<pre>\n",
    " .   .   .   .   .   .   .\n",
    " .  17  16  15  14  13   .\n",
    " .  18   5   4   3  12   .\n",
    " .  19   6   <b>1</b>   <b>2</b>  11  28\n",
    " .  20   7   8   9  <b>10</b>  27\n",
    " .  21  22  23  24  25  <b>26</b>\n",
    " .   .   .   .   .   .   .\n",
    "</pre>\n",
    "\n",
    "Requested data can only be retrieved from square `1`, and programs can only move U, D, L, R. They always take the shortest path using Manhattan distance. I've also shown the location of the lowest value in each successive square.\n",
    "\n",
    "**How many steps are required to carry the data from the square identified in your puzzle input all the way to the access port?**\n",
    "\n",
    "#### Requirement\n",
    "\n",
    "- We need to determine the location of our input data.\n",
    "- Then determine Manhattan distance of this value to our `1` position.\n",
    "\n",
    "#### Options\n",
    "\n",
    "1. We could use a generator to allocate each successive value.\n",
    "2. We could determine the size of each successive square. And then determine the position of our data in that outermost square.\n",
    "\n",
    "I'm going to with option 2, as it should be pretty quick.\n",
    "\n",
    "#### Determine the Perimeter\n",
    "\n",
    "- Any given perimeter is given by: $p = 4(e-1)$, where e is the length of the edge. Or: $p = 4e-4$\n",
    "- The length of the edge is given by: $e = 2(r+1)-1 = 2r + 1$, where r is the current ring.\n",
    "- So, $p = 4(2r+1-1) = 8r$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perimeter(ring: int) -> int:\n",
    "    \"\"\" Return the total number of values in this particular ring.\n",
    "    I.e. successive squares have edges of length 1, 3, 5, 7, etc. But we won't count the starting square as a ring.\n",
    "    Perimeters will be 8, 16, 24, etc \"\"\"\n",
    "    return (8 * ring)\n",
    "\n",
    "def position(target: int, ring: int, ring_start: int) -> Point:\n",
    "    \"\"\" Determine the location of our target value in the grid.\n",
    "    Do this by starting in our lower right position, and then move one position at a time, until we reach our target.\n",
    "    Args:\n",
    "    - target = the value we need to know the position of\n",
    "    - ring = the current ring (where 1 is the centre, 2 is the second ring, etc)\n",
    "    - ring_start = the lowest value of this ring\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Looking for {target} in ring {ring}, which starts at {ring_start}\")\n",
    "\n",
    "    # the inclusive boundaries of our ring\n",
    "    x_max = y_max = 0 + ring\n",
    "    x_min = y_min = 0 - ring\n",
    "\n",
    "    curr_val = ring_start\n",
    "    curr_x = 0 + ring\n",
    "    curr_y = 0 + (ring-1)\n",
    "\n",
    "    if ring_start == target:\n",
    "        return Point(curr_x, curr_y)\n",
    "\n",
    "    assert curr_val < target and curr_x == x_max, \"We're on the right edge\"\n",
    "    \n",
    "    # move up until we can't go further\n",
    "    while curr_y > y_min:\n",
    "        curr_val += 1\n",
    "        curr_y -= 1\n",
    "\n",
    "        if curr_val == target:\n",
    "            return Point(curr_x, curr_y)\n",
    "\n",
    "    assert curr_val < target and curr_y == y_min, \"We're on the top row\"\n",
    "\n",
    "    # move left until we can't go further\n",
    "    while curr_x > x_min:\n",
    "        curr_val += 1\n",
    "        curr_x -= 1\n",
    "\n",
    "        if curr_val == target:\n",
    "            return Point(curr_x, curr_y)\n",
    "\n",
    "    assert curr_val < target and curr_x == x_min, \"We're on the left edge\"\n",
    "        \n",
    "    # move down until we can't go further\n",
    "    while curr_y < y_max:\n",
    "        curr_val += 1\n",
    "        curr_y += 1\n",
    "\n",
    "        if curr_val == target:\n",
    "            return Point(curr_x, curr_y)\n",
    "\n",
    "    assert curr_val < target and curr_y == y_max, \"We're on the bottom row\"\n",
    "\n",
    "    # move right until we can't go further\n",
    "    while curr_x < x_max:\n",
    "        curr_val += 1\n",
    "        curr_x += 1\n",
    "\n",
    "        if curr_val == target:\n",
    "            return Point(curr_x, curr_y)\n",
    "\n",
    "    assert False, \"We can't be here!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrLrWR9jGtij"
   },
   "outputs": [],
   "source": [
    "def part1(data: int) -> int:\n",
    "\n",
    "    # Get the ring where our data is\n",
    "    prev_highest = highest = 1 # we start with 1 at the center\n",
    "    ring = 0 \n",
    "    while highest <= data:\n",
    "        ring += 1\n",
    "        per = perimeter(ring)\n",
    "        prev_highest = highest\n",
    "        highest += per\n",
    "\n",
    "    # Now get the position of our data in the ring\n",
    "    data_point = position(data, ring, prev_highest+1)\n",
    "    logger.debug(f\"Our data is at {data_point}\")\n",
    "    dist = data_point.manhattan_distance_from(Point(0,0))\n",
    "    logger.debug(f\"Manhattan distance = {dist}\")\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3-5S0Z1Gtij"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part1(1024), 31) # test data\n",
    "soln = part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3 Part 2\n",
    "\n",
    "Darn, I should have gone with Option 1!!\n",
    "\n",
    "The puzzle has changed such that each value assigned is the sum of the adjacent values that have already been assigned. \n",
    "\n",
    "**What is the first value written that is larger than your puzzle input?**\n",
    "\n",
    "<pre>\n",
    "147  142  133  122   59\n",
    "304    5    4    2   57\n",
    "330   10    <b>1</b>    <b>1</b>   54\n",
    "351   11   23   25   <b>26</b>\n",
    "362  747    .    .    .\n",
    "</pre>\n",
    "\n",
    "So, we're going to have to generate each value succcessively.  The number we need to reach isn't very high, so this won't be a problem.\n",
    "\n",
    "This feels like a perfect time to use a NumPy array!\n",
    "\n",
    "- Create a generator that returns successive positions, spiralling out from the centre.\n",
    "- Guess at a starting size for a square array, and initialise it with zeroes.\n",
    "- Work out the middle of our array, and save this is a delta that we will add to EVERY\n",
    "  coordinate returned by our spiral generator. (Because our spiral generator will start with 0,0.)\n",
    "- Initialise our middle coordinate to 1.\n",
    "- Then simply use NumPy sum to calculate the sum of all adjacent locations. Remember that those we haven't filled yet will have a value of 0.\n",
    "- Add this calculated sum into the new location.\n",
    "\n",
    "Easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spiral_next_posn():\n",
    "    \"\"\"A generator that yields the next location in the spiral \"\"\"\n",
    "    curr_x = curr_y = 0\n",
    "    yield curr_x, curr_y # the origin\n",
    "\n",
    "    ring = 1\n",
    "    while True:\n",
    "        # the inclusive boundaries of our ring\n",
    "        x_max = y_max = 0 + ring\n",
    "        x_min = y_min = 0 - ring\n",
    "\n",
    "        # our lower right starting position in the new ring\n",
    "        curr_x = 0 + ring\n",
    "        curr_y = 0 + (ring-1)\n",
    "        yield curr_x, curr_y        \n",
    "        \n",
    "        while curr_y > y_min: # we're on the right edge\n",
    "            curr_y -= 1  # move up\n",
    "            yield curr_x, curr_y\n",
    "\n",
    "        while curr_x > x_min: # we're on the top edge\n",
    "            curr_x -= 1  # move left\n",
    "            yield curr_x, curr_y\n",
    "\n",
    "        while curr_y < y_max: # we've on the left edge\n",
    "            curr_y += 1  # move down\n",
    "            yield curr_x, curr_y\n",
    "\n",
    "        while curr_x < x_max: # we're on the bottom edge\n",
    "            curr_x += 1  # move right\n",
    "            yield curr_x, curr_y\n",
    "\n",
    "        ring += 1 # move to next ring and start again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pBkMNEhGtik"
   },
   "outputs": [],
   "source": [
    "def part2(data: int) -> int:\n",
    "    \"\"\" We want this to return the first value larger than our input \"\"\"\n",
    "    \n",
    "    size = 20\n",
    "    grid = np.zeros((size, size), dtype=np.int32)\n",
    "    \n",
    "    spiral_generator = spiral_next_posn()\n",
    "    # this returns 0,0\n",
    "    # but we want this to be the centre of our grid. So we'll add a delta\n",
    "    delta = size // 2\n",
    "    \n",
    "    x, y = next(spiral_generator) \n",
    "    x, y = x+delta, y+delta\n",
    "    curr_val = 1\n",
    "    grid[y, x] = curr_val # initialise the center\n",
    "    logger.debug(\"Posn 1: %d, %d has value %d\", x, y, curr_val)    \n",
    "\n",
    "    # now we continue around the spiral\n",
    "    for i, posn in enumerate(spiral_generator, start=2):\n",
    "        x, y = posn\n",
    "        x, y = x+delta, y+delta\n",
    "        assert x<size and y<size, \"No solution in grid of this size\"\n",
    "        \n",
    "        curr_val = int(grid[y-1:y+2, x-1:x+2].sum()) # Get the sum of all adjacent values\n",
    "        grid[y, x] = curr_val\n",
    "\n",
    "        logger.debug(f\"Posn %d: %d, %d has value %d\", i, x, y, curr_val)\n",
    "        if curr_val > data:\n",
    "            break\n",
    "\n",
    "    return curr_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHZ7Y15FGtik"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part2(142), 147) # assert that 147 comes after 142\n",
    "soln = part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZvWwxmJbGbD"
   },
   "source": [
    "## Day 4: High-Entropy Passphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGKQZAMNKA8M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = \"4\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8k00bAJR7vCX"
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = f.read().splitlines()\n",
    "\n",
    "logger.debug(\"Input data:\\n%s\", dc.top_and_tail(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 4 Part 1\n",
    "\n",
    "- A passphrase consists of a series of words (lowercase letters) separated by spaces.\n",
    "- A valid passphrase must contain no duplicate words.\n",
    "\n",
    "E.g.\n",
    "- `aa bb cc dd ee` is valid.\n",
    "- `aa bb cc dd aa` is not valid - the word aa appears more than once.\n",
    "- `aa bb cc dd aaa` is valid - aa and aaa count as different words.\n",
    "\n",
    "The system's full passphrase list is available as our puzzle input. \n",
    "**How many passphrases are valid?**\n",
    "\n",
    "My solution is to use the [collections.Counter class](https://realpython.com/python-counter/). It is a subclass of dict, which takes any supplied sequence or iterable, and counts how many unique instances of a value occur. The resulting dict stores the unique objects as keys, and the count of each object as the value.\n",
    "\n",
    "So, I will:\n",
    "\n",
    "- Split each supplied phrase into words.\n",
    "- Count the words, using Counter.\n",
    "- Determine the `most_common()` word, which returns the `word: count` pair.\n",
    "- If the count is 1, then this phrase is valid.\n",
    "\n",
    "I'll put this all into a single line list comprehension, returning only those phrases that are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yq4_ffMZ75iq"
   },
   "outputs": [],
   "source": [
    "def part1(data):\n",
    "    valid_phrases = [phrase for phrase in data if Counter(phrase.split()).most_common()[0][1] == 1]\n",
    "    return len(valid_phrases)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeazYTD0xS2C"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part1([\"aa bb cc dd ee\", \"aa bb cc dd aa\", \"aa bb cc dd aaa\"]), 2) # test with sample data\n",
    "soln = part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG210YZNxPO5"
   },
   "source": [
    "### Day 4 Part 2\n",
    "\n",
    "Now, a valid passphrase must contain no two words that are anagrams of each other - that is, a passphrase is invalid if any word's letters can be rearranged to form any other word in the passphrase.\n",
    "\n",
    "Okay, the adaptation from Part 1 is pretty trivial. Let's just put each word into alphabetical order before counting.\n",
    "\n",
    "**Without allowing any words that are anagrams, how many passphrases are valid?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGOtNVJ8xWHZ"
   },
   "outputs": [],
   "source": [
    "def part2(data):\n",
    "    valid_phrases = []\n",
    "    for phrase in data:\n",
    "        # put each word into alphabetical order\n",
    "        canonical_words = [\"\".join(sorted(word)) for word in phrase.split()]\n",
    "        if Counter(canonical_words).most_common()[0][1] == 1: # check all our words only appear once\n",
    "            valid_phrases.append(phrase)\n",
    "\n",
    "    return len(valid_phrases)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuLYqDZX76u4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part2([\"abcde fghij\", # valid\n",
    "                \"abcde xyz ecdab\", # not valid\n",
    "                \"a ab abc abd abf abj\", # valid\n",
    "                \"iiii oiii ooii oooi oooo\", # valid\n",
    "                \"oiii ioii iioi iiio\" # not valid\n",
    "               ]), 3) # test with sample data\n",
    "soln = part2(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZvWwxmJbGbD"
   },
   "source": [
    "## Day 5: A Maze of Twisty Trampolines, All Alike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGKQZAMNKA8M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = \"5\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8k00bAJR7vCX"
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = list(map(int, f.read().splitlines()))\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data, zero_indexed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0tvEzJYxD6r"
   },
   "source": [
    "### Day 5 Part 1\n",
    "\n",
    "We're given a list of CPU \"jump\" instructions. Our input is simply a list of jump offsets, i.e.offsets, so:\n",
    "\n",
    "- `-1` means jump to previous instruction\n",
    "- `0` means stay on this instruction\n",
    "- `1` means jump to the next instruction\n",
    "\n",
    "But, AFTER we execute an instruction, the offset of that particular instruction is incremented by `1`.  So, if we encounter a `0`, this would mean \"stay put\", but then this offset would be incremented to `1`. So now we would execute the jump again, but this time moving forward by `1`.\n",
    "\n",
    "**How many steps does it take to reach the exit?** I.e. to follow an instruction that takes us outside of the program.\n",
    "\n",
    "My solution:\n",
    "- Our program is a set of jump instructions, with each jump offset as an element in a list.\n",
    "- Store the current index position in the list as `ptr`\n",
    "- We start at `ptr = 0`\n",
    "- With each program instruction, retrieve the value in the list at elemenet `ptr`. Add this value to `ptr` to get the new index position.\n",
    "- If the new index position is outside of the list, then we've reached the end, so return the number of instructions executed.\n",
    "- If the new index is inside the list, then update the value of the previous list position by 1.\n",
    "\n",
    "**Caution**: Since we update the values inside the list, you need to pass a copy of the list to the function. Otherwise the original data is modified, and the function cannot be re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(data, part=1):\n",
    "    prev_ptr = 0\n",
    "    ptr = 0  # start at instruction 0\n",
    "    for step in count(1): # a great way to increment a counter in an infinite loop\n",
    "        ptr += data[ptr]  # move to offset requested\n",
    "        if 0 <= ptr < len(data):\n",
    "            if part == 2 and data[prev_ptr] >= 3: # Part 2 only\n",
    "                data[prev_ptr] -= 1\n",
    "            else:\n",
    "                data[prev_ptr] += 1  # increment value of previous instruction\n",
    "            prev_ptr = ptr\n",
    "        else:  # we've jumped out of the program\n",
    "            return step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeazYTD0xS2C"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(solve([0, 3, 0, 1, -3]), 5) # test with sample data\n",
    "soln = solve(input_data.copy())\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG210YZNxPO5"
   },
   "source": [
    "### Day 5 Part 2\n",
    "\n",
    "Now, the jumps are even stranger: after each jump, if the offset was three or more, instead decrease it by 1. Otherwise, increase it by 1 as before.\n",
    "\n",
    "All I need to do is add an `if` condition, to such that if the value of the prev index was 3 or more, then decrement the value by 1.  Else, increment by 1 as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeazYTD0xS2C",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(solve([0, 3, 0, 1, -3], 2), 10) # test with sample data\n",
    "soln = solve(input_data.copy(), 2)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZvWwxmJbGbD"
   },
   "source": [
    "## Day 6: Memory Reallocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGKQZAMNKA8M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = \"6\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8k00bAJR7vCX"
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = dc.get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = list(map(int, f.read().split()))\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data, zero_indexed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0tvEzJYxD6r"
   },
   "source": [
    "### Day 6 Part 1\n",
    "\n",
    "Intro:\n",
    "\n",
    "- We have 16 memory banks.\n",
    "- Each memory bank can hold any number of blocks.\n",
    "- Our _reallocation routine_ attempts to balance the blocks between the memory banks.\n",
    "- Each cycle:\n",
    "  - Find the bank with the most blocks (with ties won by lowest-numbered memory bank), and redisribute these blocks...\n",
    "  - By removing all the blocks from this bank, and then inserting one block in each successive bank (by index), wrapping as required.\n",
    "\n",
    "**How many redistribution cycles must be completed before a configuration is produced that has been seen before?**\n",
    "\n",
    "My solution:\n",
    "\n",
    "- Store each configuration we've seen before in a set.\n",
    "- Each config is converted to a tuple before adding to the set, because a tuple is a hashable type, whereas a list is not.  We need the element to be hashable, so that we can compare if we've seen this configuration before.\n",
    "- Now we run a loop that redistributes until we find a configuration we've seen before.\n",
    "- Redistribution works by:\n",
    "  - Locating the index with the most blocks and setting this index to 0.\n",
    "  - For the number of blocks retrieved, iterate over this many remaining elements and add one to the value of each. Use `%` operator to allow us to wrap back to the front of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yq4_ffMZ75iq"
   },
   "outputs": [],
   "source": [
    "def solve(data):\n",
    "    \"\"\" Return a tuple of:\n",
    "      - the number of steps required to reach a repeated config\n",
    "      - the config itself \"\"\"\n",
    "    current_config = data.copy() # we don't want to change input\n",
    "    banks = len(data)\n",
    "    \n",
    "    seen = set() # store configs we've seen before, as tuples\n",
    "    seen.add(tuple(data))\n",
    "\n",
    "    for step in count(1): # infinite count\n",
    "        most_blocks_idx, blocks = max(enumerate(current_config), key=lambda x: x[1])\n",
    "        current_config[most_blocks_idx] = 0 # reset this bank to zero\n",
    "\n",
    "        # increment circularly until no more blocks to redistribute\n",
    "        for i in range(blocks, ):\n",
    "            idx = (most_blocks_idx + i + 1) % banks\n",
    "            current_config[idx] += 1\n",
    "\n",
    "        config_as_tuple = tuple(current_config)\n",
    "        if config_as_tuple in seen:\n",
    "            return step, current_config\n",
    "        else:\n",
    "            seen.add(config_as_tuple)\n",
    "\n",
    "        if step == 100000: # just in case!\n",
    "            return step, current_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeazYTD0xS2C"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(solve([0, 2, 7, 0]), (5, [2, 4, 1, 2])) # test with sample data\n",
    "soln = solve(input_data)\n",
    "logger.info(f\"Part 1 soln={soln[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG210YZNxPO5"
   },
   "source": [
    "### Day 6 Part 2\n",
    "\n",
    "Now we want to know **the number of steps before we reach the same configuration again.  I.e. the overall size of the loop.**\n",
    "\n",
    "Easy!  Just re-run the same function, but passing in the configuration that achieved in Part 1 as input.  The function will then run until it hits the same configuration again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuLYqDZX76u4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(solve([2, 4, 1, 2]), (4, [2, 4, 1, 2])) # test with sample data\n",
    "soln = solve(soln[1])\n",
    "logger.info(f\"Part 2 soln={soln[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZvWwxmJbGbD"
   },
   "source": [
    "## Day 7: Recursive Circus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGKQZAMNKA8M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = \"7\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8k00bAJR7vCX"
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = f.read().splitlines()\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0tvEzJYxD6r"
   },
   "source": [
    "### Day 7 Part 1\n",
    "\n",
    "We're told we have a recursive scenario:\n",
    "\n",
    "- We're visualising a huge tower, made up of:\n",
    "  - Programs that each sit under a disc.\n",
    "  - Each disc sits under one or more programs, which in turn have their own discs.\n",
    "  - The bottom of the tower is a single program with the first disc.\n",
    "  - At the tops of the top-most towers, there are programs with no discs. I.e. the leaf programs.\n",
    "- Each program has these attributes:\n",
    "  - Name\n",
    "  - Weight\n",
    "  - Collection of programs immediately above (if not a leaf program)\n",
    "\n",
    "Our source data is out of sequence.\n",
    "\n",
    "The sample data looks like this:\n",
    "\n",
    "```\n",
    "pbga (66)\n",
    "xhth (57)\n",
    "ebii (61)\n",
    "havc (66)\n",
    "ktlj (57)\n",
    "fwft (72) -> ktlj, cntj, xhth\n",
    "qoyq (66)\n",
    "padx (45) -> pbga, havc, qoyq\n",
    "tknk (41) -> ugml, padx, fwft\n",
    "jptl (61)\n",
    "ugml (68) -> gyxo, ebii, jptl\n",
    "gyxo (61)\n",
    "cntj (57)\n",
    "```\n",
    "\n",
    "And it represents this:\n",
    "```\n",
    "                gyxo\n",
    "              /     \n",
    "         ugml - ebii\n",
    "       /      \\     \n",
    "      |         jptl\n",
    "      |        \n",
    "      |         pbga\n",
    "     /        /\n",
    "tknk --- padx - havc\n",
    "     \\        \\\n",
    "      |         qoyq\n",
    "      |             \n",
    "      |         ktlj\n",
    "       \\      /     \n",
    "         fwft - cntj\n",
    "              \\     \n",
    "                xhth\n",
    "```\n",
    "\n",
    "**What is the name of the bottom program?**\n",
    "\n",
    "Solution:\n",
    "\n",
    "This seems like a good candidate for building a networkx graph.\n",
    "\n",
    "- Create a `Prog` dataclass to store each program, along with any children it has.\n",
    "- Then map the children, by splitting the input data at the \"->\"\n",
    "- Now we build a **directed graph**, i.e. a graph with direction. We do this by adding edge program as a node, and for any nodes that have children, add an edge back to the parent node.\n",
    "- The bottom program is the root node of our graph. We can networkx allows us to determine the number of incoming edges for each node in our directed graph.  The root node will be the only node that has 0 incoming edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Prog:\n",
    "    \"\"\" A Prog has a weight, and optionally has children of type Prog \"\"\"\n",
    "    name: str\n",
    "    weight: int\n",
    "    children: list[str] = field(default_factory=list) # default to empty list\n",
    "\n",
    "    def add_child(self, child: str):\n",
    "        \"\"\" Add a child program name for this Program \"\"\"\n",
    "        self.children.append(child)\n",
    "\n",
    "def parse_input(data) -> dict[str, Prog]:\n",
    "    \"\"\" Take input lines, and convert to a list of Program objects.\n",
    "    We're parsing lines that look like: fwft (72) -> ktlj, cntj, xhth\n",
    "    \"\"\"\n",
    "    # Note that the last group is optional. If absent, it will not be present in the match object\n",
    "    pattern = re.compile(r'(?P<name>\\w+) \\((?P<weight>\\d+)\\)(?: -> (?P<children>[\\w, ]+))?')\n",
    "    progs = {} # key = name, value = Prog\n",
    "    for line in data:\n",
    "        match = pattern.match(line)\n",
    "        assert match, f\"Bad input data in line {line}\"\n",
    "\n",
    "        name = match.group('name')\n",
    "        weight = int(match.group('weight'))\n",
    "        children = match.group('children')\n",
    "        if children:\n",
    "            children = [child.strip() for child in children.split(',')]\n",
    "        else:\n",
    "            children = []\n",
    "        \n",
    "        progs[name] = Prog(name, weight, children)\n",
    "        \n",
    "    return progs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(graph: nx.DiGraph, root):\n",
    "    distances_from_root = nx.single_source_shortest_path_length(graph, root)\n",
    "\n",
    "    # Create shells based on distances from the root\n",
    "    max_dist = max(distances_from_root.values())\n",
    "    shells = [[] for _ in range(max_dist + 1)]\n",
    "    for node, dist in distances_from_root.items():\n",
    "        shells[dist].append(node)\n",
    "   \n",
    "    # Generate positions using shell_layout\n",
    "    pos = nx.shell_layout(graph, shells)\n",
    "    \n",
    "    # Draw all nodes, then labels, then edges, then weights\n",
    "    nx.draw_networkx_nodes(graph, pos, node_color=\"green\")\n",
    "    nx.draw_networkx_labels(graph, pos, font_size=11)\n",
    "    nx.draw_networkx_edges(graph, pos, edge_color=\"green\", width=0.5)\n",
    "    nx.draw_networkx_edge_labels(graph, pos, \n",
    "                                 nx.get_edge_attributes(graph, \"distance\"),\n",
    "                                 font_size=8)\n",
    "    \n",
    "    # nx.draw(graph, pos=pos, edge_color=\"grey\", width=1, with_labels=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yq4_ffMZ75iq"
   },
   "outputs": [],
   "source": [
    "def part1(data):\n",
    "    \"\"\" Return the root node, and the dict of Progs \"\"\"\n",
    "    progs = parse_input(data)\n",
    "    logger.debug(\"\\n\" + \"\\n\".join(str(prog) for prog in progs.values()))\n",
    "    \n",
    "    graph = nx.DiGraph()\n",
    "    for name, prog in progs.items():\n",
    "        graph.add_node(name)\n",
    "        for child_name in prog.children:\n",
    "            graph.add_node(child_name)\n",
    "            graph.add_edge(name, child_name, distance=progs[child_name].weight)\n",
    "    \n",
    "    # determine the number of incoming edges for each node\n",
    "    nodes = [(node, in_degree) for node, in_degree in graph.in_degree()]\n",
    "    \n",
    "    # Get the node with no incoming edges. This is our root.\n",
    "    root = next(node for node, in_degree in nodes if in_degree == 0)\n",
    "\n",
    "    draw_graph(graph, root)\n",
    "    return root, progs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeazYTD0xS2C"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_data = [\n",
    "    \"pbga (66)\",\n",
    "    \"xhth (57)\",\n",
    "    \"ebii (61)\",\n",
    "    \"havc (66)\",\n",
    "    \"ktlj (57)\",\n",
    "    \"fwft (72) -> ktlj, cntj, xhth\",\n",
    "    \"qoyq (66)\",\n",
    "    \"padx (45) -> pbga, havc, qoyq\",\n",
    "    \"tknk (41) -> ugml, padx, fwft\",\n",
    "    \"jptl (61)\",\n",
    "    \"ugml (68) -> gyxo, ebii, jptl\",\n",
    "    \"gyxo (61)\",\n",
    "    \"cntj (57)\"\n",
    "]\n",
    "\n",
    "sample_solution = part1(sample_data)\n",
    "validate(sample_solution[0], \"tknk\") # test with sample data\n",
    "soln = part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG210YZNxPO5"
   },
   "source": [
    "### Day 7 Part 2\n",
    "\n",
    "Sad times. It looks like I can't avoid the recursion!\n",
    "\n",
    "We're told that each path to a leaf needs to have the same weight. One of the paths will have a different weight, which means we need to adjust the weight of one of the programs.\n",
    "\n",
    "**Given that exactly one program is the wrong weight, what would its weight need to be to balance the entire tower?**\n",
    "\n",
    "Solution:\n",
    "\n",
    "- Create a recursive function that calculates the total weight from a given node. It works by adding the weight of this node to the recursive weight of all children.\n",
    "- That would be sufficient if we only needed the weight of the entire tower. But we need to determine the first tower that is out of balance, and to do this, we need to calculate the total weight at each level.  To do this, use a defaultdict(list) to store a list of (name, recursive weight) for each first-level child at this level.\n",
    "- Then we need to determine if any of these first-level weights are different. We're told that if any weight is different from the others at this level, then this tower is out of balance. Furthermore, the first level that is out of balance on the way back will be out of balance as a result of one program in that particular tower.\n",
    "- So, for the inbalanced tower, determine the two weights: the weight of the outlier, and the correct weight.\n",
    "- Determine which child program corresponds to the recursive outlier weight.\n",
    "- Determine the difference between correct weight and outlier weight, and add this to the weight of our identified child node. This gives us our new required weight.\n",
    "- Return the new required weight; and, once we've found the required weight, simply return it all the way up the recursion stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGOtNVJ8xWHZ"
   },
   "outputs": [],
   "source": [
    "def part2(progs: dict[str, Prog], node_name: str, level: int = 0, stop_on_inbalance=True) -> tuple[int, int]:\n",
    "    \"\"\" Determines the recursive total weight for this program and all children.\n",
    "    Also determine the desired new weight for the single program that is out of balance.\n",
    "\n",
    "    Args:\n",
    "        progs (dict[str, Prog]): the dict of programs.\n",
    "        node_name (str): the root node we want to recurse for.\n",
    "        level (int, optional): the current level, relative to original root supplied. Defaults to 0.\n",
    "        stop_on_inbalance (boolean): Whether to exit the function once we identify the inbalance.\n",
    "                                     Defaults to True. If false, we will complete the weight recursion.\n",
    "\n",
    "    Returns:\n",
    "        _type_: (total weight, new weight for program)\n",
    "    \"\"\"\n",
    "    curr_node = progs[node_name]\n",
    "    \n",
    "    level_weights = defaultdict(list) # Dictionary to store total weights of children at each level\n",
    "    \n",
    "    total_weight = curr_node.weight # initialise with weight of this prog\n",
    "    next_level = level+1\n",
    "    for child in curr_node.children: # and now recursively add the weight of all children\n",
    "        child_recursive_weight, new_weight = part2(progs, child, next_level)\n",
    "        \n",
    "        # if we've identified the outlier, we can quit the recursion now\n",
    "        if new_weight and stop_on_inbalance: \n",
    "            return child_recursive_weight, new_weight\n",
    "        \n",
    "        total_weight += child_recursive_weight # the recursive weight of this child\n",
    "        level_weights[next_level].append((child, child_recursive_weight))\n",
    "        \n",
    "    # Check if any child has a different weight\n",
    "    for lvl, recursive_weights in level_weights.items(): # current lvl, list of tuples\n",
    "        weight_counts: dict[int, list] = defaultdict(list) # store {weight, [name1, name2, etc]}\n",
    "        for child_name, recursive_weight in recursive_weights:\n",
    "            weight_counts[recursive_weight].append(child_name)\n",
    "            \n",
    "        if len(weight_counts) > 1:  # Different weights found, this tower is out of balance\n",
    "            logger.debug(f\"Level {lvl} has different weights: {recursive_weights}\")\n",
    "            \n",
    "            # Identifier the outlier\n",
    "            outlier_weight = correct_weight = 0\n",
    "            outlier_name = None\n",
    "            for weight, child_names in weight_counts.items():\n",
    "                if len(child_names) == 1: # this is the outlier\n",
    "                    outlier_weight = weight\n",
    "                    outlier_name = child_names[0]\n",
    "                else: # more than one name with this weight - these towers are correct\n",
    "                    correct_weight = weight    \n",
    "                    \n",
    "            assert outlier_weight and correct_weight, \"We should have determined two weights\"        \n",
    "            assert outlier_name, \"We should have identified the program with wrong weight\"\n",
    "            \n",
    "            logger.debug(f\"Prog to change={outlier_name}; current weight={progs[outlier_name].weight}\")\n",
    "            \n",
    "            # Calculate the new required weight for the outlier\n",
    "            new_weight = progs[outlier_name].weight + (correct_weight - outlier_weight)   \n",
    "            logger.debug(f\"Required new weight={new_weight}\")\n",
    "            return total_weight, new_weight\n",
    "                    \n",
    "    return total_weight, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuLYqDZX76u4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part2(sample_solution[1], sample_solution[0])[1], 60) # test with sample data\n",
    "weight = part2(soln[1], soln[0])[1]\n",
    "logger.info(f\"Part 2 soln={weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 8: I Heard You Like Registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"8\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = f.read().splitlines()\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 8 Part 1\n",
    "\n",
    "We're simulating a computer that can execute specific instructions.\n",
    "\n",
    "The instructions:\n",
    "- Modify the value of a specified register.\n",
    "- But only if the condition is True. If False, we just skip to the next instruction.\n",
    "- All registers start with a value of `0`.\n",
    "- There can be many registers!\n",
    "\n",
    "Instructions look like:\n",
    "\n",
    "```\n",
    "b inc 5 if a > 1\n",
    "a inc 1 if b < 5\n",
    "c dec -10 if a >= 1\n",
    "c inc -20 if c == 10\n",
    "```\n",
    "\n",
    "**What is the largest value in any register after completing the instructions in your puzzle input?**\n",
    "\n",
    "Solution:\n",
    "\n",
    "- I create an `Instructions` class that can execute either the `inc` or `dec` instruction.  It works by taking the instruction type, looking up that type in a dictionary, and mapping it to an appropriate function call, i.e. `operator.add` or `operator.sub`, respectively.\n",
    "- Now I create a `Computer` class:\n",
    "  - Use defaultdict(int) to store the registers, since we don't know how many, or what they'll be named. And this will initialise them to `0`.\n",
    "  - We pass the input data to run_program(). This uses regex to parse the input into register name, instruction type, value, and condition.\n",
    "  - Evaluate the condition by splitting it into \"left op right\", using op to map to an operator function, and then performing that operation.\n",
    "  - If the condition is true, update the value of the specified register, by executing the specified instruction.\n",
    "- Finally, to solve, return the register with the highest stored value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Instructions():\n",
    "    \"\"\" Define an instruction set, made up of instruction constants \"\"\"\n",
    "    ops_dict = {\n",
    "        \"inc\": operator.add, \n",
    "        \"dec\": operator.sub\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def execute(cls, instr_type: str, reg_val: int, value: int):\n",
    "        \"\"\" Dispatch to the specified instruction, with the specified value \"\"\"\n",
    "        # method = getattr(cls, f'_{instr}', None)\n",
    "        assert instr_type in Instructions.ops_dict, \"Invalid operation\"\n",
    "        return Instructions.ops_dict[instr_type](reg_val, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Computer:\n",
    "    \"\"\" Simulate a computer with many registers \"\"\"\n",
    "    \n",
    "    ops = {\n",
    "        \">\": operator.gt,\n",
    "        \"<\": operator.lt,\n",
    "        \">=\": operator.ge,\n",
    "        \"<=\": operator.le,\n",
    "        \"==\": operator.eq,\n",
    "        \"!=\": operator.ne,\n",
    "    }\n",
    "\n",
    "    def __init__(self, init_val: int = 0) -> None:\n",
    "        self._registers: dict[str, int] = defaultdict(int)\n",
    "        self._registers_max: dict[str, int] = defaultdict(int) # for Part 2\n",
    "    \n",
    "    @property\n",
    "    def registers(self) -> dict[str, int]:\n",
    "        \"\"\" Return the dict of registers \"\"\"\n",
    "        return self._registers\n",
    "    \n",
    "    @property\n",
    "    def registers_max(self) -> dict[str, int]:\n",
    "        \"\"\" Return the (register, value) of the max value stored at any point in any register \"\"\"\n",
    "        return self._registers_max\n",
    "    \n",
    "    def get_register_value(self, register: str):\n",
    "        \"\"\" Return the value of the specified register \"\"\"\n",
    "        return self._registers[register]\n",
    "    \n",
    "    def set_register_value(self, register: str, val: int):\n",
    "        \"\"\" Set the value of the specified register \"\"\"\n",
    "        self._registers[register] = val\n",
    "        self._update_register_max(register, val)\n",
    "        \n",
    "    def _update_register_max(self, register: str, val: int):\n",
    "        \"\"\" Update the maximum value stored in this register \"\"\"\n",
    "        self._registers_max[register] = max(val, self._registers_max[register]) # for Part 2\n",
    "\n",
    "    def _evaluate_condition(self, condition: str):\n",
    "        \"\"\" We expect all conditions to follow the format:\n",
    "        left op right, where:\n",
    "            - left is a register\n",
    "            - op is one of the allowed operators\n",
    "            - right is an int value\n",
    "        \"\"\"\n",
    "        left, op, right = condition.split()\n",
    "        if op not in Computer.ops:\n",
    "            raise ValueError(f\"Invalid operation in condition {condition}\")\n",
    "\n",
    "        # Evaluate and return the result of the comparison\n",
    "        return Computer.ops[op](self.get_register_value(left), int(right))        \n",
    "        \n",
    "    def run_program(self, program: list[str]):\n",
    "        \"\"\" Execute the specified program. \n",
    "        All instructions have register, instruction, value, and condition \"\"\"\n",
    "        \n",
    "        self.__init__() # reset\n",
    "        \n",
    "        # e.g. c inc -20 if c == 10\n",
    "        pattern = re.compile(r'(\\w+) (\\w+) (-?\\d+) if (.+)')\n",
    "\n",
    "        # exit the loop when we reach an instruction that does not exist\n",
    "        for line in program:\n",
    "            reg, instr_type, val, cond = pattern.findall(line)[0]\n",
    "            \n",
    "            if self._evaluate_condition(cond):\n",
    "                reg_val = self.get_register_value(reg)\n",
    "                self.set_register_value(reg, Instructions.execute(instr_type, int(reg_val), int(val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer = Computer()\n",
    "def part1(data) -> tuple[str,int]:\n",
    "    computer.run_program(data)\n",
    "    return max(computer.registers.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_data = [\n",
    "    \"b inc 5 if a > 1\",\n",
    "    \"a inc 1 if b < 5\",\n",
    "    \"c dec -10 if a >= 1\",\n",
    "    \"c inc -20 if c == 10\"\n",
    "]\n",
    "validate(part1(sample_data)[1], 1) # test with sample data\n",
    "soln = part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 8 Part 2\n",
    "\n",
    "**Now we also need to determine the highest value held in any register, at any time during execution of the program.**\n",
    "\n",
    "This is easy enough.\n",
    "- I just create a second defaultdict called `_registers_max`, to store the highest value that has been stored for any given register.\n",
    "- Then I update `set_register_value()` so that it also updates `_registers_max`. This only updates if the value is larger than the current."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part2(data) -> tuple[str,int]:\n",
    "    computer.run_program(data)\n",
    "    return max(computer.registers_max.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_data = [\n",
    "    \"b inc 5 if a > 1\",\n",
    "    \"a inc 1 if b < 5\",\n",
    "    \"c dec -10 if a >= 1\",\n",
    "    \"c inc -20 if c == 10\"\n",
    "]\n",
    "validate(part2(sample_data)[1], 10) # test with sample data\n",
    "soln = part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 9: Stream Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"9\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = f.read()\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 9 Part 1\n",
    "\n",
    "Our input is a stream of characters.\n",
    "\n",
    "- The input is a single group.\n",
    "- A group is represented by: `{ ... }`\n",
    "- A group contains zero or more of:\n",
    "  - Comma separated things. \n",
    "  - Where things can be nested groups or garbage. \n",
    "- Garbage is given by: `< ... >`\n",
    "  - Garbage can contain other `<`.\n",
    "- Any `!` means ignore the next character, even if the next character is a `!`\n",
    "\n",
    "Groups have a score:\n",
    "\n",
    "- Outer most group scores 1.\n",
    "- First nested groups scores 2.\n",
    "- Second nested groups score 3, etc.\n",
    "\n",
    "Solution:\n",
    "\n",
    "- Let's write a **parser**\n",
    "- Simply process the input, one char at a time.\n",
    "- Store state in a state stack.\n",
    "- If we enter a block:\n",
    "  - Append BLOCK to our stack.\n",
    "  - We can determine current nesting level by the size of the stack. Increment the number of blocks at this level; store in a defaultdict. \n",
    "- If we exit a block, pop the BLOCK state.\n",
    "- If we enter garbage, append GARBAGE to our stack. If we exit garbage, pop the stack.\n",
    "- If we read a \"!\", append IGNORE_NEXT state to our stack. After we read the next char, pop it and return to previous state.\n",
    "\n",
    "Finally, return the product of level*block_count, for each level.  This gives us the total score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(Enum):\n",
    "    BLOCK = auto()\n",
    "    GARBAGE = auto()\n",
    "    IGNORE_NEXT = auto()\n",
    "    \n",
    "def parse(block: str) -> tuple[dict, int]:\n",
    "    \"\"\" Parse a block.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (blocks_at level, garbage_count)\n",
    "    \"\"\"\n",
    "    blocks_at_level = defaultdict(int)\n",
    "    state_stack = deque()\n",
    "    garbage_count = 0 # part 2\n",
    "    \n",
    "    for char in block:\n",
    "        if not state_stack or state_stack[-1] == State.BLOCK:\n",
    "            if char == \"{\": # open BLOCK\n",
    "                state_stack.append(State.BLOCK)\n",
    "                blocks_at_level[len(state_stack)] += 1\n",
    "            elif char == \"}\": # end BLOCK\n",
    "                assert state_stack.pop() == State.BLOCK, \"Block should have ended\"\n",
    "            elif char == \"<\": # open GARBAGE\n",
    "                state_stack.append(State.GARBAGE)\n",
    "            elif char == \"!\": # set IGNORE NEXT\n",
    "                state_stack.append(State.IGNORE_NEXT)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        elif state_stack[-1] == State.GARBAGE:\n",
    "            if char == \"!\": # set IGNORE NEXT\n",
    "                state_stack.append(State.IGNORE_NEXT)\n",
    "            elif char == \">\":\n",
    "                assert state_stack.pop() == State.GARBAGE, \"Garbage should have ended\"\n",
    "            else:\n",
    "                garbage_count += 1\n",
    "        \n",
    "        else: # unset IGNORE NEXT\n",
    "            assert state_stack.pop() == State.IGNORE_NEXT, \"Ignore next should have ended\"\n",
    "            \n",
    "    return blocks_at_level, garbage_count        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(data):\n",
    "    blocks_at_level, garbage_count = parse(data)\n",
    "    logger.debug(blocks_at_level)\n",
    "    \n",
    "    return sum(k*v for k, v in blocks_at_level.items()), garbage_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_data = [\n",
    "    r\"{}\",\n",
    "    r\"{{{}}}\",\n",
    "    r\"{{},{}}\",\n",
    "    r\"{{{},{},{{}}}}\",\n",
    "    r\"{<a>,<a>,<a>,<a>}\",\n",
    "    r\"{{<ab>},{<ab>},{<ab>},{<ab>}}\",\n",
    "    r\"{{<!!>},{<!!>},{<!!>},{<!!>}}\",\n",
    "    r\"{{<a!>},{<a!>},{<a!>},{<ab>}}\"\n",
    "]\n",
    "sample_data_scores = [1, 6, 5, 16, 1, 9, 9, 3]\n",
    "\n",
    "for sample, score in zip(sample_data, sample_data_scores):\n",
    "    validate(solve(sample)[0], score) # test with sample data\n",
    "\n",
    "soln = solve(input_data)\n",
    "logger.info(f\"Part 1 soln={soln[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 9 Part 2\n",
    "\n",
    "We're asked to count all the characters in garbage. We're told:\n",
    "\n",
    "- Ignore the garbage boundaries themselves.\n",
    "- Don't count IGNORED chars, nor the `!` that causes the ignoring.\n",
    "\n",
    "Very easy... Just count every time we see a character whilst in GARBAGE state, excluding `!` and `}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_data = [\n",
    "    r'{<>}',\n",
    "    r'{<random characters>}',\n",
    "    r'{<<<<>}',\n",
    "    r'{<{!>}>}',\n",
    "    r'{<!!>}',\n",
    "    r'{<!!!>>}',\n",
    "    r'{<{o\"i!a,<{i<a>}'\n",
    "]\n",
    "sample_data_scores = [0, 17, 3, 2, 0, 0, 10]\n",
    "\n",
    "for sample, score in zip(sample_data, sample_data_scores):\n",
    "    validate(solve(sample)[1], score) # test with sample data\n",
    "    \n",
    "logger.info(f\"Part 2 soln={soln[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 10: Knot Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"10\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = f.read().strip()\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 10 Part 1\n",
    "\n",
    "We're told we're going to implement a hash based on knot-tying.\n",
    "\n",
    "- We have a circular string, which defaults to length 256, and has marks at locations 0-255.\n",
    "- Hasing is implemented by reversing lengths of the string.\n",
    "- Reversing starts at posn 0, and applies to the next length supplied (input data).\n",
    "- We then move on to the next position in the string, after skipping s positions.\n",
    "- The skip size starts at 0, and increases by 1 with each iteration.\n",
    "\n",
    "**After executing an iteration for all lengths supplied, what is the result of multiplying the first two numbers in the list?**\n",
    "\n",
    "Solution:\n",
    "\n",
    "- Store the values 0-255 in a list.\n",
    "- Iterate through lengths.  For each length:\n",
    "  - Reverse the block that starts at current posn, and is of required length.\n",
    "  - Wrap over to the beginning, if required.\n",
    "  - Move to the position after the length, and then skip the required number of positions.\n",
    "  - Then increment the skip size.\n",
    "- Return the list.\n",
    "- Calculate the product of the first two elements of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_hash(lengths, list_size=256, iterations=1):\n",
    "    \"\"\" Apply knot hashing routine i times. Returns the resulting rearranged list.\n",
    "    \n",
    "    Args:\n",
    "        data (list[int]): lengths to use\n",
    "        listsize (int, optional): the number of marks in our string circle. Defaults to 256.\n",
    "        iterations: the number of times to run the hash\n",
    "    \"\"\"\n",
    "    loop = list(range(list_size))\n",
    "    posn = 0\n",
    "    skip_size = 0\n",
    "    \n",
    "    for i in range(iterations): # required for Part 2\n",
    "        for curr_len in lengths:\n",
    "            end_index = (posn + curr_len) % list_size\n",
    "            \n",
    "            # Reverse the block with wrapping\n",
    "            if posn + curr_len < list_size:\n",
    "                # If the end index is greater than the start index, no wrapping is needed\n",
    "                loop[posn:posn + curr_len] = loop[posn:posn + curr_len][::-1]\n",
    "            else: # The block wraps around \n",
    "                block = loop[posn:] + loop[:end_index]\n",
    "                reversed_block = block[::-1]\n",
    "                \n",
    "                # Place the reversed block back into the array\n",
    "                loop[posn:] = reversed_block[:list_size - posn]\n",
    "                loop[:end_index] = reversed_block[list_size - posn:]\n",
    "\n",
    "            posn = (posn + curr_len + skip_size) % list_size\n",
    "            skip_size += 1\n",
    "            # logger.debug(f\"After processing length {curr_len}:\\n{loop[:10]}...{loop[-10:]}\")\n",
    "\n",
    "    return loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_data = [3, 4, 1, 5]\n",
    "sparse_hash_val = sparse_hash(sample_data, list_size=5)\n",
    "validate(sparse_hash_val[0]*sparse_hash_val[1], 12) # test with sample data\n",
    "\n",
    "sparse_hash_val = sparse_hash(list(map(int, input_data.split(\",\")))) # read input as a list of int\n",
    "logger.info(f\"Part 1 soln={sparse_hash_val[0]*sparse_hash_val[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 10 Part 2\n",
    "\n",
    "- The input is no longer a list of numbers, but instead a string of bytes. Ignore any whitespace.\n",
    "- We need to convert each byte into its ASCII value, including the commas. E.g. `\"1,2,3\"` -> `[49, 44, 50, 44, 51]` \\\n",
    "  These are our new list of lengths.\n",
    "- Add `[17, 31, 73, 47, 23]` to our lengths. E.g. now we would have `[49, 44, 50, 44, 51, 17, 31, 73, 47, 23]`\n",
    "- Run this list of lengths through the hashing algorithm from part 1. But this time, we need to run the algorithm 64 times, maintaining the position and skip length between interations. The resulting list of 256 numbers is called the _sparse hash_.\n",
    "- We need to reduce this to a _dense hash_ by performing bitwise XOR for each block of 16 numbers in the _sparse hash_. \\\n",
    "  There are 16 blocks, so the _dense hash_ will therefore be 16 numbers.\n",
    "- Convert these numbers to hex, and then return a single concatenated hex value. Thus, the final response will be 32 hex digits.\n",
    "\n",
    "**Treating your puzzle input as a string of ASCII characters, what is the Knot Hash of your puzzle input?**\n",
    "\n",
    "My solution:\n",
    "\n",
    "- First, instead of turning the input data into a list of int, we instead process as a raw str.\n",
    "- For each character in the string, determine the ord() value (i.e. the ASCII code). Return a list of these ords.\n",
    "- Add the required suffix list.\n",
    "- Now, apply the _sparse_hash_ algorithm we created for Part 1, passing in our new list of ords as the required lengths. Also, I've added an increments parameter to the function, so we can tell the _sparse_hash_ function to run 64 iterations, as required for Part 2.\n",
    "- We now have the _soft_hash_.  We need to split it into 16 blocks, which we can do with a simple range().\n",
    "- For each block (which is 16 elements long), we need to XOR each successive pair of values.  We can do this using `itertools.reduce()` for the 16 values, and pass it a lambda function that performs the bitwise XOR. This gives us a list of 16 ints.\n",
    "- We need to turn these 16 ints into 16 pairs of hex digits. Any int from 0-255 can be expressed as a hex value from Ox00 to 0xFF. But the conversion for any int in the range 0-15 only requires one hex digit, so we need to suffix with a zero. Therefore I'm using a format string to convert the ints to 2-digit hex values: \\\n",
    "`f\"{int_val:02x}\"` where `0` is the fill value, `2` is the required width, and `x` means convert to hex.\n",
    "- Finally, concatenate these strings using `\"\".join()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_hash(data: str, suffix=[17, 31, 73, 47, 23]):\n",
    "    ascii_list = [ord(char) for char in data]\n",
    "    ascii_list += suffix\n",
    "    \n",
    "    sparse_hash_list = sparse_hash(ascii_list, iterations=64)\n",
    "    assert len(sparse_hash_list) == 256, \"There should be 256 ints in the sprase hash\"\n",
    "    \n",
    "    # create dense hash by XOR'ing each successive 16 ints, in each of the 16 blocks. (The list is 256 ints in total.)\n",
    "    dense_hash_list = [reduce(lambda x, y: x^y, sparse_hash_list[i*16: (i+1)*16]) for i in range(16)]\n",
    "    assert len(dense_hash_list) == 16, \"The dense hash reduces 256 ints -> 16 blocks = 16 ints\"\n",
    "    \n",
    "    # convert to str representation. Each int needs to be converted to a pair of hex chars.\n",
    "    # Note that any ints in the range 0->15 will only require one hex char, so we need to prefix in that situation\n",
    "    dense_hash_val = \"\".join(f\"{int_val:02x}\" for int_val in dense_hash_list)\n",
    "    return dense_hash_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_data = [\n",
    "    \"\",\n",
    "    \"AoC 2017\",\n",
    "    \"1,2,3\",\n",
    "    \"1,2,4\"\n",
    "]\n",
    "sample_data_hashes = [\n",
    "    \"a2582a3a0e66e6e86e3812dcb672a272\",\n",
    "    \"33efeb34ea91902bb2f59c9920caa6cd\",\n",
    "    \"3efbe78a8d82f29979031a4aa0b16a9d\",\n",
    "    \"63960835bcdc130f0b66d7ff4f6a5a8e\"\n",
    "]\n",
    "\n",
    "for sample, dense_hash_val in zip(sample_data, sample_data_hashes):\n",
    "    validate(dense_hash(sample), dense_hash_val) # test with sample data\n",
    "    \n",
    "dense_hash_val = dense_hash(input_data)\n",
    "logger.info(f\"Part 2 soln={dense_hash_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 11: Hex Ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"11\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = f.read().strip()\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 11 Part 1\n",
    "\n",
    "We're in a hexagonal grid, such that adjacent hexagons can be found as follows:\n",
    "\n",
    "```\n",
    "  \\ n  /\n",
    "nw +--+ ne\n",
    "  /    \\\n",
    "-+      +-\n",
    "  \\    /\n",
    "sw +--+ se\n",
    "  / s  \\\n",
    "```\n",
    "\n",
    "- Moving from one hexagon to an adjacent hexagon is called a _step_.\n",
    "- We're given the path taken by the child process. E.g. `se,nw,ne,s,sw,sw,` etc. \n",
    "\n",
    "**Starting from the same location, what is the minimum number of steps to reach the child process?** \n",
    "\n",
    "My solution:\n",
    "\n",
    "- First, we need to establish valid moves. To do this, I've created a set of hexagon vectors. \n",
    "  - To move up and down, we require a vertical vector (n or s). Vertical moves always add or remove 2 from the vertical axis.\n",
    "  - To move left or right, we require a diagonal vector. Diagonal moves change both x and y by a magnitude of 1.\n",
    "  - There is no _horizontal only_ vector.\n",
    "- Then, we take the path given, and add up the vectors. Determine the final point.\n",
    "- Then, we can establish minimum vectors to reach this final point.\n",
    "\n",
    "There are a couple of ways to do this.\n",
    "\n",
    "1. With a BFS.\n",
    "2. With an A*.\n",
    "\n",
    "#### BFS\n",
    "\n",
    "**[BFS](https://aoc.just2good.co.uk/python/shortest_paths)** is just flood fill from our starting point.  From any given location, we determine all valid neighbours and add them to the queue to be expanded.  The BFS expands outwards, and stops when our fill has reached the goal point.  This will work and is guaranteed to find the shortest path.  However, it's slow because the flood fill expands in all directions at the same rate.\n",
    "\n",
    "#### A*\n",
    "\n",
    "**[A*](https://aoc.just2good.co.uk/python/shortest_paths#a-algorithm)** is the same as the BFS, but preferentially expands the frontier in the direction that brings us closer  to the goal. To achieve this, we need a _heuristic_ that calculates the approximate distance to the goal.  Then, we add the set of adjacent hexagons to the queue, just as we would with the BFS.  But when we then pop the next neighbour to explore, we always pop the neighbour with the lowest _heuristic_ score. I.e. the neighbour that brings us closer to the goal.\n",
    "\n",
    "Here, I'm calculating the _heuristic_ with a static `distance()` function in my `Hex` class. This returns the absolute value of the horizontal or vertical distance to the goal; whichever is larger. So the heuristic gives a smaller distance if we pop an adjacent hexagon that is closer to the goal.\n",
    "\n",
    "In the end, I implemented both, to see the difference in performance.\n",
    "- BFS solves the solution in just under 30s.\n",
    "- A* solves the solution in about 20ms! So that's about 1500x faster!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hex:\n",
    "    hex_vectors = {\n",
    "        \"n\": (0, 2),\n",
    "        \"ne\": (1, 1),\n",
    "        \"se\": (1, -1),\n",
    "        \"s\": (0, -2),\n",
    "        \"sw\": (-1, -1),\n",
    "        \"nw\": (-1, 1)\n",
    "    }\n",
    "    \n",
    "    @staticmethod\n",
    "    def distance(first: Point, second: Point):\n",
    "        # Estimate the distance as the maximum of the absolute differences\n",
    "        # This is a better estimate than Manhattan distance for a Hex grid   \n",
    "        return max(abs(first.x - second.x), abs(first.y - second.y))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_path(data) -> list[Point]:\n",
    "    \"\"\" Read the specified steps and determine the path taken \n",
    "    \n",
    "    Returns:\n",
    "        list[Point]: the path taken\n",
    "    \"\"\"\n",
    "    path_followed = data.split(\",\")\n",
    "    \n",
    "    start = Point(0,0)\n",
    "    curr_posn = start\n",
    "    path_points = [curr_posn]\n",
    "\n",
    "    for curr_vector in path_followed:\n",
    "        curr_posn += Point(*Hex.hex_vectors[curr_vector])\n",
    "        path_points.append(curr_posn)\n",
    "    \n",
    "    return path_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_with_bfs(start:Point, goal:Point) -> tuple[int, dict]:\n",
    "    queue = []\n",
    "    heapq.heappush(queue, (0, start)) # posn, steps\n",
    "    came_from = {} # use a dict so we can build a breadcrumb trail\n",
    "    came_from[start] = None\n",
    "\n",
    "    while queue:\n",
    "        step_count, curr_posn = heapq.heappop(queue)\n",
    "\n",
    "        # Check if the target is reached\n",
    "        if curr_posn == goal:\n",
    "            return step_count, came_from\n",
    "\n",
    "        # Explore adjacent hexagons\n",
    "        for dx, dy in Hex.hex_vectors.values():\n",
    "            adjacent = curr_posn + Point(dx, dy)\n",
    "            if adjacent not in came_from:\n",
    "                came_from[adjacent] = curr_posn\n",
    "                heapq.heappush(queue, (step_count + 1, adjacent))\n",
    "\n",
    "    assert False, \"We should never get here.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_with_astar(start: Point, goal: Point) -> tuple[int, dict]:\n",
    "    \"\"\" Obtain the fastest path from origin to goal using A*.\n",
    "    Returns: tuple[int, dict]: steps required, breadcrumbs\n",
    "    \"\"\"\n",
    "    queue = []\n",
    "    came_from = {} # use a dict so we can build a breadcrumb trail\n",
    "    came_from[start] = None\n",
    "    heapq.heappush(queue, (0, 0, start)) # distance heuristic, steps, posn\n",
    "\n",
    "    while queue:\n",
    "        _, step_count, curr_posn = heapq.heappop(queue)\n",
    "\n",
    "        # Check if the target is reached\n",
    "        if curr_posn == goal:\n",
    "            return step_count, came_from\n",
    "\n",
    "        # Explore adjacent hexagons\n",
    "        for dx, dy in Hex.hex_vectors.values():\n",
    "            adjacent = curr_posn + Point(dx, dy)\n",
    "            if adjacent not in came_from:\n",
    "                came_from[adjacent] = curr_posn\n",
    "                heuristic_cost = Hex.distance(adjacent, goal)\n",
    "                new_cost = step_count + 1 + heuristic_cost # heuristic is combination of distance to goal, and step count\n",
    "                heapq.heappush(queue, (new_cost, step_count + 1, adjacent))\n",
    "\n",
    "    assert False, \"We should never get here.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data: str):\n",
    "    path_taken = build_path(data)\n",
    "    start = path_taken[0]\n",
    "    goal = path_taken[-1]\n",
    "    logger.debug(f\"Goal: {goal}\")\n",
    "    \n",
    "    # return solve_with_bfs(start, goal)\n",
    "    return solve_with_astar(start, goal)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_paths = [\n",
    "    \"ne,ne,ne\",\n",
    "    \"ne,ne,sw,sw\",\n",
    "    \"ne,ne,s,s\",\n",
    "    \"se,sw,se,sw,sw\"\n",
    "]\n",
    "sample_shortest = [3, 0, 2, 3]\n",
    "\n",
    "for path, shortest in zip(sample_paths, sample_shortest):\n",
    "    validate(solve_part1(path)[0], shortest) # test with sample data\n",
    "\n",
    "steps, breadcrumb_trail = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 11 Part 2\n",
    "\n",
    "**How many steps away is the furthest he ever got from his starting position?**\n",
    "\n",
    "We could just run our A* for every point in the journey, but this would take ages.\n",
    "\n",
    "So my solution:\n",
    "\n",
    "- Go through every point in the supplied path and determine the approximate maximum distance using the heuristic we used for Part 1.\n",
    "- Since this max distance is only approximate, we need to determine the actual path for all points that are approximately this far out.  I arbitrarily decided to check all points that are at least 90% as far out as this approx max.\n",
    "\n",
    "This solution completes in under 20s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data: str):\n",
    "    path_taken = build_path(data)\n",
    "    start = path_taken[0]\n",
    "    goal = path_taken[-1]\n",
    "    \n",
    "    # Find the point in our path with the max 'straight' (approx) distance\n",
    "    furthest_straight_dist = 0\n",
    "    for point in path_taken:\n",
    "        furthest_straight_dist = max(Hex.distance(start, point), furthest_straight_dist)\n",
    "\n",
    "    logger.debug(f\"Furthest straight distance: {furthest_straight_dist}\")\n",
    "        \n",
    "    # Examine all points that are at least 90% as far out, using approx straight distance\n",
    "    threshold = int(0.9 * furthest_straight_dist)\n",
    "    max_steps = 0\n",
    "    for point in path_taken:\n",
    "        curr_distance = Hex.distance(start, point)\n",
    "        if curr_distance >= threshold: # get path to this point\n",
    "            max_steps = max(solve_with_astar(start, point)[0], max_steps)\n",
    "            logger.debug(\"Current distance: %d; Current max: %d\", curr_distance, max_steps)\n",
    "            \n",
    "    return max_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_paths = [\n",
    "    \"ne,ne,ne\",\n",
    "    \"ne,ne,sw,sw\",\n",
    "    \"ne,ne,s,s\",\n",
    "    \"se,sw,se,sw,sw\"\n",
    "]\n",
    "sample_shortest = [3, 2, 2, 3]\n",
    "\n",
    "for path, shortest in zip(sample_paths, sample_shortest):\n",
    "    validate(solve_part2(path), shortest) # test with sample data\n",
    "\n",
    "max_steps = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={max_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Day n: title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = \"n\" # replace with actual number (without leading digit)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = dc.get_locations(d_name)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "    with open(locations.input_file, mode=\"rt\") as f:\n",
    "        input_data = f.read().splitlines()\n",
    "\n",
    "    logger.info(\"Input data:\\n%s\", dc.top_and_tail(input_data))\n",
    "except ValueError as e:\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day n Part 1\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part1(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"abcdef\"\"\")\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part1(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")\n",
    "\n",
    "logger.info(\"All tests passed!\")\n",
    "\n",
    "soln = solve_part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day n Part 2\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_part2(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_inputs = []\n",
    "sample_inputs.append(\"\"\"abcdef\"\"\")\n",
    "sample_answers = [\"uvwxyz\"]\n",
    "\n",
    "for curr_input, curr_ans in zip(sample_inputs, sample_answers):\n",
    "    validate(solve_part2(curr_input), curr_ans) # test with sample data\n",
    "    logger.info(\"Test passed\")    \n",
    "\n",
    "logger.info(\"Tests passed!\")\n",
    "\n",
    "soln = solve_part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".AoC-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
