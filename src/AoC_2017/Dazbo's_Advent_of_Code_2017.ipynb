{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "This notebook contains my solutions for **<a href=\"https://adventofcode.com/2017\" target=\"_blank\">Advent of Code 2017</a>**.\n",
    "\n",
    "A few notes...\n",
    "- The source for this notebook source lives in my GitHub repo, <a href=\"https://github.com/derailed-dash/Advent-of-Code/blob/master/src/AoC_2017/Dazbo's_Advent_of_Code_2017.ipynb\" target=\"_blank\">here</a>.\n",
    "- You can run this Notebook wherever you like. For example, you could...\n",
    "  - Run it locally, in your own Jupyter environment.\n",
    "  - Run it in a cloud-based Jupyter environment, with no setup required on your part!  For example, <a href=\"https://colab.research.google.com/github/derailed-dash/Advent-of-Code/blob/master/src/AoC_2017/Dazbo's_Advent_of_Code_2017.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Google Colab\"/></a>\n",
    "- **To run the notebook, execute the cells in the [Setup](#Setup) section, as described below. Then you can run the code for any given day.**\n",
    "- Be mindful that the first time you run this notebook, you will need to **obtain your AoC session key** and store it, if you have not done so already. This allows the notebook to automatically retrieve your input data. (See the guidance in the **[Get Access to Your AoC Data](#Get-Access-to-Your-AoC-Data)** section for details.)\n",
    "- Use the navigation menu on the left to jump to any particular day.\n",
    "- All of my AoC solutions are documented in my <a href=\"https://aoc.just2good.co.uk/\" target=\"_blank\">AoC Python Walkthrough site</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3PMQJRrR38P",
    "tags": []
   },
   "source": [
    "# Setup\n",
    "\n",
    "You need to run all cells in this section, before running any particular day solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWxsAMaXTGEQ"
   },
   "source": [
    "## Packages and Imports\n",
    "\n",
    "Here we use `pip` to install the packages used by my solutions in this event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Dgeww1rMrkQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install jupyterlab-lsp colorama python-dotenv ipykernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5Ki_HvOJUWk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import copy\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from enum import Enum\n",
    "from functools import cache\n",
    "from itertools import permutations, combinations, count\n",
    "import operator\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import unittest\n",
    "import requests\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from colorama import Fore\n",
    "from collections import Counter, deque, defaultdict\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZNTgtGzUImv",
    "tags": []
   },
   "source": [
    "## Logging and Output\n",
    "\n",
    "Set up a new logger that uses `ColouredFormatter`, such that we have coloured logging.  The log colour depends on the logging level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwzjfUFCKhXe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# SETUP LOGGING\n",
    "#\n",
    "# Create a new instance of \"logger\" in the client application\n",
    "# Set to your preferred logging level\n",
    "# And add the stream_handler from this module, if you want coloured output\n",
    "##########################################################################\n",
    "\n",
    "# logger for aoc_commons only\n",
    "logger = logging.getLogger(__name__) # aoc_common.aoc_commons\n",
    "logger.setLevel(logging.INFO)\n",
    "stream_handler = None\n",
    "\n",
    "class ColouredFormatter(logging.Formatter):\n",
    "    \"\"\" Custom Formater which adds colour to output, based on logging level \"\"\"\n",
    "\n",
    "    level_mapping = {\"DEBUG\": (Fore.BLUE, \"DBG\"),\n",
    "                     \"INFO\": (Fore.GREEN, \"INF\"),\n",
    "                     \"WARNING\": (Fore.YELLOW, \"WRN\"),\n",
    "                     \"ERROR\": (Fore.RED, \"ERR\"),\n",
    "                     \"CRITICAL\": (Fore.MAGENTA, \"CRT\")\n",
    "    }\n",
    "\n",
    "    def __init__(self, *args, apply_colour=True, shorten_lvl=True, **kwargs) -> None:\n",
    "        \"\"\" Args:\n",
    "            apply_colour (bool, optional): Apply colouring to messages. Defaults to True.\n",
    "            shorten_lvl (bool, optional): Shorten level names to 3 chars. Defaults to True.\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._apply_colour = apply_colour\n",
    "        self._shorten_lvl = shorten_lvl\n",
    "\n",
    "    def format(self, record):\n",
    "        if record.levelname in ColouredFormatter.level_mapping:\n",
    "            new_rec = copy.copy(record)\n",
    "            colour, new_level = ColouredFormatter.level_mapping[record.levelname]\n",
    "\n",
    "            if self._shorten_lvl:\n",
    "                new_rec.levelname = new_level\n",
    "\n",
    "            if self._apply_colour:\n",
    "                msg = colour + super().format(new_rec) + Fore.RESET\n",
    "            else:\n",
    "                msg = super().format(new_rec)\n",
    "\n",
    "            return msg\n",
    "\n",
    "        # If our logging message is not using one of these levels...\n",
    "        return super().format(record)\n",
    "\n",
    "if not stream_handler:\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_fmt = ColouredFormatter(fmt='%(asctime)s.%(msecs)03d:%(name)s - %(levelname)s: %(message)s',\n",
    "                                   datefmt='%H:%M:%S')\n",
    "    stream_handler.setFormatter(stream_fmt)\n",
    "    \n",
    "if not logger.handlers:\n",
    "    # Add our ColouredFormatter as the default console logging\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "def retrieve_console_logger(script_name):\n",
    "    \"\"\" Create and return a new logger, named after the script\n",
    "    So, in your calling code, add a line like this:\n",
    "    logger = ac.retrieve_console_logger(locations.script_name)\n",
    "    \"\"\"\n",
    "    a_logger = logging.getLogger(script_name)\n",
    "    a_logger.addHandler(stream_handler)\n",
    "    a_logger.propagate = False\n",
    "    return a_logger\n",
    "\n",
    "def setup_file_logging(a_logger: logging.Logger, folder: str|Path=\"\"):\n",
    "    \"\"\" Add a FileHandler to the specified logger. File name is based on the logger name.\n",
    "    In calling code, we can add a line like this:\n",
    "    td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "    Args:\n",
    "        a_logger (Logger): The existing logger\n",
    "        folder (str): Where the log file will be created. Will be created if it doesn't exist\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)     # Create directory if it does not exist\n",
    "    file_handler = logging.FileHandler(Path(folder, a_logger.name + \".log\"), mode='w')\n",
    "    file_fmt = logging.Formatter(fmt=\"%(asctime)s.%(msecs)03d:%(name)s:%(levelname)8s: %(message)s\",\n",
    "                                datefmt='%H:%M:%S')\n",
    "    file_handler.setFormatter(file_fmt)\n",
    "    a_logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_and_tail(data, block_size=5, include_line_numbers=True, zero_indexed=False):\n",
    "    \"\"\" Print a summary of a large amount of data \n",
    "\n",
    "    Args:\n",
    "        data (_type_): The data to present in summary form.\n",
    "        block_size (int, optional): How many rows to include in the top, and in the tail.\n",
    "        include_line_numbers (bool, optional): Prefix with line number. Defaults to True.\n",
    "        zero_indexed (bool, optional): Lines start at 0? Defaults to False.\n",
    "    \"\"\"\n",
    "    if isinstance(data, list):\n",
    "        # Get the number of digits of the last item for proper alignment\n",
    "        num_digits_last_item = len(str(len(data)))\n",
    "\n",
    "        # Format the string with line number\n",
    "        def format_with_line_number(idx, line):\n",
    "            start = 0 if zero_indexed else 1\n",
    "            if include_line_numbers:\n",
    "                return f\"{idx + start:>{num_digits_last_item}}: {line}\"\n",
    "            else:\n",
    "                return line\n",
    "\n",
    "        start = 0 if zero_indexed else 1\n",
    "        if len(data) < 11:\n",
    "            return \"\\n\".join(format_with_line_number(i, line) for i, line in enumerate(data))\n",
    "        else:\n",
    "            top = [format_with_line_number(i, line) for i, line in enumerate(data[:block_size])]\n",
    "            tail = [format_with_line_number(i, line) for i, line in enumerate(data[-block_size:], start=len(data)-block_size)]\n",
    "            return \"\\n\".join(top + [\"...\"] + tail)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y61RhVrHSjVA"
   },
   "source": [
    "## Get Access to Your AoC Data\n",
    "\n",
    "Now provide your unique AoC session key, in order to download your input data. You can get this by:\n",
    "1. Logging into [Advent of Code](https://adventofcode.com/).\n",
    "1. From your browser, open Developer Tools. (In Chrome, you can do this by pressing F12.)\n",
    "1. Open the `Application` tab.\n",
    "1. Storage -> Cookies -> https://adventofcode.com\n",
    "1. Copy the value associated with the cookie called `session`.\n",
    "1. Once you've determiend your session key, I recommend you store it in a file called `.env`, in your `Advent-of-Code` folder, like this: \\\n",
    "`AOC_SESSION_COOKIE=536...your-own-session-key...658` \\\n",
    "This notebook will try to retrieve the key from that location.  If it is unable to retrieve the key, it will prompt you to enter your key in the cell below.\n",
    "\n",
    "![Finding the session cookie](https://aoc.just2good.co.uk/assets/images/aoc-cookie.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_envs_from_file() -> bool:\n",
    "    \"\"\" Look for .env files, read variables from it, and store as environment variables \"\"\"\n",
    "    potential_path = \".env\"\n",
    "    for _ in range(3):\n",
    "        logger.debug(\"Trying .env at %s\", os.path.realpath(potential_path))\n",
    "        if os.path.exists(potential_path):\n",
    "            logger.info(\"Using .env at %s\", os.path.realpath(potential_path))\n",
    "            load_dotenv(potential_path, verbose=True)\n",
    "            return True\n",
    "        \n",
    "        potential_path = os.path.join('..', potential_path)\n",
    "   \n",
    "    logger.warning(\"No .env file found.\")\n",
    "    return False\n",
    "\n",
    "get_envs_from_file() # read env variables from a .env file, if we can find one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSem0cT_LApT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.getenv('AOC_SESSION_COOKIE'):\n",
    "    logger.info('Session cookie retrieved: %s...%s', os.environ['AOC_SESSION_COOKIE'][0:6], os.environ['AOC_SESSION_COOKIE'][-6:])\n",
    "else: # it's not in our environment variables, so we'll need to input the value\n",
    "    os.environ['AOC_SESSION_COOKIE'] = getpass('Enter AoC session key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9A24B4MSyhT"
   },
   "source": [
    "## Load Helpers and Useful Classes\n",
    "\n",
    "Now we load a bunch of helper functions and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwzjfUFCKhXe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# SETUP LOGGING\n",
    "#\n",
    "# Create a new instance of \"logger\" in the client application\n",
    "# Set to your preferred logging level\n",
    "# And add the stream_handler from this module, if you want coloured output\n",
    "##########################################################################\n",
    "\n",
    "# logger for aoc_commons only\n",
    "logger = logging.getLogger(__name__) # aoc_common.aoc_commons\n",
    "logger.setLevel(logging.INFO)\n",
    "stream_handler = None\n",
    "\n",
    "class ColouredFormatter(logging.Formatter):\n",
    "    \"\"\" Custom Formater which adds colour to output, based on logging level \"\"\"\n",
    "\n",
    "    level_mapping = {\"DEBUG\": (Fore.BLUE, \"DBG\"),\n",
    "                     \"INFO\": (Fore.GREEN, \"INF\"),\n",
    "                     \"WARNING\": (Fore.YELLOW, \"WRN\"),\n",
    "                     \"ERROR\": (Fore.RED, \"ERR\"),\n",
    "                     \"CRITICAL\": (Fore.MAGENTA, \"CRT\")\n",
    "    }\n",
    "\n",
    "    def __init__(self, *args, apply_colour=True, shorten_lvl=True, **kwargs) -> None:\n",
    "        \"\"\" Args:\n",
    "            apply_colour (bool, optional): Apply colouring to messages. Defaults to True.\n",
    "            shorten_lvl (bool, optional): Shorten level names to 3 chars. Defaults to True.\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._apply_colour = apply_colour\n",
    "        self._shorten_lvl = shorten_lvl\n",
    "\n",
    "    def format(self, record):\n",
    "        if record.levelname in ColouredFormatter.level_mapping:\n",
    "            new_rec = copy.copy(record)\n",
    "            colour, new_level = ColouredFormatter.level_mapping[record.levelname]\n",
    "\n",
    "            if self._shorten_lvl:\n",
    "                new_rec.levelname = new_level\n",
    "\n",
    "            if self._apply_colour:\n",
    "                msg = colour + super().format(new_rec) + Fore.RESET\n",
    "            else:\n",
    "                msg = super().format(new_rec)\n",
    "\n",
    "            return msg\n",
    "\n",
    "        # If our logging message is not using one of these levels...\n",
    "        return super().format(record)\n",
    "\n",
    "if not stream_handler:\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_fmt = ColouredFormatter(fmt='%(asctime)s.%(msecs)03d:%(name)s - %(levelname)s: %(message)s',\n",
    "                                   datefmt='%H:%M:%S')\n",
    "    stream_handler.setFormatter(stream_fmt)\n",
    "    \n",
    "if not logger.handlers:\n",
    "    # Add our ColouredFormatter as the default console logging\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "def retrieve_console_logger(script_name):\n",
    "    \"\"\" Create and return a new logger, named after the script\n",
    "    So, in your calling code, add a line like this:\n",
    "    logger = ac.retrieve_console_logger(locations.script_name)\n",
    "    \"\"\"\n",
    "    a_logger = logging.getLogger(script_name)\n",
    "    a_logger.addHandler(stream_handler)\n",
    "    a_logger.propagate = False\n",
    "    return a_logger\n",
    "\n",
    "def setup_file_logging(a_logger: logging.Logger, folder: str|Path=\"\"):\n",
    "    \"\"\" Add a FileHandler to the specified logger. File name is based on the logger name.\n",
    "    In calling code, we can add a line like this:\n",
    "    td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "    Args:\n",
    "        a_logger (Logger): The existing logger\n",
    "        folder (str): Where the log file will be created. Will be created if it doesn't exist\n",
    "    \"\"\"\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)     # Create directory if it does not exist\n",
    "    file_handler = logging.FileHandler(Path(folder, a_logger.name + \".log\"), mode='w')\n",
    "    file_fmt = logging.Formatter(fmt=\"%(asctime)s.%(msecs)03d:%(name)s:%(levelname)8s: %(message)s\",\n",
    "                                datefmt='%H:%M:%S')\n",
    "    file_handler.setFormatter(file_fmt)\n",
    "    a_logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPOsmENmYf8h",
    "tags": []
   },
   "source": [
    "### Locations\n",
    "\n",
    "Where any input and output files get stored.\n",
    "\n",
    "<img src=\"https://aoc.just2good.co.uk/assets/images/notebook-content-screenshot.png\" width=\"320\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VK27bcGiK0_M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Paths and Locations\n",
    "#################################################################\n",
    "\n",
    "@dataclass\n",
    "class Locations:\n",
    "    \"\"\" Dataclass for storing various location properties \"\"\"\n",
    "    script_name: str\n",
    "    script_dir: Path\n",
    "    input_dir: Path\n",
    "    output_dir: Path\n",
    "    input_file: Path\n",
    "\n",
    "def get_locations(script_name, folder=\"\") -> Locations:\n",
    "    \"\"\" Set various paths, based on the location of the calling script. \"\"\"\n",
    "    current_directory = os.getcwd()\n",
    "    script_dir = Path(Path().resolve(), folder, script_name)\n",
    "    input_dir = Path(script_dir, \"input\")\n",
    "    output_dir = Path(script_dir, \"output\")\n",
    "    input_file = Path(input_dir, \"input.txt\")\n",
    "\n",
    "    return Locations(script_name, script_dir,\n",
    "                     input_dir,\n",
    "                     output_dir,\n",
    "                     input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14ISscMTadAO"
   },
   "source": [
    "### Retrieve the Input Data\n",
    "\n",
    "This works by using your unique session cookie to retrieve your input data. E.g. from a URL like:\n",
    "\n",
    "`https://adventofcode.com/2015/day/1/input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwP0r3BAaxjt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Retrieving input data\n",
    "##################################################################\n",
    "\n",
    "def write_puzzle_input_file(year: int, day, locations: Locations):\n",
    "    \"\"\" Use session key to obtain user's unique data for this year and day.\n",
    "    Only retrieve if the input file does not already exist.\n",
    "    Return True if successful.\n",
    "    Requires env: AOC_SESSION_COOKIE, which can be set from the .env.\n",
    "    \"\"\"\n",
    "    if os.path.exists(locations.input_file):\n",
    "        logger.debug(\"%s already exists\", os.path.basename(locations.input_file))\n",
    "        return os.path.basename(locations.input_file)\n",
    "\n",
    "    session_cookie = os.getenv('AOC_SESSION_COOKIE')\n",
    "    if not session_cookie:\n",
    "        raise ValueError(\"Could not retrieve session cookie.\")\n",
    "\n",
    "    logger.info('Session cookie retrieved: %s...%s', session_cookie[0:6], session_cookie[-6:])\n",
    "\n",
    "    # Create input folder, if it doesn't exist\n",
    "    if not locations.input_dir.exists():\n",
    "        locations.input_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    url = f\"https://adventofcode.com/{year}/day/{day}/input\"\n",
    "    cookies = {\"session\": session_cookie}\n",
    "    response = requests.get(url, cookies=cookies, timeout=5)\n",
    "\n",
    "    data = \"\"\n",
    "    if response.status_code == 200:\n",
    "        data = response.text\n",
    "\n",
    "        with open(locations.input_file, 'w') as file:\n",
    "            logger.debug(\"Writing input file %s\", os.path.basename(locations.input_file))\n",
    "            file.write(data)\n",
    "            return data\n",
    "    else:\n",
    "        raise ValueError(f\"Unable to retrieve input data. HTTP response: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yakibhW73Rqi"
   },
   "source": [
    "### Testing\n",
    "\n",
    "A really simple function for testing that our solution produces the expected test output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6nbd6WMryWi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(test, answer):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        test: the answer given by our solution\n",
    "        answer: the expected answer, e.g. from instructions\n",
    "    \"\"\"\n",
    "    if test != answer:\n",
    "        raise AssertionError(f\"{test} != {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bcBQkP0a2zA"
   },
   "source": [
    "### Useful Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8sU4Ez_bBKl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# POINTS, VECTORS AND GRIDS\n",
    "#################################################################\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Point:\n",
    "    \"\"\" Class for storing a point x,y coordinate \"\"\"\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "    def __add__(self, other: Point):\n",
    "        return Point(self.x + other.x, self.y + other.y)\n",
    "\n",
    "    def __mul__(self, other: Point):\n",
    "        \"\"\" (x, y) * (a, b) = (xa, yb) \"\"\"\n",
    "        return Point(self.x * other.x, self.y * other.y)\n",
    "\n",
    "    def __sub__(self, other: Point):\n",
    "        return self + Point(-other.x, -other.y)\n",
    "\n",
    "    def yield_neighbours(self, include_diagonals=True, include_self=False):\n",
    "        \"\"\" Generator to yield neighbouring Points \"\"\"\n",
    "\n",
    "        deltas: list\n",
    "        if not include_diagonals:\n",
    "            deltas = [vector.value for vector in Vectors if abs(vector.value[0]) != abs(vector.value[1])]\n",
    "        else:\n",
    "            deltas = [vector.value for vector in Vectors]\n",
    "\n",
    "        if include_self:\n",
    "            deltas.append((0, 0))\n",
    "\n",
    "        for delta in deltas:\n",
    "            yield Point(self.x + delta[0], self.y + delta[1])\n",
    "\n",
    "    def neighbours(self, include_diagonals=True, include_self=False) -> list[Point]:\n",
    "        \"\"\" Return all the neighbours, with specified constraints.\n",
    "        It wraps the generator with a list. \"\"\"\n",
    "        return list(self.yield_neighbours(include_diagonals, include_self))\n",
    "\n",
    "    def get_specific_neighbours(self, directions: list[Vectors]) -> list[Point]:\n",
    "        \"\"\" Get neighbours, given a specific list of allowed locations \"\"\"\n",
    "        return [(self + Point(*vector.value)) for vector in list(directions)]\n",
    "\n",
    "    @staticmethod\n",
    "    def manhattan_distance(a_point: Point) -> int:\n",
    "        \"\"\" Return the Manhattan distance value of this vector \"\"\"\n",
    "        return sum(abs(coord) for coord in asdict(a_point).values())\n",
    "\n",
    "    def manhattan_distance_from(self, other: Point) -> int:\n",
    "        \"\"\" Manhattan distance between this Vector and another Vector \"\"\"\n",
    "        diff = self-other\n",
    "        return Point.manhattan_distance(diff)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"P({self.x},{self.y})\"\n",
    "\n",
    "class Vectors(Enum):\n",
    "    \"\"\" Enumeration of 8 directions.\n",
    "    Note: y axis increments in the North direction, i.e. N = (0, 1) \"\"\"\n",
    "    N = (0, 1)\n",
    "    NE = (1, 1)\n",
    "    E = (1, 0)\n",
    "    SE = (1, -1)\n",
    "    S = (0, -1)\n",
    "    SW = (-1, -1)\n",
    "    W = (-1, 0)\n",
    "    NW = (-1, 1)\n",
    "\n",
    "    @property\n",
    "    def y_inverted(self):\n",
    "        \"\"\" Return vector, but with y-axis inverted. I.e. N = (0, -1) \"\"\"\n",
    "        x, y = self.value\n",
    "        return (x, -y)\n",
    "\n",
    "class VectorDicts():\n",
    "    \"\"\" Contains constants for Vectors \"\"\"\n",
    "    ARROWS = {\n",
    "        '^': Vectors.N.value,\n",
    "        '>': Vectors.E.value,\n",
    "        'v': Vectors.S.value,\n",
    "        '<': Vectors.W.value\n",
    "    }\n",
    "\n",
    "    DIRS = {\n",
    "        'U': Vectors.N.value,\n",
    "        'R': Vectors.E.value,\n",
    "        'D': Vectors.S.value,\n",
    "        'L': Vectors.W.value\n",
    "    }\n",
    "\n",
    "    NINE_BOX: dict[str, tuple[int, int]] = {\n",
    "        # x, y vector for adjacent locations\n",
    "        'tr': (1, 1),\n",
    "        'mr': (1, 0),\n",
    "        'br': (1, -1),\n",
    "        'bm': (0, -1),\n",
    "        'bl': (-1, -1),\n",
    "        'ml': (-1, 0),\n",
    "        'tl': (-1, 1),\n",
    "        'tm': (0, 1)\n",
    "    }\n",
    "\n",
    "class Grid():\n",
    "    \"\"\" 2D grid of point values. \"\"\"\n",
    "    def __init__(self, grid_array: list) -> None:\n",
    "        self._array = grid_array\n",
    "        self._width = len(self._array[0])\n",
    "        self._height = len(self._array)\n",
    "\n",
    "    def value_at_point(self, point: Point) -> int:\n",
    "        \"\"\" The value at this point \"\"\"\n",
    "        return self._array[point.y][point.x]\n",
    "\n",
    "    def set_value_at_point(self, point: Point, value: int):\n",
    "        self._array[point.y][point.x] = value\n",
    "\n",
    "    def valid_location(self, point: Point) -> bool:\n",
    "        \"\"\" Check if a location is within the grid \"\"\"\n",
    "        if (0 <= point.x < self._width and  0 <= point.y < self._height):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def width(self):\n",
    "        \"\"\" Array width (cols) \"\"\"\n",
    "        return self._width\n",
    "\n",
    "    @property\n",
    "    def height(self):\n",
    "        \"\"\" Array height (rows) \"\"\"\n",
    "        return self._height\n",
    "\n",
    "    def all_points(self) -> list[Point]:\n",
    "        points = [Point(x, y) for x in range(self.width) for y in range(self.height)]\n",
    "        return points\n",
    "\n",
    "    def rows_as_str(self):\n",
    "        \"\"\" Return the grid \"\"\"\n",
    "        return [\"\".join(str(char) for char in row) for row in self._array]\n",
    "\n",
    "    def cols_as_str(self):\n",
    "        \"\"\" Render columns as str. Returns: list of str \"\"\"\n",
    "        cols_list = list(zip(*self._array))\n",
    "        return [\"\".join(str(char) for char in col) for col in cols_list]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Grid(size={self.width}*{self.height})\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"\\n\".join(\"\".join(map(str, row)) for row in self._array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xNijk6xbCVa"
   },
   "source": [
    "### Useful Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DT5FSYliC9wp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# CONSOLE STUFF\n",
    "#################################################################\n",
    "\n",
    "def cls():\n",
    "    \"\"\" Clear console \"\"\"\n",
    "    os.system('cls' if os.name=='nt' else 'clear')\n",
    "\n",
    "#################################################################\n",
    "# USEFUL FUNCTIONS\n",
    "#################################################################\n",
    "\n",
    "def binary_search(target, low:int, high:int, func, *func_args, reverse_search=False):\n",
    "    \"\"\" Generic binary search function that takes a target to find,\n",
    "    low and high values to start with, and a function to run, plus its args.\n",
    "    Implicitly returns None if the search is exceeded. \"\"\"\n",
    "\n",
    "    res = None  # just set it to something that isn't the target\n",
    "    candidate = 0  # initialise; we'll set it to the mid point in a second\n",
    "\n",
    "    while low < high:  # search exceeded\n",
    "        candidate = int((low+high) // 2)  # pick mid-point of our low and high\n",
    "        res = func(candidate, *func_args) # run our function, whatever it is\n",
    "        logger.debug(\"%d -> %d\", candidate, res)\n",
    "        if res == target:\n",
    "            return candidate  # solution found\n",
    "\n",
    "        comp = operator.lt if not reverse_search else operator.gt\n",
    "        if comp(res, target):\n",
    "            low = candidate\n",
    "        else:\n",
    "            high = candidate\n",
    "\n",
    "def merge_intervals(intervals: list[list]) -> list[list]:\n",
    "    \"\"\" Takes intervals in the form [[a, b][c, d][d, e]...]\n",
    "    Intervals can overlap.  Compresses to minimum number of non-overlapping intervals. \"\"\"\n",
    "    intervals.sort()\n",
    "    stack = []\n",
    "    stack.append(intervals[0])\n",
    "\n",
    "    for interval in intervals[1:]:\n",
    "        # Check for overlapping interval\n",
    "        if stack[-1][0] <= interval[0] <= stack[-1][-1]:\n",
    "            stack[-1][-1] = max(stack[-1][-1], interval[-1])\n",
    "        else:\n",
    "            stack.append(interval)\n",
    "\n",
    "    return stack\n",
    "\n",
    "@cache\n",
    "def get_factors(num: int) -> set[int]:\n",
    "    \"\"\" Gets the factors for a given number. Returns a set[int] of factors.\n",
    "        # E.g. when num=8, factors will be 1, 2, 4, 8 \"\"\"\n",
    "    factors = set()\n",
    "\n",
    "    # Iterate from 1 to sqrt of 8,\n",
    "    # since a larger factor of num must be a multiple of a smaller factor already checked\n",
    "    for i in range(1, int(num**0.5) + 1):  # e.g. with num=8, this is range(1, 3)\n",
    "        if num % i == 0: # if it is a factor, then dividing num by it will yield no remainder\n",
    "            factors.add(i)  # e.g. 1, 2\n",
    "            factors.add(num//i)  # i.e. 8//1 = 8, 8//2 = 4\n",
    "\n",
    "    return factors\n",
    "\n",
    "def to_base_n(number: int, base: int):\n",
    "    \"\"\" Convert any integer number into a base-n string representation of that number.\n",
    "    E.g. to_base_n(38, 5) = 123\n",
    "\n",
    "    Args:\n",
    "        number (int): The number to convert\n",
    "        base (int): The base to apply\n",
    "\n",
    "    Returns:\n",
    "        [str]: The string representation of the number\n",
    "    \"\"\"\n",
    "    ret_str = \"\"\n",
    "    curr_num = number\n",
    "    while curr_num:\n",
    "        ret_str = str(curr_num % base) + ret_str\n",
    "        curr_num //= base\n",
    "\n",
    "    return ret_str if number > 0 else \"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YtEtBnfNUKw"
   },
   "source": [
    "### Generic Initialisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbdA-geUNqAF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "FOLDER = \"aoc\"\n",
    "YEAR = 2017\n",
    "logger_identifier = \"aoc\" + str(YEAR)\n",
    "logger = retrieve_console_logger(logger_identifier)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y68fv1BebLsG"
   },
   "source": [
    "# Days\n",
    "\n",
    "Here you'll find a template to build a solution for a given day, and then the solutions for all days in this event.\n",
    "\n",
    "To copy the template day, select all the cells in the `Day n` template, add a new cell at the end, and then paste the cells there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZvWwxmJbGbD"
   },
   "source": [
    "## Day n: title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGKQZAMNKA8M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = \"n\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8k00bAJR7vCX"
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = f.read().splitlines()\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", top_and_tail(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0tvEzJYxD6r"
   },
   "source": [
    "### Day n Part 1\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yq4_ffMZ75iq"
   },
   "outputs": [],
   "source": [
    "def solve(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeazYTD0xS2C"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(solve(\"abcdef\"), \"uvwxyz\") # test with sample data\n",
    "soln = solve(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG210YZNxPO5"
   },
   "source": [
    "### Day n Part 2\n",
    "\n",
    "Overview..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGOtNVJ8xWHZ"
   },
   "outputs": [],
   "source": [
    "def solve(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuLYqDZX76u4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(solve(\"abcdef\"), \"uvwxyz\") # test with sample data\n",
    "soln = solve(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FT4HLZLwevr"
   },
   "source": [
    "## Day 1: Inverse Captcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VoMC3MaJ1I9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = 1\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNvM0hOF0tBR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.INFO)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = f.read().strip()\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", top_and_tail(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAh6_AWRbYPo"
   },
   "source": [
    "### Day 1 Part 1\n",
    "\n",
    "The time is 25ms to midnight, and we're inside the computer that prints the _Naughty or Nice_ list! Each day in this year's challenge brings us 1ms closer to midnight.\n",
    "\n",
    "Today, we have to solve a Captcha to prove that we're _not_ human.\n",
    "\n",
    "Sum all digits that match the next digit in a circular list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omfr-hKq_Kyq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sum_match_digits(data, offset: int) -> int:\n",
    "    circular_digits = data + data\n",
    "    logger.debug(circular_digits)\n",
    "    total = 0\n",
    "    for i in range(len(data)):\n",
    "        if circular_digits[i] == circular_digits[i+offset]:\n",
    "            total += int(circular_digits[i])\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhWomZ6ewNi-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def part1(data) -> int:\n",
    "    return sum_match_digits(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uw4xFe7R7jf0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part1(\"91212129\"), 9) # test with sample data\n",
    "soln = part1(input_data)\n",
    "logger.info(\"Part 1: total=%d\", soln)\n",
    "# logger.info(\"Execution time: %.3f seconds\", t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6ARzwH_AHU0"
   },
   "source": [
    "### Day 1 Part 2\n",
    "\n",
    "Sum all the digits that match a digit that is exactly halfway along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uju3nPBKx9RW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def part2(data) -> int:\n",
    "    half = len(data)//2\n",
    "    logger.debug(\"Half=%s\", half)\n",
    "    return sum_match_digits(data, half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcJdRHyK8TRY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part2(\"12131415\"), 4)\n",
    "soln = part2(input_data)\n",
    "logger.info(\"Part 2: total=%d\", soln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poXq9ao40tAm"
   },
   "source": [
    "## Day 2: Corruption Checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONNCiHUsJY98",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = 2\n",
    "day_link = f\"See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yN5DrfkD3nVL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.INFO)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = f.read().splitlines()\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", top_and_tail(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjXkDtXs0tBS"
   },
   "source": [
    "### Day 2 Part 1\n",
    "\n",
    "We neeed to calculate the spreadsheet's checksum.\n",
    "\n",
    "For each row, determine the difference between the largest value and the smallest value; the checksum is the sum of all of these differences.\n",
    "\n",
    "The input data is multiple lines.  The data can be split by either space or tab. I'll use regex to split on either. This returns a list of str values for each row.  Then I'll map these str values to int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "854PR2kB0tBS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def part1(data) -> int:\n",
    "    \"\"\" Process each line. Get the largest and smallest int values from each line.\n",
    "    Determine the difference.\n",
    "    Sum the differences to give the checksum. \"\"\"\n",
    "\n",
    "    checksum = 0\n",
    "    for row in data:\n",
    "        vals = list(map(int, re.split(r'[\\t ]+', row))) # split on either tab or space\n",
    "        checksum += max(vals) - min(vals)\n",
    "\n",
    "    return checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbN7qjTS0tBT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part1(\"\"\"5 1 9 5\n",
    "7 5 3\n",
    "2 4 6 8\"\"\".splitlines()), 18) # test with sample data\n",
    "\n",
    "soln = part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AbGpopH0tBT"
   },
   "source": [
    "### Day 2 Part 2\n",
    "\n",
    "The new goal is to find the only two numbers in each row where one evenly divides the other - that is, where the result of the division operation is a whole number. They would like you to find those numbers on each line, divide them, and add up each line's result.\n",
    "\n",
    "Here I use `itertools.combinations` to return pairs of numbers from each row.\n",
    "\n",
    "E.g.\n",
    "[5, 9, 2, 8] -> (5, 9) (5, 2) (5, 8) (9, 2) (9, 8) (2, 8)\n",
    "\n",
    "Note that reverse pairs are not included in `combinations`. If you want reverse pairs, use `permutations` instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkUzEQ-90tBT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def part2(data) -> int:\n",
    "    \"\"\" Process each line. Find the only two pairs of numbers where one is divisible by the other.\n",
    "    Perform the division.\n",
    "    Sum the quotients to give the checksum. \"\"\"\n",
    "\n",
    "    checksum = 0\n",
    "    for row in data:\n",
    "        vals = list(map(int, re.split(r'[\\t ]+', row))) # split on either tab or space\n",
    "        logger.debug(vals)\n",
    "        for num1, num2 in combinations(vals, 2): # get all pairs of numbers, in one direction only\n",
    "            if num1 % num2 == 0: # check if divisible\n",
    "                checksum += num1 // num2\n",
    "            elif num2 % num1 == 0: # check if divisible in opposite direction\n",
    "                checksum += num2 // num1\n",
    "\n",
    "    return checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOVJ3YH40tBU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part2(\"\"\"5 9 2 8\n",
    "9 4 7 3\n",
    "3 8 6 5\"\"\".splitlines()), 9) # test with sample data\n",
    "\n",
    "soln = part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYTo0doWGtij"
   },
   "source": [
    "## Day 3: Spiral Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhGyVz5bIzi4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = 3\n",
    "day_link = f\"See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DtijnUvGtij",
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.INFO)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = int(f.read())\n",
    "\n",
    "logger.info(\"Input data:\\n%d\", input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3 Part 1\n",
    "\n",
    "We're presented with a 2D grid of spiral numbers, like this:\n",
    "\n",
    "<pre>\n",
    " .   .   .   .   .   .   .\n",
    " .  17  16  15  14  13   .\n",
    " .  18   5   4   3  12   .\n",
    " .  19   6   <b>1</b>   <b>2</b>  11  28\n",
    " .  20   7   8   9  <b>10</b>  27\n",
    " .  21  22  23  24  25  <b>26</b>\n",
    " .   .   .   .   .   .   .\n",
    "</pre>\n",
    "\n",
    "Requested data can only be retrieved from square `1`, and programs can only move U, D, L, R. They always take the shortest path using Manhattan distance. I've also shown the location of the lowest value in each successive square.\n",
    "\n",
    "**How many steps are required to carry the data from the square identified in your puzzle input all the way to the access port?**\n",
    "\n",
    "#### Requirement\n",
    "\n",
    "- We need to determine the location of our input data.\n",
    "- Then determine Manhattan distance of this value to our `1` position.\n",
    "\n",
    "#### Options\n",
    "\n",
    "1. We could use a generator to allocate each successive value.\n",
    "2. We could determine the size of each successive square. And then determine the position of our data in that outermost square.\n",
    "\n",
    "I'm going to with option 2, as it should be pretty quick.\n",
    "\n",
    "#### Determine the Perimeter\n",
    "\n",
    "- Any given perimeter is given by: $p = 4(e-1)$, where e is the length of the edge. Or: $p = 4e-4$\n",
    "- The length of the edge is given by: $e = 2(r+1)-1 = 2r + 1$, where r is the current ring.\n",
    "- So, $p = 4(2r+1-1) = 8r$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perimeter(ring: int) -> int:\n",
    "    \"\"\" Return the total number of values in this particular ring.\n",
    "    I.e. successive squares have edges of length 1, 3, 5, 7, etc. But we won't count the starting square as a ring.\n",
    "    Perimeters will be 8, 16, 24, etc \"\"\"\n",
    "    return (8 * ring)\n",
    "\n",
    "def position(target: int, ring: int, ring_start: int) -> Point:\n",
    "    \"\"\" Determine the location of our target value in the grid.\n",
    "    Do this by starting in our lower right position, and then move one position at a time, until we reach our target.\n",
    "    Args:\n",
    "    - target = the value we need to know the position of\n",
    "    - ring = the current ring (where 1 is the centre, 2 is the second ring, etc)\n",
    "    - ring_start = the lowest value of this ring\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Looking for {target} in ring {ring}, which starts at {ring_start}\")\n",
    "\n",
    "    # the inclusive boundaries of our ring\n",
    "    x_max = y_max = 0 + ring\n",
    "    x_min = y_min = 0 - ring\n",
    "\n",
    "    curr_val = ring_start\n",
    "    curr_x = 0 + ring\n",
    "    curr_y = 0 + (ring-1)\n",
    "\n",
    "    if ring_start == target:\n",
    "        return Point(curr_x, curr_y)\n",
    "\n",
    "    assert curr_val < target and curr_x == x_max, \"We're on the right edge\"\n",
    "    \n",
    "    # move up until we can't go further\n",
    "    while curr_y > y_min:\n",
    "        curr_val += 1\n",
    "        curr_y -= 1\n",
    "\n",
    "        if curr_val == target:\n",
    "            return Point(curr_x, curr_y)\n",
    "\n",
    "    assert curr_val < target and curr_y == y_min, \"We're on the top row\"\n",
    "\n",
    "    # move left until we can't go further\n",
    "    while curr_x > x_min:\n",
    "        curr_val += 1\n",
    "        curr_x -= 1\n",
    "\n",
    "        if curr_val == target:\n",
    "            return Point(curr_x, curr_y)\n",
    "\n",
    "    assert curr_val < target and curr_x == x_min, \"We're on the left edge\"\n",
    "        \n",
    "    # move down until we can't go further\n",
    "    while curr_y < y_max:\n",
    "        curr_val += 1\n",
    "        curr_y += 1\n",
    "\n",
    "        if curr_val == target:\n",
    "            return Point(curr_x, curr_y)\n",
    "\n",
    "    assert curr_val < target and curr_y == y_max, \"We're on the bottom row\"\n",
    "\n",
    "    # move right until we can't go further\n",
    "    while curr_x < x_max:\n",
    "        curr_val += 1\n",
    "        curr_x += 1\n",
    "\n",
    "        if curr_val == target:\n",
    "            return Point(curr_x, curr_y)\n",
    "\n",
    "    assert False, \"We can't be here!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrLrWR9jGtij"
   },
   "outputs": [],
   "source": [
    "def part1(data: int) -> int:\n",
    "\n",
    "    # Get the ring where our data is\n",
    "    prev_highest = highest = 1 # we start with 1 at the center\n",
    "    ring = 0 \n",
    "    while highest <= data:\n",
    "        ring += 1\n",
    "        per = perimeter(ring)\n",
    "        prev_highest = highest\n",
    "        highest += per\n",
    "\n",
    "    # Now get the position of our data in the ring\n",
    "    data_point = position(data, ring, prev_highest+1)\n",
    "    logger.debug(f\"Our data is at {data_point}\")\n",
    "    dist = data_point.manhattan_distance_from(Point(0,0))\n",
    "    logger.debug(f\"Manhattan distance = {dist}\")\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3-5S0Z1Gtij"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part1(1024), 31) # test data\n",
    "soln = part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3 Part 2\n",
    "\n",
    "Darn, I should have gone with Option 1!!\n",
    "\n",
    "The puzzle has changed such that each value assigned is the sum of the adjacent values that have already been assigned. \n",
    "\n",
    "**What is the first value written that is larger than your puzzle input?**\n",
    "\n",
    "<pre>\n",
    "147  142  133  122   59\n",
    "304    5    4    2   57\n",
    "330   10    <b>1</b>    <b>1</b>   54\n",
    "351   11   23   25   <b>26</b>\n",
    "362  747    .    .    .\n",
    "</pre>\n",
    "\n",
    "So, we're going to have to generate each value succcessively.  The number we need to reach isn't very high, so this won't be a problem.\n",
    "\n",
    "This feels like a perfect time to use a NumPy array!\n",
    "\n",
    "- Create a generator that returns successive positions, spiralling out from the centre.\n",
    "- Guess at a starting size for a square array, and initialise it with zeroes.\n",
    "- Work out the middle of our array, and save this is a delta that we will add to EVERY\n",
    "  coordinate returned by our spiral generator. (Because our spiral generator will start with 0,0.)\n",
    "- Initialise our middle coordinate to 1.\n",
    "- Then simply use NumPy sum to calculate the sum of all adjacent locations. Remember that those we haven't filled yet will have a value of 0.\n",
    "- Add this calculated sum into the new location.\n",
    "\n",
    "Easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spiral_next_posn():\n",
    "    \"\"\"A generator that yields the next location in the spiral \"\"\"\n",
    "    curr_x = curr_y = 0\n",
    "    yield curr_x, curr_y # the origin\n",
    "\n",
    "    ring = 1\n",
    "    while True:\n",
    "        # the inclusive boundaries of our ring\n",
    "        x_max = y_max = 0 + ring\n",
    "        x_min = y_min = 0 - ring\n",
    "\n",
    "        # our lower right starting position in the new ring\n",
    "        curr_x = 0 + ring\n",
    "        curr_y = 0 + (ring-1)\n",
    "        yield curr_x, curr_y        \n",
    "        \n",
    "        while curr_y > y_min: # we're on the right edge\n",
    "            curr_y -= 1  # move up\n",
    "            yield curr_x, curr_y\n",
    "\n",
    "        while curr_x > x_min: # we're on the top edge\n",
    "            curr_x -= 1  # move left\n",
    "            yield curr_x, curr_y\n",
    "\n",
    "        while curr_y < y_max: # we've on the left edge\n",
    "            curr_y += 1  # move down\n",
    "            yield curr_x, curr_y\n",
    "\n",
    "        while curr_x < x_max: # we're on the bottom edge\n",
    "            curr_x += 1  # move right\n",
    "            yield curr_x, curr_y\n",
    "\n",
    "        ring += 1 # move to next ring and start again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pBkMNEhGtik"
   },
   "outputs": [],
   "source": [
    "def part2(data: int) -> int:\n",
    "    \"\"\" We want this to return the first value larger than our input \"\"\"\n",
    "    \n",
    "    size = 20\n",
    "    grid = np.zeros((size, size), dtype=np.int32)\n",
    "    \n",
    "    spiral_generator = spiral_next_posn()\n",
    "    # this returns 0,0\n",
    "    # but we want this to be the centre of our grid. So we'll add a delta\n",
    "    delta = size // 2\n",
    "    \n",
    "    x, y = next(spiral_generator) \n",
    "    x, y = x+delta, y+delta\n",
    "    curr_val = 1\n",
    "    grid[y, x] = curr_val # initialise the center\n",
    "    logger.debug(\"Posn 1: %d, %d has value %d\", x, y, curr_val)    \n",
    "\n",
    "    # now we continue around the spiral\n",
    "    for i, posn in enumerate(spiral_generator, start=2):\n",
    "        x, y = posn\n",
    "        x, y = x+delta, y+delta\n",
    "        assert x<size and y<size, \"No solution in grid of this size\"\n",
    "        \n",
    "        curr_val = int(grid[y-1:y+2, x-1:x+2].sum()) # Get the sum of all adjacent values\n",
    "        grid[y, x] = curr_val\n",
    "\n",
    "        logger.debug(f\"Posn %d: %d, %d has value %d\", i, x, y, curr_val)\n",
    "        if curr_val > data:\n",
    "            break\n",
    "\n",
    "    return curr_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHZ7Y15FGtik"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part2(142), 147) # assert that 147 comes after 142\n",
    "soln = part2(input_data)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZvWwxmJbGbD"
   },
   "source": [
    "## Day 4: High-Entropy Passphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGKQZAMNKA8M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = \"4\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8k00bAJR7vCX"
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = f.read().splitlines()\n",
    "\n",
    "logger.debug(\"Input data:\\n%s\", top_and_tail(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 4 Part 1\n",
    "\n",
    "- A passphrase consists of a series of words (lowercase letters) separated by spaces.\n",
    "- A valid passphrase must contain no duplicate words.\n",
    "\n",
    "E.g.\n",
    "- `aa bb cc dd ee` is valid.\n",
    "- `aa bb cc dd aa` is not valid - the word aa appears more than once.\n",
    "- `aa bb cc dd aaa` is valid - aa and aaa count as different words.\n",
    "\n",
    "The system's full passphrase list is available as our puzzle input. \n",
    "**How many passphrases are valid?**\n",
    "\n",
    "My solution is to use the [collections.Counter class](https://realpython.com/python-counter/). It is a subclass of dict, which takes any supplied sequence or iterable, and counts how many unique instances of a value occur. The resulting dict stores the unique objects as keys, and the count of each object as the value.\n",
    "\n",
    "So, I will:\n",
    "\n",
    "- Split each supplied phrase into words.\n",
    "- Count the words, using Counter.\n",
    "- Determine the `most_common()` word, which returns the `word: count` pair.\n",
    "- If the count is 1, then this phrase is valid.\n",
    "\n",
    "I'll put this all into a single line list comprehension, returning only those phrases that are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yq4_ffMZ75iq"
   },
   "outputs": [],
   "source": [
    "def part1(data):\n",
    "    valid_phrases = [phrase for phrase in data if Counter(phrase.split()).most_common()[0][1] == 1]\n",
    "    return len(valid_phrases)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeazYTD0xS2C"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part1([\"aa bb cc dd ee\", \"aa bb cc dd aa\", \"aa bb cc dd aaa\"]), 2) # test with sample data\n",
    "soln = part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG210YZNxPO5"
   },
   "source": [
    "### Day 4 Part 2\n",
    "\n",
    "Now, a valid passphrase must contain no two words that are anagrams of each other - that is, a passphrase is invalid if any word's letters can be rearranged to form any other word in the passphrase.\n",
    "\n",
    "Okay, the adaptation from Part 1 is pretty trivial. Let's just put each word into alphabetical order before counting.\n",
    "\n",
    "**Without allowing any words that are anagrams, how many passphrases are valid?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGOtNVJ8xWHZ"
   },
   "outputs": [],
   "source": [
    "def part2(data):\n",
    "    valid_phrases = []\n",
    "    for phrase in data:\n",
    "        # put each word into alphabetical order\n",
    "        canonical_words = [\"\".join(sorted(word)) for word in phrase.split()]\n",
    "        if Counter(canonical_words).most_common()[0][1] == 1: # check all our words only appear once\n",
    "            valid_phrases.append(phrase)\n",
    "\n",
    "    return len(valid_phrases)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuLYqDZX76u4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part2([\"abcde fghij\", # valid\n",
    "                \"abcde xyz ecdab\", # not valid\n",
    "                \"a ab abc abd abf abj\", # valid\n",
    "                \"iiii oiii ooii oooi oooo\", # valid\n",
    "                \"oiii ioii iioi iiio\" # not valid\n",
    "               ]), 3) # test with sample data\n",
    "soln = part2(input_data)\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZvWwxmJbGbD"
   },
   "source": [
    "## Day 5: A Maze of Twisty Trampolines, All Alike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGKQZAMNKA8M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = \"5\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8k00bAJR7vCX"
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = list(map(int, f.read().splitlines()))\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", top_and_tail(input_data, zero_indexed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0tvEzJYxD6r"
   },
   "source": [
    "### Day 5 Part 1\n",
    "\n",
    "We're given a list of CPU \"jump\" instructions. Our input is simply a list of jump offsets, i.e.offsets, so:\n",
    "\n",
    "- `-1` means jump to previous instruction\n",
    "- `0` means stay on this instruction\n",
    "- `1` means jump to the next instruction\n",
    "\n",
    "But, AFTER we execute an instruction, the offset of that particular instruction is incremented by `1`.  So, if we encounter a `0`, this would mean \"stay put\", but then this offset would be incremented to `1`. So now we would execute the jump again, but this time moving forward by `1`.\n",
    "\n",
    "**How many steps does it take to reach the exit?** I.e. to follow an instruction that takes us outside of the program.\n",
    "\n",
    "My solution:\n",
    "- Our program is a set of jump instructions, with each jump offset as an element in a list.\n",
    "- Store the current index position in the list as `ptr`\n",
    "- We start at `ptr = 0`\n",
    "- With each program instruction, retrieve the value in the list at elemenet `ptr`. Add this value to `ptr` to get the new index position.\n",
    "- If the new index position is outside of the list, then we've reached the end, so return the number of instructions executed.\n",
    "- If the new index is inside the list, then update the value of the previous list position by 1.\n",
    "\n",
    "**Caution**: Since we update the values inside the list, you need to pass a copy of the list to the function. Otherwise the original data is modified, and the function cannot be re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(data, part=1):\n",
    "    prev_ptr = 0\n",
    "    ptr = 0  # start at instruction 0\n",
    "    for step in count(1): # a great way to increment a counter in an infinite loop\n",
    "        ptr += data[ptr]  # move to offset requested\n",
    "        if 0 <= ptr < len(data):\n",
    "            if part == 2 and data[prev_ptr] >= 3: # Part 2 only\n",
    "                data[prev_ptr] -= 1\n",
    "            else:\n",
    "                data[prev_ptr] += 1  # increment value of previous instruction\n",
    "            prev_ptr = ptr\n",
    "        else:  # we've jumped out of the program\n",
    "            break\n",
    "\n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeazYTD0xS2C"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(solve([0, 3, 0, 1, -3]), 5) # test with sample data\n",
    "soln = solve(input_data.copy())\n",
    "logger.info(f\"Part 1 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG210YZNxPO5"
   },
   "source": [
    "### Day 5 Part 2\n",
    "\n",
    "Now, the jumps are even stranger: after each jump, if the offset was three or more, instead decrease it by 1. Otherwise, increase it by 1 as before.\n",
    "\n",
    "All I need to do is add an `if` condition, to such that if the value of the prev index was 3 or more, then decrement the value by 1.  Else, increment by 1 as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeazYTD0xS2C",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(solve([0, 3, 0, 1, -3], 2), 10) # test with sample data\n",
    "soln = solve(input_data.copy(), 2)\n",
    "logger.info(f\"Part 2 soln={soln}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZvWwxmJbGbD"
   },
   "source": [
    "## Day 6: Memory Reallocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGKQZAMNKA8M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = \"6\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8k00bAJR7vCX"
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = list(map(int, f.read().split()))\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", top_and_tail(input_data, zero_indexed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0tvEzJYxD6r"
   },
   "source": [
    "### Day 6 Part 1\n",
    "\n",
    "Intro:\n",
    "\n",
    "- We have 16 memory banks.\n",
    "- Each memory bank can hold any number of blocks.\n",
    "- Our _reallocation routine_ attempts to balance the blocks between the memory banks.\n",
    "- Each cycle:\n",
    "  - Find the bank with the most blocks (with ties won by lowest-numbered memory bank), and redisribute these blocks...\n",
    "  - By removing all the blocks from this bank, and then inserting one block in each successive bank (by index), wrapping as required.\n",
    "\n",
    "**How many redistribution cycles must be completed before a configuration is produced that has been seen before?**\n",
    "\n",
    "My solution:\n",
    "\n",
    "- Store each configuration we've seen before in a set.\n",
    "- Each config is converted to a tuple before adding to the set, because a tuple is a hashable type, whereas a list is not.  We need the element to be hashable, so that we can compare if we've seen this configuration before.\n",
    "- Now we run a loop that redistributes until we find a configuration we've seen before.\n",
    "- Redistribution works by:\n",
    "  - Locating the index with the most blocks and setting this index to 0.\n",
    "  - For the number of blocks retrieved, iterate over this many remaining elements and add one to the value of each. Use `%` operator to allow us to wrap back to the front of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yq4_ffMZ75iq"
   },
   "outputs": [],
   "source": [
    "def solve(data):\n",
    "    \"\"\" Return a tuple of:\n",
    "      - the number of steps required to reach a repeated config\n",
    "      - the config itself \"\"\"\n",
    "    current_config = data.copy() # we don't want to change input\n",
    "    banks = len(data)\n",
    "    \n",
    "    seen = set() # store configs we've seen before, as tuples\n",
    "    seen.add(tuple(data))\n",
    "\n",
    "    for step in count(1): # infinite count\n",
    "        most_blocks_idx, blocks = max(enumerate(current_config), key=lambda x: x[1])\n",
    "        current_config[most_blocks_idx] = 0 # reset this bank to zero\n",
    "\n",
    "        # increment circularly until no more blocks to redistribute\n",
    "        for i in range(blocks, ):\n",
    "            idx = (most_blocks_idx + i + 1) % banks\n",
    "            current_config[idx] += 1\n",
    "\n",
    "        config_as_tuple = tuple(current_config)\n",
    "        if config_as_tuple in seen:\n",
    "            break\n",
    "        else:\n",
    "            seen.add(config_as_tuple)\n",
    "\n",
    "        if step == 100000: # just in case!\n",
    "            break\n",
    "\n",
    "    return step, current_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeazYTD0xS2C"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(solve([0, 2, 7, 0]), (5, [2, 4, 1, 2])) # test with sample data\n",
    "soln = solve(input_data)\n",
    "logger.info(f\"Part 1 soln={soln[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG210YZNxPO5"
   },
   "source": [
    "### Day 6 Part 2\n",
    "\n",
    "Now we want to know **the number of steps before we reach the same configuration again.  I.e. the overall size of the loop.**\n",
    "\n",
    "Easy!  Just re-run the same function, but passing in the configuration that achieved in Part 1 as input.  The function will then run until it hits the same configuration again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuLYqDZX76u4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(solve([2, 4, 1, 2]), (4, [2, 4, 1, 2])) # test with sample data\n",
    "soln = solve(soln[1])\n",
    "logger.info(f\"Part 2 soln={soln[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZvWwxmJbGbD"
   },
   "source": [
    "## Day 7: Recursive Circus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGKQZAMNKA8M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "DAY = \"7\" # replace with actual number (without leading digit)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "day_link = f\"#### See [Day {DAY}](https://adventofcode.com/{YEAR}/day/{DAY}).\"\n",
    "display(Markdown(day_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8k00bAJR7vCX"
   },
   "outputs": [],
   "source": [
    "d_name = \"d\" + str(DAY).zfill(2) # e.g. d01\n",
    "script_name = \"aoc\" + str(YEAR) + d_name # e.g. aoc2017d01\n",
    "locations = get_locations(d_name)\n",
    "\n",
    "# SETUP LOGGING\n",
    "logger.setLevel(logging.INFO)\n",
    "# td.setup_file_logging(logger, locations.output_dir)\n",
    "\n",
    "# Retrieve input and store in local file\n",
    "try:\n",
    "    write_puzzle_input_file(YEAR, DAY, locations)\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "\n",
    "with open(locations.input_file, mode=\"rt\") as f:\n",
    "    input_data = f.read().splitlines()\n",
    "\n",
    "logger.info(\"Input data:\\n%s\", top_and_tail(input_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0tvEzJYxD6r"
   },
   "source": [
    "### Day 7 Part 1\n",
    "\n",
    "We're told we have a recursive scenario:\n",
    "\n",
    "- We're visualising a huge tower, made up of:\n",
    "  - Programs that each sit under a disc.\n",
    "  - Each disc sits under one or more programs, which in turn have their own discs.\n",
    "  - The bottom of the tower is a single program with the first disc.\n",
    "  - At the tops of the top-most towers, there are programs with no discs. I.e. the leaf programs.\n",
    "- Each program has these attributes:\n",
    "  - Name\n",
    "  - Weight\n",
    "  - Collection of programs immediately above (if not a leaf program)\n",
    "\n",
    "Our source data is out of sequence.\n",
    "\n",
    "The sample data looks like this:\n",
    "\n",
    "```\n",
    "pbga (66)\n",
    "xhth (57)\n",
    "ebii (61)\n",
    "havc (66)\n",
    "ktlj (57)\n",
    "fwft (72) -> ktlj, cntj, xhth\n",
    "qoyq (66)\n",
    "padx (45) -> pbga, havc, qoyq\n",
    "tknk (41) -> ugml, padx, fwft\n",
    "jptl (61)\n",
    "ugml (68) -> gyxo, ebii, jptl\n",
    "gyxo (61)\n",
    "cntj (57)\n",
    "```\n",
    "\n",
    "And it represents this:\n",
    "```\n",
    "                gyxo\n",
    "              /     \n",
    "         ugml - ebii\n",
    "       /      \\     \n",
    "      |         jptl\n",
    "      |        \n",
    "      |         pbga\n",
    "     /        /\n",
    "tknk --- padx - havc\n",
    "     \\        \\\n",
    "      |         qoyq\n",
    "      |             \n",
    "      |         ktlj\n",
    "       \\      /     \n",
    "         fwft - cntj\n",
    "              \\     \n",
    "                xhth\n",
    "```\n",
    "\n",
    "**What is the name of the bottom program?**\n",
    "\n",
    "Solution:\n",
    "\n",
    "This seems like a good candidate for building a networkx graph.\n",
    "\n",
    "- Create a `Prog` dataclass to store each program, along with any children it has.\n",
    "- Then map the children, by splitting the input data at the \"->\"\n",
    "- Now we build a **directed graph**, i.e. a graph with direction. We do this by adding edge program as a node, and for any nodes that have children, add an edge back to the parent node.\n",
    "- The bottom program is the root node of our graph. We can networkx allows us to determine the number of incoming edges for each node in our directed graph.  The root node will be the only node that has 0 incoming edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Prog:\n",
    "    \"\"\" A Prog has a weight, and optionally has children of type Prog \"\"\"\n",
    "    name: str\n",
    "    weight: int\n",
    "    children: list[str] = field(default_factory=list) # default to empty list\n",
    "\n",
    "    def add_child(self, child: str):\n",
    "        \"\"\" Add a child program name for this Program \"\"\"\n",
    "        self.children.append(child)\n",
    "\n",
    "def parse_input(data) -> dict[str, Prog]:\n",
    "    \"\"\" Take input lines, and convert to a list of Program objects.\n",
    "    We're parsing lines that look like: fwft (72) -> ktlj, cntj, xhth\n",
    "    \"\"\"\n",
    "    # Note that the last group is optional. If absent, it will not be present in the match object\n",
    "    pattern = re.compile(r'(?P<name>\\w+) \\((?P<weight>\\d+)\\)(?: -> (?P<children>[\\w, ]+))?')\n",
    "    progs = {} # key = name, value = Prog\n",
    "    for line in data:\n",
    "        match = pattern.match(line)\n",
    "        assert match, f\"Bad input data in line {line}\"\n",
    "\n",
    "        name = match.group('name')\n",
    "        weight = int(match.group('weight'))\n",
    "        children = match.group('children')\n",
    "        if children:\n",
    "            children = [child.strip() for child in children.split(',')]\n",
    "        else:\n",
    "            children = []\n",
    "        \n",
    "        progs[name] = Prog(name, weight, children)\n",
    "        \n",
    "    return progs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(graph: nx.DiGraph, root):\n",
    "    distances_from_root = nx.single_source_shortest_path_length(graph, root)\n",
    "\n",
    "    # Create shells based on distances from the root\n",
    "    max_dist = max(distances_from_root.values())\n",
    "    shells = [[] for _ in range(max_dist + 1)]\n",
    "    for node, dist in distances_from_root.items():\n",
    "        shells[dist].append(node)\n",
    "   \n",
    "    # Generate positions using shell_layout\n",
    "    pos = nx.shell_layout(graph, shells)\n",
    "    \n",
    "    # Draw all nodes, then labels, then edges, then weights\n",
    "    nx.draw_networkx_nodes(graph, pos, node_color=\"green\")\n",
    "    nx.draw_networkx_labels(graph, pos, font_size=11)\n",
    "    nx.draw_networkx_edges(graph, pos, edge_color=\"green\", width=0.5)\n",
    "    nx.draw_networkx_edge_labels(graph, pos, \n",
    "                                 nx.get_edge_attributes(graph, \"distance\"),\n",
    "                                 font_size=8)\n",
    "    \n",
    "    # nx.draw(graph, pos=pos, edge_color=\"grey\", width=1, with_labels=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yq4_ffMZ75iq"
   },
   "outputs": [],
   "source": [
    "def part1(data):\n",
    "    \"\"\" Return the root node, and the dict of Progs \"\"\"\n",
    "    progs = parse_input(data)\n",
    "    logger.debug(\"\\n\" + \"\\n\".join(str(prog) for prog in progs.values()))\n",
    "    \n",
    "    graph = nx.DiGraph()\n",
    "    for name, prog in progs.items():\n",
    "        graph.add_node(name)\n",
    "        for child_name in prog.children:\n",
    "            graph.add_node(child_name)\n",
    "            graph.add_edge(name, child_name, distance=progs[child_name].weight)\n",
    "    \n",
    "    # determine the number of incoming edges for each node\n",
    "    nodes = [(node, in_degree) for node, in_degree in graph.in_degree()]\n",
    "    \n",
    "    # Get the node with no incoming edges. This is our root.\n",
    "    root = next(node for node, in_degree in nodes if in_degree == 0)\n",
    "\n",
    "    draw_graph(graph, root)\n",
    "    return root, progs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeazYTD0xS2C"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sample_data = [\n",
    "    \"pbga (66)\",\n",
    "    \"xhth (57)\",\n",
    "    \"ebii (61)\",\n",
    "    \"havc (66)\",\n",
    "    \"ktlj (57)\",\n",
    "    \"fwft (72) -> ktlj, cntj, xhth\",\n",
    "    \"qoyq (66)\",\n",
    "    \"padx (45) -> pbga, havc, qoyq\",\n",
    "    \"tknk (41) -> ugml, padx, fwft\",\n",
    "    \"jptl (61)\",\n",
    "    \"ugml (68) -> gyxo, ebii, jptl\",\n",
    "    \"gyxo (61)\",\n",
    "    \"cntj (57)\"\n",
    "]\n",
    "\n",
    "sample_solution = part1(sample_data)\n",
    "validate(sample_solution[0], \"tknk\") # test with sample data\n",
    "soln = part1(input_data)\n",
    "logger.info(f\"Part 1 soln={soln[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG210YZNxPO5"
   },
   "source": [
    "### Day 7 Part 2\n",
    "\n",
    "Sad times. It looks like I can't avoid the recursion!\n",
    "\n",
    "We're told that each path to a leaf needs to have the same weight. One of the paths will have a different weight, which means we need to adjust the weight of one of the programs.\n",
    "\n",
    "**Given that exactly one program is the wrong weight, what would its weight need to be to balance the entire tower?**\n",
    "\n",
    "Solution:\n",
    "\n",
    "- Create a recursive function that calculates the total weight from a given node. It works by adding the weight of this node to the recursive weight of all children.\n",
    "- That would be sufficient if we only needed the weight of the entire tower. But we need to determine the first tower that is out of balance, and to do this, we need to calculate the total weight at each level.  To do this, use a defaultdict(list) to store a list of (name, recursive weight) for each first-level child at this level.\n",
    "- Then we need to determine if any of these first-level weights are different. We're told that if any weight is different from the others at this level, then this tower is out of balance. Furthermore, the first level that is out of balance on the way back will be out of balance as a result of one program in that particular tower.\n",
    "- So, for the inbalanced tower, determine the two weights: the weight of the outlier, and the correct weight.\n",
    "- Determine which child program corresponds to the recursive outlier weight.\n",
    "- Determine the difference between correct weight and outlier weight, and add this to the weight of our identified child node. This gives us our new required weight.\n",
    "- Return the new required weight; and, once we've found the required weight, simply return it all the way up the recursion stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGOtNVJ8xWHZ"
   },
   "outputs": [],
   "source": [
    "def part2(progs: dict[str, Prog], node_name: str, level: int = 0, stop_on_inbalance=True) -> tuple[int, int]:\n",
    "    \"\"\" Determines the recursive total weight for this program and all children.\n",
    "    Also determine the desired new weight for the single program that is out of balance.\n",
    "\n",
    "    Args:\n",
    "        progs (dict[str, Prog]): the dict of programs.\n",
    "        node_name (str): the root node we want to recurse for.\n",
    "        level (int, optional): the current level, relative to original root supplied. Defaults to 0.\n",
    "        stop_on_inbalance (boolean): Whether to exit the function once we identify the inbalance.\n",
    "                                     Defaults to True. If false, we will complete the weight recursion.\n",
    "\n",
    "    Returns:\n",
    "        _type_: (total weight, new weight for program)\n",
    "    \"\"\"\n",
    "    curr_node = progs[node_name]\n",
    "    \n",
    "    level_weights = defaultdict(list) # Dictionary to store total weights of children at each level\n",
    "    \n",
    "    total_weight = curr_node.weight # initialise with weight of this prog\n",
    "    next_level = level+1\n",
    "    for child in curr_node.children: # and now recursively add the weight of all children\n",
    "        child_recursive_weight, new_weight = part2(progs, child, next_level)\n",
    "        \n",
    "        # if we've identified the outlier, we can quit the recursion now\n",
    "        if new_weight and stop_on_inbalance: \n",
    "            return child_recursive_weight, new_weight\n",
    "        \n",
    "        total_weight += child_recursive_weight # the recursive weight of this child\n",
    "        level_weights[next_level].append((child, child_recursive_weight))\n",
    "        \n",
    "    # Check if any child has a different weight\n",
    "    for lvl, recursive_weights in level_weights.items(): # current lvl, list of tuples\n",
    "        weight_counts: dict[int, list] = defaultdict(list) # store {weight, [name1, name2, etc]}\n",
    "        for child_name, recursive_weight in recursive_weights:\n",
    "            weight_counts[recursive_weight].append(child_name)\n",
    "            \n",
    "        if len(weight_counts) > 1:  # Different weights found, this tower is out of balance\n",
    "            logger.debug(f\"Level {lvl} has different weights: {recursive_weights}\")\n",
    "            \n",
    "            # Identifier the outlier\n",
    "            outlier_weight = correct_weight = 0\n",
    "            outlier_name = None\n",
    "            for weight, child_names in weight_counts.items():\n",
    "                if len(child_names) == 1: # this is the outlier\n",
    "                    outlier_weight = weight\n",
    "                    outlier_name = child_names[0]\n",
    "                else: # more than one name with this weight - these towers are correct\n",
    "                    correct_weight = weight    \n",
    "                    \n",
    "            assert outlier_weight and correct_weight, \"We should have determined two weights\"        \n",
    "            assert outlier_name, \"We should have identified the program with wrong weight\"\n",
    "            \n",
    "            logger.debug(f\"Prog to change={outlier_name}; current weight={progs[outlier_name].weight}\")\n",
    "            \n",
    "            # Calculate the new required weight for the outlier\n",
    "            new_weight = progs[outlier_name].weight + (correct_weight - outlier_weight)   \n",
    "            logger.debug(f\"Required new weight={new_weight}\")\n",
    "            return total_weight, new_weight\n",
    "                    \n",
    "    return total_weight, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuLYqDZX76u4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "validate(part2(sample_solution[1], sample_solution[0])[1], 60) # test with sample data\n",
    "weight = part2(soln[1], soln[0])[1]\n",
    "logger.info(f\"Part 2 soln={weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "aca_aoc",
   "language": "python",
   "name": "aca_aoc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
